OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-02 02:39:18.241000: I am training on qa-rtx6k-006.crc.nd.edu
2023-09-02 02:39:18.242247: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset123_Polyp/PolypTrainer__nnUNetPlans__2d/458806_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

model: Res2Network(
  (backbone): Res2Net(
    (conv1): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(64, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(256, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(512, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(1024, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (ca_1): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_1): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_2): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_2): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_3): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_3): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_4): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_4): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(2048, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv5): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
)
===========<class 'nnunetv2.training.network.model.dim2.res2net.res2unetv2.Res2Network'>============
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 22, 'patch_size': [352, 352], 'median_image_size_in_voxels': [352.0, 352.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'Res2UNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset123_Polyp', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 352, 352], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 194.9335479736328, 'median': 205.0, 'min': 0.0, 'percentile_00_5': 59.0, 'percentile_99_5': 255.0, 'std': 45.12168884277344}, '1': {'max': 255.0, 'mean': 118.9454574584961, 'median': 114.0, 'min': 0.0, 'percentile_00_5': 24.0, 'percentile_99_5': 250.0, 'std': 45.21835708618164}, '2': {'max': 255.0, 'mean': 85.0717544555664, 'median': 79.0, 'min': 0.0, 'percentile_00_5': 10.0, 'percentile_99_5': 238.0, 'std': 40.7197151184082}}} 

2023-09-02 02:39:28.194711: unpacking dataset...
2023-09-02 02:39:34.983237: unpacking done...
2023-09-02 02:39:34.984714: do_dummy_2d_data_aug: False
2023-09-02 02:39:35.003053: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset123_Polyp/splits_final.json
2023-09-02 02:39:35.004093: The split file contains 1 splits.
2023-09-02 02:39:35.004467: Desired fold for training: 0
2023-09-02 02:39:35.004894: This split has 1450 training and 798 validation cases.
==================batch size: 22==================
2023-09-02 02:39:35.033412: Unable to plot network architecture:
2023-09-02 02:39:35.033805: No module named 'hiddenlayer'
===================debug: False===================
2023-09-02 02:39:37.214196: 
2023-09-02 02:39:37.215673: Epoch 0
2023-09-02 02:39:37.216589: Current learning rate: backbone 0.001, others 0.001
2023-09-02 02:39:37.217466: start training, 250
================num of epochs: 250================
using pin_memory on device 0
2023-09-02 02:40:50.542522: finished training
epoch: 0, dataset: CVC-300, dice: 0.41892
CVC-300 :  0.41892
epoch: 0, dataset: CVC-ClinicDB, dice: 0.5225274193548386
CVC-ClinicDB :  0.5225274193548386
epoch: 0, dataset: Kvasir, dice: 0.641785
Kvasir :  0.641785
epoch: 0, dataset: CVC-ColonDB, dice: 0.3752707894736843
CVC-ColonDB :  0.3752707894736843
epoch: 0, dataset: ETIS-LaribPolypDB, dice: 0.34526530612244904
ETIS-LaribPolypDB :  0.34526530612244904
using pin_memory on device 0
2023-09-02 02:41:53.345869: train_loss 0.2059
2023-09-02 02:41:53.347542: val_loss -0.021
2023-09-02 02:41:53.349792: Pseudo dice [0.5077]
2023-09-02 02:41:53.350591: Epoch time: 136.13 s
2023-09-02 02:41:53.351233: Yayy! New best EMA pseudo Dice: 0.5077
2023-09-02 02:41:56.165949: 
2023-09-02 02:41:56.167405: Epoch 1
2023-09-02 02:41:56.168205: Current learning rate: backbone 0.000997, others 0.000997
2023-09-02 02:41:56.169582: start training, 250
================num of epochs: 250================
2023-09-02 02:42:54.978712: finished training
epoch: 1, dataset: CVC-300, dice: 0.8482666666666667
CVC-300 :  0.8482666666666667
epoch: 1, dataset: CVC-ClinicDB, dice: 0.7618806451612904
CVC-ClinicDB :  0.7618806451612904
epoch: 1, dataset: Kvasir, dice: 0.8402130000000001
Kvasir :  0.8402130000000001
epoch: 1, dataset: CVC-ColonDB, dice: 0.646632368421053
CVC-ColonDB :  0.646632368421053
epoch: 1, dataset: ETIS-LaribPolypDB, dice: 0.5655280612244897
ETIS-LaribPolypDB :  0.5655280612244897
2023-09-02 02:43:55.422425: train_loss -0.9375
2023-09-02 02:43:55.423621: val_loss -0.9165
2023-09-02 02:43:55.424562: Pseudo dice [0.7211]
2023-09-02 02:43:55.425247: Epoch time: 119.26 s
2023-09-02 02:43:55.425820: Yayy! New best EMA pseudo Dice: 0.5291
2023-09-02 02:43:58.195100: 
2023-09-02 02:43:58.196380: Epoch 2
2023-09-02 02:43:58.197380: Current learning rate: backbone 0.000994, others 0.000994
2023-09-02 02:43:58.198741: start training, 250
================num of epochs: 250================
2023-09-02 02:44:56.446074: finished training
epoch: 2, dataset: CVC-300, dice: 0.8435366666666667
CVC-300 :  0.8435366666666667
epoch: 2, dataset: CVC-ClinicDB, dice: 0.785772580645161
CVC-ClinicDB :  0.785772580645161
epoch: 2, dataset: Kvasir, dice: 0.7971180000000001
Kvasir :  0.7971180000000001
epoch: 2, dataset: CVC-ColonDB, dice: 0.5904586842105268
CVC-ColonDB :  0.5904586842105268
epoch: 2, dataset: ETIS-LaribPolypDB, dice: 0.5069448979591838
ETIS-LaribPolypDB :  0.5069448979591838
2023-09-02 02:45:51.966580: train_loss -1.2133
2023-09-02 02:45:51.967856: val_loss -1.0413
2023-09-02 02:45:51.968800: Pseudo dice [0.7947]
2023-09-02 02:45:51.969543: Epoch time: 113.77 s
2023-09-02 02:45:51.970167: Yayy! New best EMA pseudo Dice: 0.5556
2023-09-02 02:45:54.790904: 
2023-09-02 02:45:54.792164: Epoch 3
2023-09-02 02:45:54.792829: Current learning rate: backbone 0.000991, others 0.000991
2023-09-02 02:45:54.794042: start training, 250
================num of epochs: 250================
2023-09-02 02:46:53.306780: finished training
epoch: 3, dataset: CVC-300, dice: 0.8766299999999999
CVC-300 :  0.8766299999999999
epoch: 3, dataset: CVC-ClinicDB, dice: 0.8105403225806451
CVC-ClinicDB :  0.8105403225806451
epoch: 3, dataset: Kvasir, dice: 0.867865
Kvasir :  0.867865
epoch: 3, dataset: CVC-ColonDB, dice: 0.651601842105263
CVC-ColonDB :  0.651601842105263
epoch: 3, dataset: ETIS-LaribPolypDB, dice: 0.6006158163265306
ETIS-LaribPolypDB :  0.6006158163265306
2023-09-02 02:47:48.199717: train_loss -1.2564
2023-09-02 02:47:48.200857: val_loss -1.0531
2023-09-02 02:47:48.201897: Pseudo dice [0.8168]
2023-09-02 02:47:48.202651: Epoch time: 113.41 s
2023-09-02 02:47:48.203270: Yayy! New best EMA pseudo Dice: 0.5817
2023-09-02 02:47:50.976175: 
2023-09-02 02:47:50.977504: Epoch 4
2023-09-02 02:47:50.978325: Current learning rate: backbone 0.00098799, others 0.00098799
2023-09-02 02:47:50.979390: start training, 250
================num of epochs: 250================
2023-09-02 02:48:49.213146: finished training
epoch: 4, dataset: CVC-300, dice: 0.8092433333333334
CVC-300 :  0.8092433333333334
epoch: 4, dataset: CVC-ClinicDB, dice: 0.8031725806451612
CVC-ClinicDB :  0.8031725806451612
epoch: 4, dataset: Kvasir, dice: 0.8702529999999998
Kvasir :  0.8702529999999998
epoch: 4, dataset: CVC-ColonDB, dice: 0.6007578947368418
CVC-ColonDB :  0.6007578947368418
epoch: 4, dataset: ETIS-LaribPolypDB, dice: 0.5969938775510204
ETIS-LaribPolypDB :  0.5969938775510204
2023-09-02 02:49:44.119671: train_loss -1.2886
2023-09-02 02:49:44.120964: val_loss -0.9695
2023-09-02 02:49:44.121980: Pseudo dice [0.7693]
2023-09-02 02:49:44.122697: Epoch time: 113.15 s
2023-09-02 02:49:44.123181: Yayy! New best EMA pseudo Dice: 0.6005
2023-09-02 02:49:46.951531: 
2023-09-02 02:49:46.952732: Epoch 5
2023-09-02 02:49:46.953391: Current learning rate: backbone 0.00098499, others 0.00098499
2023-09-02 02:49:46.954425: start training, 250
================num of epochs: 250================
2023-09-02 02:50:44.831263: finished training
epoch: 5, dataset: CVC-300, dice: 0.8860549999999997
CVC-300 :  0.8860549999999997
epoch: 5, dataset: CVC-ClinicDB, dice: 0.7984451612903226
CVC-ClinicDB :  0.7984451612903226
epoch: 5, dataset: Kvasir, dice: 0.8794140000000001
Kvasir :  0.8794140000000001
epoch: 5, dataset: CVC-ColonDB, dice: 0.6658342105263161
CVC-ColonDB :  0.6658342105263161
epoch: 5, dataset: ETIS-LaribPolypDB, dice: 0.6569714285714284
ETIS-LaribPolypDB :  0.6569714285714284
2023-09-02 02:51:38.658352: train_loss -1.3103
2023-09-02 02:51:38.659480: val_loss -1.1275
2023-09-02 02:51:38.660355: Pseudo dice [0.8306]
2023-09-02 02:51:38.661015: Epoch time: 111.71 s
2023-09-02 02:51:38.661529: Yayy! New best EMA pseudo Dice: 0.6235
2023-09-02 02:51:41.446380: 
2023-09-02 02:51:41.447412: Epoch 6
2023-09-02 02:51:41.448052: Current learning rate: backbone 0.00098198, others 0.00098198
2023-09-02 02:51:41.449013: start training, 250
================num of epochs: 250================
2023-09-02 02:52:39.341283: finished training
epoch: 6, dataset: CVC-300, dice: 0.7904150000000001
CVC-300 :  0.7904150000000001
epoch: 6, dataset: CVC-ClinicDB, dice: 0.7941951612903227
CVC-ClinicDB :  0.7941951612903227
epoch: 6, dataset: Kvasir, dice: 0.8501320000000001
Kvasir :  0.8501320000000001
epoch: 6, dataset: CVC-ColonDB, dice: 0.6373663157894733
CVC-ColonDB :  0.6373663157894733
epoch: 6, dataset: ETIS-LaribPolypDB, dice: 0.6108642857142861
ETIS-LaribPolypDB :  0.6108642857142861
2023-09-02 02:53:34.737736: train_loss -1.3248
2023-09-02 02:53:34.738907: val_loss -1.0354
2023-09-02 02:53:34.739813: Pseudo dice [0.7958]
2023-09-02 02:53:34.740567: Epoch time: 113.29 s
2023-09-02 02:53:34.741228: Yayy! New best EMA pseudo Dice: 0.6407
2023-09-02 02:53:37.859922: 
2023-09-02 02:53:37.861567: Epoch 7
2023-09-02 02:53:37.862242: Current learning rate: backbone 0.00097898, others 0.00097898
2023-09-02 02:53:37.863177: start training, 250
================num of epochs: 250================
2023-09-02 02:54:35.785156: finished training
epoch: 7, dataset: CVC-300, dice: 0.8534599999999998
CVC-300 :  0.8534599999999998
epoch: 7, dataset: CVC-ClinicDB, dice: 0.790267741935484
CVC-ClinicDB :  0.790267741935484
epoch: 7, dataset: Kvasir, dice: 0.862449
Kvasir :  0.862449
epoch: 7, dataset: CVC-ColonDB, dice: 0.6760786842105269
CVC-ColonDB :  0.6760786842105269
epoch: 7, dataset: ETIS-LaribPolypDB, dice: 0.6172066326530615
ETIS-LaribPolypDB :  0.6172066326530615
2023-09-02 02:55:29.925294: train_loss -1.3342
2023-09-02 02:55:29.926492: val_loss -1.0741
2023-09-02 02:55:29.927476: Pseudo dice [0.8047]
2023-09-02 02:55:29.928199: Epoch time: 112.07 s
2023-09-02 02:55:29.928756: Yayy! New best EMA pseudo Dice: 0.6571
2023-09-02 02:55:32.740522: 
2023-09-02 02:55:32.741769: Epoch 8
2023-09-02 02:55:32.742526: Current learning rate: backbone 0.00097597, others 0.00097597
2023-09-02 02:55:32.743577: start training, 250
================num of epochs: 250================
2023-09-02 02:56:30.661644: finished training
epoch: 8, dataset: CVC-300, dice: 0.8720300000000002
CVC-300 :  0.8720300000000002
epoch: 8, dataset: CVC-ClinicDB, dice: 0.8084999999999999
CVC-ClinicDB :  0.8084999999999999
epoch: 8, dataset: Kvasir, dice: 0.86705
Kvasir :  0.86705
epoch: 8, dataset: CVC-ColonDB, dice: 0.6442355263157894
CVC-ColonDB :  0.6442355263157894
epoch: 8, dataset: ETIS-LaribPolypDB, dice: 0.6598535714285712
ETIS-LaribPolypDB :  0.6598535714285712
2023-09-02 02:57:25.243062: train_loss -1.3459
2023-09-02 02:57:25.244398: val_loss -0.9577
2023-09-02 02:57:25.245286: Pseudo dice [0.7703]
2023-09-02 02:57:25.245913: Epoch time: 112.5 s
2023-09-02 02:57:25.246741: Yayy! New best EMA pseudo Dice: 0.6685
2023-09-02 02:57:28.074541: 
2023-09-02 02:57:28.075773: Epoch 9
2023-09-02 02:57:28.076629: Current learning rate: backbone 0.00097296, others 0.00097296
2023-09-02 02:57:28.077625: start training, 250
================num of epochs: 250================
2023-09-02 02:58:25.964820: finished training
epoch: 9, dataset: CVC-300, dice: 0.8914783333333332
CVC-300 :  0.8914783333333332
epoch: 9, dataset: CVC-ClinicDB, dice: 0.7963209677419353
CVC-ClinicDB :  0.7963209677419353
epoch: 9, dataset: Kvasir, dice: 0.8664959999999998
Kvasir :  0.8664959999999998
epoch: 9, dataset: CVC-ColonDB, dice: 0.6516218421052631
CVC-ColonDB :  0.6516218421052631
epoch: 9, dataset: ETIS-LaribPolypDB, dice: 0.6972489795918374
ETIS-LaribPolypDB :  0.6972489795918374
2023-09-02 02:59:19.878419: train_loss -1.3563
2023-09-02 02:59:19.879706: val_loss -1.0392
2023-09-02 02:59:19.880614: Pseudo dice [0.7982]
2023-09-02 02:59:19.881296: Epoch time: 111.81 s
2023-09-02 02:59:21.456624: Yayy! New best EMA pseudo Dice: 0.6814
2023-09-02 02:59:24.473236: 
2023-09-02 02:59:24.474372: Epoch 10
2023-09-02 02:59:24.475041: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-02 02:59:24.475999: start training, 250
================num of epochs: 250================
2023-09-02 03:00:22.349696: finished training
epoch: 10, dataset: CVC-300, dice: 0.8444283333333336
CVC-300 :  0.8444283333333336
epoch: 10, dataset: CVC-ClinicDB, dice: 0.7974483870967743
CVC-ClinicDB :  0.7974483870967743
epoch: 10, dataset: Kvasir, dice: 0.8605359999999999
Kvasir :  0.8605359999999999
epoch: 10, dataset: CVC-ColonDB, dice: 0.6170697368421055
CVC-ColonDB :  0.6170697368421055
epoch: 10, dataset: ETIS-LaribPolypDB, dice: 0.5912596938775512
ETIS-LaribPolypDB :  0.5912596938775512
2023-09-02 03:01:16.467012: train_loss -1.3627
2023-09-02 03:01:16.468217: val_loss -1.0564
2023-09-02 03:01:16.469072: Pseudo dice [0.7997]
2023-09-02 03:01:16.469740: Epoch time: 112.0 s
2023-09-02 03:01:16.470360: Yayy! New best EMA pseudo Dice: 0.6933
2023-09-02 03:01:19.254703: 
2023-09-02 03:01:19.255851: Epoch 11
2023-09-02 03:01:19.256545: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-02 03:01:19.257560: start training, 250
================num of epochs: 250================
2023-09-02 03:02:17.206257: finished training
epoch: 11, dataset: CVC-300, dice: 0.6894083333333331
CVC-300 :  0.6894083333333331
epoch: 11, dataset: CVC-ClinicDB, dice: 0.8320096774193548
CVC-ClinicDB :  0.8320096774193548
epoch: 11, dataset: Kvasir, dice: 0.859482
Kvasir :  0.859482
epoch: 11, dataset: CVC-ColonDB, dice: 0.5881960526315788
CVC-ColonDB :  0.5881960526315788
epoch: 11, dataset: ETIS-LaribPolypDB, dice: 0.5914484693877553
ETIS-LaribPolypDB :  0.5914484693877553
2023-09-02 03:03:11.602232: train_loss -1.3625
2023-09-02 03:03:11.603387: val_loss -1.0674
2023-09-02 03:03:11.604482: Pseudo dice [0.8083]
2023-09-02 03:03:11.605123: Epoch time: 112.35 s
2023-09-02 03:03:11.605664: Yayy! New best EMA pseudo Dice: 0.7048
2023-09-02 03:03:14.384247: 
2023-09-02 03:03:14.385384: Epoch 12
2023-09-02 03:03:14.386057: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-02 03:03:14.387136: start training, 250
================num of epochs: 250================
2023-09-02 03:04:12.510337: finished training
epoch: 12, dataset: CVC-300, dice: 0.6427983333333331
CVC-300 :  0.6427983333333331
epoch: 12, dataset: CVC-ClinicDB, dice: 0.7775451612903226
CVC-ClinicDB :  0.7775451612903226
epoch: 12, dataset: Kvasir, dice: 0.841994
Kvasir :  0.841994
epoch: 12, dataset: CVC-ColonDB, dice: 0.5697502631578952
CVC-ColonDB :  0.5697502631578952
epoch: 12, dataset: ETIS-LaribPolypDB, dice: 0.46036989795918376
ETIS-LaribPolypDB :  0.46036989795918376
2023-09-02 03:05:07.192437: train_loss -1.3686
2023-09-02 03:05:07.193657: val_loss -1.0116
2023-09-02 03:05:07.194650: Pseudo dice [0.7795]
2023-09-02 03:05:07.195441: Epoch time: 112.81 s
2023-09-02 03:05:07.196048: Yayy! New best EMA pseudo Dice: 0.7122
2023-09-02 03:05:09.930253: 
2023-09-02 03:05:09.931494: Epoch 13
2023-09-02 03:05:09.932207: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-02 03:05:09.933332: start training, 250
================num of epochs: 250================
2023-09-02 03:06:07.831734: finished training
epoch: 13, dataset: CVC-300, dice: 0.7951999999999997
CVC-300 :  0.7951999999999997
epoch: 13, dataset: CVC-ClinicDB, dice: 0.8159016129032256
CVC-ClinicDB :  0.8159016129032256
epoch: 13, dataset: Kvasir, dice: 0.8730200000000002
Kvasir :  0.8730200000000002
epoch: 13, dataset: CVC-ColonDB, dice: 0.5993605263157893
CVC-ColonDB :  0.5993605263157893
epoch: 13, dataset: ETIS-LaribPolypDB, dice: 0.6338357142857143
ETIS-LaribPolypDB :  0.6338357142857143
2023-09-02 03:07:01.905488: train_loss -1.3654
2023-09-02 03:07:01.906738: val_loss -1.0374
2023-09-02 03:07:01.907658: Pseudo dice [0.8043]
2023-09-02 03:07:01.908343: Epoch time: 111.98 s
2023-09-02 03:07:01.908941: Yayy! New best EMA pseudo Dice: 0.7214
2023-09-02 03:07:04.745034: 
2023-09-02 03:07:04.746281: Epoch 14
2023-09-02 03:07:04.747033: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-02 03:07:04.748145: start training, 250
================num of epochs: 250================
2023-09-02 03:08:02.704831: finished training
epoch: 14, dataset: CVC-300, dice: 0.35029333333333335
CVC-300 :  0.35029333333333335
epoch: 14, dataset: CVC-ClinicDB, dice: 0.7736854838709674
CVC-ClinicDB :  0.7736854838709674
epoch: 14, dataset: Kvasir, dice: 0.7997640000000001
Kvasir :  0.7997640000000001
epoch: 14, dataset: CVC-ColonDB, dice: 0.39845921052631617
CVC-ColonDB :  0.39845921052631617
epoch: 14, dataset: ETIS-LaribPolypDB, dice: 0.4765494897959185
ETIS-LaribPolypDB :  0.4765494897959185
2023-09-02 03:08:56.868407: train_loss -1.3735
2023-09-02 03:08:56.869773: val_loss -1.0892
2023-09-02 03:08:56.870854: Pseudo dice [0.8245]
2023-09-02 03:08:56.871672: Epoch time: 112.12 s
2023-09-02 03:08:56.872339: Yayy! New best EMA pseudo Dice: 0.7317
2023-09-02 03:08:59.662345: 
2023-09-02 03:08:59.663606: Epoch 15
2023-09-02 03:08:59.664307: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-02 03:08:59.665445: start training, 250
================num of epochs: 250================
2023-09-02 03:09:57.730117: finished training
epoch: 15, dataset: CVC-300, dice: 0.8110316666666665
CVC-300 :  0.8110316666666665
epoch: 15, dataset: CVC-ClinicDB, dice: 0.8393193548387097
CVC-ClinicDB :  0.8393193548387097
epoch: 15, dataset: Kvasir, dice: 0.8843990000000004
Kvasir :  0.8843990000000004
epoch: 15, dataset: CVC-ColonDB, dice: 0.6742110526315791
CVC-ColonDB :  0.6742110526315791
epoch: 15, dataset: ETIS-LaribPolypDB, dice: 0.70737193877551
ETIS-LaribPolypDB :  0.70737193877551
2023-09-02 03:10:52.815739: train_loss -1.3845
2023-09-02 03:10:52.816962: val_loss -1.0485
2023-09-02 03:10:52.817892: Pseudo dice [0.8124]
2023-09-02 03:10:52.818610: Epoch time: 113.15 s
2023-09-02 03:10:52.819277: Yayy! New best EMA pseudo Dice: 0.7398
2023-09-02 03:10:55.694950: 
2023-09-02 03:10:55.696108: Epoch 16
2023-09-02 03:10:55.696911: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-02 03:10:55.698009: start training, 250
================num of epochs: 250================
2023-09-02 03:11:53.634653: finished training
epoch: 16, dataset: CVC-300, dice: 0.838775
CVC-300 :  0.838775
epoch: 16, dataset: CVC-ClinicDB, dice: 0.8248645161290323
CVC-ClinicDB :  0.8248645161290323
epoch: 16, dataset: Kvasir, dice: 0.8852139999999998
Kvasir :  0.8852139999999998
epoch: 16, dataset: CVC-ColonDB, dice: 0.6619905263157903
CVC-ColonDB :  0.6619905263157903
epoch: 16, dataset: ETIS-LaribPolypDB, dice: 0.7247760204081635
ETIS-LaribPolypDB :  0.7247760204081635
2023-09-02 03:12:48.019675: train_loss -1.3816
2023-09-02 03:12:48.020789: val_loss -1.0768
2023-09-02 03:12:48.021702: Pseudo dice [0.8167]
2023-09-02 03:12:48.022389: Epoch time: 112.33 s
2023-09-02 03:12:48.023004: Yayy! New best EMA pseudo Dice: 0.7475
2023-09-02 03:12:50.867071: 
2023-09-02 03:12:50.868204: Epoch 17
2023-09-02 03:12:50.869026: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-02 03:12:50.870111: start training, 250
================num of epochs: 250================
2023-09-02 03:13:48.791607: finished training
epoch: 17, dataset: CVC-300, dice: 0.4394583333333333
CVC-300 :  0.4394583333333333
epoch: 17, dataset: CVC-ClinicDB, dice: 0.7811903225806452
CVC-ClinicDB :  0.7811903225806452
epoch: 17, dataset: Kvasir, dice: 0.862038
Kvasir :  0.862038
epoch: 17, dataset: CVC-ColonDB, dice: 0.3720744736842106
CVC-ColonDB :  0.3720744736842106
epoch: 17, dataset: ETIS-LaribPolypDB, dice: 0.42459132653061227
ETIS-LaribPolypDB :  0.42459132653061227
2023-09-02 03:14:42.782479: train_loss -1.3922
2023-09-02 03:14:42.783722: val_loss -1.0623
2023-09-02 03:14:42.784613: Pseudo dice [0.8011]
2023-09-02 03:14:42.785383: Epoch time: 111.92 s
2023-09-02 03:14:42.785997: Yayy! New best EMA pseudo Dice: 0.7529
2023-09-02 03:14:45.593667: 
2023-09-02 03:14:45.594954: Epoch 18
2023-09-02 03:14:45.595713: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-02 03:14:45.596881: start training, 250
================num of epochs: 250================
2023-09-02 03:15:43.717831: finished training
epoch: 18, dataset: CVC-300, dice: 0.8554700000000001
CVC-300 :  0.8554700000000001
epoch: 18, dataset: CVC-ClinicDB, dice: 0.8545000000000001
CVC-ClinicDB :  0.8545000000000001
epoch: 18, dataset: Kvasir, dice: 0.863698
Kvasir :  0.863698
epoch: 18, dataset: CVC-ColonDB, dice: 0.7091771052631574
CVC-ColonDB :  0.7091771052631574
epoch: 18, dataset: ETIS-LaribPolypDB, dice: 0.7269576530612246
ETIS-LaribPolypDB :  0.7269576530612246
2023-09-02 03:16:38.328456: train_loss -1.3974
2023-09-02 03:16:38.329712: val_loss -1.081
2023-09-02 03:16:38.330831: Pseudo dice [0.8204]
2023-09-02 03:16:38.331581: Epoch time: 112.74 s
2023-09-02 03:16:38.332314: Yayy! New best EMA pseudo Dice: 0.7596
2023-09-02 03:16:41.142589: 
2023-09-02 03:16:41.143924: Epoch 19
2023-09-02 03:16:41.144688: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-02 03:16:41.145864: start training, 250
================num of epochs: 250================
2023-09-02 03:17:39.090865: finished training
epoch: 19, dataset: CVC-300, dice: 0.8614816666666667
CVC-300 :  0.8614816666666667
epoch: 19, dataset: CVC-ClinicDB, dice: 0.8252241935483873
CVC-ClinicDB :  0.8252241935483873
epoch: 19, dataset: Kvasir, dice: 0.8856529999999997
Kvasir :  0.8856529999999997
epoch: 19, dataset: CVC-ColonDB, dice: 0.6246426315789478
CVC-ColonDB :  0.6246426315789478
epoch: 19, dataset: ETIS-LaribPolypDB, dice: 0.6597362244897961
ETIS-LaribPolypDB :  0.6597362244897961
2023-09-02 03:18:32.996501: train_loss -1.396
2023-09-02 03:18:32.998082: val_loss -1.0745
2023-09-02 03:18:32.999295: Pseudo dice [0.8136]
2023-09-02 03:18:33.000220: Epoch time: 111.86 s
2023-09-02 03:18:34.585709: Yayy! New best EMA pseudo Dice: 0.765
2023-09-02 03:18:37.420949: 
2023-09-02 03:18:37.422163: Epoch 20
2023-09-02 03:18:37.422908: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-02 03:18:37.423990: start training, 250
================num of epochs: 250================
2023-09-02 03:19:35.331187: finished training
epoch: 20, dataset: CVC-300, dice: 0.803751666666667
CVC-300 :  0.803751666666667
epoch: 20, dataset: CVC-ClinicDB, dice: 0.8237209677419352
CVC-ClinicDB :  0.8237209677419352
epoch: 20, dataset: Kvasir, dice: 0.8714710000000001
Kvasir :  0.8714710000000001
epoch: 20, dataset: CVC-ColonDB, dice: 0.5600571052631584
CVC-ColonDB :  0.5600571052631584
epoch: 20, dataset: ETIS-LaribPolypDB, dice: 0.7115831632653059
ETIS-LaribPolypDB :  0.7115831632653059
2023-09-02 03:20:29.109189: train_loss -1.3969
2023-09-02 03:20:29.110535: val_loss -1.0629
2023-09-02 03:20:29.111575: Pseudo dice [0.8052]
2023-09-02 03:20:29.112361: Epoch time: 111.69 s
2023-09-02 03:20:29.113109: Yayy! New best EMA pseudo Dice: 0.769
2023-09-02 03:20:32.278323: 
2023-09-02 03:20:32.280042: Epoch 21
2023-09-02 03:20:32.281364: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-02 03:20:32.282959: start training, 250
================num of epochs: 250================
2023-09-02 03:21:30.175891: finished training
epoch: 21, dataset: CVC-300, dice: 0.8884600000000002
CVC-300 :  0.8884600000000002
epoch: 21, dataset: CVC-ClinicDB, dice: 0.8465435483870968
CVC-ClinicDB :  0.8465435483870968
epoch: 21, dataset: Kvasir, dice: 0.8715210000000003
Kvasir :  0.8715210000000003
epoch: 21, dataset: CVC-ColonDB, dice: 0.6734842105263161
CVC-ColonDB :  0.6734842105263161
epoch: 21, dataset: ETIS-LaribPolypDB, dice: 0.716170918367347
ETIS-LaribPolypDB :  0.716170918367347
2023-09-02 03:22:24.649224: train_loss -1.3912
2023-09-02 03:22:24.650618: val_loss -1.1156
2023-09-02 03:22:24.651700: Pseudo dice [0.8308]
2023-09-02 03:22:24.652486: Epoch time: 112.37 s
2023-09-02 03:22:24.653111: Yayy! New best EMA pseudo Dice: 0.7752
2023-09-02 03:22:27.441293: 
2023-09-02 03:22:27.442507: Epoch 22
2023-09-02 03:22:27.443274: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-02 03:22:27.444412: start training, 250
================num of epochs: 250================
2023-09-02 03:23:25.445910: finished training
epoch: 22, dataset: CVC-300, dice: 0.8353266666666669
CVC-300 :  0.8353266666666669
epoch: 22, dataset: CVC-ClinicDB, dice: 0.8389354838709677
CVC-ClinicDB :  0.8389354838709677
epoch: 22, dataset: Kvasir, dice: 0.8657050000000001
Kvasir :  0.8657050000000001
epoch: 22, dataset: CVC-ColonDB, dice: 0.6779815789473687
CVC-ColonDB :  0.6779815789473687
epoch: 22, dataset: ETIS-LaribPolypDB, dice: 0.6563918367346943
ETIS-LaribPolypDB :  0.6563918367346943
2023-09-02 03:24:19.567921: train_loss -1.4007
2023-09-02 03:24:19.569120: val_loss -1.095
2023-09-02 03:24:19.570330: Pseudo dice [0.8214]
2023-09-02 03:24:19.571206: Epoch time: 112.13 s
2023-09-02 03:24:19.572007: Yayy! New best EMA pseudo Dice: 0.7798
2023-09-02 03:24:22.400444: 
2023-09-02 03:24:22.401567: Epoch 23
2023-09-02 03:24:22.402325: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-02 03:24:22.403492: start training, 250
================num of epochs: 250================
2023-09-02 03:25:20.368212: finished training
epoch: 23, dataset: CVC-300, dice: 0.8420733333333332
CVC-300 :  0.8420733333333332
epoch: 23, dataset: CVC-ClinicDB, dice: 0.8519758064516129
CVC-ClinicDB :  0.8519758064516129
epoch: 23, dataset: Kvasir, dice: 0.8778800000000002
Kvasir :  0.8778800000000002
epoch: 23, dataset: CVC-ColonDB, dice: 0.6659015789473689
CVC-ColonDB :  0.6659015789473689
epoch: 23, dataset: ETIS-LaribPolypDB, dice: 0.7162102040816326
ETIS-LaribPolypDB :  0.7162102040816326
2023-09-02 03:26:14.432512: train_loss -1.4013
2023-09-02 03:26:14.433789: val_loss -0.9576
2023-09-02 03:26:14.434759: Pseudo dice [0.7608]
2023-09-02 03:26:14.435572: Epoch time: 112.03 s
2023-09-02 03:26:15.891323: 
2023-09-02 03:26:15.892698: Epoch 24
2023-09-02 03:26:15.893440: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-02 03:26:15.894569: start training, 250
================num of epochs: 250================
2023-09-02 03:27:13.820990: finished training
epoch: 24, dataset: CVC-300, dice: 0.83279
CVC-300 :  0.83279
epoch: 24, dataset: CVC-ClinicDB, dice: 0.8228048387096775
CVC-ClinicDB :  0.8228048387096775
epoch: 24, dataset: Kvasir, dice: 0.8616650000000001
Kvasir :  0.8616650000000001
epoch: 24, dataset: CVC-ColonDB, dice: 0.6485128947368433
CVC-ColonDB :  0.6485128947368433
epoch: 24, dataset: ETIS-LaribPolypDB, dice: 0.7263979591836736
ETIS-LaribPolypDB :  0.7263979591836736
2023-09-02 03:28:07.579434: train_loss -1.4052
2023-09-02 03:28:07.580694: val_loss -1.0815
2023-09-02 03:28:07.581779: Pseudo dice [0.8105]
2023-09-02 03:28:07.582580: Epoch time: 111.69 s
2023-09-02 03:28:07.583244: Yayy! New best EMA pseudo Dice: 0.7812
2023-09-02 03:28:10.411174: 
2023-09-02 03:28:10.412621: Epoch 25
2023-09-02 03:28:10.413423: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-02 03:28:10.414518: start training, 250
================num of epochs: 250================
2023-09-02 03:29:08.331380: finished training
epoch: 25, dataset: CVC-300, dice: 0.8376016666666666
CVC-300 :  0.8376016666666666
epoch: 25, dataset: CVC-ClinicDB, dice: 0.8428048387096776
CVC-ClinicDB :  0.8428048387096776
epoch: 25, dataset: Kvasir, dice: 0.8627060000000003
Kvasir :  0.8627060000000003
epoch: 25, dataset: CVC-ColonDB, dice: 0.6746171052631584
CVC-ColonDB :  0.6746171052631584
epoch: 25, dataset: ETIS-LaribPolypDB, dice: 0.7004959183673468
ETIS-LaribPolypDB :  0.7004959183673468
2023-09-02 03:30:02.487770: train_loss -1.4057
2023-09-02 03:30:02.489126: val_loss -0.9843
2023-09-02 03:30:02.490169: Pseudo dice [0.7966]
2023-09-02 03:30:02.490986: Epoch time: 112.08 s
2023-09-02 03:30:02.491672: Yayy! New best EMA pseudo Dice: 0.7827
2023-09-02 03:30:05.351382: 
2023-09-02 03:30:05.352609: Epoch 26
2023-09-02 03:30:05.353469: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-02 03:30:05.354596: start training, 250
================num of epochs: 250================
2023-09-02 03:31:03.321993: finished training
epoch: 26, dataset: CVC-300, dice: 0.8645249999999999
CVC-300 :  0.8645249999999999
epoch: 26, dataset: CVC-ClinicDB, dice: 0.8118048387096769
CVC-ClinicDB :  0.8118048387096769
epoch: 26, dataset: Kvasir, dice: 0.8727349999999996
Kvasir :  0.8727349999999996
epoch: 26, dataset: CVC-ColonDB, dice: 0.6628328947368423
CVC-ColonDB :  0.6628328947368423
epoch: 26, dataset: ETIS-LaribPolypDB, dice: 0.7273295918367348
ETIS-LaribPolypDB :  0.7273295918367348
2023-09-02 03:31:57.603022: train_loss -1.412
2023-09-02 03:31:57.604218: val_loss -1.059
2023-09-02 03:31:57.605268: Pseudo dice [0.8187]
2023-09-02 03:31:57.606163: Epoch time: 112.25 s
2023-09-02 03:31:57.606863: Yayy! New best EMA pseudo Dice: 0.7863
2023-09-02 03:32:00.685396: 
2023-09-02 03:32:00.686659: Epoch 27
2023-09-02 03:32:00.687454: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-02 03:32:00.688522: start training, 250
================num of epochs: 250================
2023-09-02 03:32:58.594378: finished training
epoch: 27, dataset: CVC-300, dice: 0.8566416666666666
CVC-300 :  0.8566416666666666
epoch: 27, dataset: CVC-ClinicDB, dice: 0.8236387096774191
CVC-ClinicDB :  0.8236387096774191
epoch: 27, dataset: Kvasir, dice: 0.8817559999999998
Kvasir :  0.8817559999999998
epoch: 27, dataset: CVC-ColonDB, dice: 0.6530889473684218
CVC-ColonDB :  0.6530889473684218
epoch: 27, dataset: ETIS-LaribPolypDB, dice: 0.7558107142857148
ETIS-LaribPolypDB :  0.7558107142857148
2023-09-02 03:33:53.087231: train_loss -1.4168
2023-09-02 03:33:53.088616: val_loss -1.059
2023-09-02 03:33:53.089631: Pseudo dice [0.8178]
2023-09-02 03:33:53.090515: Epoch time: 112.4 s
2023-09-02 03:33:53.091162: Yayy! New best EMA pseudo Dice: 0.7895
2023-09-02 03:33:55.962044: 
2023-09-02 03:33:55.963416: Epoch 28
2023-09-02 03:33:55.964201: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-02 03:33:55.965330: start training, 250
================num of epochs: 250================
2023-09-02 03:34:53.837301: finished training
epoch: 28, dataset: CVC-300, dice: 0.8530916666666662
CVC-300 :  0.8530916666666662
epoch: 28, dataset: CVC-ClinicDB, dice: 0.8228193548387096
CVC-ClinicDB :  0.8228193548387096
epoch: 28, dataset: Kvasir, dice: 0.8697290000000001
Kvasir :  0.8697290000000001
epoch: 28, dataset: CVC-ColonDB, dice: 0.6431952631578949
CVC-ColonDB :  0.6431952631578949
epoch: 28, dataset: ETIS-LaribPolypDB, dice: 0.7505545918367345
ETIS-LaribPolypDB :  0.7505545918367345
2023-09-02 03:35:48.239117: train_loss -1.4176
2023-09-02 03:35:48.240565: val_loss -1.0856
2023-09-02 03:35:48.241657: Pseudo dice [0.8215]
2023-09-02 03:35:48.242480: Epoch time: 112.28 s
2023-09-02 03:35:48.243158: Yayy! New best EMA pseudo Dice: 0.7927
2023-09-02 03:35:51.053796: 
2023-09-02 03:35:51.055074: Epoch 29
2023-09-02 03:35:51.055864: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-02 03:35:51.057002: start training, 250
================num of epochs: 250================
2023-09-02 03:36:48.965993: finished training
epoch: 29, dataset: CVC-300, dice: 0.8746616666666667
CVC-300 :  0.8746616666666667
epoch: 29, dataset: CVC-ClinicDB, dice: 0.844482258064516
CVC-ClinicDB :  0.844482258064516
epoch: 29, dataset: Kvasir, dice: 0.8917470000000002
Kvasir :  0.8917470000000002
epoch: 29, dataset: CVC-ColonDB, dice: 0.6666978947368424
CVC-ColonDB :  0.6666978947368424
epoch: 29, dataset: ETIS-LaribPolypDB, dice: 0.6809969387755105
ETIS-LaribPolypDB :  0.6809969387755105
2023-09-02 03:37:43.447979: train_loss -1.4129
2023-09-02 03:37:43.449249: val_loss -1.0937
2023-09-02 03:37:43.450240: Pseudo dice [0.8221]
2023-09-02 03:37:43.451141: Epoch time: 112.4 s
2023-09-02 03:37:45.107943: Yayy! New best EMA pseudo Dice: 0.7956
2023-09-02 03:37:48.249036: 
2023-09-02 03:37:48.250345: Epoch 30
2023-09-02 03:37:48.251085: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-02 03:37:48.252472: start training, 250
================num of epochs: 250================
2023-09-02 03:38:46.275538: finished training
epoch: 30, dataset: CVC-300, dice: 0.8474799999999999
CVC-300 :  0.8474799999999999
epoch: 30, dataset: CVC-ClinicDB, dice: 0.8187758064516125
CVC-ClinicDB :  0.8187758064516125
epoch: 30, dataset: Kvasir, dice: 0.8687850000000004
Kvasir :  0.8687850000000004
epoch: 30, dataset: CVC-ColonDB, dice: 0.6325884210526318
CVC-ColonDB :  0.6325884210526318
epoch: 30, dataset: ETIS-LaribPolypDB, dice: 0.6390846938775513
ETIS-LaribPolypDB :  0.6390846938775513
2023-09-02 03:39:40.461284: train_loss -1.4123
2023-09-02 03:39:40.462484: val_loss -1.0293
2023-09-02 03:39:40.463458: Pseudo dice [0.8039]
2023-09-02 03:39:40.464194: Epoch time: 112.21 s
2023-09-02 03:39:40.464957: Yayy! New best EMA pseudo Dice: 0.7964
2023-09-02 03:39:43.310111: 
2023-09-02 03:39:43.311727: Epoch 31
2023-09-02 03:39:43.312592: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-02 03:39:43.313740: start training, 250
================num of epochs: 250================
2023-09-02 03:40:41.244830: finished training
epoch: 31, dataset: CVC-300, dice: 0.8285483333333336
CVC-300 :  0.8285483333333336
epoch: 31, dataset: CVC-ClinicDB, dice: 0.8319370967741935
CVC-ClinicDB :  0.8319370967741935
epoch: 31, dataset: Kvasir, dice: 0.877162
Kvasir :  0.877162
epoch: 31, dataset: CVC-ColonDB, dice: 0.6515513157894735
CVC-ColonDB :  0.6515513157894735
epoch: 31, dataset: ETIS-LaribPolypDB, dice: 0.7217362244897961
ETIS-LaribPolypDB :  0.7217362244897961
2023-09-02 03:41:35.252208: train_loss -1.4176
2023-09-02 03:41:35.253439: val_loss -1.0682
2023-09-02 03:41:35.254429: Pseudo dice [0.812]
2023-09-02 03:41:35.255258: Epoch time: 111.94 s
2023-09-02 03:41:35.255912: Yayy! New best EMA pseudo Dice: 0.798
2023-09-02 03:41:38.070161: 
2023-09-02 03:41:38.071559: Epoch 32
2023-09-02 03:41:38.072370: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-02 03:41:38.073513: start training, 250
================num of epochs: 250================
2023-09-02 03:42:36.015534: finished training
epoch: 32, dataset: CVC-300, dice: 0.8356516666666665
CVC-300 :  0.8356516666666665
epoch: 32, dataset: CVC-ClinicDB, dice: 0.8236403225806449
CVC-ClinicDB :  0.8236403225806449
epoch: 32, dataset: Kvasir, dice: 0.8752369999999999
Kvasir :  0.8752369999999999
epoch: 32, dataset: CVC-ColonDB, dice: 0.6339168421052633
CVC-ColonDB :  0.6339168421052633
epoch: 32, dataset: ETIS-LaribPolypDB, dice: 0.6974683673469386
ETIS-LaribPolypDB :  0.6974683673469386
2023-09-02 03:43:29.863467: train_loss -1.4174
2023-09-02 03:43:29.864693: val_loss -1.0457
2023-09-02 03:43:29.865680: Pseudo dice [0.8185]
2023-09-02 03:43:29.866573: Epoch time: 111.79 s
2023-09-02 03:43:29.867305: Yayy! New best EMA pseudo Dice: 0.8001
2023-09-02 03:43:32.952399: 
2023-09-02 03:43:32.953840: Epoch 33
2023-09-02 03:43:32.954615: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-02 03:43:32.955726: start training, 250
================num of epochs: 250================
2023-09-02 03:44:30.985054: finished training
epoch: 33, dataset: CVC-300, dice: 0.8558616666666671
CVC-300 :  0.8558616666666671
epoch: 33, dataset: CVC-ClinicDB, dice: 0.8358967741935481
CVC-ClinicDB :  0.8358967741935481
epoch: 33, dataset: Kvasir, dice: 0.861863
Kvasir :  0.861863
epoch: 33, dataset: CVC-ColonDB, dice: 0.6208110526315794
CVC-ColonDB :  0.6208110526315794
epoch: 33, dataset: ETIS-LaribPolypDB, dice: 0.6787857142857144
ETIS-LaribPolypDB :  0.6787857142857144
2023-09-02 03:45:24.796671: train_loss -1.4171
2023-09-02 03:45:24.798196: val_loss -1.0201
2023-09-02 03:45:24.799280: Pseudo dice [0.7972]
2023-09-02 03:45:24.800070: Epoch time: 111.85 s
2023-09-02 03:45:26.065869: 
2023-09-02 03:45:26.067190: Epoch 34
2023-09-02 03:45:26.067984: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-02 03:45:26.069147: start training, 250
================num of epochs: 250================
2023-09-02 03:46:23.998136: finished training
epoch: 34, dataset: CVC-300, dice: 0.8680016666666666
CVC-300 :  0.8680016666666666
epoch: 34, dataset: CVC-ClinicDB, dice: 0.8255161290322578
CVC-ClinicDB :  0.8255161290322578
epoch: 34, dataset: Kvasir, dice: 0.8779069999999998
Kvasir :  0.8779069999999998
epoch: 34, dataset: CVC-ColonDB, dice: 0.6462823684210536
CVC-ColonDB :  0.6462823684210536
epoch: 34, dataset: ETIS-LaribPolypDB, dice: 0.7175301020408158
ETIS-LaribPolypDB :  0.7175301020408158
2023-09-02 03:47:17.457838: train_loss -1.4195
2023-09-02 03:47:17.459272: val_loss -1.049
2023-09-02 03:47:17.460331: Pseudo dice [0.8173]
2023-09-02 03:47:17.461137: Epoch time: 111.39 s
2023-09-02 03:47:17.462004: Yayy! New best EMA pseudo Dice: 0.8015
2023-09-02 03:47:20.323156: 
2023-09-02 03:47:20.324574: Epoch 35
2023-09-02 03:47:20.325418: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-02 03:47:20.326622: start training, 250
================num of epochs: 250================
2023-09-02 03:48:18.401795: finished training
epoch: 35, dataset: CVC-300, dice: 0.8738850000000001
CVC-300 :  0.8738850000000001
epoch: 35, dataset: CVC-ClinicDB, dice: 0.8462225806451612
CVC-ClinicDB :  0.8462225806451612
epoch: 35, dataset: Kvasir, dice: 0.8804000000000001
Kvasir :  0.8804000000000001
epoch: 35, dataset: CVC-ColonDB, dice: 0.6786563157894735
CVC-ColonDB :  0.6786563157894735
epoch: 35, dataset: ETIS-LaribPolypDB, dice: 0.6959326530612245
ETIS-LaribPolypDB :  0.6959326530612245
2023-09-02 03:49:14.123530: train_loss -1.4245
2023-09-02 03:49:14.124883: val_loss -1.0438
2023-09-02 03:49:14.125944: Pseudo dice [0.8096]
2023-09-02 03:49:14.126749: Epoch time: 113.8 s
2023-09-02 03:49:14.127464: Yayy! New best EMA pseudo Dice: 0.8023
2023-09-02 03:49:17.306337: 
2023-09-02 03:49:17.307890: Epoch 36
2023-09-02 03:49:17.308752: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-02 03:49:17.309924: start training, 250
================num of epochs: 250================
2023-09-02 03:50:15.251373: finished training
epoch: 36, dataset: CVC-300, dice: 0.8659999999999999
CVC-300 :  0.8659999999999999
epoch: 36, dataset: CVC-ClinicDB, dice: 0.8441838709677421
CVC-ClinicDB :  0.8441838709677421
epoch: 36, dataset: Kvasir, dice: 0.8889770000000001
Kvasir :  0.8889770000000001
epoch: 36, dataset: CVC-ColonDB, dice: 0.6654568421052637
CVC-ColonDB :  0.6654568421052637
epoch: 36, dataset: ETIS-LaribPolypDB, dice: 0.7127816326530615
ETIS-LaribPolypDB :  0.7127816326530615
2023-09-02 03:51:09.054719: train_loss -1.427
2023-09-02 03:51:09.056027: val_loss -0.9685
2023-09-02 03:51:09.057046: Pseudo dice [0.7901]
2023-09-02 03:51:09.057859: Epoch time: 111.75 s
2023-09-02 03:51:10.276108: 
2023-09-02 03:51:10.277251: Epoch 37
2023-09-02 03:51:10.278019: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-02 03:51:10.279166: start training, 250
================num of epochs: 250================
2023-09-02 03:52:08.237131: finished training
epoch: 37, dataset: CVC-300, dice: 0.8390666666666665
CVC-300 :  0.8390666666666665
epoch: 37, dataset: CVC-ClinicDB, dice: 0.851288709677419
CVC-ClinicDB :  0.851288709677419
epoch: 37, dataset: Kvasir, dice: 0.8867359999999997
Kvasir :  0.8867359999999997
epoch: 37, dataset: CVC-ColonDB, dice: 0.6775928947368426
CVC-ColonDB :  0.6775928947368426
epoch: 37, dataset: ETIS-LaribPolypDB, dice: 0.7130142857142857
ETIS-LaribPolypDB :  0.7130142857142857
2023-09-02 03:53:01.389059: train_loss -1.4275
2023-09-02 03:53:01.390271: val_loss -1.0614
2023-09-02 03:53:01.391292: Pseudo dice [0.8144]
2023-09-02 03:53:01.392107: Epoch time: 111.11 s
2023-09-02 03:53:01.392801: Yayy! New best EMA pseudo Dice: 0.8024
2023-09-02 03:53:04.251148: 
2023-09-02 03:53:04.252544: Epoch 38
2023-09-02 03:53:04.253322: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-02 03:53:04.254379: start training, 250
================num of epochs: 250================
2023-09-02 03:54:02.346570: finished training
epoch: 38, dataset: CVC-300, dice: 0.7982416666666665
CVC-300 :  0.7982416666666665
epoch: 38, dataset: CVC-ClinicDB, dice: 0.8550887096774195
CVC-ClinicDB :  0.8550887096774195
epoch: 38, dataset: Kvasir, dice: 0.8634360000000001
Kvasir :  0.8634360000000001
epoch: 38, dataset: CVC-ColonDB, dice: 0.6308502631578948
CVC-ColonDB :  0.6308502631578948
epoch: 38, dataset: ETIS-LaribPolypDB, dice: 0.6318239795918364
ETIS-LaribPolypDB :  0.6318239795918364
2023-09-02 03:54:56.036215: train_loss -1.4282
2023-09-02 03:54:56.037527: val_loss -1.0869
2023-09-02 03:54:56.038569: Pseudo dice [0.8248]
2023-09-02 03:54:56.039409: Epoch time: 111.79 s
2023-09-02 03:54:56.040164: Yayy! New best EMA pseudo Dice: 0.8047
2023-09-02 03:54:58.932945: 
2023-09-02 03:54:58.934305: Epoch 39
2023-09-02 03:54:58.935086: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-02 03:54:58.936332: start training, 250
================num of epochs: 250================
2023-09-02 03:55:56.837531: finished training
epoch: 39, dataset: CVC-300, dice: 0.8505616666666669
CVC-300 :  0.8505616666666669
epoch: 39, dataset: CVC-ClinicDB, dice: 0.8192338709677419
CVC-ClinicDB :  0.8192338709677419
epoch: 39, dataset: Kvasir, dice: 0.8798689999999999
Kvasir :  0.8798689999999999
epoch: 39, dataset: CVC-ColonDB, dice: 0.6346871052631579
CVC-ColonDB :  0.6346871052631579
epoch: 39, dataset: ETIS-LaribPolypDB, dice: 0.6974020408163271
ETIS-LaribPolypDB :  0.6974020408163271
2023-09-02 03:56:50.222048: train_loss -1.4183
2023-09-02 03:56:50.223403: val_loss -0.9143
2023-09-02 03:56:50.224450: Pseudo dice [0.7612]
2023-09-02 03:56:50.225274: Epoch time: 111.29 s
2023-09-02 03:56:53.072578: 
2023-09-02 03:56:53.073866: Epoch 40
2023-09-02 03:56:53.075018: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-02 03:56:53.076857: start training, 250
================num of epochs: 250================
2023-09-02 03:57:51.018652: finished training
epoch: 40, dataset: CVC-300, dice: 0.8374333333333336
CVC-300 :  0.8374333333333336
epoch: 40, dataset: CVC-ClinicDB, dice: 0.8301596774193549
CVC-ClinicDB :  0.8301596774193549
epoch: 40, dataset: Kvasir, dice: 0.8927759999999998
Kvasir :  0.8927759999999998
epoch: 40, dataset: CVC-ColonDB, dice: 0.6098823684210531
CVC-ColonDB :  0.6098823684210531
epoch: 40, dataset: ETIS-LaribPolypDB, dice: 0.688863775510204
ETIS-LaribPolypDB :  0.688863775510204
2023-09-02 03:58:44.510180: train_loss -1.4175
2023-09-02 03:58:44.511456: val_loss -1.0245
2023-09-02 03:58:44.512553: Pseudo dice [0.7998]
2023-09-02 03:58:44.513899: Epoch time: 111.44 s
2023-09-02 03:58:45.774740: 
2023-09-02 03:58:45.776098: Epoch 41
2023-09-02 03:58:45.777386: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-02 03:58:45.779098: start training, 250
================num of epochs: 250================
2023-09-02 03:59:43.915904: finished training
epoch: 41, dataset: CVC-300, dice: 0.7572483333333333
CVC-300 :  0.7572483333333333
epoch: 41, dataset: CVC-ClinicDB, dice: 0.8095387096774193
CVC-ClinicDB :  0.8095387096774193
epoch: 41, dataset: Kvasir, dice: 0.8751990000000001
Kvasir :  0.8751990000000001
epoch: 41, dataset: CVC-ColonDB, dice: 0.5737934210526322
CVC-ColonDB :  0.5737934210526322
epoch: 41, dataset: ETIS-LaribPolypDB, dice: 0.6953295918367349
ETIS-LaribPolypDB :  0.6953295918367349
2023-09-02 04:00:37.401748: train_loss -1.417
2023-09-02 04:00:37.403300: val_loss -0.9786
2023-09-02 04:00:37.404742: Pseudo dice [0.7783]
2023-09-02 04:00:37.405598: Epoch time: 111.63 s
2023-09-02 04:00:38.597013: 
2023-09-02 04:00:38.598410: Epoch 42
2023-09-02 04:00:38.599402: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-02 04:00:38.600649: start training, 250
================num of epochs: 250================
2023-09-02 04:01:36.517555: finished training
epoch: 42, dataset: CVC-300, dice: 0.8724466666666667
CVC-300 :  0.8724466666666667
epoch: 42, dataset: CVC-ClinicDB, dice: 0.8438516129032259
CVC-ClinicDB :  0.8438516129032259
epoch: 42, dataset: Kvasir, dice: 0.8628150000000002
Kvasir :  0.8628150000000002
epoch: 42, dataset: CVC-ColonDB, dice: 0.6583486842105262
CVC-ColonDB :  0.6583486842105262
epoch: 42, dataset: ETIS-LaribPolypDB, dice: 0.7218147959183676
ETIS-LaribPolypDB :  0.7218147959183676
2023-09-02 04:02:29.751876: train_loss -1.4239
2023-09-02 04:02:29.753913: val_loss -1.0665
2023-09-02 04:02:29.755324: Pseudo dice [0.8193]
2023-09-02 04:02:29.756208: Epoch time: 111.16 s
2023-09-02 04:02:30.945125: 
2023-09-02 04:02:30.946530: Epoch 43
2023-09-02 04:02:30.947345: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-02 04:02:30.948524: start training, 250
================num of epochs: 250================
2023-09-02 04:03:28.922615: finished training
epoch: 43, dataset: CVC-300, dice: 0.8493266666666667
CVC-300 :  0.8493266666666667
epoch: 43, dataset: CVC-ClinicDB, dice: 0.872124193548387
CVC-ClinicDB :  0.872124193548387
epoch: 43, dataset: Kvasir, dice: 0.8818830000000005
Kvasir :  0.8818830000000005
epoch: 43, dataset: CVC-ColonDB, dice: 0.6486739473684217
CVC-ColonDB :  0.6486739473684217
epoch: 43, dataset: ETIS-LaribPolypDB, dice: 0.6944173469387755
ETIS-LaribPolypDB :  0.6944173469387755
2023-09-02 04:04:21.636922: train_loss -1.4307
2023-09-02 04:04:21.638355: val_loss -1.0875
2023-09-02 04:04:21.639453: Pseudo dice [0.8317]
2023-09-02 04:04:21.640274: Epoch time: 110.69 s
2023-09-02 04:04:22.849307: 
2023-09-02 04:04:22.850755: Epoch 44
2023-09-02 04:04:22.851548: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-02 04:04:22.852709: start training, 250
================num of epochs: 250================
2023-09-02 04:05:21.089837: finished training
epoch: 44, dataset: CVC-300, dice: 0.87424
CVC-300 :  0.87424
epoch: 44, dataset: CVC-ClinicDB, dice: 0.8354967741935483
CVC-ClinicDB :  0.8354967741935483
epoch: 44, dataset: Kvasir, dice: 0.8881809999999999
Kvasir :  0.8881809999999999
epoch: 44, dataset: CVC-ColonDB, dice: 0.6406815789473692
CVC-ColonDB :  0.6406815789473692
epoch: 44, dataset: ETIS-LaribPolypDB, dice: 0.7123760204081637
ETIS-LaribPolypDB :  0.7123760204081637
2023-09-02 04:06:14.197998: train_loss -1.4326
2023-09-02 04:06:14.199317: val_loss -0.9949
2023-09-02 04:06:14.200401: Pseudo dice [0.8009]
2023-09-02 04:06:14.201197: Epoch time: 111.35 s
2023-09-02 04:06:15.387480: 
2023-09-02 04:06:15.388822: Epoch 45
2023-09-02 04:06:15.389702: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-02 04:06:15.390905: start training, 250
================num of epochs: 250================
2023-09-02 04:07:13.389794: finished training
epoch: 45, dataset: CVC-300, dice: 0.8657349999999997
CVC-300 :  0.8657349999999997
epoch: 45, dataset: CVC-ClinicDB, dice: 0.8600758064516129
CVC-ClinicDB :  0.8600758064516129
epoch: 45, dataset: Kvasir, dice: 0.8946029999999999
Kvasir :  0.8946029999999999
epoch: 45, dataset: CVC-ColonDB, dice: 0.6578578947368428
CVC-ColonDB :  0.6578578947368428
epoch: 45, dataset: ETIS-LaribPolypDB, dice: 0.6907755102040818
ETIS-LaribPolypDB :  0.6907755102040818
2023-09-02 04:08:05.939245: train_loss -1.4353
2023-09-02 04:08:05.940547: val_loss -0.9694
2023-09-02 04:08:05.941617: Pseudo dice [0.7863]
2023-09-02 04:08:05.942451: Epoch time: 110.55 s
2023-09-02 04:08:07.151632: 
2023-09-02 04:08:07.152865: Epoch 46
2023-09-02 04:08:07.153621: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-02 04:08:07.154701: start training, 250
================num of epochs: 250================
2023-09-02 04:09:05.197068: finished training
epoch: 46, dataset: CVC-300, dice: 0.8312750000000001
CVC-300 :  0.8312750000000001
epoch: 46, dataset: CVC-ClinicDB, dice: 0.8483806451612901
CVC-ClinicDB :  0.8483806451612901
epoch: 46, dataset: Kvasir, dice: 0.8836350000000003
Kvasir :  0.8836350000000003
epoch: 46, dataset: CVC-ColonDB, dice: 0.6207181578947373
CVC-ColonDB :  0.6207181578947373
epoch: 46, dataset: ETIS-LaribPolypDB, dice: 0.655836224489796
ETIS-LaribPolypDB :  0.655836224489796
2023-09-02 04:09:57.845187: train_loss -1.4365
2023-09-02 04:09:57.846486: val_loss -1.0412
2023-09-02 04:09:57.847499: Pseudo dice [0.8108]
2023-09-02 04:09:57.848278: Epoch time: 110.69 s
2023-09-02 04:09:59.034367: 
2023-09-02 04:09:59.035822: Epoch 47
2023-09-02 04:09:59.036621: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-02 04:09:59.037797: start training, 250
================num of epochs: 250================
2023-09-02 04:10:57.318424: finished training
epoch: 47, dataset: CVC-300, dice: 0.8696466666666667
CVC-300 :  0.8696466666666667
epoch: 47, dataset: CVC-ClinicDB, dice: 0.8576354838709677
CVC-ClinicDB :  0.8576354838709677
epoch: 47, dataset: Kvasir, dice: 0.8795169999999999
Kvasir :  0.8795169999999999
epoch: 47, dataset: CVC-ColonDB, dice: 0.6516031578947368
CVC-ColonDB :  0.6516031578947368
epoch: 47, dataset: ETIS-LaribPolypDB, dice: 0.7121464285714287
ETIS-LaribPolypDB :  0.7121464285714287
2023-09-02 04:11:49.883159: train_loss -1.4341
2023-09-02 04:11:49.884654: val_loss -0.9707
2023-09-02 04:11:49.885837: Pseudo dice [0.7885]
2023-09-02 04:11:49.886725: Epoch time: 110.85 s
2023-09-02 04:11:51.074711: 
2023-09-02 04:11:51.076102: Epoch 48
2023-09-02 04:11:51.077008: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-02 04:11:51.078350: start training, 250
================num of epochs: 250================
2023-09-02 04:12:49.147238: finished training
epoch: 48, dataset: CVC-300, dice: 0.8613316666666667
CVC-300 :  0.8613316666666667
epoch: 48, dataset: CVC-ClinicDB, dice: 0.8549048387096777
CVC-ClinicDB :  0.8549048387096777
epoch: 48, dataset: Kvasir, dice: 0.8822220000000003
Kvasir :  0.8822220000000003
epoch: 48, dataset: CVC-ColonDB, dice: 0.6461131578947376
CVC-ColonDB :  0.6461131578947376
epoch: 48, dataset: ETIS-LaribPolypDB, dice: 0.7226250000000004
ETIS-LaribPolypDB :  0.7226250000000004
2023-09-02 04:13:41.359115: train_loss -1.4368
2023-09-02 04:13:41.360493: val_loss -1.0114
2023-09-02 04:13:41.361955: Pseudo dice [0.808]
2023-09-02 04:13:41.362775: Epoch time: 110.29 s
2023-09-02 04:13:42.616463: 
2023-09-02 04:13:42.618044: Epoch 49
2023-09-02 04:13:42.618905: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-02 04:13:42.620222: start training, 250
================num of epochs: 250================
2023-09-02 04:14:40.927042: finished training
epoch: 49, dataset: CVC-300, dice: 0.8666083333333333
CVC-300 :  0.8666083333333333
epoch: 49, dataset: CVC-ClinicDB, dice: 0.8603661290322582
CVC-ClinicDB :  0.8603661290322582
epoch: 49, dataset: Kvasir, dice: 0.8946949999999998
Kvasir :  0.8946949999999998
epoch: 49, dataset: CVC-ColonDB, dice: 0.6583292105263161
CVC-ColonDB :  0.6583292105263161
epoch: 49, dataset: ETIS-LaribPolypDB, dice: 0.731981632653061
ETIS-LaribPolypDB :  0.731981632653061
2023-09-02 04:15:33.685919: train_loss -1.4399
2023-09-02 04:15:33.687268: val_loss -0.9957
2023-09-02 04:15:33.688301: Pseudo dice [0.7995]
2023-09-02 04:15:33.689166: Epoch time: 111.07 s
2023-09-02 04:15:36.676471: 
2023-09-02 04:15:36.677904: Epoch 50
2023-09-02 04:15:36.678737: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-02 04:15:36.679938: start training, 250
================num of epochs: 250================
2023-09-02 04:16:35.017085: finished training
epoch: 50, dataset: CVC-300, dice: 0.8453633333333335
CVC-300 :  0.8453633333333335
epoch: 50, dataset: CVC-ClinicDB, dice: 0.8607887096774189
CVC-ClinicDB :  0.8607887096774189
epoch: 50, dataset: Kvasir, dice: 0.880535
Kvasir :  0.880535
epoch: 50, dataset: CVC-ColonDB, dice: 0.6495636842105267
CVC-ColonDB :  0.6495636842105267
epoch: 50, dataset: ETIS-LaribPolypDB, dice: 0.7178316326530615
ETIS-LaribPolypDB :  0.7178316326530615
2023-09-02 04:17:31.292501: train_loss -1.4397
2023-09-02 04:17:31.294055: val_loss -1.0252
2023-09-02 04:17:31.295264: Pseudo dice [0.8128]
2023-09-02 04:17:31.296136: Epoch time: 114.62 s
2023-09-02 04:17:32.537843: 
2023-09-02 04:17:32.539155: Epoch 51
2023-09-02 04:17:32.539962: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-02 04:17:32.541579: start training, 250
================num of epochs: 250================
2023-09-02 04:18:30.858000: finished training
epoch: 51, dataset: CVC-300, dice: 0.8327616666666668
CVC-300 :  0.8327616666666668
epoch: 51, dataset: CVC-ClinicDB, dice: 0.8637887096774196
CVC-ClinicDB :  0.8637887096774196
epoch: 51, dataset: Kvasir, dice: 0.8899380000000001
Kvasir :  0.8899380000000001
epoch: 51, dataset: CVC-ColonDB, dice: 0.6767418421052629
CVC-ColonDB :  0.6767418421052629
epoch: 51, dataset: ETIS-LaribPolypDB, dice: 0.7181142857142858
ETIS-LaribPolypDB :  0.7181142857142858
2023-09-02 04:19:23.215147: train_loss -1.4384
2023-09-02 04:19:23.216486: val_loss -0.9896
2023-09-02 04:19:23.217531: Pseudo dice [0.7946]
2023-09-02 04:19:23.218356: Epoch time: 110.68 s
2023-09-02 04:19:24.436341: 
2023-09-02 04:19:24.437701: Epoch 52
2023-09-02 04:19:24.438537: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-02 04:19:24.439806: start training, 250
================num of epochs: 250================
2023-09-02 04:20:22.520567: finished training
epoch: 52, dataset: CVC-300, dice: 0.8616716666666665
CVC-300 :  0.8616716666666665
epoch: 52, dataset: CVC-ClinicDB, dice: 0.8716225806451615
CVC-ClinicDB :  0.8716225806451615
epoch: 52, dataset: Kvasir, dice: 0.8948580000000002
Kvasir :  0.8948580000000002
epoch: 52, dataset: CVC-ColonDB, dice: 0.6861110526315797
CVC-ColonDB :  0.6861110526315797
epoch: 52, dataset: ETIS-LaribPolypDB, dice: 0.730966836734694
ETIS-LaribPolypDB :  0.730966836734694
2023-09-02 04:21:15.451596: train_loss -1.4383
2023-09-02 04:21:15.452853: val_loss -1.0643
2023-09-02 04:21:15.454719: Pseudo dice [0.822]
2023-09-02 04:21:15.456125: Epoch time: 111.02 s
2023-09-02 04:21:16.685340: 
2023-09-02 04:21:16.686676: Epoch 53
2023-09-02 04:21:16.687495: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-02 04:21:16.688826: start training, 250
================num of epochs: 250================
2023-09-02 04:22:14.992018: finished training
epoch: 53, dataset: CVC-300, dice: 0.884108333333333
CVC-300 :  0.884108333333333
epoch: 53, dataset: CVC-ClinicDB, dice: 0.8520790322580646
CVC-ClinicDB :  0.8520790322580646
epoch: 53, dataset: Kvasir, dice: 0.896054
Kvasir :  0.896054
epoch: 53, dataset: CVC-ColonDB, dice: 0.6932634210526318
CVC-ColonDB :  0.6932634210526318
epoch: 53, dataset: ETIS-LaribPolypDB, dice: 0.7456071428571434
ETIS-LaribPolypDB :  0.7456071428571434
2023-09-02 04:23:07.521593: train_loss -1.4424
2023-09-02 04:23:07.522958: val_loss -1.0468
2023-09-02 04:23:07.524083: Pseudo dice [0.822]
2023-09-02 04:23:07.525085: Epoch time: 110.84 s
2023-09-02 04:23:07.525866: Yayy! New best EMA pseudo Dice: 0.8056
2023-09-02 04:23:10.431872: 
2023-09-02 04:23:10.433283: Epoch 54
2023-09-02 04:23:10.434141: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-02 04:23:10.435411: start training, 250
================num of epochs: 250================
2023-09-02 04:24:09.114488: finished training
epoch: 54, dataset: CVC-300, dice: 0.8732766666666664
CVC-300 :  0.8732766666666664
epoch: 54, dataset: CVC-ClinicDB, dice: 0.8394725806451614
CVC-ClinicDB :  0.8394725806451614
epoch: 54, dataset: Kvasir, dice: 0.887667
Kvasir :  0.887667
epoch: 54, dataset: CVC-ColonDB, dice: 0.676768157894737
CVC-ColonDB :  0.676768157894737
epoch: 54, dataset: ETIS-LaribPolypDB, dice: 0.7281673469387756
ETIS-LaribPolypDB :  0.7281673469387756
2023-09-02 04:25:06.208548: train_loss -1.4405
2023-09-02 04:25:06.210145: val_loss -0.9219
2023-09-02 04:25:06.211550: Pseudo dice [0.786]
2023-09-02 04:25:06.212581: Epoch time: 115.78 s
2023-09-02 04:25:07.452178: 
2023-09-02 04:25:07.453680: Epoch 55
2023-09-02 04:25:07.454552: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-02 04:25:07.456285: start training, 250
================num of epochs: 250================
2023-09-02 04:26:05.786249: finished training
epoch: 55, dataset: CVC-300, dice: 0.853008333333333
CVC-300 :  0.853008333333333
epoch: 55, dataset: CVC-ClinicDB, dice: 0.8523225806451612
CVC-ClinicDB :  0.8523225806451612
epoch: 55, dataset: Kvasir, dice: 0.8805070000000004
Kvasir :  0.8805070000000004
epoch: 55, dataset: CVC-ColonDB, dice: 0.6757078947368425
CVC-ColonDB :  0.6757078947368425
epoch: 55, dataset: ETIS-LaribPolypDB, dice: 0.6704755102040817
ETIS-LaribPolypDB :  0.6704755102040817
2023-09-02 04:27:02.690746: train_loss -1.4406
2023-09-02 04:27:02.692024: val_loss -0.9395
2023-09-02 04:27:02.693103: Pseudo dice [0.7919]
2023-09-02 04:27:02.693928: Epoch time: 115.24 s
2023-09-02 04:27:03.899654: 
2023-09-02 04:27:03.901089: Epoch 56
2023-09-02 04:27:03.901907: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-02 04:27:03.903424: start training, 250
================num of epochs: 250================
2023-09-02 04:28:02.176474: finished training
epoch: 56, dataset: CVC-300, dice: 0.83428
CVC-300 :  0.83428
epoch: 56, dataset: CVC-ClinicDB, dice: 0.8517693548387095
CVC-ClinicDB :  0.8517693548387095
epoch: 56, dataset: Kvasir, dice: 0.884132
Kvasir :  0.884132
epoch: 56, dataset: CVC-ColonDB, dice: 0.675832105263158
CVC-ColonDB :  0.675832105263158
epoch: 56, dataset: ETIS-LaribPolypDB, dice: 0.6846229591836731
ETIS-LaribPolypDB :  0.6846229591836731
2023-09-02 04:28:55.215597: train_loss -1.4292
2023-09-02 04:28:55.216845: val_loss -1.0695
2023-09-02 04:28:55.217944: Pseudo dice [0.8089]
2023-09-02 04:28:55.218778: Epoch time: 111.32 s
2023-09-02 04:28:56.433532: 
2023-09-02 04:28:56.435047: Epoch 57
2023-09-02 04:28:56.435949: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-02 04:28:56.437219: start training, 250
================num of epochs: 250================
2023-09-02 04:29:54.464930: finished training
epoch: 57, dataset: CVC-300, dice: 0.8541916666666667
CVC-300 :  0.8541916666666667
epoch: 57, dataset: CVC-ClinicDB, dice: 0.8486499999999998
CVC-ClinicDB :  0.8486499999999998
epoch: 57, dataset: Kvasir, dice: 0.8861230000000002
Kvasir :  0.8861230000000002
epoch: 57, dataset: CVC-ColonDB, dice: 0.6658418421052632
CVC-ColonDB :  0.6658418421052632
epoch: 57, dataset: ETIS-LaribPolypDB, dice: 0.7210892857142862
ETIS-LaribPolypDB :  0.7210892857142862
2023-09-02 04:30:46.724699: train_loss -1.4322
2023-09-02 04:30:46.727806: val_loss -1.0487
2023-09-02 04:30:46.731085: Pseudo dice [0.8149]
2023-09-02 04:30:46.732558: Epoch time: 110.29 s
2023-09-02 04:30:47.945475: 
2023-09-02 04:30:47.946899: Epoch 58
2023-09-02 04:30:47.947706: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-02 04:30:47.948887: start training, 250
================num of epochs: 250================
2023-09-02 04:31:46.004361: finished training
epoch: 58, dataset: CVC-300, dice: 0.8815300000000001
CVC-300 :  0.8815300000000001
epoch: 58, dataset: CVC-ClinicDB, dice: 0.8520258064516126
CVC-ClinicDB :  0.8520258064516126
epoch: 58, dataset: Kvasir, dice: 0.8903570000000005
Kvasir :  0.8903570000000005
epoch: 58, dataset: CVC-ColonDB, dice: 0.6792797368421056
CVC-ColonDB :  0.6792797368421056
epoch: 58, dataset: ETIS-LaribPolypDB, dice: 0.7302219387755102
ETIS-LaribPolypDB :  0.7302219387755102
2023-09-02 04:32:38.517395: train_loss -1.4376
2023-09-02 04:32:38.520176: val_loss -1.0185
2023-09-02 04:32:38.522087: Pseudo dice [0.8009]
2023-09-02 04:32:38.523368: Epoch time: 110.57 s
2023-09-02 04:32:39.733070: 
2023-09-02 04:32:39.734733: Epoch 59
2023-09-02 04:32:39.735746: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-02 04:32:39.737483: start training, 250
================num of epochs: 250================
2023-09-02 04:33:38.430167: finished training
epoch: 59, dataset: CVC-300, dice: 0.8798549999999997
CVC-300 :  0.8798549999999997
epoch: 59, dataset: CVC-ClinicDB, dice: 0.8485822580645164
CVC-ClinicDB :  0.8485822580645164
epoch: 59, dataset: Kvasir, dice: 0.8926349999999996
Kvasir :  0.8926349999999996
epoch: 59, dataset: CVC-ColonDB, dice: 0.6815742105263161
CVC-ColonDB :  0.6815742105263161
epoch: 59, dataset: ETIS-LaribPolypDB, dice: 0.7303275510204087
ETIS-LaribPolypDB :  0.7303275510204087
2023-09-02 04:34:29.590613: train_loss -1.4428
2023-09-02 04:34:29.592280: val_loss -1.0551
2023-09-02 04:34:29.593421: Pseudo dice [0.8214]
2023-09-02 04:34:29.594263: Epoch time: 109.86 s
2023-09-02 04:34:31.392394: Yayy! New best EMA pseudo Dice: 0.8057
2023-09-02 04:34:34.374448: 
2023-09-02 04:34:34.375833: Epoch 60
2023-09-02 04:34:34.376733: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-02 04:34:34.378330: start training, 250
================num of epochs: 250================
2023-09-02 04:35:33.107569: finished training
epoch: 60, dataset: CVC-300, dice: 0.893791666666667
CVC-300 :  0.893791666666667
epoch: 60, dataset: CVC-ClinicDB, dice: 0.8516645161290322
CVC-ClinicDB :  0.8516645161290322
epoch: 60, dataset: Kvasir, dice: 0.8960009999999999
Kvasir :  0.8960009999999999
epoch: 60, dataset: CVC-ColonDB, dice: 0.7071389473684211
CVC-ColonDB :  0.7071389473684211
epoch: 60, dataset: ETIS-LaribPolypDB, dice: 0.73280306122449
ETIS-LaribPolypDB :  0.73280306122449
2023-09-02 04:36:31.151505: train_loss -1.4436
2023-09-02 04:36:31.153029: val_loss -0.9724
2023-09-02 04:36:31.154509: Pseudo dice [0.7946]
2023-09-02 04:36:31.155418: Epoch time: 116.78 s
2023-09-02 04:36:32.414143: 
2023-09-02 04:36:32.415963: Epoch 61
2023-09-02 04:36:32.417241: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-02 04:36:32.419297: start training, 250
================num of epochs: 250================
2023-09-02 04:37:31.055709: finished training
epoch: 61, dataset: CVC-300, dice: 0.8726100000000001
CVC-300 :  0.8726100000000001
epoch: 61, dataset: CVC-ClinicDB, dice: 0.8574451612903224
CVC-ClinicDB :  0.8574451612903224
epoch: 61, dataset: Kvasir, dice: 0.892281
Kvasir :  0.892281
epoch: 61, dataset: CVC-ColonDB, dice: 0.7057350000000002
CVC-ColonDB :  0.7057350000000002
epoch: 61, dataset: ETIS-LaribPolypDB, dice: 0.7462362244897967
ETIS-LaribPolypDB :  0.7462362244897967
2023-09-02 04:38:23.042985: train_loss -1.4445
2023-09-02 04:38:23.044370: val_loss -1.0488
2023-09-02 04:38:23.045507: Pseudo dice [0.818]
2023-09-02 04:38:23.046341: Epoch time: 110.63 s
2023-09-02 04:38:23.047089: Yayy! New best EMA pseudo Dice: 0.8059
2023-09-02 04:38:25.982724: 
2023-09-02 04:38:25.984273: Epoch 62
2023-09-02 04:38:25.985229: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-02 04:38:25.987142: start training, 250
================num of epochs: 250================
2023-09-02 04:39:24.395077: finished training
epoch: 62, dataset: CVC-300, dice: 0.8211833333333335
CVC-300 :  0.8211833333333335
epoch: 62, dataset: CVC-ClinicDB, dice: 0.8523451612903229
CVC-ClinicDB :  0.8523451612903229
epoch: 62, dataset: Kvasir, dice: 0.87775
Kvasir :  0.87775
epoch: 62, dataset: CVC-ColonDB, dice: 0.6442200000000001
CVC-ColonDB :  0.6442200000000001
epoch: 62, dataset: ETIS-LaribPolypDB, dice: 0.7000081632653062
ETIS-LaribPolypDB :  0.7000081632653062
2023-09-02 04:40:17.346280: train_loss -1.4413
2023-09-02 04:40:17.347827: val_loss -1.0167
2023-09-02 04:40:17.348945: Pseudo dice [0.8047]
2023-09-02 04:40:17.349849: Epoch time: 111.37 s
2023-09-02 04:40:18.575759: 
2023-09-02 04:40:18.577121: Epoch 63
2023-09-02 04:40:18.577968: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-02 04:40:18.579494: start training, 250
================num of epochs: 250================
2023-09-02 04:41:16.610267: finished training
epoch: 63, dataset: CVC-300, dice: 0.860086666666667
CVC-300 :  0.860086666666667
epoch: 63, dataset: CVC-ClinicDB, dice: 0.843298387096774
CVC-ClinicDB :  0.843298387096774
epoch: 63, dataset: Kvasir, dice: 0.875748
Kvasir :  0.875748
epoch: 63, dataset: CVC-ColonDB, dice: 0.6736221052631576
CVC-ColonDB :  0.6736221052631576
epoch: 63, dataset: ETIS-LaribPolypDB, dice: 0.6972209183673475
ETIS-LaribPolypDB :  0.6972209183673475
2023-09-02 04:42:08.978377: train_loss -1.4409
2023-09-02 04:42:08.980005: val_loss -1.0443
2023-09-02 04:42:08.981281: Pseudo dice [0.8269]
2023-09-02 04:42:08.982152: Epoch time: 110.4 s
2023-09-02 04:42:08.982941: Yayy! New best EMA pseudo Dice: 0.8079
2023-09-02 04:42:11.926904: 
2023-09-02 04:42:11.928320: Epoch 64
2023-09-02 04:42:11.929185: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-02 04:42:11.930466: start training, 250
================num of epochs: 250================
2023-09-02 04:43:10.043565: finished training
epoch: 64, dataset: CVC-300, dice: 0.8527283333333333
CVC-300 :  0.8527283333333333
epoch: 64, dataset: CVC-ClinicDB, dice: 0.8619887096774193
CVC-ClinicDB :  0.8619887096774193
epoch: 64, dataset: Kvasir, dice: 0.886534
Kvasir :  0.886534
epoch: 64, dataset: CVC-ColonDB, dice: 0.6682544736842104
CVC-ColonDB :  0.6682544736842104
epoch: 64, dataset: ETIS-LaribPolypDB, dice: 0.6999923469387754
ETIS-LaribPolypDB :  0.6999923469387754
2023-09-02 04:44:05.522884: train_loss -1.4447
2023-09-02 04:44:05.524457: val_loss -1.0662
2023-09-02 04:44:05.525825: Pseudo dice [0.8342]
2023-09-02 04:44:05.526670: Epoch time: 113.6 s
2023-09-02 04:44:05.527549: Yayy! New best EMA pseudo Dice: 0.8106
2023-09-02 04:44:08.555970: 
2023-09-02 04:44:08.557691: Epoch 65
2023-09-02 04:44:08.558663: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-02 04:44:08.560425: start training, 250
================num of epochs: 250================
2023-09-02 04:45:07.330487: finished training
epoch: 65, dataset: CVC-300, dice: 0.8590966666666664
CVC-300 :  0.8590966666666664
epoch: 65, dataset: CVC-ClinicDB, dice: 0.8558435483870969
CVC-ClinicDB :  0.8558435483870969
epoch: 65, dataset: Kvasir, dice: 0.8876720000000006
Kvasir :  0.8876720000000006
epoch: 65, dataset: CVC-ColonDB, dice: 0.6832452631578947
CVC-ColonDB :  0.6832452631578947
epoch: 65, dataset: ETIS-LaribPolypDB, dice: 0.7224887755102041
ETIS-LaribPolypDB :  0.7224887755102041
2023-09-02 04:46:01.063083: train_loss -1.4463
2023-09-02 04:46:01.064726: val_loss -0.9972
2023-09-02 04:46:01.066109: Pseudo dice [0.8076]
2023-09-02 04:46:01.067050: Epoch time: 112.51 s
2023-09-02 04:46:02.375566: 
2023-09-02 04:46:02.377270: Epoch 66
2023-09-02 04:46:02.378204: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-02 04:46:02.379602: start training, 250
================num of epochs: 250================
2023-09-02 04:47:00.736171: finished training
epoch: 66, dataset: CVC-300, dice: 0.8661483333333335
CVC-300 :  0.8661483333333335
epoch: 66, dataset: CVC-ClinicDB, dice: 0.8459516129032258
CVC-ClinicDB :  0.8459516129032258
epoch: 66, dataset: Kvasir, dice: 0.8876479999999995
Kvasir :  0.8876479999999995
epoch: 66, dataset: CVC-ColonDB, dice: 0.6948900000000003
CVC-ColonDB :  0.6948900000000003
epoch: 66, dataset: ETIS-LaribPolypDB, dice: 0.7271622448979593
ETIS-LaribPolypDB :  0.7271622448979593
2023-09-02 04:47:55.348121: train_loss -1.4467
2023-09-02 04:47:55.349801: val_loss -0.9636
2023-09-02 04:47:55.351142: Pseudo dice [0.7976]
2023-09-02 04:47:55.352050: Epoch time: 112.97 s
2023-09-02 04:47:56.661136: 
2023-09-02 04:47:56.662703: Epoch 67
2023-09-02 04:47:56.663597: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-02 04:47:56.665673: start training, 250
================num of epochs: 250================
2023-09-02 04:48:55.410035: finished training
epoch: 67, dataset: CVC-300, dice: 0.87553
CVC-300 :  0.87553
epoch: 67, dataset: CVC-ClinicDB, dice: 0.8440129032258062
CVC-ClinicDB :  0.8440129032258062
epoch: 67, dataset: Kvasir, dice: 0.8919210000000001
Kvasir :  0.8919210000000001
epoch: 67, dataset: CVC-ColonDB, dice: 0.6888176315789475
CVC-ColonDB :  0.6888176315789475
epoch: 67, dataset: ETIS-LaribPolypDB, dice: 0.7496198979591842
ETIS-LaribPolypDB :  0.7496198979591842
2023-09-02 04:49:49.819606: train_loss -1.4487
2023-09-02 04:49:49.821134: val_loss -1.0693
2023-09-02 04:49:49.822412: Pseudo dice [0.8308]
2023-09-02 04:49:49.823350: Epoch time: 113.16 s
2023-09-02 04:49:49.824179: Yayy! New best EMA pseudo Dice: 0.8112
2023-09-02 04:49:52.873868: 
2023-09-02 04:49:52.875856: Epoch 68
2023-09-02 04:49:52.876870: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-02 04:49:52.878857: start training, 250
================num of epochs: 250================
2023-09-02 04:50:51.460059: finished training
epoch: 68, dataset: CVC-300, dice: 0.865278333333333
CVC-300 :  0.865278333333333
epoch: 68, dataset: CVC-ClinicDB, dice: 0.8558999999999998
CVC-ClinicDB :  0.8558999999999998
epoch: 68, dataset: Kvasir, dice: 0.8958240000000001
Kvasir :  0.8958240000000001
epoch: 68, dataset: CVC-ColonDB, dice: 0.6787831578947376
CVC-ColonDB :  0.6787831578947376
epoch: 68, dataset: ETIS-LaribPolypDB, dice: 0.7282418367346943
ETIS-LaribPolypDB :  0.7282418367346943
2023-09-02 04:51:50.666448: train_loss -1.4482
2023-09-02 04:51:50.667885: val_loss -1.0242
2023-09-02 04:51:50.669034: Pseudo dice [0.823]
2023-09-02 04:51:50.669898: Epoch time: 117.79 s
2023-09-02 04:51:50.670709: Yayy! New best EMA pseudo Dice: 0.8124
2023-09-02 04:51:53.655290: 
2023-09-02 04:51:53.657385: Epoch 69
2023-09-02 04:51:53.658683: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-02 04:51:53.660339: start training, 250
================num of epochs: 250================
2023-09-02 04:52:51.829755: finished training
epoch: 69, dataset: CVC-300, dice: 0.8749533333333335
CVC-300 :  0.8749533333333335
epoch: 69, dataset: CVC-ClinicDB, dice: 0.8537225806451613
CVC-ClinicDB :  0.8537225806451613
epoch: 69, dataset: Kvasir, dice: 0.8954489999999999
Kvasir :  0.8954489999999999
epoch: 69, dataset: CVC-ColonDB, dice: 0.6848131578947366
CVC-ColonDB :  0.6848131578947366
epoch: 69, dataset: ETIS-LaribPolypDB, dice: 0.7062954081632655
ETIS-LaribPolypDB :  0.7062954081632655
2023-09-02 04:53:45.556468: train_loss -1.4483
2023-09-02 04:53:45.557800: val_loss -1.0348
2023-09-02 04:53:45.558938: Pseudo dice [0.821]
2023-09-02 04:53:45.559819: Epoch time: 111.9 s
2023-09-02 04:53:47.200847: Yayy! New best EMA pseudo Dice: 0.8132
2023-09-02 04:53:50.222556: 
2023-09-02 04:53:50.224200: Epoch 70
2023-09-02 04:53:50.225109: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-02 04:53:50.226549: start training, 250
================num of epochs: 250================
2023-09-02 04:54:48.248322: finished training
epoch: 70, dataset: CVC-300, dice: 0.8708933333333332
CVC-300 :  0.8708933333333332
epoch: 70, dataset: CVC-ClinicDB, dice: 0.8443790322580642
CVC-ClinicDB :  0.8443790322580642
epoch: 70, dataset: Kvasir, dice: 0.9002740000000001
Kvasir :  0.9002740000000001
epoch: 70, dataset: CVC-ColonDB, dice: 0.6777426315789474
CVC-ColonDB :  0.6777426315789474
epoch: 70, dataset: ETIS-LaribPolypDB, dice: 0.7037306122448979
ETIS-LaribPolypDB :  0.7037306122448979
2023-09-02 04:55:41.966426: train_loss -1.4489
2023-09-02 04:55:41.968544: val_loss -1.0029
2023-09-02 04:55:41.969960: Pseudo dice [0.8107]
2023-09-02 04:55:41.970882: Epoch time: 111.75 s
2023-09-02 04:55:43.249886: 
2023-09-02 04:55:43.251476: Epoch 71
2023-09-02 04:55:43.252837: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-02 04:55:43.255247: start training, 250
================num of epochs: 250================
2023-09-02 04:56:42.010476: finished training
epoch: 71, dataset: CVC-300, dice: 0.8756849999999995
CVC-300 :  0.8756849999999995
epoch: 71, dataset: CVC-ClinicDB, dice: 0.846327419354839
CVC-ClinicDB :  0.846327419354839
epoch: 71, dataset: Kvasir, dice: 0.9035760000000002
Kvasir :  0.9035760000000002
epoch: 71, dataset: CVC-ColonDB, dice: 0.6916560526315793
CVC-ColonDB :  0.6916560526315793
epoch: 71, dataset: ETIS-LaribPolypDB, dice: 0.7490397959183671
ETIS-LaribPolypDB :  0.7490397959183671
2023-09-02 04:57:39.997229: train_loss -1.4496
2023-09-02 04:57:39.998820: val_loss -0.9971
2023-09-02 04:57:40.000178: Pseudo dice [0.815]
2023-09-02 04:57:40.001047: Epoch time: 116.75 s
2023-09-02 04:57:41.240251: 
2023-09-02 04:57:41.241753: Epoch 72
2023-09-02 04:57:41.242655: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-02 04:57:41.243964: start training, 250
================num of epochs: 250================
2023-09-02 04:58:39.963275: finished training
epoch: 72, dataset: CVC-300, dice: 0.8735783333333337
CVC-300 :  0.8735783333333337
epoch: 72, dataset: CVC-ClinicDB, dice: 0.8455822580645164
CVC-ClinicDB :  0.8455822580645164
epoch: 72, dataset: Kvasir, dice: 0.8899349999999999
Kvasir :  0.8899349999999999
epoch: 72, dataset: CVC-ColonDB, dice: 0.6841784210526317
CVC-ColonDB :  0.6841784210526317
epoch: 72, dataset: ETIS-LaribPolypDB, dice: 0.7322285714285718
ETIS-LaribPolypDB :  0.7322285714285718
2023-09-02 04:59:37.375050: train_loss -1.4512
2023-09-02 04:59:37.377087: val_loss -1.0538
2023-09-02 04:59:37.378477: Pseudo dice [0.835]
2023-09-02 04:59:37.379460: Epoch time: 116.14 s
2023-09-02 04:59:37.380288: Yayy! New best EMA pseudo Dice: 0.8154
2023-09-02 04:59:40.386615: 
2023-09-02 04:59:40.390773: Epoch 73
2023-09-02 04:59:40.393203: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-02 04:59:40.396381: start training, 250
================num of epochs: 250================
2023-09-02 05:00:38.867942: finished training
epoch: 73, dataset: CVC-300, dice: 0.8429066666666666
CVC-300 :  0.8429066666666666
epoch: 73, dataset: CVC-ClinicDB, dice: 0.8440935483870968
CVC-ClinicDB :  0.8440935483870968
epoch: 73, dataset: Kvasir, dice: 0.8886030000000001
Kvasir :  0.8886030000000001
epoch: 73, dataset: CVC-ColonDB, dice: 0.6891910526315785
CVC-ColonDB :  0.6891910526315785
epoch: 73, dataset: ETIS-LaribPolypDB, dice: 0.7049071428571427
ETIS-LaribPolypDB :  0.7049071428571427
2023-09-02 05:01:36.864145: train_loss -1.4517
2023-09-02 05:01:36.865712: val_loss -1.075
2023-09-02 05:01:36.866914: Pseudo dice [0.8369]
2023-09-02 05:01:36.867762: Epoch time: 116.48 s
2023-09-02 05:01:36.868514: Yayy! New best EMA pseudo Dice: 0.8175
2023-09-02 05:01:40.305286: 
2023-09-02 05:01:40.306900: Epoch 74
2023-09-02 05:01:40.307806: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-02 05:01:40.309186: start training, 250
================num of epochs: 250================
2023-09-02 05:02:39.100216: finished training
epoch: 74, dataset: CVC-300, dice: 0.8354183333333334
CVC-300 :  0.8354183333333334
epoch: 74, dataset: CVC-ClinicDB, dice: 0.852182258064516
CVC-ClinicDB :  0.852182258064516
epoch: 74, dataset: Kvasir, dice: 0.8887610000000007
Kvasir :  0.8887610000000007
epoch: 74, dataset: CVC-ColonDB, dice: 0.6532002631578948
CVC-ColonDB :  0.6532002631578948
epoch: 74, dataset: ETIS-LaribPolypDB, dice: 0.7212081632653059
ETIS-LaribPolypDB :  0.7212081632653059
2023-09-02 05:03:39.796620: train_loss -1.4499
2023-09-02 05:03:39.798328: val_loss -1.0596
2023-09-02 05:03:39.799646: Pseudo dice [0.8256]
2023-09-02 05:03:39.800632: Epoch time: 119.49 s
2023-09-02 05:03:39.801451: Yayy! New best EMA pseudo Dice: 0.8183
2023-09-02 05:03:42.749926: 
2023-09-02 05:03:42.751358: Epoch 75
2023-09-02 05:03:42.752340: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-02 05:03:42.753918: start training, 250
================num of epochs: 250================
2023-09-02 05:04:41.163198: finished training
epoch: 75, dataset: CVC-300, dice: 0.8002050000000003
CVC-300 :  0.8002050000000003
epoch: 75, dataset: CVC-ClinicDB, dice: 0.813333870967742
CVC-ClinicDB :  0.813333870967742
epoch: 75, dataset: Kvasir, dice: 0.8708679999999996
Kvasir :  0.8708679999999996
epoch: 75, dataset: CVC-ColonDB, dice: 0.6008168421052631
CVC-ColonDB :  0.6008168421052631
epoch: 75, dataset: ETIS-LaribPolypDB, dice: 0.6865204081632649
ETIS-LaribPolypDB :  0.6865204081632649
2023-09-02 05:05:41.364946: train_loss -1.4499
2023-09-02 05:05:41.367015: val_loss -1.0173
2023-09-02 05:05:41.368339: Pseudo dice [0.8129]
2023-09-02 05:05:41.369215: Epoch time: 118.62 s
2023-09-02 05:05:42.603409: 
2023-09-02 05:05:42.604725: Epoch 76
2023-09-02 05:05:42.605646: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-02 05:05:42.607004: start training, 250
================num of epochs: 250================
2023-09-02 05:06:40.482548: finished training
epoch: 76, dataset: CVC-300, dice: 0.7596999999999999
CVC-300 :  0.7596999999999999
epoch: 76, dataset: CVC-ClinicDB, dice: 0.8135919354838709
CVC-ClinicDB :  0.8135919354838709
epoch: 76, dataset: Kvasir, dice: 0.8687349999999999
Kvasir :  0.8687349999999999
epoch: 76, dataset: CVC-ColonDB, dice: 0.5940721052631575
CVC-ColonDB :  0.5940721052631575
epoch: 76, dataset: ETIS-LaribPolypDB, dice: 0.6922540816326531
ETIS-LaribPolypDB :  0.6922540816326531
2023-09-02 05:07:39.877228: train_loss -1.451
2023-09-02 05:07:39.878889: val_loss -1.0403
2023-09-02 05:07:39.880367: Pseudo dice [0.8284]
2023-09-02 05:07:39.881613: Epoch time: 117.28 s
2023-09-02 05:07:39.882507: Yayy! New best EMA pseudo Dice: 0.8188
2023-09-02 05:07:43.276072: 
2023-09-02 05:07:43.277495: Epoch 77
2023-09-02 05:07:43.278385: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-02 05:07:43.279568: start training, 250
================num of epochs: 250================
2023-09-02 05:08:41.455933: finished training
epoch: 77, dataset: CVC-300, dice: 0.8636533333333334
CVC-300 :  0.8636533333333334
epoch: 77, dataset: CVC-ClinicDB, dice: 0.842116129032258
CVC-ClinicDB :  0.842116129032258
epoch: 77, dataset: Kvasir, dice: 0.8771159999999999
Kvasir :  0.8771159999999999
epoch: 77, dataset: CVC-ColonDB, dice: 0.6419542105263163
CVC-ColonDB :  0.6419542105263163
epoch: 77, dataset: ETIS-LaribPolypDB, dice: 0.744714285714286
ETIS-LaribPolypDB :  0.744714285714286
2023-09-02 05:09:37.588249: train_loss -1.4517
2023-09-02 05:09:37.589785: val_loss -0.9304
2023-09-02 05:09:37.591207: Pseudo dice [0.7965]
2023-09-02 05:09:37.592163: Epoch time: 114.31 s
2023-09-02 05:09:38.819527: 
2023-09-02 05:09:38.820885: Epoch 78
2023-09-02 05:09:38.821774: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-02 05:09:38.823048: start training, 250
================num of epochs: 250================
2023-09-02 05:10:37.097685: finished training
epoch: 78, dataset: CVC-300, dice: 0.8634650000000003
CVC-300 :  0.8634650000000003
epoch: 78, dataset: CVC-ClinicDB, dice: 0.844766129032258
CVC-ClinicDB :  0.844766129032258
epoch: 78, dataset: Kvasir, dice: 0.885403
Kvasir :  0.885403
epoch: 78, dataset: CVC-ColonDB, dice: 0.6656244736842105
CVC-ColonDB :  0.6656244736842105
epoch: 78, dataset: ETIS-LaribPolypDB, dice: 0.7452969387755101
ETIS-LaribPolypDB :  0.7452969387755101
2023-09-02 05:11:36.877630: train_loss -1.4531
2023-09-02 05:11:36.879340: val_loss -0.9766
2023-09-02 05:11:36.880586: Pseudo dice [0.8032]
2023-09-02 05:11:36.881551: Epoch time: 118.06 s
2023-09-02 05:11:38.173628: 
2023-09-02 05:11:38.175356: Epoch 79
2023-09-02 05:11:38.176394: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-02 05:11:38.178148: start training, 250
================num of epochs: 250================
2023-09-02 05:12:36.816174: finished training
epoch: 79, dataset: CVC-300, dice: 0.8562983333333336
CVC-300 :  0.8562983333333336
epoch: 79, dataset: CVC-ClinicDB, dice: 0.8435741935483874
CVC-ClinicDB :  0.8435741935483874
epoch: 79, dataset: Kvasir, dice: 0.884326
Kvasir :  0.884326
epoch: 79, dataset: CVC-ColonDB, dice: 0.6674436842105264
CVC-ColonDB :  0.6674436842105264
epoch: 79, dataset: ETIS-LaribPolypDB, dice: 0.7293964285714287
ETIS-LaribPolypDB :  0.7293964285714287
2023-09-02 05:13:35.972468: train_loss -1.4534
2023-09-02 05:13:35.973930: val_loss -1.0656
2023-09-02 05:13:35.975200: Pseudo dice [0.8336]
2023-09-02 05:13:35.976106: Epoch time: 117.8 s
2023-09-02 05:13:38.876111: 
2023-09-02 05:13:38.877522: Epoch 80
2023-09-02 05:13:38.878423: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-02 05:13:38.879835: start training, 250
================num of epochs: 250================
2023-09-02 05:14:37.823355: finished training
epoch: 80, dataset: CVC-300, dice: 0.8704233333333333
CVC-300 :  0.8704233333333333
epoch: 80, dataset: CVC-ClinicDB, dice: 0.8436048387096773
CVC-ClinicDB :  0.8436048387096773
epoch: 80, dataset: Kvasir, dice: 0.8870829999999998
Kvasir :  0.8870829999999998
epoch: 80, dataset: CVC-ColonDB, dice: 0.6686121052631575
CVC-ColonDB :  0.6686121052631575
epoch: 80, dataset: ETIS-LaribPolypDB, dice: 0.754397448979592
ETIS-LaribPolypDB :  0.754397448979592
2023-09-02 05:15:33.777465: train_loss -1.4535
2023-09-02 05:15:33.779006: val_loss -0.9454
2023-09-02 05:15:33.780139: Pseudo dice [0.8014]
2023-09-02 05:15:33.781089: Epoch time: 114.9 s
2023-09-02 05:15:35.010365: 
2023-09-02 05:15:35.011841: Epoch 81
2023-09-02 05:15:35.012779: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-02 05:15:35.014097: start training, 250
================num of epochs: 250================
2023-09-02 05:16:33.435710: finished training
epoch: 81, dataset: CVC-300, dice: 0.8719083333333334
CVC-300 :  0.8719083333333334
epoch: 81, dataset: CVC-ClinicDB, dice: 0.8456822580645157
CVC-ClinicDB :  0.8456822580645157
epoch: 81, dataset: Kvasir, dice: 0.9007360000000001
Kvasir :  0.9007360000000001
epoch: 81, dataset: CVC-ColonDB, dice: 0.6537531578947366
CVC-ColonDB :  0.6537531578947366
epoch: 81, dataset: ETIS-LaribPolypDB, dice: 0.7328780612244902
ETIS-LaribPolypDB :  0.7328780612244902
2023-09-02 05:17:29.332872: train_loss -1.4504
2023-09-02 05:17:29.334362: val_loss -0.9087
2023-09-02 05:17:29.335536: Pseudo dice [0.8014]
2023-09-02 05:17:29.336542: Epoch time: 114.32 s
2023-09-02 05:17:30.559885: 
2023-09-02 05:17:30.561302: Epoch 82
2023-09-02 05:17:30.562245: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-02 05:17:30.563587: start training, 250
================num of epochs: 250================
2023-09-02 05:18:29.003495: finished training
epoch: 82, dataset: CVC-300, dice: 0.8709016666666667
CVC-300 :  0.8709016666666667
epoch: 82, dataset: CVC-ClinicDB, dice: 0.837517741935484
CVC-ClinicDB :  0.837517741935484
epoch: 82, dataset: Kvasir, dice: 0.8951250000000001
Kvasir :  0.8951250000000001
epoch: 82, dataset: CVC-ColonDB, dice: 0.6785457894736849
CVC-ColonDB :  0.6785457894736849
epoch: 82, dataset: ETIS-LaribPolypDB, dice: 0.7229923469387757
ETIS-LaribPolypDB :  0.7229923469387757
2023-09-02 05:19:22.675446: train_loss -1.4513
2023-09-02 05:19:22.677025: val_loss -1.0141
2023-09-02 05:19:22.678158: Pseudo dice [0.8221]
2023-09-02 05:19:22.679097: Epoch time: 112.12 s
2023-09-02 05:19:23.850505: 
2023-09-02 05:19:23.852116: Epoch 83
2023-09-02 05:19:23.853054: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-02 05:19:23.854360: start training, 250
================num of epochs: 250================
2023-09-02 05:20:22.332334: finished training
epoch: 83, dataset: CVC-300, dice: 0.869685
CVC-300 :  0.869685
epoch: 83, dataset: CVC-ClinicDB, dice: 0.8373693548387098
CVC-ClinicDB :  0.8373693548387098
epoch: 83, dataset: Kvasir, dice: 0.8928980000000005
Kvasir :  0.8928980000000005
epoch: 83, dataset: CVC-ColonDB, dice: 0.6726526315789471
CVC-ColonDB :  0.6726526315789471
epoch: 83, dataset: ETIS-LaribPolypDB, dice: 0.7289964285714287
ETIS-LaribPolypDB :  0.7289964285714287
2023-09-02 05:21:16.406697: train_loss -1.4533
2023-09-02 05:21:16.408306: val_loss -0.9334
2023-09-02 05:21:16.409460: Pseudo dice [0.8053]
2023-09-02 05:21:16.410425: Epoch time: 112.56 s
2023-09-02 05:21:17.581415: 
2023-09-02 05:21:17.582907: Epoch 84
2023-09-02 05:21:17.583844: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-02 05:21:17.585267: start training, 250
================num of epochs: 250================
2023-09-02 05:22:15.567084: finished training
epoch: 84, dataset: CVC-300, dice: 0.8596150000000001
CVC-300 :  0.8596150000000001
epoch: 84, dataset: CVC-ClinicDB, dice: 0.8484838709677419
CVC-ClinicDB :  0.8484838709677419
epoch: 84, dataset: Kvasir, dice: 0.881965
Kvasir :  0.881965
epoch: 84, dataset: CVC-ColonDB, dice: 0.6799407894736842
CVC-ColonDB :  0.6799407894736842
epoch: 84, dataset: ETIS-LaribPolypDB, dice: 0.7327239795918364
ETIS-LaribPolypDB :  0.7327239795918364
2023-09-02 05:23:13.195409: train_loss -1.4535
2023-09-02 05:23:13.196940: val_loss -0.9927
2023-09-02 05:23:13.198118: Pseudo dice [0.8137]
2023-09-02 05:23:13.199037: Epoch time: 115.62 s
2023-09-02 05:23:14.369078: 
2023-09-02 05:23:14.370565: Epoch 85
2023-09-02 05:23:14.371459: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-02 05:23:14.372678: start training, 250
================num of epochs: 250================
2023-09-02 05:24:12.351094: finished training
epoch: 85, dataset: CVC-300, dice: 0.8214400000000004
CVC-300 :  0.8214400000000004
epoch: 85, dataset: CVC-ClinicDB, dice: 0.8463854838709675
CVC-ClinicDB :  0.8463854838709675
epoch: 85, dataset: Kvasir, dice: 0.8719130000000003
Kvasir :  0.8719130000000003
epoch: 85, dataset: CVC-ColonDB, dice: 0.6405192105263162
CVC-ColonDB :  0.6405192105263162
epoch: 85, dataset: ETIS-LaribPolypDB, dice: 0.7485193877551025
ETIS-LaribPolypDB :  0.7485193877551025
2023-09-02 05:25:05.595091: train_loss -1.4509
2023-09-02 05:25:05.596620: val_loss -1.1153
2023-09-02 05:25:05.597744: Pseudo dice [0.8511]
2023-09-02 05:25:05.598688: Epoch time: 111.23 s
2023-09-02 05:25:06.765846: 
2023-09-02 05:25:06.767245: Epoch 86
2023-09-02 05:25:06.768149: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-02 05:25:06.769471: start training, 250
================num of epochs: 250================
2023-09-02 05:26:05.033484: finished training
epoch: 86, dataset: CVC-300, dice: 0.836648333333333
CVC-300 :  0.836648333333333
epoch: 86, dataset: CVC-ClinicDB, dice: 0.8556177419354836
CVC-ClinicDB :  0.8556177419354836
epoch: 86, dataset: Kvasir, dice: 0.8807000000000004
Kvasir :  0.8807000000000004
epoch: 86, dataset: CVC-ColonDB, dice: 0.6688457894736837
CVC-ColonDB :  0.6688457894736837
epoch: 86, dataset: ETIS-LaribPolypDB, dice: 0.7355438775510204
ETIS-LaribPolypDB :  0.7355438775510204
2023-09-02 05:27:01.553731: train_loss -1.4523
2023-09-02 05:27:01.555393: val_loss -0.9927
2023-09-02 05:27:01.556734: Pseudo dice [0.8222]
2023-09-02 05:27:01.557626: Epoch time: 114.79 s
2023-09-02 05:27:02.759947: 
2023-09-02 05:27:02.761283: Epoch 87
2023-09-02 05:27:02.762259: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-02 05:27:02.763596: start training, 250
================num of epochs: 250================
2023-09-02 05:28:00.832698: finished training
epoch: 87, dataset: CVC-300, dice: 0.8634116666666667
CVC-300 :  0.8634116666666667
epoch: 87, dataset: CVC-ClinicDB, dice: 0.8498467741935484
CVC-ClinicDB :  0.8498467741935484
epoch: 87, dataset: Kvasir, dice: 0.8799270000000005
Kvasir :  0.8799270000000005
epoch: 87, dataset: CVC-ColonDB, dice: 0.6847534210526317
CVC-ColonDB :  0.6847534210526317
epoch: 87, dataset: ETIS-LaribPolypDB, dice: 0.7295795918367348
ETIS-LaribPolypDB :  0.7295795918367348
2023-09-02 05:28:54.730737: train_loss -1.4532
2023-09-02 05:28:54.732228: val_loss -0.9674
2023-09-02 05:28:54.733375: Pseudo dice [0.8143]
2023-09-02 05:28:54.734286: Epoch time: 111.97 s
2023-09-02 05:28:55.903826: 
2023-09-02 05:28:55.905183: Epoch 88
2023-09-02 05:28:55.906135: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-02 05:28:55.907381: start training, 250
================num of epochs: 250================
2023-09-02 05:29:53.954896: finished training
epoch: 88, dataset: CVC-300, dice: 0.8963033333333332
CVC-300 :  0.8963033333333332
epoch: 88, dataset: CVC-ClinicDB, dice: 0.8493129032258065
CVC-ClinicDB :  0.8493129032258065
epoch: 88, dataset: Kvasir, dice: 0.889225
Kvasir :  0.889225
epoch: 88, dataset: CVC-ColonDB, dice: 0.6900692105263165
CVC-ColonDB :  0.6900692105263165
epoch: 88, dataset: ETIS-LaribPolypDB, dice: 0.7279479591836736
ETIS-LaribPolypDB :  0.7279479591836736
2023-09-02 05:30:47.596997: train_loss -1.454
2023-09-02 05:30:47.598327: val_loss -0.9609
2023-09-02 05:30:47.599419: Pseudo dice [0.8089]
2023-09-02 05:30:47.600284: Epoch time: 111.69 s
2023-09-02 05:30:48.770338: 
2023-09-02 05:30:48.771772: Epoch 89
2023-09-02 05:30:48.772685: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-02 05:30:48.773943: start training, 250
================num of epochs: 250================
2023-09-02 05:31:47.037194: finished training
epoch: 89, dataset: CVC-300, dice: 0.8366983333333333
CVC-300 :  0.8366983333333333
epoch: 89, dataset: CVC-ClinicDB, dice: 0.8411016129032259
CVC-ClinicDB :  0.8411016129032259
epoch: 89, dataset: Kvasir, dice: 0.8893080000000001
Kvasir :  0.8893080000000001
epoch: 89, dataset: CVC-ColonDB, dice: 0.6535673684210535
CVC-ColonDB :  0.6535673684210535
epoch: 89, dataset: ETIS-LaribPolypDB, dice: 0.7064173469387754
ETIS-LaribPolypDB :  0.7064173469387754
2023-09-02 05:32:40.387668: train_loss -1.4552
2023-09-02 05:32:40.389020: val_loss -0.924
2023-09-02 05:32:40.390167: Pseudo dice [0.8044]
2023-09-02 05:32:40.391062: Epoch time: 111.62 s
2023-09-02 05:32:43.151935: 
2023-09-02 05:32:43.153350: Epoch 90
2023-09-02 05:32:43.154232: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-02 05:32:43.155603: start training, 250
================num of epochs: 250================
2023-09-02 05:33:41.223548: finished training
epoch: 90, dataset: CVC-300, dice: 0.8831200000000002
CVC-300 :  0.8831200000000002
epoch: 90, dataset: CVC-ClinicDB, dice: 0.8454903225806449
CVC-ClinicDB :  0.8454903225806449
epoch: 90, dataset: Kvasir, dice: 0.893425
Kvasir :  0.893425
epoch: 90, dataset: CVC-ColonDB, dice: 0.678622631578948
CVC-ColonDB :  0.678622631578948
epoch: 90, dataset: ETIS-LaribPolypDB, dice: 0.7117683673469387
ETIS-LaribPolypDB :  0.7117683673469387
2023-09-02 05:34:32.382814: train_loss -1.4559
2023-09-02 05:34:32.384332: val_loss -0.9446
2023-09-02 05:34:32.385494: Pseudo dice [0.8109]
2023-09-02 05:34:32.386447: Epoch time: 109.23 s
2023-09-02 05:34:33.528667: 
2023-09-02 05:34:33.530027: Epoch 91
2023-09-02 05:34:33.531008: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-02 05:34:33.532319: start training, 250
================num of epochs: 250================
2023-09-02 05:35:31.707796: finished training
epoch: 91, dataset: CVC-300, dice: 0.8779516666666667
CVC-300 :  0.8779516666666667
epoch: 91, dataset: CVC-ClinicDB, dice: 0.8599709677419356
CVC-ClinicDB :  0.8599709677419356
epoch: 91, dataset: Kvasir, dice: 0.8837409999999996
Kvasir :  0.8837409999999996
epoch: 91, dataset: CVC-ColonDB, dice: 0.6946323684210524
CVC-ColonDB :  0.6946323684210524
epoch: 91, dataset: ETIS-LaribPolypDB, dice: 0.7474872448979596
ETIS-LaribPolypDB :  0.7474872448979596
2023-09-02 05:36:27.750621: train_loss -1.4562
2023-09-02 05:36:27.752238: val_loss -1.0651
2023-09-02 05:36:27.753452: Pseudo dice [0.8438]
2023-09-02 05:36:27.754442: Epoch time: 114.22 s
2023-09-02 05:36:28.951812: 
2023-09-02 05:36:28.953176: Epoch 92
2023-09-02 05:36:28.954086: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-02 05:36:28.955517: start training, 250
================num of epochs: 250================
2023-09-02 05:37:27.271674: finished training
epoch: 92, dataset: CVC-300, dice: 0.8643716666666666
CVC-300 :  0.8643716666666666
epoch: 92, dataset: CVC-ClinicDB, dice: 0.8589612903225803
CVC-ClinicDB :  0.8589612903225803
epoch: 92, dataset: Kvasir, dice: 0.8798789999999999
Kvasir :  0.8798789999999999
epoch: 92, dataset: CVC-ColonDB, dice: 0.6778942105263164
CVC-ColonDB :  0.6778942105263164
epoch: 92, dataset: ETIS-LaribPolypDB, dice: 0.7070265306122452
ETIS-LaribPolypDB :  0.7070265306122452
2023-09-02 05:38:20.481032: train_loss -1.4564
2023-09-02 05:38:20.482512: val_loss -1.1074
2023-09-02 05:38:20.484410: Pseudo dice [0.8477]
2023-09-02 05:38:20.486514: Epoch time: 111.53 s
2023-09-02 05:38:20.487688: Yayy! New best EMA pseudo Dice: 0.821
2023-09-02 05:38:23.270084: 
2023-09-02 05:38:23.271679: Epoch 93
2023-09-02 05:38:23.272605: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-02 05:38:23.274026: start training, 250
================num of epochs: 250================
2023-09-02 05:39:21.326906: finished training
epoch: 93, dataset: CVC-300, dice: 0.8739900000000004
CVC-300 :  0.8739900000000004
epoch: 93, dataset: CVC-ClinicDB, dice: 0.8660967741935485
CVC-ClinicDB :  0.8660967741935485
epoch: 93, dataset: Kvasir, dice: 0.8937599999999998
Kvasir :  0.8937599999999998
epoch: 93, dataset: CVC-ColonDB, dice: 0.695688684210527
CVC-ColonDB :  0.695688684210527
epoch: 93, dataset: ETIS-LaribPolypDB, dice: 0.7155836734693878
ETIS-LaribPolypDB :  0.7155836734693878
2023-09-02 05:40:14.372417: train_loss -1.4569
2023-09-02 05:40:14.373880: val_loss -1.0198
2023-09-02 05:40:14.375097: Pseudo dice [0.8227]
2023-09-02 05:40:14.376041: Epoch time: 111.1 s
2023-09-02 05:40:14.376881: Yayy! New best EMA pseudo Dice: 0.8211
2023-09-02 05:40:17.146394: 
2023-09-02 05:40:17.147830: Epoch 94
2023-09-02 05:40:17.148813: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-02 05:40:17.150129: start training, 250
================num of epochs: 250================
2023-09-02 05:41:15.170604: finished training
epoch: 94, dataset: CVC-300, dice: 0.8592000000000002
CVC-300 :  0.8592000000000002
epoch: 94, dataset: CVC-ClinicDB, dice: 0.866540322580645
CVC-ClinicDB :  0.866540322580645
epoch: 94, dataset: Kvasir, dice: 0.8733309999999996
Kvasir :  0.8733309999999996
epoch: 94, dataset: CVC-ColonDB, dice: 0.7104597368421052
CVC-ColonDB :  0.7104597368421052
epoch: 94, dataset: ETIS-LaribPolypDB, dice: 0.7335556122448981
ETIS-LaribPolypDB :  0.7335556122448981
2023-09-02 05:42:08.492094: train_loss -1.4564
2023-09-02 05:42:08.493575: val_loss -1.0924
2023-09-02 05:42:08.494738: Pseudo dice [0.8422]
2023-09-02 05:42:08.495647: Epoch time: 111.35 s
2023-09-02 05:42:08.496468: Yayy! New best EMA pseudo Dice: 0.8232
2023-09-02 05:42:11.282499: 
2023-09-02 05:42:11.283893: Epoch 95
2023-09-02 05:42:11.284828: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-02 05:42:11.286141: start training, 250
================num of epochs: 250================
2023-09-02 05:43:09.520168: finished training
epoch: 95, dataset: CVC-300, dice: 0.8667583333333332
CVC-300 :  0.8667583333333332
epoch: 95, dataset: CVC-ClinicDB, dice: 0.8621338709677417
CVC-ClinicDB :  0.8621338709677417
epoch: 95, dataset: Kvasir, dice: 0.8917810000000004
Kvasir :  0.8917810000000004
epoch: 95, dataset: CVC-ColonDB, dice: 0.7111513157894743
CVC-ColonDB :  0.7111513157894743
epoch: 95, dataset: ETIS-LaribPolypDB, dice: 0.7522688775510206
ETIS-LaribPolypDB :  0.7522688775510206
2023-09-02 05:44:03.059023: train_loss -1.4568
2023-09-02 05:44:03.060622: val_loss -1.1599
2023-09-02 05:44:03.062030: Pseudo dice [0.8699]
2023-09-02 05:44:03.063031: Epoch time: 111.78 s
2023-09-02 05:44:03.064315: Yayy! New best EMA pseudo Dice: 0.8279
2023-09-02 05:44:05.872674: 
2023-09-02 05:44:05.874182: Epoch 96
2023-09-02 05:44:05.875092: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-02 05:44:05.876524: start training, 250
================num of epochs: 250================
2023-09-02 05:45:04.024527: finished training
epoch: 96, dataset: CVC-300, dice: 0.8655566666666668
CVC-300 :  0.8655566666666668
epoch: 96, dataset: CVC-ClinicDB, dice: 0.8638419354838709
CVC-ClinicDB :  0.8638419354838709
epoch: 96, dataset: Kvasir, dice: 0.8985450000000001
Kvasir :  0.8985450000000001
epoch: 96, dataset: CVC-ColonDB, dice: 0.6772744736842102
CVC-ColonDB :  0.6772744736842102
epoch: 96, dataset: ETIS-LaribPolypDB, dice: 0.7413688775510208
ETIS-LaribPolypDB :  0.7413688775510208
2023-09-02 05:45:57.194897: train_loss -1.4577
2023-09-02 05:45:57.196322: val_loss -0.9873
2023-09-02 05:45:57.198082: Pseudo dice [0.8195]
2023-09-02 05:45:57.199172: Epoch time: 111.32 s
2023-09-02 05:45:58.414306: 
2023-09-02 05:45:58.415685: Epoch 97
2023-09-02 05:45:58.416595: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-02 05:45:58.418512: start training, 250
================num of epochs: 250================
2023-09-02 05:46:56.409597: finished training
epoch: 97, dataset: CVC-300, dice: 0.8587883333333333
CVC-300 :  0.8587883333333333
epoch: 97, dataset: CVC-ClinicDB, dice: 0.861782258064516
CVC-ClinicDB :  0.861782258064516
epoch: 97, dataset: Kvasir, dice: 0.8986530000000004
Kvasir :  0.8986530000000004
epoch: 97, dataset: CVC-ColonDB, dice: 0.6831750000000001
CVC-ColonDB :  0.6831750000000001
epoch: 97, dataset: ETIS-LaribPolypDB, dice: 0.7232653061224493
ETIS-LaribPolypDB :  0.7232653061224493
2023-09-02 05:47:49.283043: train_loss -1.4573
2023-09-02 05:47:49.284564: val_loss -0.9987
2023-09-02 05:47:49.285744: Pseudo dice [0.8237]
2023-09-02 05:47:49.286670: Epoch time: 110.87 s
2023-09-02 05:47:50.480546: 
2023-09-02 05:47:50.481934: Epoch 98
2023-09-02 05:47:50.482898: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-02 05:47:50.484221: start training, 250
================num of epochs: 250================
2023-09-02 05:48:48.613604: finished training
epoch: 98, dataset: CVC-300, dice: 0.7980550000000002
CVC-300 :  0.7980550000000002
epoch: 98, dataset: CVC-ClinicDB, dice: 0.826282258064516
CVC-ClinicDB :  0.826282258064516
epoch: 98, dataset: Kvasir, dice: 0.8687039999999999
Kvasir :  0.8687039999999999
epoch: 98, dataset: CVC-ColonDB, dice: 0.6411792105263161
CVC-ColonDB :  0.6411792105263161
epoch: 98, dataset: ETIS-LaribPolypDB, dice: 0.6881790816326534
ETIS-LaribPolypDB :  0.6881790816326534
2023-09-02 05:49:41.885469: train_loss -1.4554
2023-09-02 05:49:41.886809: val_loss -0.947
2023-09-02 05:49:41.887944: Pseudo dice [0.8011]
2023-09-02 05:49:41.888889: Epoch time: 111.41 s
2023-09-02 05:49:43.073793: 
2023-09-02 05:49:43.075331: Epoch 99
2023-09-02 05:49:43.076326: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-02 05:49:43.077602: start training, 250
================num of epochs: 250================
2023-09-02 05:50:41.031610: finished training
epoch: 99, dataset: CVC-300, dice: 0.8263600000000003
CVC-300 :  0.8263600000000003
epoch: 99, dataset: CVC-ClinicDB, dice: 0.8479596774193549
CVC-ClinicDB :  0.8479596774193549
epoch: 99, dataset: Kvasir, dice: 0.8812399999999994
Kvasir :  0.8812399999999994
epoch: 99, dataset: CVC-ColonDB, dice: 0.6705913157894741
CVC-ColonDB :  0.6705913157894741
epoch: 99, dataset: ETIS-LaribPolypDB, dice: 0.7025566326530613
ETIS-LaribPolypDB :  0.7025566326530613
2023-09-02 05:51:32.016885: train_loss -1.454
2023-09-02 05:51:32.018321: val_loss -0.951
2023-09-02 05:51:32.019512: Pseudo dice [0.8033]
2023-09-02 05:51:32.020430: Epoch time: 108.94 s
2023-09-02 05:51:34.783847: 
2023-09-02 05:51:34.785173: Epoch 100
2023-09-02 05:51:34.786141: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-02 05:51:34.787445: start training, 250
================num of epochs: 250================
2023-09-02 05:52:32.793847: finished training
epoch: 100, dataset: CVC-300, dice: 0.8602183333333333
CVC-300 :  0.8602183333333333
epoch: 100, dataset: CVC-ClinicDB, dice: 0.8442
CVC-ClinicDB :  0.8442
epoch: 100, dataset: Kvasir, dice: 0.8838879999999996
Kvasir :  0.8838879999999996
epoch: 100, dataset: CVC-ColonDB, dice: 0.6635539473684215
CVC-ColonDB :  0.6635539473684215
epoch: 100, dataset: ETIS-LaribPolypDB, dice: 0.7143147959183678
ETIS-LaribPolypDB :  0.7143147959183678
2023-09-02 05:53:23.874280: train_loss -1.4557
2023-09-02 05:53:23.875715: val_loss -1.0462
2023-09-02 05:53:23.876882: Pseudo dice [0.8291]
2023-09-02 05:53:23.877830: Epoch time: 109.09 s
2023-09-02 05:53:25.279463: 
2023-09-02 05:53:25.280961: Epoch 101
2023-09-02 05:53:25.282009: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-02 05:53:25.283350: start training, 250
================num of epochs: 250================
2023-09-02 05:54:23.322173: finished training
epoch: 101, dataset: CVC-300, dice: 0.8511116666666668
CVC-300 :  0.8511116666666668
epoch: 101, dataset: CVC-ClinicDB, dice: 0.863783870967742
CVC-ClinicDB :  0.863783870967742
epoch: 101, dataset: Kvasir, dice: 0.8891140000000002
Kvasir :  0.8891140000000002
epoch: 101, dataset: CVC-ColonDB, dice: 0.6654060526315789
CVC-ColonDB :  0.6654060526315789
epoch: 101, dataset: ETIS-LaribPolypDB, dice: 0.7293964285714287
ETIS-LaribPolypDB :  0.7293964285714287
2023-09-02 05:55:14.928211: train_loss -1.4573
2023-09-02 05:55:14.929883: val_loss -1.0272
2023-09-02 05:55:14.931133: Pseudo dice [0.8388]
2023-09-02 05:55:14.932110: Epoch time: 109.65 s
2023-09-02 05:55:16.100458: 
2023-09-02 05:55:16.101849: Epoch 102
2023-09-02 05:55:16.102833: Current learning rate: backbone 0.000688, others 0.000688
2023-09-02 05:55:16.104112: start training, 250
================num of epochs: 250================
2023-09-02 05:56:14.052605: finished training
epoch: 102, dataset: CVC-300, dice: 0.8478866666666665
CVC-300 :  0.8478866666666665
epoch: 102, dataset: CVC-ClinicDB, dice: 0.8664870967741933
CVC-ClinicDB :  0.8664870967741933
epoch: 102, dataset: Kvasir, dice: 0.8964529999999999
Kvasir :  0.8964529999999999
epoch: 102, dataset: CVC-ColonDB, dice: 0.670473157894737
CVC-ColonDB :  0.670473157894737
epoch: 102, dataset: ETIS-LaribPolypDB, dice: 0.7104270408163269
ETIS-LaribPolypDB :  0.7104270408163269
2023-09-02 05:57:07.691457: train_loss -1.4578
2023-09-02 05:57:07.693132: val_loss -0.9788
2023-09-02 05:57:07.694265: Pseudo dice [0.8179]
2023-09-02 05:57:07.695179: Epoch time: 111.59 s
2023-09-02 05:57:08.878752: 
2023-09-02 05:57:08.880174: Epoch 103
2023-09-02 05:57:08.881129: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-02 05:57:08.882462: start training, 250
================num of epochs: 250================
2023-09-02 05:58:06.868205: finished training
epoch: 103, dataset: CVC-300, dice: 0.8614166666666665
CVC-300 :  0.8614166666666665
epoch: 103, dataset: CVC-ClinicDB, dice: 0.8644709677419355
CVC-ClinicDB :  0.8644709677419355
epoch: 103, dataset: Kvasir, dice: 0.8976869999999996
Kvasir :  0.8976869999999996
epoch: 103, dataset: CVC-ColonDB, dice: 0.6961831578947374
CVC-ColonDB :  0.6961831578947374
epoch: 103, dataset: ETIS-LaribPolypDB, dice: 0.733598469387755
ETIS-LaribPolypDB :  0.733598469387755
2023-09-02 05:59:01.160864: train_loss -1.459
2023-09-02 05:59:01.162362: val_loss -1.0001
2023-09-02 05:59:01.163598: Pseudo dice [0.8222]
2023-09-02 05:59:01.164564: Epoch time: 112.28 s
2023-09-02 05:59:02.349834: 
2023-09-02 05:59:02.351191: Epoch 104
2023-09-02 05:59:02.352228: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-02 05:59:02.353598: start training, 250
================num of epochs: 250================
2023-09-02 06:00:00.702632: finished training
epoch: 104, dataset: CVC-300, dice: 0.8556783333333333
CVC-300 :  0.8556783333333333
epoch: 104, dataset: CVC-ClinicDB, dice: 0.8617483870967739
CVC-ClinicDB :  0.8617483870967739
epoch: 104, dataset: Kvasir, dice: 0.8770850000000003
Kvasir :  0.8770850000000003
epoch: 104, dataset: CVC-ColonDB, dice: 0.6869107894736849
CVC-ColonDB :  0.6869107894736849
epoch: 104, dataset: ETIS-LaribPolypDB, dice: 0.7412408163265312
ETIS-LaribPolypDB :  0.7412408163265312
2023-09-02 06:00:54.036225: train_loss -1.4583
2023-09-02 06:00:54.037742: val_loss -0.8583
2023-09-02 06:00:54.038891: Pseudo dice [0.7876]
2023-09-02 06:00:54.039816: Epoch time: 111.69 s
2023-09-02 06:00:55.200087: 
2023-09-02 06:00:55.201606: Epoch 105
2023-09-02 06:00:55.202549: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-02 06:00:55.203983: start training, 250
================num of epochs: 250================
2023-09-02 06:01:53.243013: finished training
epoch: 105, dataset: CVC-300, dice: 0.8585600000000002
CVC-300 :  0.8585600000000002
epoch: 105, dataset: CVC-ClinicDB, dice: 0.8480645161290322
CVC-ClinicDB :  0.8480645161290322
epoch: 105, dataset: Kvasir, dice: 0.895394
Kvasir :  0.895394
epoch: 105, dataset: CVC-ColonDB, dice: 0.6752381578947381
CVC-ColonDB :  0.6752381578947381
epoch: 105, dataset: ETIS-LaribPolypDB, dice: 0.702864285714286
ETIS-LaribPolypDB :  0.702864285714286
2023-09-02 06:02:46.460759: train_loss -1.4586
2023-09-02 06:02:46.462329: val_loss -0.9103
2023-09-02 06:02:46.463771: Pseudo dice [0.798]
2023-09-02 06:02:46.464678: Epoch time: 111.26 s
2023-09-02 06:02:47.675055: 
2023-09-02 06:02:47.677169: Epoch 106
2023-09-02 06:02:47.678572: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-02 06:02:47.680547: start training, 250
================num of epochs: 250================
2023-09-02 06:03:45.564200: finished training
epoch: 106, dataset: CVC-300, dice: 0.855956666666667
CVC-300 :  0.855956666666667
epoch: 106, dataset: CVC-ClinicDB, dice: 0.859582258064516
CVC-ClinicDB :  0.859582258064516
epoch: 106, dataset: Kvasir, dice: 0.8967689999999999
Kvasir :  0.8967689999999999
epoch: 106, dataset: CVC-ColonDB, dice: 0.6750113157894739
CVC-ColonDB :  0.6750113157894739
epoch: 106, dataset: ETIS-LaribPolypDB, dice: 0.7079510204081634
ETIS-LaribPolypDB :  0.7079510204081634
2023-09-02 06:04:39.444514: train_loss -1.4589
2023-09-02 06:04:39.445953: val_loss -0.9403
2023-09-02 06:04:39.447108: Pseudo dice [0.8136]
2023-09-02 06:04:39.448013: Epoch time: 111.77 s
2023-09-02 06:04:40.639558: 
2023-09-02 06:04:40.640920: Epoch 107
2023-09-02 06:04:40.641904: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-02 06:04:40.643273: start training, 250
================num of epochs: 250================
2023-09-02 06:05:38.728706: finished training
epoch: 107, dataset: CVC-300, dice: 0.8609833333333333
CVC-300 :  0.8609833333333333
epoch: 107, dataset: CVC-ClinicDB, dice: 0.8506241935483873
CVC-ClinicDB :  0.8506241935483873
epoch: 107, dataset: Kvasir, dice: 0.8914409999999998
Kvasir :  0.8914409999999998
epoch: 107, dataset: CVC-ColonDB, dice: 0.6669400000000005
CVC-ColonDB :  0.6669400000000005
epoch: 107, dataset: ETIS-LaribPolypDB, dice: 0.7019040816326533
ETIS-LaribPolypDB :  0.7019040816326533
2023-09-02 06:06:32.488774: train_loss -1.4586
2023-09-02 06:06:32.490384: val_loss -1.0096
2023-09-02 06:06:32.491526: Pseudo dice [0.8315]
2023-09-02 06:06:32.492464: Epoch time: 111.85 s
2023-09-02 06:06:33.677821: 
2023-09-02 06:06:33.679318: Epoch 108
2023-09-02 06:06:33.680278: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-02 06:06:33.681649: start training, 250
================num of epochs: 250================
2023-09-02 06:07:31.558588: finished training
epoch: 108, dataset: CVC-300, dice: 0.8744083333333335
CVC-300 :  0.8744083333333335
epoch: 108, dataset: CVC-ClinicDB, dice: 0.8573419354838713
CVC-ClinicDB :  0.8573419354838713
epoch: 108, dataset: Kvasir, dice: 0.8963239999999999
Kvasir :  0.8963239999999999
epoch: 108, dataset: CVC-ColonDB, dice: 0.6769855263157898
CVC-ColonDB :  0.6769855263157898
epoch: 108, dataset: ETIS-LaribPolypDB, dice: 0.7388066326530615
ETIS-LaribPolypDB :  0.7388066326530615
2023-09-02 06:08:25.886671: train_loss -1.4592
2023-09-02 06:08:25.888197: val_loss -0.9545
2023-09-02 06:08:25.889357: Pseudo dice [0.8241]
2023-09-02 06:08:25.890291: Epoch time: 112.21 s
2023-09-02 06:08:27.085989: 
2023-09-02 06:08:27.087266: Epoch 109
2023-09-02 06:08:27.088219: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-02 06:08:27.089520: start training, 250
================num of epochs: 250================
2023-09-02 06:09:24.942066: finished training
epoch: 109, dataset: CVC-300, dice: 0.8721683333333332
CVC-300 :  0.8721683333333332
epoch: 109, dataset: CVC-ClinicDB, dice: 0.8584290322580647
CVC-ClinicDB :  0.8584290322580647
epoch: 109, dataset: Kvasir, dice: 0.8968150000000001
Kvasir :  0.8968150000000001
epoch: 109, dataset: CVC-ColonDB, dice: 0.6742150000000003
CVC-ColonDB :  0.6742150000000003
epoch: 109, dataset: ETIS-LaribPolypDB, dice: 0.7034571428571429
ETIS-LaribPolypDB :  0.7034571428571429
2023-09-02 06:10:18.952531: train_loss -1.4592
2023-09-02 06:10:18.954004: val_loss -0.9823
2023-09-02 06:10:18.955129: Pseudo dice [0.822]
2023-09-02 06:10:18.956035: Epoch time: 111.87 s
2023-09-02 06:10:21.776401: 
2023-09-02 06:10:21.777828: Epoch 110
2023-09-02 06:10:21.778802: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-02 06:10:21.780092: start training, 250
================num of epochs: 250================
2023-09-02 06:11:19.801297: finished training
epoch: 110, dataset: CVC-300, dice: 0.8634616666666669
CVC-300 :  0.8634616666666669
epoch: 110, dataset: CVC-ClinicDB, dice: 0.8626612903225805
CVC-ClinicDB :  0.8626612903225805
epoch: 110, dataset: Kvasir, dice: 0.8988
Kvasir :  0.8988
epoch: 110, dataset: CVC-ColonDB, dice: 0.6778610526315793
CVC-ColonDB :  0.6778610526315793
epoch: 110, dataset: ETIS-LaribPolypDB, dice: 0.7322704081632655
ETIS-LaribPolypDB :  0.7322704081632655
2023-09-02 06:12:14.130006: train_loss -1.4596
2023-09-02 06:12:14.131545: val_loss -1.0151
2023-09-02 06:12:14.132806: Pseudo dice [0.8327]
2023-09-02 06:12:14.133791: Epoch time: 112.35 s
2023-09-02 06:12:15.344948: 
2023-09-02 06:12:15.346457: Epoch 111
2023-09-02 06:12:15.347371: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-02 06:12:15.348667: start training, 250
================num of epochs: 250================
2023-09-02 06:13:13.137808: finished training
epoch: 111, dataset: CVC-300, dice: 0.8777066666666667
CVC-300 :  0.8777066666666667
epoch: 111, dataset: CVC-ClinicDB, dice: 0.8674725806451612
CVC-ClinicDB :  0.8674725806451612
epoch: 111, dataset: Kvasir, dice: 0.896079
Kvasir :  0.896079
epoch: 111, dataset: CVC-ColonDB, dice: 0.6827544736842106
CVC-ColonDB :  0.6827544736842106
epoch: 111, dataset: ETIS-LaribPolypDB, dice: 0.7401821428571435
ETIS-LaribPolypDB :  0.7401821428571435
2023-09-02 06:14:07.025165: train_loss -1.4597
2023-09-02 06:14:07.026626: val_loss -0.9994
2023-09-02 06:14:07.027795: Pseudo dice [0.8285]
2023-09-02 06:14:07.029050: Epoch time: 111.68 s
2023-09-02 06:14:08.265340: 
2023-09-02 06:14:08.266940: Epoch 112
2023-09-02 06:14:08.267955: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-02 06:14:08.269431: start training, 250
================num of epochs: 250================
2023-09-02 06:15:06.188315: finished training
epoch: 112, dataset: CVC-300, dice: 0.8741116666666666
CVC-300 :  0.8741116666666666
epoch: 112, dataset: CVC-ClinicDB, dice: 0.8621241935483868
CVC-ClinicDB :  0.8621241935483868
epoch: 112, dataset: Kvasir, dice: 0.9003280000000004
Kvasir :  0.9003280000000004
epoch: 112, dataset: CVC-ColonDB, dice: 0.6905602631578949
CVC-ColonDB :  0.6905602631578949
epoch: 112, dataset: ETIS-LaribPolypDB, dice: 0.7258479591836736
ETIS-LaribPolypDB :  0.7258479591836736
2023-09-02 06:16:00.121547: train_loss -1.4605
2023-09-02 06:16:00.123137: val_loss -0.9922
2023-09-02 06:16:00.124456: Pseudo dice [0.8273]
2023-09-02 06:16:00.125445: Epoch time: 111.86 s
2023-09-02 06:16:01.351985: 
2023-09-02 06:16:01.353442: Epoch 113
2023-09-02 06:16:01.354450: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-02 06:16:01.356027: start training, 250
================num of epochs: 250================
2023-09-02 06:16:59.286561: finished training
epoch: 113, dataset: CVC-300, dice: 0.8651216666666667
CVC-300 :  0.8651216666666667
epoch: 113, dataset: CVC-ClinicDB, dice: 0.8671822580645159
CVC-ClinicDB :  0.8671822580645159
epoch: 113, dataset: Kvasir, dice: 0.8907530000000001
Kvasir :  0.8907530000000001
epoch: 113, dataset: CVC-ColonDB, dice: 0.6945284210526322
CVC-ColonDB :  0.6945284210526322
epoch: 113, dataset: ETIS-LaribPolypDB, dice: 0.7190734693877555
ETIS-LaribPolypDB :  0.7190734693877555
2023-09-02 06:17:53.211677: train_loss -1.4596
2023-09-02 06:17:53.213581: val_loss -0.9806
2023-09-02 06:17:53.215447: Pseudo dice [0.8186]
2023-09-02 06:17:53.216928: Epoch time: 111.86 s
2023-09-02 06:17:54.784743: 
2023-09-02 06:17:54.786316: Epoch 114
2023-09-02 06:17:54.787398: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-02 06:17:54.788756: start training, 250
================num of epochs: 250================
2023-09-02 06:18:52.763605: finished training
epoch: 114, dataset: CVC-300, dice: 0.8751550000000002
CVC-300 :  0.8751550000000002
epoch: 114, dataset: CVC-ClinicDB, dice: 0.8556209677419355
CVC-ClinicDB :  0.8556209677419355
epoch: 114, dataset: Kvasir, dice: 0.8951159999999996
Kvasir :  0.8951159999999996
epoch: 114, dataset: CVC-ColonDB, dice: 0.696164210526316
CVC-ColonDB :  0.696164210526316
epoch: 114, dataset: ETIS-LaribPolypDB, dice: 0.7015117346938776
ETIS-LaribPolypDB :  0.7015117346938776
2023-09-02 06:19:46.598473: train_loss -1.4597
2023-09-02 06:19:46.599992: val_loss -0.887
2023-09-02 06:19:46.601197: Pseudo dice [0.7917]
2023-09-02 06:19:46.602114: Epoch time: 111.82 s
2023-09-02 06:19:47.827130: 
2023-09-02 06:19:47.828894: Epoch 115
2023-09-02 06:19:47.829900: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-02 06:19:47.831239: start training, 250
================num of epochs: 250================
2023-09-02 06:20:45.763335: finished training
epoch: 115, dataset: CVC-300, dice: 0.865466666666667
CVC-300 :  0.865466666666667
epoch: 115, dataset: CVC-ClinicDB, dice: 0.8705612903225807
CVC-ClinicDB :  0.8705612903225807
epoch: 115, dataset: Kvasir, dice: 0.9008240000000004
Kvasir :  0.9008240000000004
epoch: 115, dataset: CVC-ColonDB, dice: 0.7099321052631576
CVC-ColonDB :  0.7099321052631576
epoch: 115, dataset: ETIS-LaribPolypDB, dice: 0.7317045918367341
ETIS-LaribPolypDB :  0.7317045918367341
2023-09-02 06:21:39.140153: train_loss -1.4594
2023-09-02 06:21:39.141747: val_loss -0.9635
2023-09-02 06:21:39.143021: Pseudo dice [0.8195]
2023-09-02 06:21:39.143976: Epoch time: 111.31 s
2023-09-02 06:21:40.371489: 
2023-09-02 06:21:40.372988: Epoch 116
2023-09-02 06:21:40.374009: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-02 06:21:40.375436: start training, 250
================num of epochs: 250================
2023-09-02 06:22:38.362646: finished training
epoch: 116, dataset: CVC-300, dice: 0.8586683333333334
CVC-300 :  0.8586683333333334
epoch: 116, dataset: CVC-ClinicDB, dice: 0.8670645161290322
CVC-ClinicDB :  0.8670645161290322
epoch: 116, dataset: Kvasir, dice: 0.8944639999999998
Kvasir :  0.8944639999999998
epoch: 116, dataset: CVC-ColonDB, dice: 0.6984581578947375
CVC-ColonDB :  0.6984581578947375
epoch: 116, dataset: ETIS-LaribPolypDB, dice: 0.7159464285714292
ETIS-LaribPolypDB :  0.7159464285714292
2023-09-02 06:23:31.068967: train_loss -1.461
2023-09-02 06:23:31.070589: val_loss -1.0033
2023-09-02 06:23:31.071909: Pseudo dice [0.8245]
2023-09-02 06:23:31.072917: Epoch time: 110.7 s
2023-09-02 06:23:32.586245: 
2023-09-02 06:23:32.587867: Epoch 117
2023-09-02 06:23:32.588835: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-02 06:23:32.590089: start training, 250
================num of epochs: 250================
2023-09-02 06:24:30.574933: finished training
epoch: 117, dataset: CVC-300, dice: 0.86556
CVC-300 :  0.86556
epoch: 117, dataset: CVC-ClinicDB, dice: 0.863958064516129
CVC-ClinicDB :  0.863958064516129
epoch: 117, dataset: Kvasir, dice: 0.8978640000000004
Kvasir :  0.8978640000000004
epoch: 117, dataset: CVC-ColonDB, dice: 0.7035815789473683
CVC-ColonDB :  0.7035815789473683
epoch: 117, dataset: ETIS-LaribPolypDB, dice: 0.7173280612244901
ETIS-LaribPolypDB :  0.7173280612244901
2023-09-02 06:25:23.839155: train_loss -1.4606
2023-09-02 06:25:23.840763: val_loss -1.0018
2023-09-02 06:25:23.841991: Pseudo dice [0.8353]
2023-09-02 06:25:23.843001: Epoch time: 111.25 s
2023-09-02 06:25:25.087693: 
2023-09-02 06:25:25.089081: Epoch 118
2023-09-02 06:25:25.090046: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-02 06:25:25.091478: start training, 250
================num of epochs: 250================
2023-09-02 06:26:23.255374: finished training
epoch: 118, dataset: CVC-300, dice: 0.8629399999999999
CVC-300 :  0.8629399999999999
epoch: 118, dataset: CVC-ClinicDB, dice: 0.8694951612903226
CVC-ClinicDB :  0.8694951612903226
epoch: 118, dataset: Kvasir, dice: 0.8978369999999992
Kvasir :  0.8978369999999992
epoch: 118, dataset: CVC-ColonDB, dice: 0.7014623684210529
CVC-ColonDB :  0.7014623684210529
epoch: 118, dataset: ETIS-LaribPolypDB, dice: 0.7200739795918367
ETIS-LaribPolypDB :  0.7200739795918367
2023-09-02 06:27:19.719388: train_loss -1.4616
2023-09-02 06:27:19.743011: val_loss -0.9979
2023-09-02 06:27:19.744897: Pseudo dice [0.8256]
2023-09-02 06:27:19.746166: Epoch time: 114.63 s
2023-09-02 06:27:20.982993: 
2023-09-02 06:27:20.984596: Epoch 119
2023-09-02 06:27:20.985578: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-02 06:27:20.987005: start training, 250
================num of epochs: 250================
2023-09-02 06:28:19.120154: finished training
epoch: 119, dataset: CVC-300, dice: 0.8694100000000002
CVC-300 :  0.8694100000000002
epoch: 119, dataset: CVC-ClinicDB, dice: 0.8664629032258068
CVC-ClinicDB :  0.8664629032258068
epoch: 119, dataset: Kvasir, dice: 0.901372
Kvasir :  0.901372
epoch: 119, dataset: CVC-ColonDB, dice: 0.7076692105263157
CVC-ColonDB :  0.7076692105263157
epoch: 119, dataset: ETIS-LaribPolypDB, dice: 0.7278107142857146
ETIS-LaribPolypDB :  0.7278107142857146
2023-09-02 06:29:13.104228: train_loss -1.4615
2023-09-02 06:29:13.105747: val_loss -0.9947
2023-09-02 06:29:13.106998: Pseudo dice [0.8245]
2023-09-02 06:29:13.108004: Epoch time: 112.12 s
2023-09-02 06:29:16.343695: 
2023-09-02 06:29:16.345180: Epoch 120
2023-09-02 06:29:16.346146: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-02 06:29:16.347412: start training, 250
================num of epochs: 250================
2023-09-02 06:30:14.402153: finished training
epoch: 120, dataset: CVC-300, dice: 0.8734749999999996
CVC-300 :  0.8734749999999996
epoch: 120, dataset: CVC-ClinicDB, dice: 0.8660677419354839
CVC-ClinicDB :  0.8660677419354839
epoch: 120, dataset: Kvasir, dice: 0.8997100000000002
Kvasir :  0.8997100000000002
epoch: 120, dataset: CVC-ColonDB, dice: 0.7039523684210527
CVC-ColonDB :  0.7039523684210527
epoch: 120, dataset: ETIS-LaribPolypDB, dice: 0.7318280612244896
ETIS-LaribPolypDB :  0.7318280612244896
2023-09-02 06:31:06.458668: train_loss -1.4621
2023-09-02 06:31:06.460176: val_loss -0.9201
2023-09-02 06:31:06.461409: Pseudo dice [0.8187]
2023-09-02 06:31:06.462402: Epoch time: 110.12 s
2023-09-02 06:31:07.675969: 
2023-09-02 06:31:07.677544: Epoch 121
2023-09-02 06:31:07.678535: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-02 06:31:07.679883: start training, 250
================num of epochs: 250================
2023-09-02 06:32:05.727525: finished training
epoch: 121, dataset: CVC-300, dice: 0.8849583333333333
CVC-300 :  0.8849583333333333
epoch: 121, dataset: CVC-ClinicDB, dice: 0.8654548387096771
CVC-ClinicDB :  0.8654548387096771
epoch: 121, dataset: Kvasir, dice: 0.8997049999999998
Kvasir :  0.8997049999999998
epoch: 121, dataset: CVC-ColonDB, dice: 0.7078223684210533
CVC-ColonDB :  0.7078223684210533
epoch: 121, dataset: ETIS-LaribPolypDB, dice: 0.7514775510204086
ETIS-LaribPolypDB :  0.7514775510204086
2023-09-02 06:32:58.111278: train_loss -1.4624
2023-09-02 06:32:58.112822: val_loss -0.9593
2023-09-02 06:32:58.114428: Pseudo dice [0.825]
2023-09-02 06:32:58.115917: Epoch time: 110.44 s
2023-09-02 06:32:59.341346: 
2023-09-02 06:32:59.342785: Epoch 122
2023-09-02 06:32:59.343740: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-02 06:32:59.345090: start training, 250
================num of epochs: 250================
2023-09-02 06:33:57.352683: finished training
epoch: 122, dataset: CVC-300, dice: 0.8721349999999998
CVC-300 :  0.8721349999999998
epoch: 122, dataset: CVC-ClinicDB, dice: 0.866358064516129
CVC-ClinicDB :  0.866358064516129
epoch: 122, dataset: Kvasir, dice: 0.8984030000000002
Kvasir :  0.8984030000000002
epoch: 122, dataset: CVC-ColonDB, dice: 0.7021923684210529
CVC-ColonDB :  0.7021923684210529
epoch: 122, dataset: ETIS-LaribPolypDB, dice: 0.7076811224489798
ETIS-LaribPolypDB :  0.7076811224489798
2023-09-02 06:34:50.330113: train_loss -1.4626
2023-09-02 06:34:50.331553: val_loss -1.0075
2023-09-02 06:34:50.332778: Pseudo dice [0.8363]
2023-09-02 06:34:50.333906: Epoch time: 110.99 s
2023-09-02 06:34:51.858361: 
2023-09-02 06:34:51.859763: Epoch 123
2023-09-02 06:34:51.860754: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-02 06:34:51.862041: start training, 250
================num of epochs: 250================
2023-09-02 06:35:49.946738: finished training
epoch: 123, dataset: CVC-300, dice: 0.8694033333333336
CVC-300 :  0.8694033333333336
epoch: 123, dataset: CVC-ClinicDB, dice: 0.8670145161290322
CVC-ClinicDB :  0.8670145161290322
epoch: 123, dataset: Kvasir, dice: 0.9009259999999999
Kvasir :  0.9009259999999999
epoch: 123, dataset: CVC-ColonDB, dice: 0.702228684210526
CVC-ColonDB :  0.702228684210526
epoch: 123, dataset: ETIS-LaribPolypDB, dice: 0.7191270408163266
ETIS-LaribPolypDB :  0.7191270408163266
2023-09-02 06:36:42.694414: train_loss -1.4621
2023-09-02 06:36:42.696019: val_loss -0.9972
2023-09-02 06:36:42.697340: Pseudo dice [0.8321]
2023-09-02 06:36:42.698332: Epoch time: 110.84 s
2023-09-02 06:36:43.913956: 
2023-09-02 06:36:43.915560: Epoch 124
2023-09-02 06:36:43.916576: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-02 06:36:43.917921: start training, 250
================num of epochs: 250================
2023-09-02 06:37:41.972013: finished training
epoch: 124, dataset: CVC-300, dice: 0.8440516666666665
CVC-300 :  0.8440516666666665
epoch: 124, dataset: CVC-ClinicDB, dice: 0.864848387096774
CVC-ClinicDB :  0.864848387096774
epoch: 124, dataset: Kvasir, dice: 0.8968949999999998
Kvasir :  0.8968949999999998
epoch: 124, dataset: CVC-ColonDB, dice: 0.678202894736842
CVC-ColonDB :  0.678202894736842
epoch: 124, dataset: ETIS-LaribPolypDB, dice: 0.7132438775510208
ETIS-LaribPolypDB :  0.7132438775510208
2023-09-02 06:38:34.849084: train_loss -1.4626
2023-09-02 06:38:34.850493: val_loss -0.9652
2023-09-02 06:38:34.851754: Pseudo dice [0.8198]
2023-09-02 06:38:34.852734: Epoch time: 110.94 s
2023-09-02 06:38:36.062805: 
2023-09-02 06:38:36.064167: Epoch 125
2023-09-02 06:38:36.065130: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-02 06:38:36.066451: start training, 250
================num of epochs: 250================
2023-09-02 06:39:34.124856: finished training
epoch: 125, dataset: CVC-300, dice: 0.8540749999999997
CVC-300 :  0.8540749999999997
epoch: 125, dataset: CVC-ClinicDB, dice: 0.8665145161290325
CVC-ClinicDB :  0.8665145161290325
epoch: 125, dataset: Kvasir, dice: 0.8979639999999999
Kvasir :  0.8979639999999999
epoch: 125, dataset: CVC-ColonDB, dice: 0.6871865789473687
CVC-ColonDB :  0.6871865789473687
epoch: 125, dataset: ETIS-LaribPolypDB, dice: 0.72431887755102
ETIS-LaribPolypDB :  0.72431887755102
2023-09-02 06:40:27.267285: train_loss -1.4634
2023-09-02 06:40:27.268792: val_loss -0.8958
2023-09-02 06:40:27.270011: Pseudo dice [0.8133]
2023-09-02 06:40:27.270988: Epoch time: 111.21 s
2023-09-02 06:40:28.484631: 
2023-09-02 06:40:28.486032: Epoch 126
2023-09-02 06:40:28.487022: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-02 06:40:28.488391: start training, 250
================num of epochs: 250================
2023-09-02 06:41:26.772298: finished training
epoch: 126, dataset: CVC-300, dice: 0.8693450000000001
CVC-300 :  0.8693450000000001
epoch: 126, dataset: CVC-ClinicDB, dice: 0.8687854838709678
CVC-ClinicDB :  0.8687854838709678
epoch: 126, dataset: Kvasir, dice: 0.9038990000000005
Kvasir :  0.9038990000000005
epoch: 126, dataset: CVC-ColonDB, dice: 0.7035771052631586
CVC-ColonDB :  0.7035771052631586
epoch: 126, dataset: ETIS-LaribPolypDB, dice: 0.7421571428571431
ETIS-LaribPolypDB :  0.7421571428571431
2023-09-02 06:42:20.938522: train_loss -1.4624
2023-09-02 06:42:20.940347: val_loss -0.9564
2023-09-02 06:42:20.941605: Pseudo dice [0.8194]
2023-09-02 06:42:20.942640: Epoch time: 112.46 s
2023-09-02 06:42:22.146992: 
2023-09-02 06:42:22.148489: Epoch 127
2023-09-02 06:42:22.149941: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-02 06:42:22.151888: start training, 250
================num of epochs: 250================
2023-09-02 06:43:20.228406: finished training
epoch: 127, dataset: CVC-300, dice: 0.8596500000000001
CVC-300 :  0.8596500000000001
epoch: 127, dataset: CVC-ClinicDB, dice: 0.8667774193548383
CVC-ClinicDB :  0.8667774193548383
epoch: 127, dataset: Kvasir, dice: 0.8952309999999997
Kvasir :  0.8952309999999997
epoch: 127, dataset: CVC-ColonDB, dice: 0.6931121052631583
CVC-ColonDB :  0.6931121052631583
epoch: 127, dataset: ETIS-LaribPolypDB, dice: 0.727066836734694
ETIS-LaribPolypDB :  0.727066836734694
2023-09-02 06:44:13.392079: train_loss -1.4616
2023-09-02 06:44:13.393665: val_loss -0.9868
2023-09-02 06:44:13.394869: Pseudo dice [0.8256]
2023-09-02 06:44:13.395852: Epoch time: 111.25 s
2023-09-02 06:44:14.608711: 
2023-09-02 06:44:14.610215: Epoch 128
2023-09-02 06:44:14.611223: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-02 06:44:14.612658: start training, 250
================num of epochs: 250================
2023-09-02 06:45:12.631567: finished training
epoch: 128, dataset: CVC-300, dice: 0.8628866666666667
CVC-300 :  0.8628866666666667
epoch: 128, dataset: CVC-ClinicDB, dice: 0.8730548387096772
CVC-ClinicDB :  0.8730548387096772
epoch: 128, dataset: Kvasir, dice: 0.87933
Kvasir :  0.87933
epoch: 128, dataset: CVC-ColonDB, dice: 0.6966660526315794
CVC-ColonDB :  0.6966660526315794
epoch: 128, dataset: ETIS-LaribPolypDB, dice: 0.7448647959183671
ETIS-LaribPolypDB :  0.7448647959183671
2023-09-02 06:46:05.951707: train_loss -1.4601
2023-09-02 06:46:05.953236: val_loss -0.9468
2023-09-02 06:46:05.954561: Pseudo dice [0.8158]
2023-09-02 06:46:05.955572: Epoch time: 111.34 s
2023-09-02 06:46:07.159418: 
2023-09-02 06:46:07.161146: Epoch 129
2023-09-02 06:46:07.162440: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-02 06:46:07.163920: start training, 250
================num of epochs: 250================
2023-09-02 06:47:05.792668: finished training
epoch: 129, dataset: CVC-300, dice: 0.8253516666666666
CVC-300 :  0.8253516666666666
epoch: 129, dataset: CVC-ClinicDB, dice: 0.8709774193548386
CVC-ClinicDB :  0.8709774193548386
epoch: 129, dataset: Kvasir, dice: 0.8802120000000007
Kvasir :  0.8802120000000007
epoch: 129, dataset: CVC-ColonDB, dice: 0.6611950000000001
CVC-ColonDB :  0.6611950000000001
epoch: 129, dataset: ETIS-LaribPolypDB, dice: 0.696441326530612
ETIS-LaribPolypDB :  0.696441326530612
2023-09-02 06:47:59.251800: train_loss -1.4574
2023-09-02 06:47:59.253423: val_loss -0.9452
2023-09-02 06:47:59.254726: Pseudo dice [0.8163]
2023-09-02 06:47:59.255750: Epoch time: 112.09 s
2023-09-02 06:48:02.081803: 
2023-09-02 06:48:02.083318: Epoch 130
2023-09-02 06:48:02.084335: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-02 06:48:02.085682: start training, 250
================num of epochs: 250================
2023-09-02 06:49:00.094243: finished training
epoch: 130, dataset: CVC-300, dice: 0.8603916666666667
CVC-300 :  0.8603916666666667
epoch: 130, dataset: CVC-ClinicDB, dice: 0.8713725806451612
CVC-ClinicDB :  0.8713725806451612
epoch: 130, dataset: Kvasir, dice: 0.8856850000000002
Kvasir :  0.8856850000000002
epoch: 130, dataset: CVC-ColonDB, dice: 0.6943434210526322
CVC-ColonDB :  0.6943434210526322
epoch: 130, dataset: ETIS-LaribPolypDB, dice: 0.7180903061224494
ETIS-LaribPolypDB :  0.7180903061224494
2023-09-02 06:49:53.345665: train_loss -1.4576
2023-09-02 06:49:53.347340: val_loss -0.9124
2023-09-02 06:49:53.348564: Pseudo dice [0.812]
2023-09-02 06:49:53.349589: Epoch time: 111.27 s
2023-09-02 06:49:54.560412: 
2023-09-02 06:49:54.562064: Epoch 131
2023-09-02 06:49:54.563138: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-02 06:49:54.564585: start training, 250
================num of epochs: 250================
2023-09-02 06:50:52.570411: finished training
epoch: 131, dataset: CVC-300, dice: 0.8704233333333332
CVC-300 :  0.8704233333333332
epoch: 131, dataset: CVC-ClinicDB, dice: 0.8636677419354841
CVC-ClinicDB :  0.8636677419354841
epoch: 131, dataset: Kvasir, dice: 0.8829200000000003
Kvasir :  0.8829200000000003
epoch: 131, dataset: CVC-ColonDB, dice: 0.6832563157894735
CVC-ColonDB :  0.6832563157894735
epoch: 131, dataset: ETIS-LaribPolypDB, dice: 0.7065954081632653
ETIS-LaribPolypDB :  0.7065954081632653
2023-09-02 06:51:46.087846: train_loss -1.4595
2023-09-02 06:51:46.089373: val_loss -0.9624
2023-09-02 06:51:46.090598: Pseudo dice [0.8276]
2023-09-02 06:51:46.091557: Epoch time: 111.53 s
2023-09-02 06:51:47.611235: 
2023-09-02 06:51:47.612785: Epoch 132
2023-09-02 06:51:47.613769: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-02 06:51:47.615035: start training, 250
================num of epochs: 250================
2023-09-02 06:52:45.679712: finished training
epoch: 132, dataset: CVC-300, dice: 0.8486966666666664
CVC-300 :  0.8486966666666664
epoch: 132, dataset: CVC-ClinicDB, dice: 0.8790000000000001
CVC-ClinicDB :  0.8790000000000001
epoch: 132, dataset: Kvasir, dice: 0.8901110000000001
Kvasir :  0.8901110000000001
epoch: 132, dataset: CVC-ColonDB, dice: 0.6943413157894734
CVC-ColonDB :  0.6943413157894734
epoch: 132, dataset: ETIS-LaribPolypDB, dice: 0.7065423469387757
ETIS-LaribPolypDB :  0.7065423469387757
2023-09-02 06:53:39.254275: train_loss -1.4613
2023-09-02 06:53:39.255834: val_loss -0.9669
2023-09-02 06:53:39.257035: Pseudo dice [0.8162]
2023-09-02 06:53:39.257976: Epoch time: 111.64 s
2023-09-02 06:53:40.475897: 
2023-09-02 06:53:40.477615: Epoch 133
2023-09-02 06:53:40.478652: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-02 06:53:40.480077: start training, 250
================num of epochs: 250================
2023-09-02 06:54:38.519994: finished training
epoch: 133, dataset: CVC-300, dice: 0.8627783333333336
CVC-300 :  0.8627783333333336
epoch: 133, dataset: CVC-ClinicDB, dice: 0.877577419354839
CVC-ClinicDB :  0.877577419354839
epoch: 133, dataset: Kvasir, dice: 0.8882920000000003
Kvasir :  0.8882920000000003
epoch: 133, dataset: CVC-ColonDB, dice: 0.6998571052631576
CVC-ColonDB :  0.6998571052631576
epoch: 133, dataset: ETIS-LaribPolypDB, dice: 0.7242112244897961
ETIS-LaribPolypDB :  0.7242112244897961
2023-09-02 06:55:32.069906: train_loss -1.4624
2023-09-02 06:55:32.071564: val_loss -0.9176
2023-09-02 06:55:32.072908: Pseudo dice [0.8131]
2023-09-02 06:55:32.073956: Epoch time: 111.6 s
2023-09-02 06:55:33.281587: 
2023-09-02 06:55:33.283104: Epoch 134
2023-09-02 06:55:33.284176: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-02 06:55:33.285609: start training, 250
================num of epochs: 250================
2023-09-02 06:56:31.312202: finished training
epoch: 134, dataset: CVC-300, dice: 0.8689733333333334
CVC-300 :  0.8689733333333334
epoch: 134, dataset: CVC-ClinicDB, dice: 0.8768209677419356
CVC-ClinicDB :  0.8768209677419356
epoch: 134, dataset: Kvasir, dice: 0.8917390000000001
Kvasir :  0.8917390000000001
epoch: 134, dataset: CVC-ColonDB, dice: 0.7083615789473684
CVC-ColonDB :  0.7083615789473684
epoch: 134, dataset: ETIS-LaribPolypDB, dice: 0.7313260204081631
ETIS-LaribPolypDB :  0.7313260204081631
2023-09-02 06:57:24.889025: train_loss -1.462
2023-09-02 06:57:24.890559: val_loss -1.0463
2023-09-02 06:57:24.891801: Pseudo dice [0.8436]
2023-09-02 06:57:24.892820: Epoch time: 111.61 s
2023-09-02 06:57:26.105604: 
2023-09-02 06:57:26.107390: Epoch 135
2023-09-02 06:57:26.108401: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-02 06:57:26.109816: start training, 250
================num of epochs: 250================
2023-09-02 06:58:24.367712: finished training
epoch: 135, dataset: CVC-300, dice: 0.87718
CVC-300 :  0.87718
epoch: 135, dataset: CVC-ClinicDB, dice: 0.8750241935483872
CVC-ClinicDB :  0.8750241935483872
epoch: 135, dataset: Kvasir, dice: 0.8994119999999998
Kvasir :  0.8994119999999998
epoch: 135, dataset: CVC-ColonDB, dice: 0.7137523684210532
CVC-ColonDB :  0.7137523684210532
epoch: 135, dataset: ETIS-LaribPolypDB, dice: 0.7416857142857145
ETIS-LaribPolypDB :  0.7416857142857145
2023-09-02 06:59:17.976745: train_loss -1.4624
2023-09-02 06:59:17.978298: val_loss -0.9792
2023-09-02 06:59:17.980108: Pseudo dice [0.8238]
2023-09-02 06:59:17.981582: Epoch time: 111.87 s
2023-09-02 06:59:19.229850: 
2023-09-02 06:59:19.231433: Epoch 136
2023-09-02 06:59:19.232464: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-02 06:59:19.234025: start training, 250
================num of epochs: 250================
2023-09-02 07:00:17.235318: finished training
epoch: 136, dataset: CVC-300, dice: 0.8730399999999999
CVC-300 :  0.8730399999999999
epoch: 136, dataset: CVC-ClinicDB, dice: 0.8781790322580648
CVC-ClinicDB :  0.8781790322580648
epoch: 136, dataset: Kvasir, dice: 0.8988890000000002
Kvasir :  0.8988890000000002
epoch: 136, dataset: CVC-ColonDB, dice: 0.7099286842105266
CVC-ColonDB :  0.7099286842105266
epoch: 136, dataset: ETIS-LaribPolypDB, dice: 0.7513852040816323
ETIS-LaribPolypDB :  0.7513852040816323
2023-09-02 07:01:11.557938: train_loss -1.463
2023-09-02 07:01:11.559597: val_loss -0.9569
2023-09-02 07:01:11.560985: Pseudo dice [0.8333]
2023-09-02 07:01:11.562125: Epoch time: 112.33 s
2023-09-02 07:01:12.779662: 
2023-09-02 07:01:12.781153: Epoch 137
2023-09-02 07:01:12.782130: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-02 07:01:12.783517: start training, 250
================num of epochs: 250================
2023-09-02 07:02:10.816689: finished training
epoch: 137, dataset: CVC-300, dice: 0.8797466666666668
CVC-300 :  0.8797466666666668
epoch: 137, dataset: CVC-ClinicDB, dice: 0.8723338709677421
CVC-ClinicDB :  0.8723338709677421
epoch: 137, dataset: Kvasir, dice: 0.9006569999999994
Kvasir :  0.9006569999999994
epoch: 137, dataset: CVC-ColonDB, dice: 0.7116407894736846
CVC-ColonDB :  0.7116407894736846
epoch: 137, dataset: ETIS-LaribPolypDB, dice: 0.7615617346938772
ETIS-LaribPolypDB :  0.7615617346938772
2023-09-02 07:03:04.227902: train_loss -1.4624
2023-09-02 07:03:04.229370: val_loss -0.9644
2023-09-02 07:03:04.230592: Pseudo dice [0.8334]
2023-09-02 07:03:04.231597: Epoch time: 111.45 s
2023-09-02 07:03:05.445813: 
2023-09-02 07:03:05.447406: Epoch 138
2023-09-02 07:03:05.448469: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-02 07:03:05.449841: start training, 250
================num of epochs: 250================
2023-09-02 07:04:03.719606: finished training
epoch: 138, dataset: CVC-300, dice: 0.8721849999999998
CVC-300 :  0.8721849999999998
epoch: 138, dataset: CVC-ClinicDB, dice: 0.8778016129032259
CVC-ClinicDB :  0.8778016129032259
epoch: 138, dataset: Kvasir, dice: 0.8937900000000001
Kvasir :  0.8937900000000001
epoch: 138, dataset: CVC-ColonDB, dice: 0.7021631578947373
CVC-ColonDB :  0.7021631578947373
epoch: 138, dataset: ETIS-LaribPolypDB, dice: 0.7484051020408166
ETIS-LaribPolypDB :  0.7484051020408166
2023-09-02 07:04:57.019650: train_loss -1.4637
2023-09-02 07:04:57.021238: val_loss -0.9592
2023-09-02 07:04:57.022532: Pseudo dice [0.8277]
2023-09-02 07:04:57.023516: Epoch time: 111.58 s
2023-09-02 07:04:58.233960: 
2023-09-02 07:04:58.235521: Epoch 139
2023-09-02 07:04:58.236609: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-02 07:04:58.237953: start training, 250
================num of epochs: 250================
2023-09-02 07:05:56.243393: finished training
epoch: 139, dataset: CVC-300, dice: 0.8703933333333338
CVC-300 :  0.8703933333333338
epoch: 139, dataset: CVC-ClinicDB, dice: 0.8724612903225808
CVC-ClinicDB :  0.8724612903225808
epoch: 139, dataset: Kvasir, dice: 0.8925759999999999
Kvasir :  0.8925759999999999
epoch: 139, dataset: CVC-ColonDB, dice: 0.7003065789473684
CVC-ColonDB :  0.7003065789473684
epoch: 139, dataset: ETIS-LaribPolypDB, dice: 0.7358826530612248
ETIS-LaribPolypDB :  0.7358826530612248
2023-09-02 07:06:50.248187: train_loss -1.4641
2023-09-02 07:06:50.249839: val_loss -1.0528
2023-09-02 07:06:50.251085: Pseudo dice [0.8544]
2023-09-02 07:06:50.252120: Epoch time: 112.02 s
2023-09-02 07:06:53.188178: 
2023-09-02 07:06:53.189557: Epoch 140
2023-09-02 07:06:53.190613: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-02 07:06:53.192006: start training, 250
================num of epochs: 250================
2023-09-02 07:07:51.190506: finished training
epoch: 140, dataset: CVC-300, dice: 0.8806583333333333
CVC-300 :  0.8806583333333333
epoch: 140, dataset: CVC-ClinicDB, dice: 0.8787403225806455
CVC-ClinicDB :  0.8787403225806455
epoch: 140, dataset: Kvasir, dice: 0.8961420000000001
Kvasir :  0.8961420000000001
epoch: 140, dataset: CVC-ColonDB, dice: 0.7039126315789476
CVC-ColonDB :  0.7039126315789476
epoch: 140, dataset: ETIS-LaribPolypDB, dice: 0.750072448979592
ETIS-LaribPolypDB :  0.750072448979592
2023-09-02 07:08:45.204591: train_loss -1.4633
2023-09-02 07:08:45.206119: val_loss -0.9729
2023-09-02 07:08:45.207391: Pseudo dice [0.8139]
2023-09-02 07:08:45.208462: Epoch time: 112.02 s
2023-09-02 07:08:46.420006: 
2023-09-02 07:08:46.421605: Epoch 141
2023-09-02 07:08:46.422640: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-02 07:08:46.424027: start training, 250
================num of epochs: 250================
2023-09-02 07:09:44.639396: finished training
epoch: 141, dataset: CVC-300, dice: 0.879621666666667
CVC-300 :  0.879621666666667
epoch: 141, dataset: CVC-ClinicDB, dice: 0.8820290322580645
CVC-ClinicDB :  0.8820290322580645
epoch: 141, dataset: Kvasir, dice: 0.8965569999999999
Kvasir :  0.8965569999999999
epoch: 141, dataset: CVC-ColonDB, dice: 0.7103547368421048
CVC-ColonDB :  0.7103547368421048
epoch: 141, dataset: ETIS-LaribPolypDB, dice: 0.7516020408163268
ETIS-LaribPolypDB :  0.7516020408163268
2023-09-02 07:10:38.839399: train_loss -1.4636
2023-09-02 07:10:38.840940: val_loss -0.9761
2023-09-02 07:10:38.842213: Pseudo dice [0.8276]
2023-09-02 07:10:38.843336: Epoch time: 112.42 s
2023-09-02 07:10:40.061461: 
2023-09-02 07:10:40.063010: Epoch 142
2023-09-02 07:10:40.064025: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-02 07:10:40.065405: start training, 250
================num of epochs: 250================
2023-09-02 07:11:38.033904: finished training
epoch: 142, dataset: CVC-300, dice: 0.8704250000000001
CVC-300 :  0.8704250000000001
epoch: 142, dataset: CVC-ClinicDB, dice: 0.8708580645161292
CVC-ClinicDB :  0.8708580645161292
epoch: 142, dataset: Kvasir, dice: 0.8945449999999995
Kvasir :  0.8945449999999995
epoch: 142, dataset: CVC-ColonDB, dice: 0.7006636842105259
CVC-ColonDB :  0.7006636842105259
epoch: 142, dataset: ETIS-LaribPolypDB, dice: 0.7473913265306125
ETIS-LaribPolypDB :  0.7473913265306125
2023-09-02 07:12:30.674317: train_loss -1.4643
2023-09-02 07:12:30.675923: val_loss -0.956
2023-09-02 07:12:30.677141: Pseudo dice [0.8192]
2023-09-02 07:12:30.678156: Epoch time: 110.61 s
2023-09-02 07:12:31.890833: 
2023-09-02 07:12:31.892266: Epoch 143
2023-09-02 07:12:31.893320: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-02 07:12:31.894708: start training, 250
================num of epochs: 250================
2023-09-02 07:13:29.790025: finished training
epoch: 143, dataset: CVC-300, dice: 0.8526483333333333
CVC-300 :  0.8526483333333333
epoch: 143, dataset: CVC-ClinicDB, dice: 0.875459677419355
CVC-ClinicDB :  0.875459677419355
epoch: 143, dataset: Kvasir, dice: 0.8966260000000001
Kvasir :  0.8966260000000001
epoch: 143, dataset: CVC-ColonDB, dice: 0.6888963157894739
CVC-ColonDB :  0.6888963157894739
epoch: 143, dataset: ETIS-LaribPolypDB, dice: 0.7268903061224492
ETIS-LaribPolypDB :  0.7268903061224492
2023-09-02 07:14:23.926654: train_loss -1.4651
2023-09-02 07:14:23.928196: val_loss -0.9735
2023-09-02 07:14:23.929408: Pseudo dice [0.8347]
2023-09-02 07:14:23.930421: Epoch time: 112.04 s
2023-09-02 07:14:25.145615: 
2023-09-02 07:14:25.147132: Epoch 144
2023-09-02 07:14:25.148152: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-02 07:14:25.149491: start training, 250
================num of epochs: 250================
2023-09-02 07:15:23.228240: finished training
epoch: 144, dataset: CVC-300, dice: 0.876506666666667
CVC-300 :  0.876506666666667
epoch: 144, dataset: CVC-ClinicDB, dice: 0.8741822580645162
CVC-ClinicDB :  0.8741822580645162
epoch: 144, dataset: Kvasir, dice: 0.8959530000000003
Kvasir :  0.8959530000000003
epoch: 144, dataset: CVC-ColonDB, dice: 0.704533684210526
CVC-ColonDB :  0.704533684210526
epoch: 144, dataset: ETIS-LaribPolypDB, dice: 0.7364301020408167
ETIS-LaribPolypDB :  0.7364301020408167
2023-09-02 07:16:17.753745: train_loss -1.4651
2023-09-02 07:16:17.755362: val_loss -0.9966
2023-09-02 07:16:17.756667: Pseudo dice [0.834]
2023-09-02 07:16:17.757722: Epoch time: 112.61 s
2023-09-02 07:16:18.974005: 
2023-09-02 07:16:18.975507: Epoch 145
2023-09-02 07:16:18.976530: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-02 07:16:18.977938: start training, 250
================num of epochs: 250================
2023-09-02 07:17:16.841766: finished training
epoch: 145, dataset: CVC-300, dice: 0.8744116666666668
CVC-300 :  0.8744116666666668
epoch: 145, dataset: CVC-ClinicDB, dice: 0.8668790322580646
CVC-ClinicDB :  0.8668790322580646
epoch: 145, dataset: Kvasir, dice: 0.8927029999999998
Kvasir :  0.8927029999999998
epoch: 145, dataset: CVC-ColonDB, dice: 0.70042052631579
CVC-ColonDB :  0.70042052631579
epoch: 145, dataset: ETIS-LaribPolypDB, dice: 0.7344882653061223
ETIS-LaribPolypDB :  0.7344882653061223
2023-09-02 07:18:11.689319: train_loss -1.4644
2023-09-02 07:18:11.690785: val_loss -0.9398
2023-09-02 07:18:11.692063: Pseudo dice [0.8217]
2023-09-02 07:18:11.693099: Epoch time: 112.72 s
2023-09-02 07:18:12.912830: 
2023-09-02 07:18:12.914281: Epoch 146
2023-09-02 07:18:12.915336: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-02 07:18:12.916730: start training, 250
================num of epochs: 250================
2023-09-02 07:19:10.801969: finished training
epoch: 146, dataset: CVC-300, dice: 0.8541966666666668
CVC-300 :  0.8541966666666668
epoch: 146, dataset: CVC-ClinicDB, dice: 0.866567741935484
CVC-ClinicDB :  0.866567741935484
epoch: 146, dataset: Kvasir, dice: 0.8891069999999999
Kvasir :  0.8891069999999999
epoch: 146, dataset: CVC-ColonDB, dice: 0.695892368421053
CVC-ColonDB :  0.695892368421053
epoch: 146, dataset: ETIS-LaribPolypDB, dice: 0.7229102040816329
ETIS-LaribPolypDB :  0.7229102040816329
2023-09-02 07:20:06.183179: train_loss -1.4648
2023-09-02 07:20:06.185659: val_loss -0.8782
2023-09-02 07:20:06.187759: Pseudo dice [0.8014]
2023-09-02 07:20:06.189433: Epoch time: 113.27 s
2023-09-02 07:20:07.409320: 
2023-09-02 07:20:07.411909: Epoch 147
2023-09-02 07:20:07.414038: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-02 07:20:07.416828: start training, 250
================num of epochs: 250================
2023-09-02 07:21:05.523991: finished training
epoch: 147, dataset: CVC-300, dice: 0.8820583333333333
CVC-300 :  0.8820583333333333
epoch: 147, dataset: CVC-ClinicDB, dice: 0.8756580645161292
CVC-ClinicDB :  0.8756580645161292
epoch: 147, dataset: Kvasir, dice: 0.890126
Kvasir :  0.890126
epoch: 147, dataset: CVC-ColonDB, dice: 0.7119981578947365
CVC-ColonDB :  0.7119981578947365
epoch: 147, dataset: ETIS-LaribPolypDB, dice: 0.7401979591836734
ETIS-LaribPolypDB :  0.7401979591836734
2023-09-02 07:22:00.635212: train_loss -1.4645
2023-09-02 07:22:00.636803: val_loss -1.0189
2023-09-02 07:22:00.638054: Pseudo dice [0.8459]
2023-09-02 07:22:00.639080: Epoch time: 113.23 s
2023-09-02 07:22:01.863831: 
2023-09-02 07:22:01.865335: Epoch 148
2023-09-02 07:22:01.866412: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-02 07:22:01.867890: start training, 250
================num of epochs: 250================
2023-09-02 07:22:59.745573: finished training
epoch: 148, dataset: CVC-300, dice: 0.8384416666666664
CVC-300 :  0.8384416666666664
epoch: 148, dataset: CVC-ClinicDB, dice: 0.8733032258064514
CVC-ClinicDB :  0.8733032258064514
epoch: 148, dataset: Kvasir, dice: 0.8937269999999994
Kvasir :  0.8937269999999994
epoch: 148, dataset: CVC-ColonDB, dice: 0.6851655263157899
CVC-ColonDB :  0.6851655263157899
epoch: 148, dataset: ETIS-LaribPolypDB, dice: 0.7061454081632655
ETIS-LaribPolypDB :  0.7061454081632655
2023-09-02 07:23:54.112398: train_loss -1.4651
2023-09-02 07:23:54.113973: val_loss -0.8866
2023-09-02 07:23:54.115216: Pseudo dice [0.8111]
2023-09-02 07:23:54.116221: Epoch time: 112.25 s
2023-09-02 07:23:55.357124: 
2023-09-02 07:23:55.358704: Epoch 149
2023-09-02 07:23:55.359847: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-02 07:23:55.361259: start training, 250
================num of epochs: 250================
2023-09-02 07:24:53.267120: finished training
epoch: 149, dataset: CVC-300, dice: 0.8709650000000001
CVC-300 :  0.8709650000000001
epoch: 149, dataset: CVC-ClinicDB, dice: 0.8749096774193551
CVC-ClinicDB :  0.8749096774193551
epoch: 149, dataset: Kvasir, dice: 0.8971600000000002
Kvasir :  0.8971600000000002
epoch: 149, dataset: CVC-ColonDB, dice: 0.7043534210526325
CVC-ColonDB :  0.7043534210526325
epoch: 149, dataset: ETIS-LaribPolypDB, dice: 0.7232913265306122
ETIS-LaribPolypDB :  0.7232913265306122
2023-09-02 07:25:48.122002: train_loss -1.4653
2023-09-02 07:25:48.123472: val_loss -1.0549
2023-09-02 07:25:48.124751: Pseudo dice [0.8571]
2023-09-02 07:25:48.125787: Epoch time: 112.77 s
2023-09-02 07:25:49.716667: Yayy! New best EMA pseudo Dice: 0.8281
2023-09-02 07:25:52.731761: 
2023-09-02 07:25:52.733532: Epoch 150
2023-09-02 07:25:52.734692: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-02 07:25:52.736238: start training, 250
================num of epochs: 250================
2023-09-02 07:26:50.821302: finished training
epoch: 150, dataset: CVC-300, dice: 0.87196
CVC-300 :  0.87196
epoch: 150, dataset: CVC-ClinicDB, dice: 0.8755887096774191
CVC-ClinicDB :  0.8755887096774191
epoch: 150, dataset: Kvasir, dice: 0.9020039999999999
Kvasir :  0.9020039999999999
epoch: 150, dataset: CVC-ColonDB, dice: 0.7019263157894737
CVC-ColonDB :  0.7019263157894737
epoch: 150, dataset: ETIS-LaribPolypDB, dice: 0.7331428571428573
ETIS-LaribPolypDB :  0.7331428571428573
2023-09-02 07:27:45.295828: train_loss -1.465
2023-09-02 07:27:45.297434: val_loss -1.0212
2023-09-02 07:27:45.298820: Pseudo dice [0.8414]
2023-09-02 07:27:45.299978: Epoch time: 112.57 s
2023-09-02 07:27:45.301007: Yayy! New best EMA pseudo Dice: 0.8295
2023-09-02 07:27:48.219393: 
2023-09-02 07:27:48.221056: Epoch 151
2023-09-02 07:27:48.222107: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-02 07:27:48.223504: start training, 250
================num of epochs: 250================
2023-09-02 07:28:46.089820: finished training
epoch: 151, dataset: CVC-300, dice: 0.8864600000000002
CVC-300 :  0.8864600000000002
epoch: 151, dataset: CVC-ClinicDB, dice: 0.8803580645161293
CVC-ClinicDB :  0.8803580645161293
epoch: 151, dataset: Kvasir, dice: 0.9000149999999991
Kvasir :  0.9000149999999991
epoch: 151, dataset: CVC-ColonDB, dice: 0.7130473684210522
CVC-ColonDB :  0.7130473684210522
epoch: 151, dataset: ETIS-LaribPolypDB, dice: 0.7455841836734698
ETIS-LaribPolypDB :  0.7455841836734698
2023-09-02 07:29:40.455564: train_loss -1.4656
2023-09-02 07:29:40.457350: val_loss -0.9415
2023-09-02 07:29:40.458729: Pseudo dice [0.8235]
2023-09-02 07:29:40.459830: Epoch time: 112.24 s
2023-09-02 07:29:41.701027: 
2023-09-02 07:29:41.702675: Epoch 152
2023-09-02 07:29:41.703699: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-02 07:29:41.705067: start training, 250
================num of epochs: 250================
2023-09-02 07:30:39.595659: finished training
epoch: 152, dataset: CVC-300, dice: 0.8675333333333337
CVC-300 :  0.8675333333333337
epoch: 152, dataset: CVC-ClinicDB, dice: 0.8769741935483873
CVC-ClinicDB :  0.8769741935483873
epoch: 152, dataset: Kvasir, dice: 0.8917610000000005
Kvasir :  0.8917610000000005
epoch: 152, dataset: CVC-ColonDB, dice: 0.6985628947368422
CVC-ColonDB :  0.6985628947368422
epoch: 152, dataset: ETIS-LaribPolypDB, dice: 0.723542346938775
ETIS-LaribPolypDB :  0.723542346938775
2023-09-02 07:31:33.645664: train_loss -1.4655
2023-09-02 07:31:33.647141: val_loss -0.8881
2023-09-02 07:31:33.648453: Pseudo dice [0.8072]
2023-09-02 07:31:33.649488: Epoch time: 111.95 s
2023-09-02 07:31:34.886285: 
2023-09-02 07:31:34.887907: Epoch 153
2023-09-02 07:31:34.888935: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-02 07:31:34.890333: start training, 250
================num of epochs: 250================
2023-09-02 07:32:33.030307: finished training
epoch: 153, dataset: CVC-300, dice: 0.8808566666666666
CVC-300 :  0.8808566666666666
epoch: 153, dataset: CVC-ClinicDB, dice: 0.8721532258064516
CVC-ClinicDB :  0.8721532258064516
epoch: 153, dataset: Kvasir, dice: 0.8907189999999998
Kvasir :  0.8907189999999998
epoch: 153, dataset: CVC-ColonDB, dice: 0.707451315789474
CVC-ColonDB :  0.707451315789474
epoch: 153, dataset: ETIS-LaribPolypDB, dice: 0.7421413265306125
ETIS-LaribPolypDB :  0.7421413265306125
2023-09-02 07:33:26.925581: train_loss -1.4658
2023-09-02 07:33:26.927077: val_loss -0.8915
2023-09-02 07:33:26.928375: Pseudo dice [0.8119]
2023-09-02 07:33:26.929393: Epoch time: 112.04 s
2023-09-02 07:33:28.175972: 
2023-09-02 07:33:28.177599: Epoch 154
2023-09-02 07:33:28.178653: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-02 07:33:28.180055: start training, 250
================num of epochs: 250================
2023-09-02 07:34:26.159074: finished training
epoch: 154, dataset: CVC-300, dice: 0.8721983333333333
CVC-300 :  0.8721983333333333
epoch: 154, dataset: CVC-ClinicDB, dice: 0.8785725806451613
CVC-ClinicDB :  0.8785725806451613
epoch: 154, dataset: Kvasir, dice: 0.8983990000000002
Kvasir :  0.8983990000000002
epoch: 154, dataset: CVC-ColonDB, dice: 0.709628157894737
CVC-ColonDB :  0.709628157894737
epoch: 154, dataset: ETIS-LaribPolypDB, dice: 0.745875
ETIS-LaribPolypDB :  0.745875
2023-09-02 07:35:21.136390: train_loss -1.466
2023-09-02 07:35:21.138176: val_loss -0.8886
2023-09-02 07:35:21.140573: Pseudo dice [0.8142]
2023-09-02 07:35:21.142325: Epoch time: 112.96 s
2023-09-02 07:35:22.482216: 
2023-09-02 07:35:22.483841: Epoch 155
2023-09-02 07:35:22.484976: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-02 07:35:22.486467: start training, 250
================num of epochs: 250================
2023-09-02 07:36:20.465900: finished training
epoch: 155, dataset: CVC-300, dice: 0.8767583333333333
CVC-300 :  0.8767583333333333
epoch: 155, dataset: CVC-ClinicDB, dice: 0.876808064516129
CVC-ClinicDB :  0.876808064516129
epoch: 155, dataset: Kvasir, dice: 0.898216
Kvasir :  0.898216
epoch: 155, dataset: CVC-ColonDB, dice: 0.7071078947368422
CVC-ColonDB :  0.7071078947368422
epoch: 155, dataset: ETIS-LaribPolypDB, dice: 0.7497392857142859
ETIS-LaribPolypDB :  0.7497392857142859
2023-09-02 07:37:14.841150: train_loss -1.466
2023-09-02 07:37:14.842728: val_loss -0.9039
2023-09-02 07:37:14.844012: Pseudo dice [0.8237]
2023-09-02 07:37:14.845035: Epoch time: 112.36 s
2023-09-02 07:37:16.104606: 
2023-09-02 07:37:16.106214: Epoch 156
2023-09-02 07:37:16.107262: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-02 07:37:16.108671: start training, 250
================num of epochs: 250================
2023-09-02 07:38:14.223489: finished training
epoch: 156, dataset: CVC-300, dice: 0.8693466666666667
CVC-300 :  0.8693466666666667
epoch: 156, dataset: CVC-ClinicDB, dice: 0.8758225806451614
CVC-ClinicDB :  0.8758225806451614
epoch: 156, dataset: Kvasir, dice: 0.8987700000000003
Kvasir :  0.8987700000000003
epoch: 156, dataset: CVC-ColonDB, dice: 0.7077705263157886
CVC-ColonDB :  0.7077705263157886
epoch: 156, dataset: ETIS-LaribPolypDB, dice: 0.7358500000000001
ETIS-LaribPolypDB :  0.7358500000000001
2023-09-02 07:39:11.748398: train_loss -1.4663
2023-09-02 07:39:11.750149: val_loss -1.0128
2023-09-02 07:39:11.752476: Pseudo dice [0.8379]
2023-09-02 07:39:11.754142: Epoch time: 115.65 s
2023-09-02 07:39:13.028839: 
2023-09-02 07:39:13.030820: Epoch 157
2023-09-02 07:39:13.031981: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-02 07:39:13.033488: start training, 250
================num of epochs: 250================
2023-09-02 07:40:10.938113: finished training
epoch: 157, dataset: CVC-300, dice: 0.87487
CVC-300 :  0.87487
epoch: 157, dataset: CVC-ClinicDB, dice: 0.8740822580645162
CVC-ClinicDB :  0.8740822580645162
epoch: 157, dataset: Kvasir, dice: 0.9003839999999999
Kvasir :  0.9003839999999999
epoch: 157, dataset: CVC-ColonDB, dice: 0.7028700000000001
CVC-ColonDB :  0.7028700000000001
epoch: 157, dataset: ETIS-LaribPolypDB, dice: 0.7219474489795922
ETIS-LaribPolypDB :  0.7219474489795922
2023-09-02 07:41:06.959066: train_loss -1.4651
2023-09-02 07:41:06.960735: val_loss -0.9703
2023-09-02 07:41:06.962125: Pseudo dice [0.8415]
2023-09-02 07:41:06.963181: Epoch time: 113.93 s
2023-09-02 07:41:08.230080: 
2023-09-02 07:41:08.231620: Epoch 158
2023-09-02 07:41:08.233145: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-02 07:41:08.235348: start training, 250
================num of epochs: 250================
2023-09-02 07:42:06.213867: finished training
epoch: 158, dataset: CVC-300, dice: 0.8672066666666667
CVC-300 :  0.8672066666666667
epoch: 158, dataset: CVC-ClinicDB, dice: 0.876875806451613
CVC-ClinicDB :  0.876875806451613
epoch: 158, dataset: Kvasir, dice: 0.8985029999999997
Kvasir :  0.8985029999999997
epoch: 158, dataset: CVC-ColonDB, dice: 0.7060834210526322
CVC-ColonDB :  0.7060834210526322
epoch: 158, dataset: ETIS-LaribPolypDB, dice: 0.7390071428571422
ETIS-LaribPolypDB :  0.7390071428571422
2023-09-02 07:43:00.881095: train_loss -1.4649
2023-09-02 07:43:00.882768: val_loss -0.9868
2023-09-02 07:43:00.884156: Pseudo dice [0.8365]
2023-09-02 07:43:00.885284: Epoch time: 112.65 s
2023-09-02 07:43:02.148079: 
2023-09-02 07:43:02.149666: Epoch 159
2023-09-02 07:43:02.150742: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-02 07:43:02.152352: start training, 250
================num of epochs: 250================
2023-09-02 07:44:00.271585: finished training
epoch: 159, dataset: CVC-300, dice: 0.8718066666666665
CVC-300 :  0.8718066666666665
epoch: 159, dataset: CVC-ClinicDB, dice: 0.8748790322580646
CVC-ClinicDB :  0.8748790322580646
epoch: 159, dataset: Kvasir, dice: 0.8958960000000001
Kvasir :  0.8958960000000001
epoch: 159, dataset: CVC-ColonDB, dice: 0.696125263157895
CVC-ColonDB :  0.696125263157895
epoch: 159, dataset: ETIS-LaribPolypDB, dice: 0.7338658163265308
ETIS-LaribPolypDB :  0.7338658163265308
2023-09-02 07:44:53.672088: train_loss -1.4659
2023-09-02 07:44:53.673758: val_loss -0.9571
2023-09-02 07:44:53.675068: Pseudo dice [0.8258]
2023-09-02 07:44:53.676133: Epoch time: 111.53 s
2023-09-02 07:44:56.560521: 
2023-09-02 07:44:56.562402: Epoch 160
2023-09-02 07:44:56.564025: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-02 07:44:56.565771: start training, 250
================num of epochs: 250================
2023-09-02 07:45:54.499587: finished training
epoch: 160, dataset: CVC-300, dice: 0.8712916666666666
CVC-300 :  0.8712916666666666
epoch: 160, dataset: CVC-ClinicDB, dice: 0.8745209677419354
CVC-ClinicDB :  0.8745209677419354
epoch: 160, dataset: Kvasir, dice: 0.8991640000000003
Kvasir :  0.8991640000000003
epoch: 160, dataset: CVC-ColonDB, dice: 0.6881847368421056
CVC-ColonDB :  0.6881847368421056
epoch: 160, dataset: ETIS-LaribPolypDB, dice: 0.7277137755102041
ETIS-LaribPolypDB :  0.7277137755102041
2023-09-02 07:46:49.022318: train_loss -1.4664
2023-09-02 07:46:49.024097: val_loss -1.0478
2023-09-02 07:46:49.025596: Pseudo dice [0.856]
2023-09-02 07:46:49.026712: Epoch time: 112.46 s
2023-09-02 07:46:49.027731: Yayy! New best EMA pseudo Dice: 0.8306
2023-09-02 07:46:51.962973: 
2023-09-02 07:46:51.964511: Epoch 161
2023-09-02 07:46:51.965554: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-02 07:46:51.966911: start training, 250
================num of epochs: 250================
2023-09-02 07:47:49.887382: finished training
epoch: 161, dataset: CVC-300, dice: 0.8660483333333335
CVC-300 :  0.8660483333333335
epoch: 161, dataset: CVC-ClinicDB, dice: 0.8724338709677423
CVC-ClinicDB :  0.8724338709677423
epoch: 161, dataset: Kvasir, dice: 0.8924840000000002
Kvasir :  0.8924840000000002
epoch: 161, dataset: CVC-ColonDB, dice: 0.6979523684210525
CVC-ColonDB :  0.6979523684210525
epoch: 161, dataset: ETIS-LaribPolypDB, dice: 0.7254903061224495
ETIS-LaribPolypDB :  0.7254903061224495
2023-09-02 07:48:43.530560: train_loss -1.4661
2023-09-02 07:48:43.532155: val_loss -0.9771
2023-09-02 07:48:43.533508: Pseudo dice [0.8277]
2023-09-02 07:48:43.534615: Epoch time: 111.57 s
2023-09-02 07:48:44.798400: 
2023-09-02 07:48:44.800003: Epoch 162
2023-09-02 07:48:44.801540: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-02 07:48:44.803173: start training, 250
================num of epochs: 250================
2023-09-02 07:49:42.942858: finished training
epoch: 162, dataset: CVC-300, dice: 0.8601916666666667
CVC-300 :  0.8601916666666667
epoch: 162, dataset: CVC-ClinicDB, dice: 0.8727564516129034
CVC-ClinicDB :  0.8727564516129034
epoch: 162, dataset: Kvasir, dice: 0.8910549999999999
Kvasir :  0.8910549999999999
epoch: 162, dataset: CVC-ColonDB, dice: 0.6910289473684217
CVC-ColonDB :  0.6910289473684217
epoch: 162, dataset: ETIS-LaribPolypDB, dice: 0.7254647959183677
ETIS-LaribPolypDB :  0.7254647959183677
2023-09-02 07:50:36.792268: train_loss -1.4667
2023-09-02 07:50:36.793926: val_loss -1.0423
2023-09-02 07:50:36.795834: Pseudo dice [0.8508]
2023-09-02 07:50:36.797951: Epoch time: 112.0 s
2023-09-02 07:50:36.799789: Yayy! New best EMA pseudo Dice: 0.8324
2023-09-02 07:50:40.024860: 
2023-09-02 07:50:40.027227: Epoch 163
2023-09-02 07:50:40.029484: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-02 07:50:40.032026: start training, 250
================num of epochs: 250================
2023-09-02 07:51:37.960318: finished training
epoch: 163, dataset: CVC-300, dice: 0.8591983333333334
CVC-300 :  0.8591983333333334
epoch: 163, dataset: CVC-ClinicDB, dice: 0.8723629032258063
CVC-ClinicDB :  0.8723629032258063
epoch: 163, dataset: Kvasir, dice: 0.8915899999999993
Kvasir :  0.8915899999999993
epoch: 163, dataset: CVC-ColonDB, dice: 0.6907068421052635
CVC-ColonDB :  0.6907068421052635
epoch: 163, dataset: ETIS-LaribPolypDB, dice: 0.7186219387755103
ETIS-LaribPolypDB :  0.7186219387755103
2023-09-02 07:52:31.502725: train_loss -1.4673
2023-09-02 07:52:31.504331: val_loss -0.9849
2023-09-02 07:52:31.505623: Pseudo dice [0.8378]
2023-09-02 07:52:31.506719: Epoch time: 111.48 s
2023-09-02 07:52:31.507664: Yayy! New best EMA pseudo Dice: 0.8329
2023-09-02 07:52:34.420534: 
2023-09-02 07:52:34.422116: Epoch 164
2023-09-02 07:52:34.423203: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-02 07:52:34.424553: start training, 250
================num of epochs: 250================
2023-09-02 07:53:32.339189: finished training
epoch: 164, dataset: CVC-300, dice: 0.8837350000000002
CVC-300 :  0.8837350000000002
epoch: 164, dataset: CVC-ClinicDB, dice: 0.8751032258064518
CVC-ClinicDB :  0.8751032258064518
epoch: 164, dataset: Kvasir, dice: 0.8972640000000004
Kvasir :  0.8972640000000004
epoch: 164, dataset: CVC-ColonDB, dice: 0.7014821052631577
CVC-ColonDB :  0.7014821052631577
epoch: 164, dataset: ETIS-LaribPolypDB, dice: 0.7399020408163266
ETIS-LaribPolypDB :  0.7399020408163266
2023-09-02 07:54:26.033679: train_loss -1.4669
2023-09-02 07:54:26.035261: val_loss -0.9906
2023-09-02 07:54:26.036591: Pseudo dice [0.8356]
2023-09-02 07:54:26.037634: Epoch time: 111.61 s
2023-09-02 07:54:26.038614: Yayy! New best EMA pseudo Dice: 0.8332
2023-09-02 07:54:29.182551: 
2023-09-02 07:54:29.184171: Epoch 165
2023-09-02 07:54:29.185268: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-02 07:54:29.186597: start training, 250
================num of epochs: 250================
2023-09-02 07:55:27.103498: finished training
epoch: 165, dataset: CVC-300, dice: 0.8712983333333334
CVC-300 :  0.8712983333333334
epoch: 165, dataset: CVC-ClinicDB, dice: 0.8731338709677421
CVC-ClinicDB :  0.8731338709677421
epoch: 165, dataset: Kvasir, dice: 0.8957640000000002
Kvasir :  0.8957640000000002
epoch: 165, dataset: CVC-ColonDB, dice: 0.6969081578947369
CVC-ColonDB :  0.6969081578947369
epoch: 165, dataset: ETIS-LaribPolypDB, dice: 0.7234739795918365
ETIS-LaribPolypDB :  0.7234739795918365
2023-09-02 07:56:21.086754: train_loss -1.4668
2023-09-02 07:56:21.088365: val_loss -1.0935
2023-09-02 07:56:21.089635: Pseudo dice [0.8648]
2023-09-02 07:56:21.090694: Epoch time: 111.91 s
2023-09-02 07:56:21.091702: Yayy! New best EMA pseudo Dice: 0.8363
2023-09-02 07:56:24.158238: 
2023-09-02 07:56:24.159890: Epoch 166
2023-09-02 07:56:24.161004: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-02 07:56:24.162468: start training, 250
================num of epochs: 250================
2023-09-02 07:57:22.165387: finished training
epoch: 166, dataset: CVC-300, dice: 0.8865483333333333
CVC-300 :  0.8865483333333333
epoch: 166, dataset: CVC-ClinicDB, dice: 0.8739709677419355
CVC-ClinicDB :  0.8739709677419355
epoch: 166, dataset: Kvasir, dice: 0.8972140000000001
Kvasir :  0.8972140000000001
epoch: 166, dataset: CVC-ColonDB, dice: 0.7034236842105267
CVC-ColonDB :  0.7034236842105267
epoch: 166, dataset: ETIS-LaribPolypDB, dice: 0.7309448979591836
ETIS-LaribPolypDB :  0.7309448979591836
2023-09-02 07:58:18.754292: train_loss -1.4677
2023-09-02 07:58:18.755944: val_loss -1.0594
2023-09-02 07:58:18.757194: Pseudo dice [0.8537]
2023-09-02 07:58:18.758219: Epoch time: 114.6 s
2023-09-02 07:58:18.759170: Yayy! New best EMA pseudo Dice: 0.8381
2023-09-02 07:58:21.658107: 
2023-09-02 07:58:21.660201: Epoch 167
2023-09-02 07:58:21.661257: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-02 07:58:21.662694: start training, 250
================num of epochs: 250================
2023-09-02 07:59:20.954544: finished training
epoch: 167, dataset: CVC-300, dice: 0.87599
CVC-300 :  0.87599
epoch: 167, dataset: CVC-ClinicDB, dice: 0.8756629032258065
CVC-ClinicDB :  0.8756629032258065
epoch: 167, dataset: Kvasir, dice: 0.8968229999999998
Kvasir :  0.8968229999999998
epoch: 167, dataset: CVC-ColonDB, dice: 0.7020160526315795
CVC-ColonDB :  0.7020160526315795
epoch: 167, dataset: ETIS-LaribPolypDB, dice: 0.7245117346938779
ETIS-LaribPolypDB :  0.7245117346938779
2023-09-02 08:00:18.072544: train_loss -1.4672
2023-09-02 08:00:18.074457: val_loss -0.9706
2023-09-02 08:00:18.076006: Pseudo dice [0.8374]
2023-09-02 08:00:18.077182: Epoch time: 116.42 s
2023-09-02 08:00:20.244986: 
2023-09-02 08:00:20.246648: Epoch 168
2023-09-02 08:00:20.247739: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-02 08:00:20.249057: start training, 250
================num of epochs: 250================
2023-09-02 08:01:18.198196: finished training
epoch: 168, dataset: CVC-300, dice: 0.8804466666666664
CVC-300 :  0.8804466666666664
epoch: 168, dataset: CVC-ClinicDB, dice: 0.874667741935484
CVC-ClinicDB :  0.874667741935484
epoch: 168, dataset: Kvasir, dice: 0.89829
Kvasir :  0.89829
epoch: 168, dataset: CVC-ColonDB, dice: 0.7039521052631577
CVC-ColonDB :  0.7039521052631577
epoch: 168, dataset: ETIS-LaribPolypDB, dice: 0.7202377551020416
ETIS-LaribPolypDB :  0.7202377551020416
2023-09-02 08:02:12.264963: train_loss -1.4672
2023-09-02 08:02:12.266721: val_loss -0.853
2023-09-02 08:02:12.267986: Pseudo dice [0.8134]
2023-09-02 08:02:12.268985: Epoch time: 112.02 s
2023-09-02 08:02:13.505322: 
2023-09-02 08:02:13.507176: Epoch 169
2023-09-02 08:02:13.508314: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-02 08:02:13.509820: start training, 250
================num of epochs: 250================
2023-09-02 08:03:11.485770: finished training
epoch: 169, dataset: CVC-300, dice: 0.8951800000000001
CVC-300 :  0.8951800000000001
epoch: 169, dataset: CVC-ClinicDB, dice: 0.8760903225806451
CVC-ClinicDB :  0.8760903225806451
epoch: 169, dataset: Kvasir, dice: 0.9000879999999997
Kvasir :  0.9000879999999997
epoch: 169, dataset: CVC-ColonDB, dice: 0.7057292105263157
CVC-ColonDB :  0.7057292105263157
epoch: 169, dataset: ETIS-LaribPolypDB, dice: 0.7277586734693879
ETIS-LaribPolypDB :  0.7277586734693879
2023-09-02 08:04:05.573433: train_loss -1.468
2023-09-02 08:04:05.575013: val_loss -0.8536
2023-09-02 08:04:05.576307: Pseudo dice [0.8207]
2023-09-02 08:04:05.577510: Epoch time: 112.07 s
2023-09-02 08:04:08.538520: 
2023-09-02 08:04:08.540136: Epoch 170
2023-09-02 08:04:08.541143: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-02 08:04:08.542661: start training, 250
================num of epochs: 250================
2023-09-02 08:05:06.466393: finished training
epoch: 170, dataset: CVC-300, dice: 0.8891283333333333
CVC-300 :  0.8891283333333333
epoch: 170, dataset: CVC-ClinicDB, dice: 0.8749435483870969
CVC-ClinicDB :  0.8749435483870969
epoch: 170, dataset: Kvasir, dice: 0.9010440000000002
Kvasir :  0.9010440000000002
epoch: 170, dataset: CVC-ColonDB, dice: 0.7030297368421062
CVC-ColonDB :  0.7030297368421062
epoch: 170, dataset: ETIS-LaribPolypDB, dice: 0.7337306122448978
ETIS-LaribPolypDB :  0.7337306122448978
2023-09-02 08:06:00.424236: train_loss -1.468
2023-09-02 08:06:00.425869: val_loss -0.9641
2023-09-02 08:06:00.427290: Pseudo dice [0.8292]
2023-09-02 08:06:00.428378: Epoch time: 111.89 s
2023-09-02 08:06:01.961049: 
2023-09-02 08:06:01.962775: Epoch 171
2023-09-02 08:06:01.963916: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-02 08:06:01.965427: start training, 250
================num of epochs: 250================
2023-09-02 08:06:59.911945: finished training
epoch: 171, dataset: CVC-300, dice: 0.883835
CVC-300 :  0.883835
epoch: 171, dataset: CVC-ClinicDB, dice: 0.8771919354838708
CVC-ClinicDB :  0.8771919354838708
epoch: 171, dataset: Kvasir, dice: 0.898001
Kvasir :  0.898001
epoch: 171, dataset: CVC-ColonDB, dice: 0.7020015789473683
CVC-ColonDB :  0.7020015789473683
epoch: 171, dataset: ETIS-LaribPolypDB, dice: 0.7369198979591834
ETIS-LaribPolypDB :  0.7369198979591834
2023-09-02 08:07:53.954467: train_loss -1.468
2023-09-02 08:07:53.956155: val_loss -1.0176
2023-09-02 08:07:53.957628: Pseudo dice [0.8438]
2023-09-02 08:07:53.958816: Epoch time: 111.99 s
2023-09-02 08:07:55.197559: 
2023-09-02 08:07:55.199172: Epoch 172
2023-09-02 08:07:55.200285: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-02 08:07:55.201813: start training, 250
================num of epochs: 250================
2023-09-02 08:08:53.113487: finished training
epoch: 172, dataset: CVC-300, dice: 0.8881816666666664
CVC-300 :  0.8881816666666664
epoch: 172, dataset: CVC-ClinicDB, dice: 0.8784951612903226
CVC-ClinicDB :  0.8784951612903226
epoch: 172, dataset: Kvasir, dice: 0.8979050000000001
Kvasir :  0.8979050000000001
epoch: 172, dataset: CVC-ColonDB, dice: 0.7056607894736848
CVC-ColonDB :  0.7056607894736848
epoch: 172, dataset: ETIS-LaribPolypDB, dice: 0.7323489795918369
ETIS-LaribPolypDB :  0.7323489795918369
2023-09-02 08:09:46.807072: train_loss -1.468
2023-09-02 08:09:46.808853: val_loss -0.9429
2023-09-02 08:09:46.810190: Pseudo dice [0.8352]
2023-09-02 08:09:46.811271: Epoch time: 111.61 s
2023-09-02 08:09:48.060292: 
2023-09-02 08:09:48.061922: Epoch 173
2023-09-02 08:09:48.063074: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-02 08:09:48.064598: start training, 250
================num of epochs: 250================
2023-09-02 08:10:45.987678: finished training
epoch: 173, dataset: CVC-300, dice: 0.880435
CVC-300 :  0.880435
epoch: 173, dataset: CVC-ClinicDB, dice: 0.8765774193548387
CVC-ClinicDB :  0.8765774193548387
epoch: 173, dataset: Kvasir, dice: 0.8961410000000001
Kvasir :  0.8961410000000001
epoch: 173, dataset: CVC-ColonDB, dice: 0.698473157894737
CVC-ColonDB :  0.698473157894737
epoch: 173, dataset: ETIS-LaribPolypDB, dice: 0.7291647959183674
ETIS-LaribPolypDB :  0.7291647959183674
2023-09-02 08:11:39.466304: train_loss -1.4683
2023-09-02 08:11:39.467947: val_loss -0.9249
2023-09-02 08:11:39.469299: Pseudo dice [0.828]
2023-09-02 08:11:39.470403: Epoch time: 111.41 s
2023-09-02 08:11:41.013860: 
2023-09-02 08:11:41.015426: Epoch 174
2023-09-02 08:11:41.016596: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-02 08:11:41.018080: start training, 250
================num of epochs: 250================
2023-09-02 08:12:38.958212: finished training
epoch: 174, dataset: CVC-300, dice: 0.8981499999999997
CVC-300 :  0.8981499999999997
epoch: 174, dataset: CVC-ClinicDB, dice: 0.8785387096774191
CVC-ClinicDB :  0.8785387096774191
epoch: 174, dataset: Kvasir, dice: 0.9027059999999999
Kvasir :  0.9027059999999999
epoch: 174, dataset: CVC-ColonDB, dice: 0.7128873684210526
CVC-ColonDB :  0.7128873684210526
epoch: 174, dataset: ETIS-LaribPolypDB, dice: 0.748375
ETIS-LaribPolypDB :  0.748375
2023-09-02 08:13:32.939528: train_loss -1.4678
2023-09-02 08:13:32.941201: val_loss -0.9685
2023-09-02 08:13:32.942666: Pseudo dice [0.8453]
2023-09-02 08:13:32.943862: Epoch time: 111.93 s
2023-09-02 08:13:34.180109: 
2023-09-02 08:13:34.181777: Epoch 175
2023-09-02 08:13:34.182800: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-02 08:13:34.184150: start training, 250
================num of epochs: 250================
2023-09-02 08:14:32.176936: finished training
epoch: 175, dataset: CVC-300, dice: 0.8959383333333334
CVC-300 :  0.8959383333333334
epoch: 175, dataset: CVC-ClinicDB, dice: 0.8760967741935484
CVC-ClinicDB :  0.8760967741935484
epoch: 175, dataset: Kvasir, dice: 0.9039639999999999
Kvasir :  0.9039639999999999
epoch: 175, dataset: CVC-ColonDB, dice: 0.7033371052631586
CVC-ColonDB :  0.7033371052631586
epoch: 175, dataset: ETIS-LaribPolypDB, dice: 0.7463591836734699
ETIS-LaribPolypDB :  0.7463591836734699
2023-09-02 08:15:26.157911: train_loss -1.4677
2023-09-02 08:15:26.159568: val_loss -0.9394
2023-09-02 08:15:26.161306: Pseudo dice [0.8273]
2023-09-02 08:15:26.162685: Epoch time: 111.98 s
2023-09-02 08:15:27.412026: 
2023-09-02 08:15:27.413495: Epoch 176
2023-09-02 08:15:27.414585: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-02 08:15:27.415967: start training, 250
================num of epochs: 250================
2023-09-02 08:16:25.343152: finished training
epoch: 176, dataset: CVC-300, dice: 0.8958716666666664
CVC-300 :  0.8958716666666664
epoch: 176, dataset: CVC-ClinicDB, dice: 0.876783870967742
CVC-ClinicDB :  0.876783870967742
epoch: 176, dataset: Kvasir, dice: 0.901684
Kvasir :  0.901684
epoch: 176, dataset: CVC-ColonDB, dice: 0.7126486842105264
CVC-ColonDB :  0.7126486842105264
epoch: 176, dataset: ETIS-LaribPolypDB, dice: 0.7430969387755102
ETIS-LaribPolypDB :  0.7430969387755102
2023-09-02 08:17:18.623629: train_loss -1.4685
2023-09-02 08:17:18.625137: val_loss -0.9663
2023-09-02 08:17:18.626406: Pseudo dice [0.8431]
2023-09-02 08:17:18.627492: Epoch time: 111.21 s
2023-09-02 08:17:19.896489: 
2023-09-02 08:17:19.898006: Epoch 177
2023-09-02 08:17:19.899053: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-02 08:17:19.900384: start training, 250
================num of epochs: 250================
2023-09-02 08:18:18.127546: finished training
epoch: 177, dataset: CVC-300, dice: 0.8933916666666665
CVC-300 :  0.8933916666666665
epoch: 177, dataset: CVC-ClinicDB, dice: 0.8781516129032257
CVC-ClinicDB :  0.8781516129032257
epoch: 177, dataset: Kvasir, dice: 0.9014910000000002
Kvasir :  0.9014910000000002
epoch: 177, dataset: CVC-ColonDB, dice: 0.7255476315789487
CVC-ColonDB :  0.7255476315789487
epoch: 177, dataset: ETIS-LaribPolypDB, dice: 0.749589285714286
ETIS-LaribPolypDB :  0.749589285714286
2023-09-02 08:19:14.497164: train_loss -1.4684
2023-09-02 08:19:14.499054: val_loss -0.9197
2023-09-02 08:19:14.500496: Pseudo dice [0.8231]
2023-09-02 08:19:14.501565: Epoch time: 114.6 s
2023-09-02 08:19:15.768673: 
2023-09-02 08:19:15.770590: Epoch 178
2023-09-02 08:19:15.771736: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-02 08:19:15.773301: start training, 250
================num of epochs: 250================
2023-09-02 08:20:14.141669: finished training
epoch: 178, dataset: CVC-300, dice: 0.8966033333333334
CVC-300 :  0.8966033333333334
epoch: 178, dataset: CVC-ClinicDB, dice: 0.8751516129032259
CVC-ClinicDB :  0.8751516129032259
epoch: 178, dataset: Kvasir, dice: 0.8966710000000003
Kvasir :  0.8966710000000003
epoch: 178, dataset: CVC-ColonDB, dice: 0.7156292105263161
CVC-ColonDB :  0.7156292105263161
epoch: 178, dataset: ETIS-LaribPolypDB, dice: 0.7421489795918367
ETIS-LaribPolypDB :  0.7421489795918367
2023-09-02 08:21:14.367984: train_loss -1.468
2023-09-02 08:21:14.369759: val_loss -0.8985
2023-09-02 08:21:14.372161: Pseudo dice [0.8264]
2023-09-02 08:21:14.373895: Epoch time: 118.6 s
2023-09-02 08:21:15.648023: 
2023-09-02 08:21:15.649668: Epoch 179
2023-09-02 08:21:15.650731: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-02 08:21:15.652404: start training, 250
================num of epochs: 250================
2023-09-02 08:22:13.692925: finished training
epoch: 179, dataset: CVC-300, dice: 0.8960166666666662
CVC-300 :  0.8960166666666662
epoch: 179, dataset: CVC-ClinicDB, dice: 0.8765516129032256
CVC-ClinicDB :  0.8765516129032256
epoch: 179, dataset: Kvasir, dice: 0.8975890000000001
Kvasir :  0.8975890000000001
epoch: 179, dataset: CVC-ColonDB, dice: 0.7190213157894744
CVC-ColonDB :  0.7190213157894744
epoch: 179, dataset: ETIS-LaribPolypDB, dice: 0.7402331632653069
ETIS-LaribPolypDB :  0.7402331632653069
2023-09-02 08:23:11.514490: train_loss -1.4681
2023-09-02 08:23:11.516954: val_loss -0.8715
2023-09-02 08:23:11.518778: Pseudo dice [0.8155]
2023-09-02 08:23:11.519923: Epoch time: 115.87 s
2023-09-02 08:23:14.462085: 
2023-09-02 08:23:14.463668: Epoch 180
2023-09-02 08:23:14.464751: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-02 08:23:14.466413: start training, 250
================num of epochs: 250================
2023-09-02 08:24:13.163697: finished training
epoch: 180, dataset: CVC-300, dice: 0.890548333333333
CVC-300 :  0.890548333333333
epoch: 180, dataset: CVC-ClinicDB, dice: 0.8753596774193546
CVC-ClinicDB :  0.8753596774193546
epoch: 180, dataset: Kvasir, dice: 0.8984899999999996
Kvasir :  0.8984899999999996
epoch: 180, dataset: CVC-ColonDB, dice: 0.7208342105263165
CVC-ColonDB :  0.7208342105263165
epoch: 180, dataset: ETIS-LaribPolypDB, dice: 0.7461311224489799
ETIS-LaribPolypDB :  0.7461311224489799
2023-09-02 08:25:13.257190: train_loss -1.4685
2023-09-02 08:25:13.259210: val_loss -0.9464
2023-09-02 08:25:13.260560: Pseudo dice [0.8404]
2023-09-02 08:25:13.261693: Epoch time: 118.8 s
2023-09-02 08:25:14.528545: 
2023-09-02 08:25:14.530118: Epoch 181
2023-09-02 08:25:14.531161: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-02 08:25:14.532891: start training, 250
================num of epochs: 250================
2023-09-02 08:26:12.896641: finished training
epoch: 181, dataset: CVC-300, dice: 0.8879683333333334
CVC-300 :  0.8879683333333334
epoch: 181, dataset: CVC-ClinicDB, dice: 0.8735935483870968
CVC-ClinicDB :  0.8735935483870968
epoch: 181, dataset: Kvasir, dice: 0.8978360000000003
Kvasir :  0.8978360000000003
epoch: 181, dataset: CVC-ColonDB, dice: 0.7146015789473679
CVC-ColonDB :  0.7146015789473679
epoch: 181, dataset: ETIS-LaribPolypDB, dice: 0.7427719387755103
ETIS-LaribPolypDB :  0.7427719387755103
2023-09-02 08:27:12.369742: train_loss -1.4685
2023-09-02 08:27:12.371679: val_loss -0.8635
2023-09-02 08:27:12.374125: Pseudo dice [0.8189]
2023-09-02 08:27:12.375770: Epoch time: 117.84 s
2023-09-02 08:27:13.677615: 
2023-09-02 08:27:13.679316: Epoch 182
2023-09-02 08:27:13.680482: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-02 08:27:13.682152: start training, 250
================num of epochs: 250================
2023-09-02 08:28:11.379555: finished training
epoch: 182, dataset: CVC-300, dice: 0.8902100000000002
CVC-300 :  0.8902100000000002
epoch: 182, dataset: CVC-ClinicDB, dice: 0.8757435483870967
CVC-ClinicDB :  0.8757435483870967
epoch: 182, dataset: Kvasir, dice: 0.8977859999999999
Kvasir :  0.8977859999999999
epoch: 182, dataset: CVC-ColonDB, dice: 0.715818157894737
CVC-ColonDB :  0.715818157894737
epoch: 182, dataset: ETIS-LaribPolypDB, dice: 0.7441229591836739
ETIS-LaribPolypDB :  0.7441229591836739
2023-09-02 08:29:11.556910: train_loss -1.4692
2023-09-02 08:29:11.559584: val_loss -0.9659
2023-09-02 08:29:11.562033: Pseudo dice [0.843]
2023-09-02 08:29:11.563648: Epoch time: 117.88 s
2023-09-02 08:29:12.781982: 
2023-09-02 08:29:12.783526: Epoch 183
2023-09-02 08:29:12.784609: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-02 08:29:12.786171: start training, 250
================num of epochs: 250================
2023-09-02 08:30:11.106402: finished training
epoch: 183, dataset: CVC-300, dice: 0.8851283333333332
CVC-300 :  0.8851283333333332
epoch: 183, dataset: CVC-ClinicDB, dice: 0.8747870967741934
CVC-ClinicDB :  0.8747870967741934
epoch: 183, dataset: Kvasir, dice: 0.8986329999999999
Kvasir :  0.8986329999999999
epoch: 183, dataset: CVC-ColonDB, dice: 0.7090734210526322
CVC-ColonDB :  0.7090734210526322
epoch: 183, dataset: ETIS-LaribPolypDB, dice: 0.7362612244897964
ETIS-LaribPolypDB :  0.7362612244897964
2023-09-02 08:31:09.572553: train_loss -1.4692
2023-09-02 08:31:09.574359: val_loss -0.9513
2023-09-02 08:31:09.575692: Pseudo dice [0.835]
2023-09-02 08:31:09.576823: Epoch time: 116.79 s
2023-09-02 08:31:10.833830: 
2023-09-02 08:31:10.835525: Epoch 184
2023-09-02 08:31:10.836654: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-02 08:31:10.838341: start training, 250
================num of epochs: 250================
2023-09-02 08:32:08.895650: finished training
epoch: 184, dataset: CVC-300, dice: 0.8915200000000002
CVC-300 :  0.8915200000000002
epoch: 184, dataset: CVC-ClinicDB, dice: 0.8786064516129033
CVC-ClinicDB :  0.8786064516129033
epoch: 184, dataset: Kvasir, dice: 0.8990060000000001
Kvasir :  0.8990060000000001
epoch: 184, dataset: CVC-ColonDB, dice: 0.719022894736842
CVC-ColonDB :  0.719022894736842
epoch: 184, dataset: ETIS-LaribPolypDB, dice: 0.7572545918367353
ETIS-LaribPolypDB :  0.7572545918367353
2023-09-02 08:33:08.924010: train_loss -1.4688
2023-09-02 08:33:08.925650: val_loss -0.9946
2023-09-02 08:33:08.927020: Pseudo dice [0.8499]
2023-09-02 08:33:08.928127: Epoch time: 118.09 s
2023-09-02 08:33:10.149823: 
2023-09-02 08:33:10.151314: Epoch 185
2023-09-02 08:33:10.152394: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-02 08:33:10.153965: start training, 250
================num of epochs: 250================
2023-09-02 08:34:08.447338: finished training
epoch: 185, dataset: CVC-300, dice: 0.8956166666666667
CVC-300 :  0.8956166666666667
epoch: 185, dataset: CVC-ClinicDB, dice: 0.8772435483870968
CVC-ClinicDB :  0.8772435483870968
epoch: 185, dataset: Kvasir, dice: 0.9004249999999999
Kvasir :  0.9004249999999999
epoch: 185, dataset: CVC-ColonDB, dice: 0.714980263157895
CVC-ColonDB :  0.714980263157895
epoch: 185, dataset: ETIS-LaribPolypDB, dice: 0.7522500000000002
ETIS-LaribPolypDB :  0.7522500000000002
2023-09-02 08:35:05.914140: train_loss -1.4681
2023-09-02 08:35:05.916036: val_loss -0.9439
2023-09-02 08:35:05.917623: Pseudo dice [0.8386]
2023-09-02 08:35:05.918790: Epoch time: 115.77 s
2023-09-02 08:35:07.151193: 
2023-09-02 08:35:07.152835: Epoch 186
2023-09-02 08:35:07.153973: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-02 08:35:07.155748: start training, 250
================num of epochs: 250================
2023-09-02 08:36:05.826942: finished training
epoch: 186, dataset: CVC-300, dice: 0.8901033333333328
CVC-300 :  0.8901033333333328
epoch: 186, dataset: CVC-ClinicDB, dice: 0.8728403225806455
CVC-ClinicDB :  0.8728403225806455
epoch: 186, dataset: Kvasir, dice: 0.8974659999999998
Kvasir :  0.8974659999999998
epoch: 186, dataset: CVC-ColonDB, dice: 0.7124752631578948
CVC-ColonDB :  0.7124752631578948
epoch: 186, dataset: ETIS-LaribPolypDB, dice: 0.7365040816326531
ETIS-LaribPolypDB :  0.7365040816326531
2023-09-02 08:37:02.767008: train_loss -1.4684
2023-09-02 08:37:02.768743: val_loss -0.9118
2023-09-02 08:37:02.770131: Pseudo dice [0.8306]
2023-09-02 08:37:02.771247: Epoch time: 115.62 s
2023-09-02 08:37:04.040003: 
2023-09-02 08:37:04.041943: Epoch 187
2023-09-02 08:37:04.043099: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-02 08:37:04.045063: start training, 250
================num of epochs: 250================
2023-09-02 08:38:02.526508: finished training
epoch: 187, dataset: CVC-300, dice: 0.8874166666666667
CVC-300 :  0.8874166666666667
epoch: 187, dataset: CVC-ClinicDB, dice: 0.8768
CVC-ClinicDB :  0.8768
epoch: 187, dataset: Kvasir, dice: 0.8995419999999997
Kvasir :  0.8995419999999997
epoch: 187, dataset: CVC-ColonDB, dice: 0.7055478947368412
CVC-ColonDB :  0.7055478947368412
epoch: 187, dataset: ETIS-LaribPolypDB, dice: 0.7334954081632656
ETIS-LaribPolypDB :  0.7334954081632656
2023-09-02 08:38:57.648728: train_loss -1.4684
2023-09-02 08:38:57.650449: val_loss -0.9815
2023-09-02 08:38:57.651800: Pseudo dice [0.8355]
2023-09-02 08:38:57.652926: Epoch time: 113.61 s
2023-09-02 08:38:58.895298: 
2023-09-02 08:38:58.897085: Epoch 188
2023-09-02 08:38:58.898205: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-02 08:38:58.899939: start training, 250
================num of epochs: 250================
2023-09-02 08:39:56.854536: finished training
epoch: 188, dataset: CVC-300, dice: 0.8891733333333333
CVC-300 :  0.8891733333333333
epoch: 188, dataset: CVC-ClinicDB, dice: 0.875158064516129
CVC-ClinicDB :  0.875158064516129
epoch: 188, dataset: Kvasir, dice: 0.8995240000000001
Kvasir :  0.8995240000000001
epoch: 188, dataset: CVC-ColonDB, dice: 0.7083907894736847
CVC-ColonDB :  0.7083907894736847
epoch: 188, dataset: ETIS-LaribPolypDB, dice: 0.7449948979591839
ETIS-LaribPolypDB :  0.7449948979591839
2023-09-02 08:40:51.309834: train_loss -1.4684
2023-09-02 08:40:51.311461: val_loss -0.9954
2023-09-02 08:40:51.312951: Pseudo dice [0.8373]
2023-09-02 08:40:51.314422: Epoch time: 112.42 s
2023-09-02 08:40:52.534383: 
2023-09-02 08:40:52.535907: Epoch 189
2023-09-02 08:40:52.537343: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-02 08:40:52.539448: start training, 250
================num of epochs: 250================
2023-09-02 08:41:50.758496: finished training
epoch: 189, dataset: CVC-300, dice: 0.8938133333333339
CVC-300 :  0.8938133333333339
epoch: 189, dataset: CVC-ClinicDB, dice: 0.8778241935483871
CVC-ClinicDB :  0.8778241935483871
epoch: 189, dataset: Kvasir, dice: 0.9012500000000001
Kvasir :  0.9012500000000001
epoch: 189, dataset: CVC-ColonDB, dice: 0.7156613157894736
CVC-ColonDB :  0.7156613157894736
epoch: 189, dataset: ETIS-LaribPolypDB, dice: 0.7478306122448981
ETIS-LaribPolypDB :  0.7478306122448981
2023-09-02 08:42:45.071226: train_loss -1.4693
2023-09-02 08:42:45.072794: val_loss -0.8104
2023-09-02 08:42:45.074121: Pseudo dice [0.8094]
2023-09-02 08:42:45.075221: Epoch time: 112.54 s
2023-09-02 08:42:47.897044: 
2023-09-02 08:42:47.898773: Epoch 190
2023-09-02 08:42:47.900182: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-02 08:42:47.901971: start training, 250
================num of epochs: 250================
2023-09-02 08:43:45.884139: finished training
epoch: 190, dataset: CVC-300, dice: 0.8904949999999997
CVC-300 :  0.8904949999999997
epoch: 190, dataset: CVC-ClinicDB, dice: 0.8799709677419355
CVC-ClinicDB :  0.8799709677419355
epoch: 190, dataset: Kvasir, dice: 0.9005249999999997
Kvasir :  0.9005249999999997
epoch: 190, dataset: CVC-ColonDB, dice: 0.7153905263157891
CVC-ColonDB :  0.7153905263157891
epoch: 190, dataset: ETIS-LaribPolypDB, dice: 0.7441464285714288
ETIS-LaribPolypDB :  0.7441464285714288
2023-09-02 08:44:41.245445: train_loss -1.4693
2023-09-02 08:44:41.247129: val_loss -0.8242
2023-09-02 08:44:41.248438: Pseudo dice [0.8066]
2023-09-02 08:44:41.249546: Epoch time: 113.35 s
2023-09-02 08:44:42.455210: 
2023-09-02 08:44:42.456868: Epoch 191
2023-09-02 08:44:42.458077: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-02 08:44:42.459674: start training, 250
================num of epochs: 250================
2023-09-02 08:45:40.260316: finished training
epoch: 191, dataset: CVC-300, dice: 0.8761333333333331
CVC-300 :  0.8761333333333331
epoch: 191, dataset: CVC-ClinicDB, dice: 0.8757596774193549
CVC-ClinicDB :  0.8757596774193549
epoch: 191, dataset: Kvasir, dice: 0.899209
Kvasir :  0.899209
epoch: 191, dataset: CVC-ColonDB, dice: 0.7055334210526321
CVC-ColonDB :  0.7055334210526321
epoch: 191, dataset: ETIS-LaribPolypDB, dice: 0.7241321428571423
ETIS-LaribPolypDB :  0.7241321428571423
2023-09-02 08:46:34.395918: train_loss -1.4694
2023-09-02 08:46:34.397723: val_loss -0.9064
2023-09-02 08:46:34.399168: Pseudo dice [0.826]
2023-09-02 08:46:34.400411: Epoch time: 111.94 s
2023-09-02 08:46:35.656335: 
2023-09-02 08:46:35.657846: Epoch 192
2023-09-02 08:46:35.658917: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-02 08:46:35.660360: start training, 250
================num of epochs: 250================
2023-09-02 08:47:33.818994: finished training
epoch: 192, dataset: CVC-300, dice: 0.8872483333333333
CVC-300 :  0.8872483333333333
epoch: 192, dataset: CVC-ClinicDB, dice: 0.8769112903225805
CVC-ClinicDB :  0.8769112903225805
epoch: 192, dataset: Kvasir, dice: 0.8984380000000003
Kvasir :  0.8984380000000003
epoch: 192, dataset: CVC-ColonDB, dice: 0.7083584210526324
CVC-ColonDB :  0.7083584210526324
epoch: 192, dataset: ETIS-LaribPolypDB, dice: 0.7342198979591837
ETIS-LaribPolypDB :  0.7342198979591837
2023-09-02 08:48:28.465750: train_loss -1.469
2023-09-02 08:48:28.467604: val_loss -0.867
2023-09-02 08:48:28.469190: Pseudo dice [0.8164]
2023-09-02 08:48:28.470451: Epoch time: 112.81 s
2023-09-02 08:48:29.736432: 
2023-09-02 08:48:29.738103: Epoch 193
2023-09-02 08:48:29.739252: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-02 08:48:29.740798: start training, 250
================num of epochs: 250================
2023-09-02 08:49:27.599177: finished training
epoch: 193, dataset: CVC-300, dice: 0.8881833333333334
CVC-300 :  0.8881833333333334
epoch: 193, dataset: CVC-ClinicDB, dice: 0.8767080645161293
CVC-ClinicDB :  0.8767080645161293
epoch: 193, dataset: Kvasir, dice: 0.89752
Kvasir :  0.89752
epoch: 193, dataset: CVC-ColonDB, dice: 0.6991039473684213
CVC-ColonDB :  0.6991039473684213
epoch: 193, dataset: ETIS-LaribPolypDB, dice: 0.7228897959183673
ETIS-LaribPolypDB :  0.7228897959183673
2023-09-02 08:50:21.403651: train_loss -1.4688
2023-09-02 08:50:21.405428: val_loss -0.9483
2023-09-02 08:50:21.406847: Pseudo dice [0.826]
2023-09-02 08:50:21.408079: Epoch time: 111.67 s
2023-09-02 08:50:22.679569: 
2023-09-02 08:50:22.681199: Epoch 194
2023-09-02 08:50:22.682462: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-02 08:50:22.684038: start training, 250
================num of epochs: 250================
2023-09-02 08:51:20.551427: finished training
epoch: 194, dataset: CVC-300, dice: 0.8952283333333334
CVC-300 :  0.8952283333333334
epoch: 194, dataset: CVC-ClinicDB, dice: 0.877806451612903
CVC-ClinicDB :  0.877806451612903
epoch: 194, dataset: Kvasir, dice: 0.8996670000000002
Kvasir :  0.8996670000000002
epoch: 194, dataset: CVC-ColonDB, dice: 0.7131381578947361
CVC-ColonDB :  0.7131381578947361
epoch: 194, dataset: ETIS-LaribPolypDB, dice: 0.7287918367346942
ETIS-LaribPolypDB :  0.7287918367346942
2023-09-02 08:52:14.126325: train_loss -1.469
2023-09-02 08:52:14.128102: val_loss -0.9081
2023-09-02 08:52:14.129693: Pseudo dice [0.8213]
2023-09-02 08:52:14.130816: Epoch time: 111.45 s
2023-09-02 08:52:15.384120: 
2023-09-02 08:52:15.385921: Epoch 195
2023-09-02 08:52:15.387041: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-02 08:52:15.388576: start training, 250
================num of epochs: 250================
2023-09-02 08:53:13.823343: finished training
epoch: 195, dataset: CVC-300, dice: 0.8902433333333335
CVC-300 :  0.8902433333333335
epoch: 195, dataset: CVC-ClinicDB, dice: 0.870156451612903
CVC-ClinicDB :  0.870156451612903
epoch: 195, dataset: Kvasir, dice: 0.8969250000000001
Kvasir :  0.8969250000000001
epoch: 195, dataset: CVC-ColonDB, dice: 0.6919607894736842
CVC-ColonDB :  0.6919607894736842
epoch: 195, dataset: ETIS-LaribPolypDB, dice: 0.7184887755102044
ETIS-LaribPolypDB :  0.7184887755102044
2023-09-02 08:54:08.394971: train_loss -1.469
2023-09-02 08:54:08.396670: val_loss -0.8286
2023-09-02 08:54:08.398066: Pseudo dice [0.7967]
2023-09-02 08:54:08.399151: Epoch time: 113.01 s
2023-09-02 08:54:09.670603: 
2023-09-02 08:54:09.672144: Epoch 196
2023-09-02 08:54:09.673405: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-02 08:54:09.674905: start training, 250
================num of epochs: 250================
2023-09-02 08:55:07.560379: finished training
epoch: 196, dataset: CVC-300, dice: 0.892535
CVC-300 :  0.892535
epoch: 196, dataset: CVC-ClinicDB, dice: 0.8745983870967743
CVC-ClinicDB :  0.8745983870967743
epoch: 196, dataset: Kvasir, dice: 0.9003360000000004
Kvasir :  0.9003360000000004
epoch: 196, dataset: CVC-ColonDB, dice: 0.6992934210526321
CVC-ColonDB :  0.6992934210526321
epoch: 196, dataset: ETIS-LaribPolypDB, dice: 0.734455612244898
ETIS-LaribPolypDB :  0.734455612244898
2023-09-02 08:56:01.943796: train_loss -1.4696
2023-09-02 08:56:01.945455: val_loss -0.9327
2023-09-02 08:56:01.946910: Pseudo dice [0.8349]
2023-09-02 08:56:01.948082: Epoch time: 112.27 s
2023-09-02 08:56:03.207629: 
2023-09-02 08:56:03.209449: Epoch 197
2023-09-02 08:56:03.210659: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-02 08:56:03.212142: start training, 250
================num of epochs: 250================
2023-09-02 08:57:01.100468: finished training
epoch: 197, dataset: CVC-300, dice: 0.8947116666666666
CVC-300 :  0.8947116666666666
epoch: 197, dataset: CVC-ClinicDB, dice: 0.8768629032258063
CVC-ClinicDB :  0.8768629032258063
epoch: 197, dataset: Kvasir, dice: 0.8997779999999999
Kvasir :  0.8997779999999999
epoch: 197, dataset: CVC-ColonDB, dice: 0.713455000000001
CVC-ColonDB :  0.713455000000001
epoch: 197, dataset: ETIS-LaribPolypDB, dice: 0.7402147959183674
ETIS-LaribPolypDB :  0.7402147959183674
2023-09-02 08:57:54.828591: train_loss -1.4695
2023-09-02 08:57:54.830263: val_loss -0.8274
2023-09-02 08:57:54.831789: Pseudo dice [0.81]
2023-09-02 08:57:54.833113: Epoch time: 111.62 s
2023-09-02 08:57:56.121644: 
2023-09-02 08:57:56.123533: Epoch 198
2023-09-02 08:57:56.124635: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-02 08:57:56.126125: start training, 250
================num of epochs: 250================
2023-09-02 08:58:54.245015: finished training
epoch: 198, dataset: CVC-300, dice: 0.8897650000000003
CVC-300 :  0.8897650000000003
epoch: 198, dataset: CVC-ClinicDB, dice: 0.8754612903225808
CVC-ClinicDB :  0.8754612903225808
epoch: 198, dataset: Kvasir, dice: 0.8999369999999999
Kvasir :  0.8999369999999999
epoch: 198, dataset: CVC-ColonDB, dice: 0.695051052631579
CVC-ColonDB :  0.695051052631579
epoch: 198, dataset: ETIS-LaribPolypDB, dice: 0.7232566326530613
ETIS-LaribPolypDB :  0.7232566326530613
2023-09-02 08:59:49.275126: train_loss -1.4695
2023-09-02 08:59:49.276781: val_loss -0.9708
2023-09-02 08:59:49.278110: Pseudo dice [0.8314]
2023-09-02 08:59:49.279230: Epoch time: 113.15 s
2023-09-02 08:59:50.544670: 
2023-09-02 08:59:50.546538: Epoch 199
2023-09-02 08:59:50.547677: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-02 08:59:50.549133: start training, 250
================num of epochs: 250================
2023-09-02 09:00:48.427842: finished training
epoch: 199, dataset: CVC-300, dice: 0.8821166666666668
CVC-300 :  0.8821166666666668
epoch: 199, dataset: CVC-ClinicDB, dice: 0.8677564516129032
CVC-ClinicDB :  0.8677564516129032
epoch: 199, dataset: Kvasir, dice: 0.898815
Kvasir :  0.898815
epoch: 199, dataset: CVC-ColonDB, dice: 0.6889923684210522
CVC-ColonDB :  0.6889923684210522
epoch: 199, dataset: ETIS-LaribPolypDB, dice: 0.7184102040816329
ETIS-LaribPolypDB :  0.7184102040816329
2023-09-02 09:01:42.260828: train_loss -1.4699
2023-09-02 09:01:42.262619: val_loss -0.8584
2023-09-02 09:01:42.264152: Pseudo dice [0.8078]
2023-09-02 09:01:42.265467: Epoch time: 111.72 s
2023-09-02 09:01:45.134473: 
2023-09-02 09:01:45.136189: Epoch 200
2023-09-02 09:01:45.137328: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-02 09:01:45.138946: start training, 250
================num of epochs: 250================
2023-09-02 09:02:43.061413: finished training
epoch: 200, dataset: CVC-300, dice: 0.8799066666666665
CVC-300 :  0.8799066666666665
epoch: 200, dataset: CVC-ClinicDB, dice: 0.8660177419354839
CVC-ClinicDB :  0.8660177419354839
epoch: 200, dataset: Kvasir, dice: 0.8987120000000001
Kvasir :  0.8987120000000001
epoch: 200, dataset: CVC-ColonDB, dice: 0.6885315789473682
CVC-ColonDB :  0.6885315789473682
epoch: 200, dataset: ETIS-LaribPolypDB, dice: 0.7129790816326533
ETIS-LaribPolypDB :  0.7129790816326533
2023-09-02 09:03:36.714018: train_loss -1.4702
2023-09-02 09:03:36.715726: val_loss -0.9249
2023-09-02 09:03:36.717093: Pseudo dice [0.8353]
2023-09-02 09:03:36.718187: Epoch time: 111.58 s
2023-09-02 09:03:37.987254: 
2023-09-02 09:03:37.988869: Epoch 201
2023-09-02 09:03:37.989944: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-02 09:03:37.991382: start training, 250
================num of epochs: 250================
2023-09-02 09:04:36.572146: finished training
epoch: 201, dataset: CVC-300, dice: 0.8855916666666667
CVC-300 :  0.8855916666666667
epoch: 201, dataset: CVC-ClinicDB, dice: 0.8780596774193552
CVC-ClinicDB :  0.8780596774193552
epoch: 201, dataset: Kvasir, dice: 0.896675
Kvasir :  0.896675
epoch: 201, dataset: CVC-ColonDB, dice: 0.6920736842105266
CVC-ColonDB :  0.6920736842105266
epoch: 201, dataset: ETIS-LaribPolypDB, dice: 0.7200326530612243
ETIS-LaribPolypDB :  0.7200326530612243
2023-09-02 09:05:32.993528: train_loss -1.4682
2023-09-02 09:05:32.995357: val_loss -0.9405
2023-09-02 09:05:32.996877: Pseudo dice [0.8476]
2023-09-02 09:05:32.998001: Epoch time: 115.01 s
2023-09-02 09:05:34.276860: 
2023-09-02 09:05:34.278678: Epoch 202
2023-09-02 09:05:34.279952: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-02 09:05:34.281613: start training, 250
================num of epochs: 250================
2023-09-02 09:06:32.457459: finished training
epoch: 202, dataset: CVC-300, dice: 0.8855199999999999
CVC-300 :  0.8855199999999999
epoch: 202, dataset: CVC-ClinicDB, dice: 0.8800161290322582
CVC-ClinicDB :  0.8800161290322582
epoch: 202, dataset: Kvasir, dice: 0.8975030000000004
Kvasir :  0.8975030000000004
epoch: 202, dataset: CVC-ColonDB, dice: 0.6944207894736851
CVC-ColonDB :  0.6944207894736851
epoch: 202, dataset: ETIS-LaribPolypDB, dice: 0.7333698979591841
ETIS-LaribPolypDB :  0.7333698979591841
2023-09-02 09:07:32.306352: train_loss -1.4693
2023-09-02 09:07:32.308181: val_loss -0.9282
2023-09-02 09:07:32.310235: Pseudo dice [0.8447]
2023-09-02 09:07:32.311946: Epoch time: 118.03 s
2023-09-02 09:07:33.711922: 
2023-09-02 09:07:33.714181: Epoch 203
2023-09-02 09:07:33.715447: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-02 09:07:33.717324: start training, 250
================num of epochs: 250================
2023-09-02 09:08:32.320922: finished training
epoch: 203, dataset: CVC-300, dice: 0.8760216666666667
CVC-300 :  0.8760216666666667
epoch: 203, dataset: CVC-ClinicDB, dice: 0.8738870967741934
CVC-ClinicDB :  0.8738870967741934
epoch: 203, dataset: Kvasir, dice: 0.8897679999999997
Kvasir :  0.8897679999999997
epoch: 203, dataset: CVC-ColonDB, dice: 0.6770263157894743
CVC-ColonDB :  0.6770263157894743
epoch: 203, dataset: ETIS-LaribPolypDB, dice: 0.7255265306122451
ETIS-LaribPolypDB :  0.7255265306122451
2023-09-02 09:09:30.528543: train_loss -1.4693
2023-09-02 09:09:30.530333: val_loss -0.8752
2023-09-02 09:09:30.531809: Pseudo dice [0.8255]
2023-09-02 09:09:30.532941: Epoch time: 116.82 s
2023-09-02 09:09:31.879091: 
2023-09-02 09:09:31.881070: Epoch 204
2023-09-02 09:09:31.882254: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-02 09:09:31.884233: start training, 250
================num of epochs: 250================
2023-09-02 09:10:30.669301: finished training
epoch: 204, dataset: CVC-300, dice: 0.8820366666666668
CVC-300 :  0.8820366666666668
epoch: 204, dataset: CVC-ClinicDB, dice: 0.87435
CVC-ClinicDB :  0.87435
epoch: 204, dataset: Kvasir, dice: 0.9004720000000002
Kvasir :  0.9004720000000002
epoch: 204, dataset: CVC-ColonDB, dice: 0.695684473684211
CVC-ColonDB :  0.695684473684211
epoch: 204, dataset: ETIS-LaribPolypDB, dice: 0.7592969387755104
ETIS-LaribPolypDB :  0.7592969387755104
2023-09-02 09:11:29.850216: train_loss -1.4696
2023-09-02 09:11:29.852543: val_loss -0.894
2023-09-02 09:11:29.854205: Pseudo dice [0.8289]
2023-09-02 09:11:29.855527: Epoch time: 117.97 s
2023-09-02 09:11:31.084295: 
2023-09-02 09:11:31.085945: Epoch 205
2023-09-02 09:11:31.087219: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-02 09:11:31.088830: start training, 250
================num of epochs: 250================
2023-09-02 09:12:29.274194: finished training
epoch: 205, dataset: CVC-300, dice: 0.87889
CVC-300 :  0.87889
epoch: 205, dataset: CVC-ClinicDB, dice: 0.878059677419355
CVC-ClinicDB :  0.878059677419355
epoch: 205, dataset: Kvasir, dice: 0.8976290000000003
Kvasir :  0.8976290000000003
epoch: 205, dataset: CVC-ColonDB, dice: 0.7001407894736834
CVC-ColonDB :  0.7001407894736834
epoch: 205, dataset: ETIS-LaribPolypDB, dice: 0.7491867346938779
ETIS-LaribPolypDB :  0.7491867346938779
2023-09-02 09:13:27.796644: train_loss -1.4695
2023-09-02 09:13:27.798452: val_loss -0.8129
2023-09-02 09:13:27.800027: Pseudo dice [0.801]
2023-09-02 09:13:27.801213: Epoch time: 116.71 s
2023-09-02 09:13:28.988288: 
2023-09-02 09:13:28.989918: Epoch 206
2023-09-02 09:13:28.991034: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-02 09:13:28.992488: start training, 250
================num of epochs: 250================
2023-09-02 09:14:27.064699: finished training
epoch: 206, dataset: CVC-300, dice: 0.878345
CVC-300 :  0.878345
epoch: 206, dataset: CVC-ClinicDB, dice: 0.8755306451612902
CVC-ClinicDB :  0.8755306451612902
epoch: 206, dataset: Kvasir, dice: 0.8955800000000003
Kvasir :  0.8955800000000003
epoch: 206, dataset: CVC-ColonDB, dice: 0.691630789473684
CVC-ColonDB :  0.691630789473684
epoch: 206, dataset: ETIS-LaribPolypDB, dice: 0.7364275510204082
ETIS-LaribPolypDB :  0.7364275510204082
2023-09-02 09:15:27.451159: train_loss -1.4695
2023-09-02 09:15:27.453838: val_loss -0.9825
2023-09-02 09:15:27.456254: Pseudo dice [0.8519]
2023-09-02 09:15:27.458553: Epoch time: 118.46 s
2023-09-02 09:15:28.631447: 
2023-09-02 09:15:28.632913: Epoch 207
2023-09-02 09:15:28.634076: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-02 09:15:28.635653: start training, 250
================num of epochs: 250================
2023-09-02 09:16:27.261948: finished training
epoch: 207, dataset: CVC-300, dice: 0.8811900000000003
CVC-300 :  0.8811900000000003
epoch: 207, dataset: CVC-ClinicDB, dice: 0.880864516129032
CVC-ClinicDB :  0.880864516129032
epoch: 207, dataset: Kvasir, dice: 0.8984729999999995
Kvasir :  0.8984729999999995
epoch: 207, dataset: CVC-ColonDB, dice: 0.7017773684210522
CVC-ColonDB :  0.7017773684210522
epoch: 207, dataset: ETIS-LaribPolypDB, dice: 0.7511448979591842
ETIS-LaribPolypDB :  0.7511448979591842
2023-09-02 09:17:26.202603: train_loss -1.4693
2023-09-02 09:17:26.204315: val_loss -0.9342
2023-09-02 09:17:26.205861: Pseudo dice [0.8335]
2023-09-02 09:17:26.207058: Epoch time: 117.57 s
2023-09-02 09:17:27.381908: 
2023-09-02 09:17:27.383514: Epoch 208
2023-09-02 09:17:27.384768: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-02 09:17:27.386354: start training, 250
================num of epochs: 250================
2023-09-02 09:18:25.324196: finished training
epoch: 208, dataset: CVC-300, dice: 0.8842016666666666
CVC-300 :  0.8842016666666666
epoch: 208, dataset: CVC-ClinicDB, dice: 0.8781096774193548
CVC-ClinicDB :  0.8781096774193548
epoch: 208, dataset: Kvasir, dice: 0.8953949999999997
Kvasir :  0.8953949999999997
epoch: 208, dataset: CVC-ColonDB, dice: 0.7074173684210526
CVC-ColonDB :  0.7074173684210526
epoch: 208, dataset: ETIS-LaribPolypDB, dice: 0.7428198979591839
ETIS-LaribPolypDB :  0.7428198979591839
2023-09-02 09:19:22.517886: train_loss -1.4698
2023-09-02 09:19:22.519554: val_loss -0.8395
2023-09-02 09:19:22.520949: Pseudo dice [0.8181]
2023-09-02 09:19:22.522079: Epoch time: 115.14 s
2023-09-02 09:19:23.702657: 
2023-09-02 09:19:23.704116: Epoch 209
2023-09-02 09:19:23.705235: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-02 09:19:23.706689: start training, 250
================num of epochs: 250================
2023-09-02 09:20:21.914141: finished training
epoch: 209, dataset: CVC-300, dice: 0.8913550000000001
CVC-300 :  0.8913550000000001
epoch: 209, dataset: CVC-ClinicDB, dice: 0.8776000000000003
CVC-ClinicDB :  0.8776000000000003
epoch: 209, dataset: Kvasir, dice: 0.8996510000000001
Kvasir :  0.8996510000000001
epoch: 209, dataset: CVC-ColonDB, dice: 0.7109921052631579
CVC-ColonDB :  0.7109921052631579
epoch: 209, dataset: ETIS-LaribPolypDB, dice: 0.7534255102040812
ETIS-LaribPolypDB :  0.7534255102040812
2023-09-02 09:21:17.008694: train_loss -1.4699
2023-09-02 09:21:17.010516: val_loss -0.8216
2023-09-02 09:21:17.011892: Pseudo dice [0.8099]
2023-09-02 09:21:17.013156: Epoch time: 113.31 s
2023-09-02 09:21:19.810076: 
2023-09-02 09:21:19.812039: Epoch 210
2023-09-02 09:21:19.813427: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-02 09:21:19.815050: start training, 250
================num of epochs: 250================
2023-09-02 09:22:18.484135: finished training
epoch: 210, dataset: CVC-300, dice: 0.8810733333333335
CVC-300 :  0.8810733333333335
epoch: 210, dataset: CVC-ClinicDB, dice: 0.87755
CVC-ClinicDB :  0.87755
epoch: 210, dataset: Kvasir, dice: 0.900074
Kvasir :  0.900074
epoch: 210, dataset: CVC-ColonDB, dice: 0.7078842105263162
CVC-ColonDB :  0.7078842105263162
epoch: 210, dataset: ETIS-LaribPolypDB, dice: 0.7504311224489794
ETIS-LaribPolypDB :  0.7504311224489794
2023-09-02 09:23:15.189049: train_loss -1.4702
2023-09-02 09:23:15.190771: val_loss -0.8421
2023-09-02 09:23:15.192110: Pseudo dice [0.8134]
2023-09-02 09:23:15.193315: Epoch time: 115.38 s
2023-09-02 09:23:16.358878: 
2023-09-02 09:23:16.360499: Epoch 211
2023-09-02 09:23:16.361643: Current learning rate: backbone 0.000335, others 0.000335
2023-09-02 09:23:16.363176: start training, 250
================num of epochs: 250================
2023-09-02 09:24:14.974518: finished training
epoch: 211, dataset: CVC-300, dice: 0.8791033333333333
CVC-300 :  0.8791033333333333
epoch: 211, dataset: CVC-ClinicDB, dice: 0.8766258064516129
CVC-ClinicDB :  0.8766258064516129
epoch: 211, dataset: Kvasir, dice: 0.897053
Kvasir :  0.897053
epoch: 211, dataset: CVC-ColonDB, dice: 0.704139473684211
CVC-ColonDB :  0.704139473684211
epoch: 211, dataset: ETIS-LaribPolypDB, dice: 0.7463959183673465
ETIS-LaribPolypDB :  0.7463959183673465
2023-09-02 09:25:09.287116: train_loss -1.4703
2023-09-02 09:25:09.288914: val_loss -0.9116
2023-09-02 09:25:09.290279: Pseudo dice [0.8282]
2023-09-02 09:25:09.291428: Epoch time: 112.93 s
2023-09-02 09:25:10.460814: 
2023-09-02 09:25:10.462761: Epoch 212
2023-09-02 09:25:10.463906: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-02 09:25:10.465930: start training, 250
================num of epochs: 250================
2023-09-02 09:26:08.983705: finished training
epoch: 212, dataset: CVC-300, dice: 0.8820516666666668
CVC-300 :  0.8820516666666668
epoch: 212, dataset: CVC-ClinicDB, dice: 0.8773435483870967
CVC-ClinicDB :  0.8773435483870967
epoch: 212, dataset: Kvasir, dice: 0.9025049999999999
Kvasir :  0.9025049999999999
epoch: 212, dataset: CVC-ColonDB, dice: 0.7022636842105273
CVC-ColonDB :  0.7022636842105273
epoch: 212, dataset: ETIS-LaribPolypDB, dice: 0.753961734693878
ETIS-LaribPolypDB :  0.753961734693878
2023-09-02 09:27:05.582597: train_loss -1.4707
2023-09-02 09:27:05.584217: val_loss -0.7716
2023-09-02 09:27:05.585615: Pseudo dice [0.8119]
2023-09-02 09:27:05.586799: Epoch time: 115.12 s
2023-09-02 09:27:06.810643: 
2023-09-02 09:27:06.812746: Epoch 213
2023-09-02 09:27:06.814122: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-02 09:27:06.816333: start training, 250
================num of epochs: 250================
2023-09-02 09:28:05.280605: finished training
epoch: 213, dataset: CVC-300, dice: 0.8845466666666665
CVC-300 :  0.8845466666666665
epoch: 213, dataset: CVC-ClinicDB, dice: 0.8775854838709675
CVC-ClinicDB :  0.8775854838709675
epoch: 213, dataset: Kvasir, dice: 0.9032000000000001
Kvasir :  0.9032000000000001
epoch: 213, dataset: CVC-ColonDB, dice: 0.7117992105263157
CVC-ColonDB :  0.7117992105263157
epoch: 213, dataset: ETIS-LaribPolypDB, dice: 0.755119387755102
ETIS-LaribPolypDB :  0.755119387755102
2023-09-02 09:28:58.786708: train_loss -1.4702
2023-09-02 09:28:58.788362: val_loss -0.8648
2023-09-02 09:28:58.789594: Pseudo dice [0.8262]
2023-09-02 09:28:58.790808: Epoch time: 111.98 s
2023-09-02 09:28:59.988836: 
2023-09-02 09:28:59.990398: Epoch 214
2023-09-02 09:28:59.991561: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-02 09:28:59.993124: start training, 250
================num of epochs: 250================
2023-09-02 09:29:57.937737: finished training
epoch: 214, dataset: CVC-300, dice: 0.8845649999999997
CVC-300 :  0.8845649999999997
epoch: 214, dataset: CVC-ClinicDB, dice: 0.8784048387096777
CVC-ClinicDB :  0.8784048387096777
epoch: 214, dataset: Kvasir, dice: 0.9023189999999994
Kvasir :  0.9023189999999994
epoch: 214, dataset: CVC-ColonDB, dice: 0.7117681578947364
CVC-ColonDB :  0.7117681578947364
epoch: 214, dataset: ETIS-LaribPolypDB, dice: 0.7539943877551023
ETIS-LaribPolypDB :  0.7539943877551023
2023-09-02 09:30:51.327006: train_loss -1.4699
2023-09-02 09:30:51.328723: val_loss -0.7923
2023-09-02 09:30:51.330410: Pseudo dice [0.8094]
2023-09-02 09:30:51.331758: Epoch time: 111.34 s
2023-09-02 09:30:52.519184: 
2023-09-02 09:30:52.520855: Epoch 215
2023-09-02 09:30:52.522172: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-02 09:30:52.523793: start training, 250
================num of epochs: 250================
2023-09-02 09:31:50.599785: finished training
epoch: 215, dataset: CVC-300, dice: 0.8848149999999998
CVC-300 :  0.8848149999999998
epoch: 215, dataset: CVC-ClinicDB, dice: 0.8777096774193548
CVC-ClinicDB :  0.8777096774193548
epoch: 215, dataset: Kvasir, dice: 0.9059269999999998
Kvasir :  0.9059269999999998
epoch: 215, dataset: CVC-ColonDB, dice: 0.7003105263157892
CVC-ColonDB :  0.7003105263157892
epoch: 215, dataset: ETIS-LaribPolypDB, dice: 0.7497795918367348
ETIS-LaribPolypDB :  0.7497795918367348
2023-09-02 09:32:42.061990: train_loss -1.4707
2023-09-02 09:32:42.063831: val_loss -0.8693
2023-09-02 09:32:42.065458: Pseudo dice [0.8234]
2023-09-02 09:32:42.066793: Epoch time: 109.54 s
2023-09-02 09:32:43.247005: 
2023-09-02 09:32:43.248988: Epoch 216
2023-09-02 09:32:43.250332: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-02 09:32:43.251978: start training, 250
================num of epochs: 250================
2023-09-02 09:33:41.368052: finished training
epoch: 216, dataset: CVC-300, dice: 0.8865116666666667
CVC-300 :  0.8865116666666667
epoch: 216, dataset: CVC-ClinicDB, dice: 0.876251612903226
CVC-ClinicDB :  0.876251612903226
epoch: 216, dataset: Kvasir, dice: 0.900187
Kvasir :  0.900187
epoch: 216, dataset: CVC-ColonDB, dice: 0.705930000000001
CVC-ColonDB :  0.705930000000001
epoch: 216, dataset: ETIS-LaribPolypDB, dice: 0.7555459183673472
ETIS-LaribPolypDB :  0.7555459183673472
2023-09-02 09:34:35.843468: train_loss -1.4705
2023-09-02 09:34:35.845177: val_loss -0.8228
2023-09-02 09:34:35.846539: Pseudo dice [0.8222]
2023-09-02 09:34:35.847671: Epoch time: 112.6 s
2023-09-02 09:34:37.014857: 
2023-09-02 09:34:37.016368: Epoch 217
2023-09-02 09:34:37.017522: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-02 09:34:37.019026: start training, 250
================num of epochs: 250================
2023-09-02 09:35:34.994555: finished training
epoch: 217, dataset: CVC-300, dice: 0.8856550000000001
CVC-300 :  0.8856550000000001
epoch: 217, dataset: CVC-ClinicDB, dice: 0.8863822580645162
CVC-ClinicDB :  0.8863822580645162
epoch: 217, dataset: Kvasir, dice: 0.8979400000000001
Kvasir :  0.8979400000000001
epoch: 217, dataset: CVC-ColonDB, dice: 0.6995807894736832
CVC-ColonDB :  0.6995807894736832
epoch: 217, dataset: ETIS-LaribPolypDB, dice: 0.7598943877551025
ETIS-LaribPolypDB :  0.7598943877551025
2023-09-02 09:36:26.430791: train_loss -1.4703
2023-09-02 09:36:26.432531: val_loss -0.953
2023-09-02 09:36:26.433973: Pseudo dice [0.8403]
2023-09-02 09:36:26.435184: Epoch time: 109.42 s
2023-09-02 09:36:27.599057: 
2023-09-02 09:36:27.600703: Epoch 218
2023-09-02 09:36:27.602262: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-02 09:36:27.604232: start training, 250
================num of epochs: 250================
2023-09-02 09:37:25.524189: finished training
epoch: 218, dataset: CVC-300, dice: 0.8623666666666666
CVC-300 :  0.8623666666666666
epoch: 218, dataset: CVC-ClinicDB, dice: 0.8810274193548385
CVC-ClinicDB :  0.8810274193548385
epoch: 218, dataset: Kvasir, dice: 0.8967670000000002
Kvasir :  0.8967670000000002
epoch: 218, dataset: CVC-ColonDB, dice: 0.69780052631579
CVC-ColonDB :  0.69780052631579
epoch: 218, dataset: ETIS-LaribPolypDB, dice: 0.7464836734693879
ETIS-LaribPolypDB :  0.7464836734693879
2023-09-02 09:38:18.927374: train_loss -1.4701
2023-09-02 09:38:18.929104: val_loss -1.0435
2023-09-02 09:38:18.930544: Pseudo dice [0.8593]
2023-09-02 09:38:18.931675: Epoch time: 111.33 s
2023-09-02 09:38:20.124103: 
2023-09-02 09:38:20.125739: Epoch 219
2023-09-02 09:38:20.126941: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-02 09:38:20.128491: start training, 250
================num of epochs: 250================
2023-09-02 09:39:18.311307: finished training
epoch: 219, dataset: CVC-300, dice: 0.867525
CVC-300 :  0.867525
epoch: 219, dataset: CVC-ClinicDB, dice: 0.876066129032258
CVC-ClinicDB :  0.876066129032258
epoch: 219, dataset: Kvasir, dice: 0.8974999999999994
Kvasir :  0.8974999999999994
epoch: 219, dataset: CVC-ColonDB, dice: 0.6969823684210529
CVC-ColonDB :  0.6969823684210529
epoch: 219, dataset: ETIS-LaribPolypDB, dice: 0.7492576530612246
ETIS-LaribPolypDB :  0.7492576530612246
2023-09-02 09:40:13.024258: train_loss -1.4706
2023-09-02 09:40:13.026037: val_loss -0.8689
2023-09-02 09:40:13.027432: Pseudo dice [0.8192]
2023-09-02 09:40:13.028574: Epoch time: 112.9 s
2023-09-02 09:40:15.875436: 
2023-09-02 09:40:15.877122: Epoch 220
2023-09-02 09:40:15.878300: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-02 09:40:15.879890: start training, 250
================num of epochs: 250================
2023-09-02 09:41:13.882971: finished training
epoch: 220, dataset: CVC-300, dice: 0.8749166666666668
CVC-300 :  0.8749166666666668
epoch: 220, dataset: CVC-ClinicDB, dice: 0.877641935483871
CVC-ClinicDB :  0.877641935483871
epoch: 220, dataset: Kvasir, dice: 0.9016949999999997
Kvasir :  0.9016949999999997
epoch: 220, dataset: CVC-ColonDB, dice: 0.7038660526315794
CVC-ColonDB :  0.7038660526315794
epoch: 220, dataset: ETIS-LaribPolypDB, dice: 0.7595301020408171
ETIS-LaribPolypDB :  0.7595301020408171
2023-09-02 09:42:07.465762: train_loss -1.4705
2023-09-02 09:42:07.467719: val_loss -0.976
2023-09-02 09:42:07.469139: Pseudo dice [0.8416]
2023-09-02 09:42:07.470352: Epoch time: 111.59 s
2023-09-02 09:42:08.687752: 
2023-09-02 09:42:08.689554: Epoch 221
2023-09-02 09:42:08.690706: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-02 09:42:08.692224: start training, 250
================num of epochs: 250================
2023-09-02 09:43:06.709080: finished training
epoch: 221, dataset: CVC-300, dice: 0.8647233333333333
CVC-300 :  0.8647233333333333
epoch: 221, dataset: CVC-ClinicDB, dice: 0.8770225806451616
CVC-ClinicDB :  0.8770225806451616
epoch: 221, dataset: Kvasir, dice: 0.9029880000000002
Kvasir :  0.9029880000000002
epoch: 221, dataset: CVC-ColonDB, dice: 0.7022605263157887
CVC-ColonDB :  0.7022605263157887
epoch: 221, dataset: ETIS-LaribPolypDB, dice: 0.7502918367346941
ETIS-LaribPolypDB :  0.7502918367346941
2023-09-02 09:44:00.419325: train_loss -1.4705
2023-09-02 09:44:00.421263: val_loss -1.0158
2023-09-02 09:44:00.422891: Pseudo dice [0.8442]
2023-09-02 09:44:00.424092: Epoch time: 111.73 s
2023-09-02 09:44:01.612643: 
2023-09-02 09:44:01.614328: Epoch 222
2023-09-02 09:44:01.615610: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-02 09:44:01.617161: start training, 250
================num of epochs: 250================
2023-09-02 09:44:59.848103: finished training
epoch: 222, dataset: CVC-300, dice: 0.8701433333333337
CVC-300 :  0.8701433333333337
epoch: 222, dataset: CVC-ClinicDB, dice: 0.8783322580645162
CVC-ClinicDB :  0.8783322580645162
epoch: 222, dataset: Kvasir, dice: 0.9029090000000002
Kvasir :  0.9029090000000002
epoch: 222, dataset: CVC-ColonDB, dice: 0.6999060526315785
CVC-ColonDB :  0.6999060526315785
epoch: 222, dataset: ETIS-LaribPolypDB, dice: 0.745864795918367
ETIS-LaribPolypDB :  0.745864795918367
2023-09-02 09:45:53.342847: train_loss -1.4712
2023-09-02 09:45:53.344662: val_loss -0.9258
2023-09-02 09:45:53.346087: Pseudo dice [0.8309]
2023-09-02 09:45:53.347258: Epoch time: 111.73 s
2023-09-02 09:45:54.523247: 
2023-09-02 09:45:54.525055: Epoch 223
2023-09-02 09:45:54.526243: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-02 09:45:54.527812: start training, 250
================num of epochs: 250================
2023-09-02 09:46:52.490703: finished training
epoch: 223, dataset: CVC-300, dice: 0.8780416666666665
CVC-300 :  0.8780416666666665
epoch: 223, dataset: CVC-ClinicDB, dice: 0.8801532258064517
CVC-ClinicDB :  0.8801532258064517
epoch: 223, dataset: Kvasir, dice: 0.902669
Kvasir :  0.902669
epoch: 223, dataset: CVC-ColonDB, dice: 0.7025018421052632
CVC-ColonDB :  0.7025018421052632
epoch: 223, dataset: ETIS-LaribPolypDB, dice: 0.7512198979591838
ETIS-LaribPolypDB :  0.7512198979591838
2023-09-02 09:47:45.979825: train_loss -1.4704
2023-09-02 09:47:45.981707: val_loss -0.9469
2023-09-02 09:47:45.983138: Pseudo dice [0.8371]
2023-09-02 09:47:45.984368: Epoch time: 111.46 s
2023-09-02 09:47:47.167922: 
2023-09-02 09:47:47.169712: Epoch 224
2023-09-02 09:47:47.171030: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-02 09:47:47.172674: start training, 250
================num of epochs: 250================
2023-09-02 09:48:45.150350: finished training
epoch: 224, dataset: CVC-300, dice: 0.8750299999999999
CVC-300 :  0.8750299999999999
epoch: 224, dataset: CVC-ClinicDB, dice: 0.8747790322580647
CVC-ClinicDB :  0.8747790322580647
epoch: 224, dataset: Kvasir, dice: 0.9018599999999999
Kvasir :  0.9018599999999999
epoch: 224, dataset: CVC-ColonDB, dice: 0.7023271052631587
CVC-ColonDB :  0.7023271052631587
epoch: 224, dataset: ETIS-LaribPolypDB, dice: 0.7421035714285716
ETIS-LaribPolypDB :  0.7421035714285716
2023-09-02 09:49:37.253004: train_loss -1.471
2023-09-02 09:49:37.254859: val_loss -0.9979
2023-09-02 09:49:37.256473: Pseudo dice [0.8447]
2023-09-02 09:49:37.257808: Epoch time: 110.09 s
2023-09-02 09:49:38.408750: 
2023-09-02 09:49:38.410528: Epoch 225
2023-09-02 09:49:38.412163: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-02 09:49:38.414352: start training, 250
================num of epochs: 250================
2023-09-02 09:50:36.606280: finished training
epoch: 225, dataset: CVC-300, dice: 0.8751616666666665
CVC-300 :  0.8751616666666665
epoch: 225, dataset: CVC-ClinicDB, dice: 0.875211290322581
CVC-ClinicDB :  0.875211290322581
epoch: 225, dataset: Kvasir, dice: 0.9030409999999999
Kvasir :  0.9030409999999999
epoch: 225, dataset: CVC-ColonDB, dice: 0.7040302631578952
CVC-ColonDB :  0.7040302631578952
epoch: 225, dataset: ETIS-LaribPolypDB, dice: 0.7501010204081627
ETIS-LaribPolypDB :  0.7501010204081627
2023-09-02 09:51:30.982567: train_loss -1.4705
2023-09-02 09:51:30.984306: val_loss -0.95
2023-09-02 09:51:30.985676: Pseudo dice [0.8329]
2023-09-02 09:51:30.986835: Epoch time: 112.58 s
2023-09-02 09:51:32.181467: 
2023-09-02 09:51:32.183174: Epoch 226
2023-09-02 09:51:32.184391: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-02 09:51:32.185912: start training, 250
================num of epochs: 250================
2023-09-02 09:52:30.193893: finished training
epoch: 226, dataset: CVC-300, dice: 0.8721783333333331
CVC-300 :  0.8721783333333331
epoch: 226, dataset: CVC-ClinicDB, dice: 0.877535483870968
CVC-ClinicDB :  0.877535483870968
epoch: 226, dataset: Kvasir, dice: 0.9029580000000003
Kvasir :  0.9029580000000003
epoch: 226, dataset: CVC-ColonDB, dice: 0.7027905263157904
CVC-ColonDB :  0.7027905263157904
epoch: 226, dataset: ETIS-LaribPolypDB, dice: 0.7434739795918369
ETIS-LaribPolypDB :  0.7434739795918369
2023-09-02 09:53:23.093629: train_loss -1.4709
2023-09-02 09:53:23.095444: val_loss -0.9204
2023-09-02 09:53:23.096883: Pseudo dice [0.8304]
2023-09-02 09:53:23.098100: Epoch time: 110.91 s
2023-09-02 09:53:24.283782: 
2023-09-02 09:53:24.285625: Epoch 227
2023-09-02 09:53:24.286959: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-02 09:53:24.288758: start training, 250
================num of epochs: 250================
2023-09-02 09:54:22.240777: finished training
epoch: 227, dataset: CVC-300, dice: 0.8759316666666668
CVC-300 :  0.8759316666666668
epoch: 227, dataset: CVC-ClinicDB, dice: 0.8797177419354837
CVC-ClinicDB :  0.8797177419354837
epoch: 227, dataset: Kvasir, dice: 0.900124
Kvasir :  0.900124
epoch: 227, dataset: CVC-ColonDB, dice: 0.7054163157894744
CVC-ColonDB :  0.7054163157894744
epoch: 227, dataset: ETIS-LaribPolypDB, dice: 0.7476489795918368
ETIS-LaribPolypDB :  0.7476489795918368
2023-09-02 09:55:16.701986: train_loss -1.471
2023-09-02 09:55:16.703815: val_loss -0.8854
2023-09-02 09:55:16.705357: Pseudo dice [0.8239]
2023-09-02 09:55:16.706664: Epoch time: 112.42 s
2023-09-02 09:55:17.913001: 
2023-09-02 09:55:17.914855: Epoch 228
2023-09-02 09:55:17.916208: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-02 09:55:17.917789: start training, 250
================num of epochs: 250================
2023-09-02 09:56:16.101207: finished training
epoch: 228, dataset: CVC-300, dice: 0.8737250000000001
CVC-300 :  0.8737250000000001
epoch: 228, dataset: CVC-ClinicDB, dice: 0.8785290322580643
CVC-ClinicDB :  0.8785290322580643
epoch: 228, dataset: Kvasir, dice: 0.9015709999999996
Kvasir :  0.9015709999999996
epoch: 228, dataset: CVC-ColonDB, dice: 0.7030023684210521
CVC-ColonDB :  0.7030023684210521
epoch: 228, dataset: ETIS-LaribPolypDB, dice: 0.7441352040816326
ETIS-LaribPolypDB :  0.7441352040816326
2023-09-02 09:57:10.600177: train_loss -1.4707
2023-09-02 09:57:10.601934: val_loss -0.892
2023-09-02 09:57:10.603413: Pseudo dice [0.8321]
2023-09-02 09:57:10.604660: Epoch time: 112.69 s
2023-09-02 09:57:11.808105: 
2023-09-02 09:57:11.809905: Epoch 229
2023-09-02 09:57:11.811223: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-02 09:57:11.813079: start training, 250
================num of epochs: 250================
2023-09-02 09:58:09.862074: finished training
epoch: 229, dataset: CVC-300, dice: 0.8792683333333332
CVC-300 :  0.8792683333333332
epoch: 229, dataset: CVC-ClinicDB, dice: 0.880975806451613
CVC-ClinicDB :  0.880975806451613
epoch: 229, dataset: Kvasir, dice: 0.9018500000000002
Kvasir :  0.9018500000000002
epoch: 229, dataset: CVC-ColonDB, dice: 0.7073642105263155
CVC-ColonDB :  0.7073642105263155
epoch: 229, dataset: ETIS-LaribPolypDB, dice: 0.7523556122448977
ETIS-LaribPolypDB :  0.7523556122448977
2023-09-02 09:59:04.155822: train_loss -1.4712
2023-09-02 09:59:04.157686: val_loss -0.8565
2023-09-02 09:59:04.159119: Pseudo dice [0.826]
2023-09-02 09:59:04.160347: Epoch time: 112.35 s
2023-09-02 09:59:06.965243: 
2023-09-02 09:59:06.966942: Epoch 230
2023-09-02 09:59:06.968132: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-02 09:59:06.969698: start training, 250
================num of epochs: 250================
2023-09-02 10:00:04.901744: finished training
epoch: 230, dataset: CVC-300, dice: 0.8798316666666669
CVC-300 :  0.8798316666666669
epoch: 230, dataset: CVC-ClinicDB, dice: 0.8817322580645162
CVC-ClinicDB :  0.8817322580645162
epoch: 230, dataset: Kvasir, dice: 0.9036260000000003
Kvasir :  0.9036260000000003
epoch: 230, dataset: CVC-ColonDB, dice: 0.7056465789473687
CVC-ColonDB :  0.7056465789473687
epoch: 230, dataset: ETIS-LaribPolypDB, dice: 0.7551698979591837
ETIS-LaribPolypDB :  0.7551698979591837
2023-09-02 10:01:02.271697: train_loss -1.4715
2023-09-02 10:01:02.273595: val_loss -0.8239
2023-09-02 10:01:02.275007: Pseudo dice [0.8163]
2023-09-02 10:01:02.276683: Epoch time: 115.31 s
2023-09-02 10:01:03.495512: 
2023-09-02 10:01:03.497356: Epoch 231
2023-09-02 10:01:03.498725: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-02 10:01:03.500498: start training, 250
================num of epochs: 250================
2023-09-02 10:02:01.775576: finished training
epoch: 231, dataset: CVC-300, dice: 0.8752599999999997
CVC-300 :  0.8752599999999997
epoch: 231, dataset: CVC-ClinicDB, dice: 0.8817548387096774
CVC-ClinicDB :  0.8817548387096774
epoch: 231, dataset: Kvasir, dice: 0.8943489999999998
Kvasir :  0.8943489999999998
epoch: 231, dataset: CVC-ColonDB, dice: 0.7024473684210533
CVC-ColonDB :  0.7024473684210533
epoch: 231, dataset: ETIS-LaribPolypDB, dice: 0.7570035714285714
ETIS-LaribPolypDB :  0.7570035714285714
2023-09-02 10:02:55.661771: train_loss -1.4706
2023-09-02 10:02:55.663413: val_loss -0.7548
2023-09-02 10:02:55.664725: Pseudo dice [0.8066]
2023-09-02 10:02:55.665860: Epoch time: 112.17 s
2023-09-02 10:02:56.851209: 
2023-09-02 10:02:56.853005: Epoch 232
2023-09-02 10:02:56.854700: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-02 10:02:56.856447: start training, 250
================num of epochs: 250================
2023-09-02 10:03:54.833133: finished training
epoch: 232, dataset: CVC-300, dice: 0.8759700000000001
CVC-300 :  0.8759700000000001
epoch: 232, dataset: CVC-ClinicDB, dice: 0.8822032258064516
CVC-ClinicDB :  0.8822032258064516
epoch: 232, dataset: Kvasir, dice: 0.9007829999999999
Kvasir :  0.9007829999999999
epoch: 232, dataset: CVC-ColonDB, dice: 0.6954171052631579
CVC-ColonDB :  0.6954171052631579
epoch: 232, dataset: ETIS-LaribPolypDB, dice: 0.7507484693877552
ETIS-LaribPolypDB :  0.7507484693877552
2023-09-02 10:04:48.614207: train_loss -1.4711
2023-09-02 10:04:48.616255: val_loss -0.8009
2023-09-02 10:04:48.617881: Pseudo dice [0.8151]
2023-09-02 10:04:48.619355: Epoch time: 111.76 s
2023-09-02 10:04:49.798517: 
2023-09-02 10:04:49.800305: Epoch 233
2023-09-02 10:04:49.801662: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-02 10:04:49.803376: start training, 250
================num of epochs: 250================
2023-09-02 10:05:48.246083: finished training
epoch: 233, dataset: CVC-300, dice: 0.8771500000000001
CVC-300 :  0.8771500000000001
epoch: 233, dataset: CVC-ClinicDB, dice: 0.8811677419354839
CVC-ClinicDB :  0.8811677419354839
epoch: 233, dataset: Kvasir, dice: 0.9010090000000001
Kvasir :  0.9010090000000001
epoch: 233, dataset: CVC-ColonDB, dice: 0.6991276315789473
CVC-ColonDB :  0.6991276315789473
epoch: 233, dataset: ETIS-LaribPolypDB, dice: 0.7485938775510211
ETIS-LaribPolypDB :  0.7485938775510211
2023-09-02 10:06:42.778113: train_loss -1.4713
2023-09-02 10:06:42.779941: val_loss -1.0455
2023-09-02 10:06:42.781399: Pseudo dice [0.8601]
2023-09-02 10:06:42.782632: Epoch time: 112.98 s
2023-09-02 10:06:43.979069: 
2023-09-02 10:06:43.980745: Epoch 234
2023-09-02 10:06:43.981930: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-02 10:06:43.983530: start training, 250
================num of epochs: 250================
2023-09-02 10:07:41.973576: finished training
epoch: 234, dataset: CVC-300, dice: 0.876466666666667
CVC-300 :  0.876466666666667
epoch: 234, dataset: CVC-ClinicDB, dice: 0.8913903225806451
CVC-ClinicDB :  0.8913903225806451
epoch: 234, dataset: Kvasir, dice: 0.9019819999999998
Kvasir :  0.9019819999999998
epoch: 234, dataset: CVC-ColonDB, dice: 0.704602894736843
CVC-ColonDB :  0.704602894736843
epoch: 234, dataset: ETIS-LaribPolypDB, dice: 0.7538321428571427
ETIS-LaribPolypDB :  0.7538321428571427
2023-09-02 10:08:35.991065: train_loss -1.4708
2023-09-02 10:08:35.993016: val_loss -0.9607
2023-09-02 10:08:35.994596: Pseudo dice [0.8366]
2023-09-02 10:08:35.995781: Epoch time: 112.01 s
2023-09-02 10:08:37.495238: 
2023-09-02 10:08:37.497098: Epoch 235
2023-09-02 10:08:37.498312: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-02 10:08:37.499867: start training, 250
================num of epochs: 250================
2023-09-02 10:09:35.481905: finished training
epoch: 235, dataset: CVC-300, dice: 0.8739800000000003
CVC-300 :  0.8739800000000003
epoch: 235, dataset: CVC-ClinicDB, dice: 0.8862790322580644
CVC-ClinicDB :  0.8862790322580644
epoch: 235, dataset: Kvasir, dice: 0.9002710000000006
Kvasir :  0.9002710000000006
epoch: 235, dataset: CVC-ColonDB, dice: 0.6985121052631583
CVC-ColonDB :  0.6985121052631583
epoch: 235, dataset: ETIS-LaribPolypDB, dice: 0.7447520408163266
ETIS-LaribPolypDB :  0.7447520408163266
2023-09-02 10:10:29.476357: train_loss -1.4716
2023-09-02 10:10:29.478134: val_loss -0.9418
2023-09-02 10:10:29.479611: Pseudo dice [0.8364]
2023-09-02 10:10:29.480801: Epoch time: 111.98 s
2023-09-02 10:10:30.663246: 
2023-09-02 10:10:30.664952: Epoch 236
2023-09-02 10:10:30.666241: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-02 10:10:30.667954: start training, 250
================num of epochs: 250================
2023-09-02 10:11:28.663540: finished training
epoch: 236, dataset: CVC-300, dice: 0.8771316666666665
CVC-300 :  0.8771316666666665
epoch: 236, dataset: CVC-ClinicDB, dice: 0.8876838709677414
CVC-ClinicDB :  0.8876838709677414
epoch: 236, dataset: Kvasir, dice: 0.8982650000000002
Kvasir :  0.8982650000000002
epoch: 236, dataset: CVC-ColonDB, dice: 0.6972989473684211
CVC-ColonDB :  0.6972989473684211
epoch: 236, dataset: ETIS-LaribPolypDB, dice: 0.7494178571428574
ETIS-LaribPolypDB :  0.7494178571428574
2023-09-02 10:12:22.665179: train_loss -1.4711
2023-09-02 10:12:22.666789: val_loss -0.8582
2023-09-02 10:12:22.668178: Pseudo dice [0.8208]
2023-09-02 10:12:22.669345: Epoch time: 112.0 s
2023-09-02 10:12:23.855550: 
2023-09-02 10:12:23.857313: Epoch 237
2023-09-02 10:12:23.858535: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-02 10:12:23.860059: start training, 250
================num of epochs: 250================
2023-09-02 10:13:21.862963: finished training
epoch: 237, dataset: CVC-300, dice: 0.8757316666666668
CVC-300 :  0.8757316666666668
epoch: 237, dataset: CVC-ClinicDB, dice: 0.8862548387096773
CVC-ClinicDB :  0.8862548387096773
epoch: 237, dataset: Kvasir, dice: 0.8994919999999997
Kvasir :  0.8994919999999997
epoch: 237, dataset: CVC-ColonDB, dice: 0.6963171052631579
CVC-ColonDB :  0.6963171052631579
epoch: 237, dataset: ETIS-LaribPolypDB, dice: 0.745245918367347
ETIS-LaribPolypDB :  0.745245918367347
2023-09-02 10:14:15.706516: train_loss -1.4717
2023-09-02 10:14:15.708385: val_loss -0.8016
2023-09-02 10:14:15.709901: Pseudo dice [0.8105]
2023-09-02 10:14:15.711234: Epoch time: 111.85 s
2023-09-02 10:14:17.178236: 
2023-09-02 10:14:17.180040: Epoch 238
2023-09-02 10:14:17.181267: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-02 10:14:17.182783: start training, 250
================num of epochs: 250================
2023-09-02 10:15:15.192281: finished training
epoch: 238, dataset: CVC-300, dice: 0.8773116666666667
CVC-300 :  0.8773116666666667
epoch: 238, dataset: CVC-ClinicDB, dice: 0.8851806451612905
CVC-ClinicDB :  0.8851806451612905
epoch: 238, dataset: Kvasir, dice: 0.8996740000000004
Kvasir :  0.8996740000000004
epoch: 238, dataset: CVC-ColonDB, dice: 0.7011160526315793
CVC-ColonDB :  0.7011160526315793
epoch: 238, dataset: ETIS-LaribPolypDB, dice: 0.7401780612244895
ETIS-LaribPolypDB :  0.7401780612244895
2023-09-02 10:16:10.752657: train_loss -1.4715
2023-09-02 10:16:10.754392: val_loss -0.9736
2023-09-02 10:16:10.755822: Pseudo dice [0.8515]
2023-09-02 10:16:10.756992: Epoch time: 113.58 s
2023-09-02 10:16:11.960170: 
2023-09-02 10:16:11.962474: Epoch 239
2023-09-02 10:16:11.963803: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-02 10:16:11.965600: start training, 250
================num of epochs: 250================
2023-09-02 10:17:10.001485: finished training
epoch: 239, dataset: CVC-300, dice: 0.8780116666666665
CVC-300 :  0.8780116666666665
epoch: 239, dataset: CVC-ClinicDB, dice: 0.8829370967741935
CVC-ClinicDB :  0.8829370967741935
epoch: 239, dataset: Kvasir, dice: 0.898068
Kvasir :  0.898068
epoch: 239, dataset: CVC-ColonDB, dice: 0.7002534210526317
CVC-ColonDB :  0.7002534210526317
epoch: 239, dataset: ETIS-LaribPolypDB, dice: 0.7458984693877551
ETIS-LaribPolypDB :  0.7458984693877551
2023-09-02 10:18:03.296573: train_loss -1.4718
2023-09-02 10:18:03.298402: val_loss -0.9505
2023-09-02 10:18:03.300006: Pseudo dice [0.8374]
2023-09-02 10:18:03.301275: Epoch time: 111.34 s
2023-09-02 10:18:06.114042: 
2023-09-02 10:18:06.115803: Epoch 240
2023-09-02 10:18:06.117009: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-02 10:18:06.118588: start training, 250
================num of epochs: 250================
2023-09-02 10:19:04.131343: finished training
epoch: 240, dataset: CVC-300, dice: 0.8751549999999998
CVC-300 :  0.8751549999999998
epoch: 240, dataset: CVC-ClinicDB, dice: 0.8823645161290322
CVC-ClinicDB :  0.8823645161290322
epoch: 240, dataset: Kvasir, dice: 0.9014299999999998
Kvasir :  0.9014299999999998
epoch: 240, dataset: CVC-ColonDB, dice: 0.7090747368421055
CVC-ColonDB :  0.7090747368421055
epoch: 240, dataset: ETIS-LaribPolypDB, dice: 0.7481265306122448
ETIS-LaribPolypDB :  0.7481265306122448
2023-09-02 10:19:57.998827: train_loss -1.471
2023-09-02 10:19:58.000623: val_loss -0.9546
2023-09-02 10:19:58.002063: Pseudo dice [0.8348]
2023-09-02 10:19:58.003254: Epoch time: 111.89 s
2023-09-02 10:19:59.484388: 
2023-09-02 10:19:59.486022: Epoch 241
2023-09-02 10:19:59.487307: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-02 10:19:59.488857: start training, 250
================num of epochs: 250================
2023-09-02 10:20:57.488894: finished training
epoch: 241, dataset: CVC-300, dice: 0.8734533333333333
CVC-300 :  0.8734533333333333
epoch: 241, dataset: CVC-ClinicDB, dice: 0.8811854838709677
CVC-ClinicDB :  0.8811854838709677
epoch: 241, dataset: Kvasir, dice: 0.8970629999999998
Kvasir :  0.8970629999999998
epoch: 241, dataset: CVC-ColonDB, dice: 0.7001036842105269
CVC-ColonDB :  0.7001036842105269
epoch: 241, dataset: ETIS-LaribPolypDB, dice: 0.743104591836735
ETIS-LaribPolypDB :  0.743104591836735
2023-09-02 10:21:51.327727: train_loss -1.4711
2023-09-02 10:21:51.329507: val_loss -0.8378
2023-09-02 10:21:51.330901: Pseudo dice [0.8087]
2023-09-02 10:21:51.332071: Epoch time: 111.84 s
2023-09-02 10:21:52.560409: 
2023-09-02 10:21:52.562239: Epoch 242
2023-09-02 10:21:52.563611: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-02 10:21:52.565271: start training, 250
================num of epochs: 250================
2023-09-02 10:22:50.664001: finished training
epoch: 242, dataset: CVC-300, dice: 0.8783383333333333
CVC-300 :  0.8783383333333333
epoch: 242, dataset: CVC-ClinicDB, dice: 0.883301612903226
CVC-ClinicDB :  0.883301612903226
epoch: 242, dataset: Kvasir, dice: 0.8967700000000001
Kvasir :  0.8967700000000001
epoch: 242, dataset: CVC-ColonDB, dice: 0.7022763157894736
CVC-ColonDB :  0.7022763157894736
epoch: 242, dataset: ETIS-LaribPolypDB, dice: 0.7484749999999999
ETIS-LaribPolypDB :  0.7484749999999999
2023-09-02 10:23:45.001889: train_loss -1.4716
2023-09-02 10:23:45.003840: val_loss -0.8201
2023-09-02 10:23:45.005481: Pseudo dice [0.8108]
2023-09-02 10:23:45.006709: Epoch time: 112.44 s
2023-09-02 10:23:46.222126: 
2023-09-02 10:23:46.223939: Epoch 243
2023-09-02 10:23:46.225135: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-02 10:23:46.226716: start training, 250
================num of epochs: 250================
2023-09-02 10:24:44.765381: finished training
epoch: 243, dataset: CVC-300, dice: 0.8740649999999998
CVC-300 :  0.8740649999999998
epoch: 243, dataset: CVC-ClinicDB, dice: 0.8869000000000001
CVC-ClinicDB :  0.8869000000000001
epoch: 243, dataset: Kvasir, dice: 0.8955319999999999
Kvasir :  0.8955319999999999
epoch: 243, dataset: CVC-ColonDB, dice: 0.6998702631578947
CVC-ColonDB :  0.6998702631578947
epoch: 243, dataset: ETIS-LaribPolypDB, dice: 0.7381132653061221
ETIS-LaribPolypDB :  0.7381132653061221
2023-09-02 10:25:41.353949: train_loss -1.4717
2023-09-02 10:25:41.355871: val_loss -0.9217
2023-09-02 10:25:41.357320: Pseudo dice [0.8376]
2023-09-02 10:25:41.358523: Epoch time: 115.13 s
2023-09-02 10:25:42.570521: 
2023-09-02 10:25:42.572303: Epoch 244
2023-09-02 10:25:42.573536: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-02 10:25:42.575205: start training, 250
================num of epochs: 250================
2023-09-02 10:26:40.858610: finished training
epoch: 244, dataset: CVC-300, dice: 0.8716516666666668
CVC-300 :  0.8716516666666668
epoch: 244, dataset: CVC-ClinicDB, dice: 0.8846354838709677
CVC-ClinicDB :  0.8846354838709677
epoch: 244, dataset: Kvasir, dice: 0.8981869999999996
Kvasir :  0.8981869999999996
epoch: 244, dataset: CVC-ColonDB, dice: 0.6986523684210525
CVC-ColonDB :  0.6986523684210525
epoch: 244, dataset: ETIS-LaribPolypDB, dice: 0.7386005102040821
ETIS-LaribPolypDB :  0.7386005102040821
2023-09-02 10:27:34.728881: train_loss -1.4714
2023-09-02 10:27:34.730655: val_loss -0.8799
2023-09-02 10:27:34.732143: Pseudo dice [0.8252]
2023-09-02 10:27:34.733436: Epoch time: 112.16 s
2023-09-02 10:27:35.937024: 
2023-09-02 10:27:35.938670: Epoch 245
2023-09-02 10:27:35.939920: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-02 10:27:35.941578: start training, 250
================num of epochs: 250================
2023-09-02 10:28:33.999050: finished training
epoch: 245, dataset: CVC-300, dice: 0.8863833333333333
CVC-300 :  0.8863833333333333
epoch: 245, dataset: CVC-ClinicDB, dice: 0.8917532258064516
CVC-ClinicDB :  0.8917532258064516
epoch: 245, dataset: Kvasir, dice: 0.8990360000000003
Kvasir :  0.8990360000000003
epoch: 245, dataset: CVC-ColonDB, dice: 0.7081228947368423
CVC-ColonDB :  0.7081228947368423
epoch: 245, dataset: ETIS-LaribPolypDB, dice: 0.7539540816326531
ETIS-LaribPolypDB :  0.7539540816326531
2023-09-02 10:29:27.458843: train_loss -1.4717
2023-09-02 10:29:27.460691: val_loss -0.8742
2023-09-02 10:29:27.462272: Pseudo dice [0.8271]
2023-09-02 10:29:27.463597: Epoch time: 111.52 s
2023-09-02 10:29:28.662867: 
2023-09-02 10:29:28.664785: Epoch 246
2023-09-02 10:29:28.666136: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-02 10:29:28.667765: start training, 250
================num of epochs: 250================
2023-09-02 10:30:26.767743: finished training
epoch: 246, dataset: CVC-300, dice: 0.869596666666667
CVC-300 :  0.869596666666667
epoch: 246, dataset: CVC-ClinicDB, dice: 0.896101612903226
CVC-ClinicDB :  0.896101612903226
epoch: 246, dataset: Kvasir, dice: 0.897546
Kvasir :  0.897546
epoch: 246, dataset: CVC-ColonDB, dice: 0.6872026315789467
CVC-ColonDB :  0.6872026315789467
epoch: 246, dataset: ETIS-LaribPolypDB, dice: 0.7196749999999998
ETIS-LaribPolypDB :  0.7196749999999998
2023-09-02 10:31:20.184171: train_loss -1.4716
2023-09-02 10:31:20.186061: val_loss -0.8506
2023-09-02 10:31:20.187709: Pseudo dice [0.8235]
2023-09-02 10:31:20.189086: Epoch time: 111.52 s
2023-09-02 10:31:21.385567: 
2023-09-02 10:31:21.387601: Epoch 247
2023-09-02 10:31:21.388938: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-02 10:31:21.390679: start training, 250
================num of epochs: 250================
2023-09-02 10:32:19.672280: finished training
epoch: 247, dataset: CVC-300, dice: 0.8719033333333335
CVC-300 :  0.8719033333333335
epoch: 247, dataset: CVC-ClinicDB, dice: 0.8901483870967744
CVC-ClinicDB :  0.8901483870967744
epoch: 247, dataset: Kvasir, dice: 0.8972570000000002
Kvasir :  0.8972570000000002
epoch: 247, dataset: CVC-ColonDB, dice: 0.6878402631578949
CVC-ColonDB :  0.6878402631578949
epoch: 247, dataset: ETIS-LaribPolypDB, dice: 0.7163102040816326
ETIS-LaribPolypDB :  0.7163102040816326
2023-09-02 10:33:12.949834: train_loss -1.4713
2023-09-02 10:33:12.951828: val_loss -0.8334
2023-09-02 10:33:12.953382: Pseudo dice [0.8185]
2023-09-02 10:33:12.954974: Epoch time: 111.57 s
2023-09-02 10:33:14.146034: 
2023-09-02 10:33:14.147949: Epoch 248
2023-09-02 10:33:14.149397: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-02 10:33:14.151182: start training, 250
================num of epochs: 250================
2023-09-02 10:34:12.385206: finished training
epoch: 248, dataset: CVC-300, dice: 0.8849733333333334
CVC-300 :  0.8849733333333334
epoch: 248, dataset: CVC-ClinicDB, dice: 0.8914887096774192
CVC-ClinicDB :  0.8914887096774192
epoch: 248, dataset: Kvasir, dice: 0.8964870000000001
Kvasir :  0.8964870000000001
epoch: 248, dataset: CVC-ColonDB, dice: 0.6956847368421052
CVC-ColonDB :  0.6956847368421052
epoch: 248, dataset: ETIS-LaribPolypDB, dice: 0.7260750000000001
ETIS-LaribPolypDB :  0.7260750000000001
2023-09-02 10:35:10.218223: train_loss -1.4715
2023-09-02 10:35:10.220115: val_loss -0.8995
2023-09-02 10:35:10.221851: Pseudo dice [0.8258]
2023-09-02 10:35:10.223295: Epoch time: 116.07 s
2023-09-02 10:35:11.475955: 
2023-09-02 10:35:11.478033: Epoch 249
2023-09-02 10:35:11.479419: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-02 10:35:11.481172: start training, 250
================num of epochs: 250================
2023-09-02 10:36:09.687256: finished training
epoch: 249, dataset: CVC-300, dice: 0.8810466666666663
CVC-300 :  0.8810466666666663
epoch: 249, dataset: CVC-ClinicDB, dice: 0.888008064516129
CVC-ClinicDB :  0.888008064516129
epoch: 249, dataset: Kvasir, dice: 0.897822
Kvasir :  0.897822
epoch: 249, dataset: CVC-ColonDB, dice: 0.6986326315789477
CVC-ColonDB :  0.6986326315789477
epoch: 249, dataset: ETIS-LaribPolypDB, dice: 0.7285765306122453
ETIS-LaribPolypDB :  0.7285765306122453
2023-09-02 10:37:02.225502: train_loss -1.4721
2023-09-02 10:37:02.227472: val_loss -0.8788
2023-09-02 10:37:02.228904: Pseudo dice [0.8262]
2023-09-02 10:37:02.230228: Epoch time: 110.75 s
2023-09-02 10:37:05.146598: 
2023-09-02 10:37:05.148169: Epoch 250
2023-09-02 10:37:05.149415: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-02 10:37:05.151026: start training, 250
================num of epochs: 250================
2023-09-02 10:38:03.493898: finished training
epoch: 250, dataset: CVC-300, dice: 0.8820749999999998
CVC-300 :  0.8820749999999998
epoch: 250, dataset: CVC-ClinicDB, dice: 0.8824032258064516
CVC-ClinicDB :  0.8824032258064516
epoch: 250, dataset: Kvasir, dice: 0.895375
Kvasir :  0.895375
epoch: 250, dataset: CVC-ColonDB, dice: 0.7008776315789468
CVC-ColonDB :  0.7008776315789468
epoch: 250, dataset: ETIS-LaribPolypDB, dice: 0.7317377551020409
ETIS-LaribPolypDB :  0.7317377551020409
2023-09-02 10:38:56.914154: train_loss -1.472
2023-09-02 10:38:56.916092: val_loss -0.9617
2023-09-02 10:38:56.917707: Pseudo dice [0.849]
2023-09-02 10:38:56.919090: Epoch time: 111.77 s
2023-09-02 10:38:58.133975: 
2023-09-02 10:38:58.135946: Epoch 251
2023-09-02 10:38:58.137826: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-02 10:38:58.139862: start training, 250
================num of epochs: 250================
2023-09-02 10:39:56.218707: finished training
epoch: 251, dataset: CVC-300, dice: 0.8822699999999998
CVC-300 :  0.8822699999999998
epoch: 251, dataset: CVC-ClinicDB, dice: 0.8851112903225808
CVC-ClinicDB :  0.8851112903225808
epoch: 251, dataset: Kvasir, dice: 0.898383
Kvasir :  0.898383
epoch: 251, dataset: CVC-ColonDB, dice: 0.6990647368421049
CVC-ColonDB :  0.6990647368421049
epoch: 251, dataset: ETIS-LaribPolypDB, dice: 0.7305474489795918
ETIS-LaribPolypDB :  0.7305474489795918
2023-09-02 10:40:49.408170: train_loss -1.472
2023-09-02 10:40:49.410083: val_loss -0.9348
2023-09-02 10:40:49.411525: Pseudo dice [0.8418]
2023-09-02 10:40:49.412720: Epoch time: 111.28 s
2023-09-02 10:40:50.645358: 
2023-09-02 10:40:50.647094: Epoch 252
2023-09-02 10:40:50.648320: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-02 10:40:50.649891: start training, 250
================num of epochs: 250================
2023-09-02 10:41:48.683895: finished training
epoch: 252, dataset: CVC-300, dice: 0.8791783333333333
CVC-300 :  0.8791783333333333
epoch: 252, dataset: CVC-ClinicDB, dice: 0.8805548387096775
CVC-ClinicDB :  0.8805548387096775
epoch: 252, dataset: Kvasir, dice: 0.8993420000000002
Kvasir :  0.8993420000000002
epoch: 252, dataset: CVC-ColonDB, dice: 0.702058684210527
CVC-ColonDB :  0.702058684210527
epoch: 252, dataset: ETIS-LaribPolypDB, dice: 0.7363428571428575
ETIS-LaribPolypDB :  0.7363428571428575
2023-09-02 10:42:42.088462: train_loss -1.4718
2023-09-02 10:42:42.090368: val_loss -0.8387
2023-09-02 10:42:42.091834: Pseudo dice [0.8221]
2023-09-02 10:42:42.093229: Epoch time: 111.44 s
2023-09-02 10:42:43.369722: 
2023-09-02 10:42:43.371549: Epoch 253
2023-09-02 10:42:43.372929: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-02 10:42:43.374698: start training, 250
================num of epochs: 250================
2023-09-02 10:43:42.134502: finished training
epoch: 253, dataset: CVC-300, dice: 0.8817100000000001
CVC-300 :  0.8817100000000001
epoch: 253, dataset: CVC-ClinicDB, dice: 0.8806387096774195
CVC-ClinicDB :  0.8806387096774195
epoch: 253, dataset: Kvasir, dice: 0.898016
Kvasir :  0.898016
epoch: 253, dataset: CVC-ColonDB, dice: 0.6996094736842109
CVC-ColonDB :  0.6996094736842109
epoch: 253, dataset: ETIS-LaribPolypDB, dice: 0.7389153061224492
ETIS-LaribPolypDB :  0.7389153061224492
2023-09-02 10:44:35.246547: train_loss -1.4718
2023-09-02 10:44:35.248159: val_loss -0.799
2023-09-02 10:44:35.249640: Pseudo dice [0.8123]
2023-09-02 10:44:35.251299: Epoch time: 111.88 s
2023-09-02 10:44:36.459593: 
2023-09-02 10:44:36.461239: Epoch 254
2023-09-02 10:44:36.462632: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-02 10:44:36.464528: start training, 250
================num of epochs: 250================
2023-09-02 10:45:34.542642: finished training
epoch: 254, dataset: CVC-300, dice: 0.8844566666666667
CVC-300 :  0.8844566666666667
epoch: 254, dataset: CVC-ClinicDB, dice: 0.8808967741935484
CVC-ClinicDB :  0.8808967741935484
epoch: 254, dataset: Kvasir, dice: 0.8999640000000001
Kvasir :  0.8999640000000001
epoch: 254, dataset: CVC-ColonDB, dice: 0.7026247368421049
CVC-ColonDB :  0.7026247368421049
epoch: 254, dataset: ETIS-LaribPolypDB, dice: 0.7436933673469388
ETIS-LaribPolypDB :  0.7436933673469388
2023-09-02 10:46:27.458327: train_loss -1.4718
2023-09-02 10:46:27.460017: val_loss -0.9129
2023-09-02 10:46:27.461578: Pseudo dice [0.8423]
2023-09-02 10:46:27.462821: Epoch time: 111.0 s
2023-09-02 10:46:28.670800: 
2023-09-02 10:46:28.672900: Epoch 255
2023-09-02 10:46:28.674299: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-02 10:46:28.676180: start training, 250
================num of epochs: 250================
2023-09-02 10:47:26.819776: finished training
epoch: 255, dataset: CVC-300, dice: 0.8844333333333336
CVC-300 :  0.8844333333333336
epoch: 255, dataset: CVC-ClinicDB, dice: 0.8770612903225804
CVC-ClinicDB :  0.8770612903225804
epoch: 255, dataset: Kvasir, dice: 0.8972180000000001
Kvasir :  0.8972180000000001
epoch: 255, dataset: CVC-ColonDB, dice: 0.7031807894736836
CVC-ColonDB :  0.7031807894736836
epoch: 255, dataset: ETIS-LaribPolypDB, dice: 0.7437219387755101
ETIS-LaribPolypDB :  0.7437219387755101
2023-09-02 10:48:19.881190: train_loss -1.4723
2023-09-02 10:48:19.882879: val_loss -0.7921
2023-09-02 10:48:19.884335: Pseudo dice [0.8016]
2023-09-02 10:48:19.885575: Epoch time: 111.21 s
2023-09-02 10:48:21.094380: 
2023-09-02 10:48:21.096657: Epoch 256
2023-09-02 10:48:21.098112: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-02 10:48:21.099950: start training, 250
================num of epochs: 250================
2023-09-02 10:49:19.467336: finished training
epoch: 256, dataset: CVC-300, dice: 0.890183333333333
CVC-300 :  0.890183333333333
epoch: 256, dataset: CVC-ClinicDB, dice: 0.8837903225806453
CVC-ClinicDB :  0.8837903225806453
epoch: 256, dataset: Kvasir, dice: 0.8999740000000002
Kvasir :  0.8999740000000002
epoch: 256, dataset: CVC-ColonDB, dice: 0.7093186842105267
CVC-ColonDB :  0.7093186842105267
epoch: 256, dataset: ETIS-LaribPolypDB, dice: 0.7515357142857146
ETIS-LaribPolypDB :  0.7515357142857146
2023-09-02 10:50:12.501734: train_loss -1.472
2023-09-02 10:50:12.503736: val_loss -0.8672
2023-09-02 10:50:12.505257: Pseudo dice [0.8236]
2023-09-02 10:50:12.506596: Epoch time: 111.41 s
2023-09-02 10:50:13.706976: 
2023-09-02 10:50:13.708832: Epoch 257
2023-09-02 10:50:13.710255: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-02 10:50:13.712091: start training, 250
================num of epochs: 250================
2023-09-02 10:51:11.794970: finished training
epoch: 257, dataset: CVC-300, dice: 0.8854000000000002
CVC-300 :  0.8854000000000002
epoch: 257, dataset: CVC-ClinicDB, dice: 0.8807129032258062
CVC-ClinicDB :  0.8807129032258062
epoch: 257, dataset: Kvasir, dice: 0.8985219999999998
Kvasir :  0.8985219999999998
epoch: 257, dataset: CVC-ColonDB, dice: 0.7043423684210524
CVC-ColonDB :  0.7043423684210524
epoch: 257, dataset: ETIS-LaribPolypDB, dice: 0.7426663265306122
ETIS-LaribPolypDB :  0.7426663265306122
2023-09-02 10:52:04.685508: train_loss -1.4719
2023-09-02 10:52:04.687190: val_loss -0.8902
2023-09-02 10:52:04.688663: Pseudo dice [0.8291]
2023-09-02 10:52:04.689915: Epoch time: 110.98 s
2023-09-02 10:52:05.900353: 
2023-09-02 10:52:05.901990: Epoch 258
2023-09-02 10:52:05.903175: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-02 10:52:05.904730: start training, 250
================num of epochs: 250================
2023-09-02 10:53:04.057793: finished training
epoch: 258, dataset: CVC-300, dice: 0.8823783333333335
CVC-300 :  0.8823783333333335
epoch: 258, dataset: CVC-ClinicDB, dice: 0.8781645161290325
CVC-ClinicDB :  0.8781645161290325
epoch: 258, dataset: Kvasir, dice: 0.8994970000000002
Kvasir :  0.8994970000000002
epoch: 258, dataset: CVC-ColonDB, dice: 0.7034507894736838
CVC-ColonDB :  0.7034507894736838
epoch: 258, dataset: ETIS-LaribPolypDB, dice: 0.7383938775510206
ETIS-LaribPolypDB :  0.7383938775510206
2023-09-02 10:53:57.487014: train_loss -1.4721
2023-09-02 10:53:57.488860: val_loss -0.9396
2023-09-02 10:53:57.490369: Pseudo dice [0.845]
2023-09-02 10:53:57.491686: Epoch time: 111.59 s
2023-09-02 10:53:58.709695: 
2023-09-02 10:53:58.711493: Epoch 259
2023-09-02 10:53:58.712817: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-02 10:53:58.714567: start training, 250
================num of epochs: 250================
2023-09-02 10:54:57.001084: finished training
epoch: 259, dataset: CVC-300, dice: 0.8806016666666667
CVC-300 :  0.8806016666666667
epoch: 259, dataset: CVC-ClinicDB, dice: 0.8823629032258062
CVC-ClinicDB :  0.8823629032258062
epoch: 259, dataset: Kvasir, dice: 0.8995330000000002
Kvasir :  0.8995330000000002
epoch: 259, dataset: CVC-ColonDB, dice: 0.7006810526315791
CVC-ColonDB :  0.7006810526315791
epoch: 259, dataset: ETIS-LaribPolypDB, dice: 0.7387658163265308
ETIS-LaribPolypDB :  0.7387658163265308
2023-09-02 10:55:50.372030: train_loss -1.4717
2023-09-02 10:55:50.373788: val_loss -0.8851
2023-09-02 10:55:50.375398: Pseudo dice [0.8294]
2023-09-02 10:55:50.376644: Epoch time: 111.66 s
2023-09-02 10:55:53.266201: 
2023-09-02 10:55:53.268181: Epoch 260
2023-09-02 10:55:53.269615: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-02 10:55:53.271424: start training, 250
================num of epochs: 250================
2023-09-02 10:56:51.421206: finished training
epoch: 260, dataset: CVC-300, dice: 0.8846783333333331
CVC-300 :  0.8846783333333331
epoch: 260, dataset: CVC-ClinicDB, dice: 0.881658064516129
CVC-ClinicDB :  0.881658064516129
epoch: 260, dataset: Kvasir, dice: 0.8985110000000002
Kvasir :  0.8985110000000002
epoch: 260, dataset: CVC-ColonDB, dice: 0.7037918421052634
CVC-ColonDB :  0.7037918421052634
epoch: 260, dataset: ETIS-LaribPolypDB, dice: 0.7455316326530617
ETIS-LaribPolypDB :  0.7455316326530617
2023-09-02 10:57:44.522699: train_loss -1.472
2023-09-02 10:57:44.524436: val_loss -0.8371
2023-09-02 10:57:44.525878: Pseudo dice [0.8215]
2023-09-02 10:57:44.527086: Epoch time: 111.26 s
2023-09-02 10:57:45.732921: 
2023-09-02 10:57:45.734752: Epoch 261
2023-09-02 10:57:45.736034: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-02 10:57:45.737665: start training, 250
================num of epochs: 250================
2023-09-02 10:58:43.906253: finished training
epoch: 261, dataset: CVC-300, dice: 0.8892466666666665
CVC-300 :  0.8892466666666665
epoch: 261, dataset: CVC-ClinicDB, dice: 0.8816629032258063
CVC-ClinicDB :  0.8816629032258063
epoch: 261, dataset: Kvasir, dice: 0.8997670000000002
Kvasir :  0.8997670000000002
epoch: 261, dataset: CVC-ColonDB, dice: 0.708881052631579
CVC-ColonDB :  0.708881052631579
epoch: 261, dataset: ETIS-LaribPolypDB, dice: 0.7445250000000002
ETIS-LaribPolypDB :  0.7445250000000002
2023-09-02 10:59:36.657822: train_loss -1.4719
2023-09-02 10:59:36.659605: val_loss -0.9032
2023-09-02 10:59:36.661052: Pseudo dice [0.8388]
2023-09-02 10:59:36.662277: Epoch time: 110.93 s
2023-09-02 10:59:37.866118: 
2023-09-02 10:59:37.867743: Epoch 262
2023-09-02 10:59:37.868954: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-02 10:59:37.870586: start training, 250
================num of epochs: 250================
2023-09-02 11:00:36.291406: finished training
epoch: 262, dataset: CVC-300, dice: 0.88734
CVC-300 :  0.88734
epoch: 262, dataset: CVC-ClinicDB, dice: 0.8800854838709676
CVC-ClinicDB :  0.8800854838709676
epoch: 262, dataset: Kvasir, dice: 0.8998940000000002
Kvasir :  0.8998940000000002
epoch: 262, dataset: CVC-ColonDB, dice: 0.7017315789473685
CVC-ColonDB :  0.7017315789473685
epoch: 262, dataset: ETIS-LaribPolypDB, dice: 0.7416734693877554
ETIS-LaribPolypDB :  0.7416734693877554
2023-09-02 11:01:28.863026: train_loss -1.472
2023-09-02 11:01:28.864833: val_loss -0.8944
2023-09-02 11:01:28.866260: Pseudo dice [0.8274]
2023-09-02 11:01:28.867518: Epoch time: 111.0 s
2023-09-02 11:01:30.060818: 
2023-09-02 11:01:30.062814: Epoch 263
2023-09-02 11:01:30.064255: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-02 11:01:30.066079: start training, 250
================num of epochs: 250================
2023-09-02 11:02:28.416235: finished training
epoch: 263, dataset: CVC-300, dice: 0.8901650000000001
CVC-300 :  0.8901650000000001
epoch: 263, dataset: CVC-ClinicDB, dice: 0.8805693548387098
CVC-ClinicDB :  0.8805693548387098
epoch: 263, dataset: Kvasir, dice: 0.900829
Kvasir :  0.900829
epoch: 263, dataset: CVC-ColonDB, dice: 0.703887105263158
CVC-ColonDB :  0.703887105263158
epoch: 263, dataset: ETIS-LaribPolypDB, dice: 0.7404775510204081
ETIS-LaribPolypDB :  0.7404775510204081
2023-09-02 11:03:24.620961: train_loss -1.4719
2023-09-02 11:03:24.622912: val_loss -0.8436
2023-09-02 11:03:24.624522: Pseudo dice [0.8293]
2023-09-02 11:03:24.625813: Epoch time: 114.56 s
2023-09-02 11:03:25.845533: 
2023-09-02 11:03:25.847523: Epoch 264
2023-09-02 11:03:25.848829: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-02 11:03:25.850480: start training, 250
================num of epochs: 250================
2023-09-02 11:04:24.091184: finished training
epoch: 264, dataset: CVC-300, dice: 0.8803033333333331
CVC-300 :  0.8803033333333331
epoch: 264, dataset: CVC-ClinicDB, dice: 0.8816387096774194
CVC-ClinicDB :  0.8816387096774194
epoch: 264, dataset: Kvasir, dice: 0.9035920000000002
Kvasir :  0.9035920000000002
epoch: 264, dataset: CVC-ColonDB, dice: 0.7054044736842108
CVC-ColonDB :  0.7054044736842108
epoch: 264, dataset: ETIS-LaribPolypDB, dice: 0.7426622448979591
ETIS-LaribPolypDB :  0.7426622448979591
2023-09-02 11:05:18.414901: train_loss -1.4723
2023-09-02 11:05:18.416864: val_loss -0.8475
2023-09-02 11:05:18.418498: Pseudo dice [0.8248]
2023-09-02 11:05:18.419987: Epoch time: 112.57 s
2023-09-02 11:05:19.654111: 
2023-09-02 11:05:19.656064: Epoch 265
2023-09-02 11:05:19.657551: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-02 11:05:19.659344: start training, 250
================num of epochs: 250================
2023-09-02 11:06:18.057395: finished training
epoch: 265, dataset: CVC-300, dice: 0.8801633333333334
CVC-300 :  0.8801633333333334
epoch: 265, dataset: CVC-ClinicDB, dice: 0.8772193548387095
CVC-ClinicDB :  0.8772193548387095
epoch: 265, dataset: Kvasir, dice: 0.9029220000000002
Kvasir :  0.9029220000000002
epoch: 265, dataset: CVC-ColonDB, dice: 0.7040484210526324
CVC-ColonDB :  0.7040484210526324
epoch: 265, dataset: ETIS-LaribPolypDB, dice: 0.7428811224489797
ETIS-LaribPolypDB :  0.7428811224489797
2023-09-02 11:07:08.778824: train_loss -1.4721
2023-09-02 11:07:08.780809: val_loss -0.7877
2023-09-02 11:07:08.782405: Pseudo dice [0.821]
2023-09-02 11:07:08.783667: Epoch time: 109.13 s
2023-09-02 11:07:10.003888: 
2023-09-02 11:07:10.005757: Epoch 266
2023-09-02 11:07:10.006989: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-02 11:07:10.011635: start training, 250
================num of epochs: 250================
2023-09-02 11:08:08.217557: finished training
epoch: 266, dataset: CVC-300, dice: 0.8888966666666664
CVC-300 :  0.8888966666666664
epoch: 266, dataset: CVC-ClinicDB, dice: 0.8778193548387095
CVC-ClinicDB :  0.8778193548387095
epoch: 266, dataset: Kvasir, dice: 0.9019669999999994
Kvasir :  0.9019669999999994
epoch: 266, dataset: CVC-ColonDB, dice: 0.7046436842105263
CVC-ColonDB :  0.7046436842105263
epoch: 266, dataset: ETIS-LaribPolypDB, dice: 0.7532882653061227
ETIS-LaribPolypDB :  0.7532882653061227
2023-09-02 11:08:59.810638: train_loss -1.4718
2023-09-02 11:08:59.812521: val_loss -0.8293
2023-09-02 11:08:59.813990: Pseudo dice [0.8245]
2023-09-02 11:08:59.815253: Epoch time: 109.81 s
2023-09-02 11:09:01.080988: 
2023-09-02 11:09:01.082821: Epoch 267
2023-09-02 11:09:01.084068: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-02 11:09:01.086022: start training, 250
================num of epochs: 250================
2023-09-02 11:09:59.435277: finished training
epoch: 267, dataset: CVC-300, dice: 0.8879650000000001
CVC-300 :  0.8879650000000001
epoch: 267, dataset: CVC-ClinicDB, dice: 0.8801919354838711
CVC-ClinicDB :  0.8801919354838711
epoch: 267, dataset: Kvasir, dice: 0.9016810000000003
Kvasir :  0.9016810000000003
epoch: 267, dataset: CVC-ColonDB, dice: 0.7059565789473683
CVC-ColonDB :  0.7059565789473683
epoch: 267, dataset: ETIS-LaribPolypDB, dice: 0.744129081632653
ETIS-LaribPolypDB :  0.744129081632653
2023-09-02 11:10:52.237300: train_loss -1.4717
2023-09-02 11:10:52.239160: val_loss -0.7459
2023-09-02 11:10:52.240726: Pseudo dice [0.8046]
2023-09-02 11:10:52.242018: Epoch time: 111.16 s
2023-09-02 11:10:53.452739: 
2023-09-02 11:10:53.454551: Epoch 268
2023-09-02 11:10:53.455866: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-02 11:10:53.457639: start training, 250
================num of epochs: 250================
2023-09-02 11:11:51.799710: finished training
epoch: 268, dataset: CVC-300, dice: 0.8753949999999999
CVC-300 :  0.8753949999999999
epoch: 268, dataset: CVC-ClinicDB, dice: 0.8800306451612905
CVC-ClinicDB :  0.8800306451612905
epoch: 268, dataset: Kvasir, dice: 0.899861
Kvasir :  0.899861
epoch: 268, dataset: CVC-ColonDB, dice: 0.6967202631578947
CVC-ColonDB :  0.6967202631578947
epoch: 268, dataset: ETIS-LaribPolypDB, dice: 0.7224576530612243
ETIS-LaribPolypDB :  0.7224576530612243
2023-09-02 11:12:45.191750: train_loss -1.4719
2023-09-02 11:12:45.193609: val_loss -1.0086
2023-09-02 11:12:45.195229: Pseudo dice [0.8521]
2023-09-02 11:12:45.196633: Epoch time: 111.74 s
2023-09-02 11:12:46.394983: 
2023-09-02 11:12:46.397096: Epoch 269
2023-09-02 11:12:46.398550: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-02 11:12:46.400396: start training, 250
================num of epochs: 250================
2023-09-02 11:13:44.568528: finished training
epoch: 269, dataset: CVC-300, dice: 0.8845466666666667
CVC-300 :  0.8845466666666667
epoch: 269, dataset: CVC-ClinicDB, dice: 0.8852822580645161
CVC-ClinicDB :  0.8852822580645161
epoch: 269, dataset: Kvasir, dice: 0.900781
Kvasir :  0.900781
epoch: 269, dataset: CVC-ColonDB, dice: 0.7023118421052634
CVC-ColonDB :  0.7023118421052634
epoch: 269, dataset: ETIS-LaribPolypDB, dice: 0.7275255102040817
ETIS-LaribPolypDB :  0.7275255102040817
2023-09-02 11:14:38.106860: train_loss -1.4719
2023-09-02 11:14:38.108666: val_loss -0.9437
2023-09-02 11:14:38.110169: Pseudo dice [0.8318]
2023-09-02 11:14:38.111446: Epoch time: 111.71 s
2023-09-02 11:14:40.916502: 
2023-09-02 11:14:40.918456: Epoch 270
2023-09-02 11:14:40.919844: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-02 11:14:40.921687: start training, 250
================num of epochs: 250================
2023-09-02 11:15:39.020276: finished training
epoch: 270, dataset: CVC-300, dice: 0.8890783333333333
CVC-300 :  0.8890783333333333
epoch: 270, dataset: CVC-ClinicDB, dice: 0.8832983870967744
CVC-ClinicDB :  0.8832983870967744
epoch: 270, dataset: Kvasir, dice: 0.9010389999999999
Kvasir :  0.9010389999999999
epoch: 270, dataset: CVC-ColonDB, dice: 0.707571842105263
CVC-ColonDB :  0.707571842105263
epoch: 270, dataset: ETIS-LaribPolypDB, dice: 0.7345683673469385
ETIS-LaribPolypDB :  0.7345683673469385
2023-09-02 11:16:32.761852: train_loss -1.4723
2023-09-02 11:16:32.763776: val_loss -0.8488
2023-09-02 11:16:32.765288: Pseudo dice [0.809]
2023-09-02 11:16:32.766540: Epoch time: 111.85 s
2023-09-02 11:16:33.957373: 
2023-09-02 11:16:33.959404: Epoch 271
2023-09-02 11:16:33.960845: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-02 11:16:33.962733: start training, 250
================num of epochs: 250================
2023-09-02 11:17:32.943888: finished training
epoch: 271, dataset: CVC-300, dice: 0.8859799999999998
CVC-300 :  0.8859799999999998
epoch: 271, dataset: CVC-ClinicDB, dice: 0.881990322580645
CVC-ClinicDB :  0.881990322580645
epoch: 271, dataset: Kvasir, dice: 0.9002229999999998
Kvasir :  0.9002229999999998
epoch: 271, dataset: CVC-ColonDB, dice: 0.7054842105263165
CVC-ColonDB :  0.7054842105263165
epoch: 271, dataset: ETIS-LaribPolypDB, dice: 0.7357520408163268
ETIS-LaribPolypDB :  0.7357520408163268
2023-09-02 11:18:26.445059: train_loss -1.4724
2023-09-02 11:18:26.447094: val_loss -0.9071
2023-09-02 11:18:26.448697: Pseudo dice [0.8316]
2023-09-02 11:18:26.450389: Epoch time: 112.49 s
2023-09-02 11:18:27.669892: 
2023-09-02 11:18:27.671646: Epoch 272
2023-09-02 11:18:27.672881: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-02 11:18:27.674619: start training, 250
================num of epochs: 250================
2023-09-02 11:19:26.172508: finished training
epoch: 272, dataset: CVC-300, dice: 0.8792516666666668
CVC-300 :  0.8792516666666668
epoch: 272, dataset: CVC-ClinicDB, dice: 0.8815403225806451
CVC-ClinicDB :  0.8815403225806451
epoch: 272, dataset: Kvasir, dice: 0.8991880000000001
Kvasir :  0.8991880000000001
epoch: 272, dataset: CVC-ColonDB, dice: 0.7015373684210533
CVC-ColonDB :  0.7015373684210533
epoch: 272, dataset: ETIS-LaribPolypDB, dice: 0.732807142857143
ETIS-LaribPolypDB :  0.732807142857143
2023-09-02 11:20:24.592282: train_loss -1.4724
2023-09-02 11:20:24.594522: val_loss -0.9295
2023-09-02 11:20:24.596349: Pseudo dice [0.8384]
2023-09-02 11:20:24.597921: Epoch time: 116.92 s
2023-09-02 11:20:25.879649: 
2023-09-02 11:20:25.881559: Epoch 273
2023-09-02 11:20:25.883133: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-02 11:20:25.885209: start training, 250
================num of epochs: 250================
2023-09-02 11:21:24.535919: finished training
epoch: 273, dataset: CVC-300, dice: 0.8881999999999999
CVC-300 :  0.8881999999999999
epoch: 273, dataset: CVC-ClinicDB, dice: 0.8822000000000001
CVC-ClinicDB :  0.8822000000000001
epoch: 273, dataset: Kvasir, dice: 0.898538
Kvasir :  0.898538
epoch: 273, dataset: CVC-ColonDB, dice: 0.7045102631578959
CVC-ColonDB :  0.7045102631578959
epoch: 273, dataset: ETIS-LaribPolypDB, dice: 0.7361479591836735
ETIS-LaribPolypDB :  0.7361479591836735
2023-09-02 11:22:17.019638: train_loss -1.4726
2023-09-02 11:22:17.022503: val_loss -0.8782
2023-09-02 11:22:17.024781: Pseudo dice [0.8279]
2023-09-02 11:22:17.026130: Epoch time: 111.14 s
2023-09-02 11:22:18.294582: 
2023-09-02 11:22:18.296473: Epoch 274
2023-09-02 11:22:18.297861: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-02 11:22:18.299758: start training, 250
================num of epochs: 250================
2023-09-02 11:23:16.763835: finished training
epoch: 274, dataset: CVC-300, dice: 0.8848033333333334
CVC-300 :  0.8848033333333334
epoch: 274, dataset: CVC-ClinicDB, dice: 0.8831709677419355
CVC-ClinicDB :  0.8831709677419355
epoch: 274, dataset: Kvasir, dice: 0.9000230000000002
Kvasir :  0.9000230000000002
epoch: 274, dataset: CVC-ColonDB, dice: 0.7075418421052636
CVC-ColonDB :  0.7075418421052636
epoch: 274, dataset: ETIS-LaribPolypDB, dice: 0.7377719387755103
ETIS-LaribPolypDB :  0.7377719387755103
2023-09-02 11:24:08.231048: train_loss -1.4725
2023-09-02 11:24:08.233147: val_loss -0.8864
2023-09-02 11:24:08.234855: Pseudo dice [0.8289]
2023-09-02 11:24:08.236186: Epoch time: 109.94 s
2023-09-02 11:24:09.831179: 
2023-09-02 11:24:09.833093: Epoch 275
2023-09-02 11:24:09.834399: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-02 11:24:09.836128: start training, 250
================num of epochs: 250================
2023-09-02 11:25:08.606563: finished training
epoch: 275, dataset: CVC-300, dice: 0.8804883333333337
CVC-300 :  0.8804883333333337
epoch: 275, dataset: CVC-ClinicDB, dice: 0.8839338709677418
CVC-ClinicDB :  0.8839338709677418
epoch: 275, dataset: Kvasir, dice: 0.8989289999999996
Kvasir :  0.8989289999999996
epoch: 275, dataset: CVC-ColonDB, dice: 0.708256842105263
CVC-ColonDB :  0.708256842105263
epoch: 275, dataset: ETIS-LaribPolypDB, dice: 0.7332173469387754
ETIS-LaribPolypDB :  0.7332173469387754
2023-09-02 11:25:59.452476: train_loss -1.4725
2023-09-02 11:25:59.454542: val_loss -0.7866
2023-09-02 11:25:59.456299: Pseudo dice [0.8077]
2023-09-02 11:25:59.457591: Epoch time: 109.62 s
2023-09-02 11:26:00.703156: 
2023-09-02 11:26:00.705686: Epoch 276
2023-09-02 11:26:00.707462: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-02 11:26:00.710323: start training, 250
================num of epochs: 250================
2023-09-02 11:26:59.124733: finished training
epoch: 276, dataset: CVC-300, dice: 0.8862483333333331
CVC-300 :  0.8862483333333331
epoch: 276, dataset: CVC-ClinicDB, dice: 0.8847387096774194
CVC-ClinicDB :  0.8847387096774194
epoch: 276, dataset: Kvasir, dice: 0.8997469999999997
Kvasir :  0.8997469999999997
epoch: 276, dataset: CVC-ColonDB, dice: 0.7066018421052624
CVC-ColonDB :  0.7066018421052624
epoch: 276, dataset: ETIS-LaribPolypDB, dice: 0.7340020408163269
ETIS-LaribPolypDB :  0.7340020408163269
2023-09-02 11:27:49.645097: train_loss -1.4724
2023-09-02 11:27:49.646910: val_loss -0.9487
2023-09-02 11:27:49.648638: Pseudo dice [0.8364]
2023-09-02 11:27:49.650131: Epoch time: 108.95 s
2023-09-02 11:27:50.898239: 
2023-09-02 11:27:50.900187: Epoch 277
2023-09-02 11:27:50.902065: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-02 11:27:50.904862: start training, 250
================num of epochs: 250================
2023-09-02 11:28:49.175583: finished training
epoch: 277, dataset: CVC-300, dice: 0.8819033333333334
CVC-300 :  0.8819033333333334
epoch: 277, dataset: CVC-ClinicDB, dice: 0.8838403225806452
CVC-ClinicDB :  0.8838403225806452
epoch: 277, dataset: Kvasir, dice: 0.8989249999999998
Kvasir :  0.8989249999999998
epoch: 277, dataset: CVC-ColonDB, dice: 0.7027839473684211
CVC-ColonDB :  0.7027839473684211
epoch: 277, dataset: ETIS-LaribPolypDB, dice: 0.7297372448979592
ETIS-LaribPolypDB :  0.7297372448979592
2023-09-02 11:29:43.332673: train_loss -1.4725
2023-09-02 11:29:43.334527: val_loss -0.9279
2023-09-02 11:29:43.336142: Pseudo dice [0.8422]
2023-09-02 11:29:43.337519: Epoch time: 112.44 s
2023-09-02 11:29:44.992949: 
2023-09-02 11:29:44.994554: Epoch 278
2023-09-02 11:29:44.995874: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-02 11:29:44.997584: start training, 250
================num of epochs: 250================
2023-09-02 11:30:43.153276: finished training
epoch: 278, dataset: CVC-300, dice: 0.8831683333333338
CVC-300 :  0.8831683333333338
epoch: 278, dataset: CVC-ClinicDB, dice: 0.8836661290322579
CVC-ClinicDB :  0.8836661290322579
epoch: 278, dataset: Kvasir, dice: 0.8997639999999997
Kvasir :  0.8997639999999997
epoch: 278, dataset: CVC-ColonDB, dice: 0.703478684210527
CVC-ColonDB :  0.703478684210527
epoch: 278, dataset: ETIS-LaribPolypDB, dice: 0.7299438775510203
ETIS-LaribPolypDB :  0.7299438775510203
2023-09-02 11:31:39.568464: train_loss -1.4726
2023-09-02 11:31:39.570661: val_loss -0.9777
2023-09-02 11:31:39.572493: Pseudo dice [0.8492]
2023-09-02 11:31:39.573937: Epoch time: 114.58 s
2023-09-02 11:31:40.850001: 
2023-09-02 11:31:40.855884: Epoch 279
2023-09-02 11:31:40.860710: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-02 11:31:40.866260: start training, 250
================num of epochs: 250================
2023-09-02 11:32:39.313452: finished training
epoch: 279, dataset: CVC-300, dice: 0.8863000000000001
CVC-300 :  0.8863000000000001
epoch: 279, dataset: CVC-ClinicDB, dice: 0.8856596774193548
CVC-ClinicDB :  0.8856596774193548
epoch: 279, dataset: Kvasir, dice: 0.9000630000000003
Kvasir :  0.9000630000000003
epoch: 279, dataset: CVC-ColonDB, dice: 0.706930789473684
CVC-ColonDB :  0.706930789473684
epoch: 279, dataset: ETIS-LaribPolypDB, dice: 0.7375158163265305
ETIS-LaribPolypDB :  0.7375158163265305
2023-09-02 11:33:31.864572: train_loss -1.4725
2023-09-02 11:33:31.866683: val_loss -1.0129
2023-09-02 11:33:31.868594: Pseudo dice [0.8589]
2023-09-02 11:33:31.869910: Epoch time: 111.02 s
2023-09-02 11:33:34.810975: 
2023-09-02 11:33:34.812942: Epoch 280
2023-09-02 11:33:34.814364: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-02 11:33:34.816340: start training, 250
================num of epochs: 250================
2023-09-02 11:34:33.467075: finished training
epoch: 280, dataset: CVC-300, dice: 0.8887516666666665
CVC-300 :  0.8887516666666665
epoch: 280, dataset: CVC-ClinicDB, dice: 0.8876322580645163
CVC-ClinicDB :  0.8876322580645163
epoch: 280, dataset: Kvasir, dice: 0.8984300000000005
Kvasir :  0.8984300000000005
epoch: 280, dataset: CVC-ColonDB, dice: 0.7062678947368423
CVC-ColonDB :  0.7062678947368423
epoch: 280, dataset: ETIS-LaribPolypDB, dice: 0.7357872448979588
ETIS-LaribPolypDB :  0.7357872448979588
2023-09-02 11:35:25.825342: train_loss -1.4724
2023-09-02 11:35:25.827551: val_loss -0.7645
2023-09-02 11:35:25.829723: Pseudo dice [0.8019]
2023-09-02 11:35:25.831402: Epoch time: 111.02 s
2023-09-02 11:35:27.077456: 
2023-09-02 11:35:27.079270: Epoch 281
2023-09-02 11:35:27.080572: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-02 11:35:27.082609: start training, 250
================num of epochs: 250================
2023-09-02 11:36:25.800780: finished training
epoch: 281, dataset: CVC-300, dice: 0.8823033333333333
CVC-300 :  0.8823033333333333
epoch: 281, dataset: CVC-ClinicDB, dice: 0.8857854838709678
CVC-ClinicDB :  0.8857854838709678
epoch: 281, dataset: Kvasir, dice: 0.8988449999999999
Kvasir :  0.8988449999999999
epoch: 281, dataset: CVC-ColonDB, dice: 0.7023789473684208
CVC-ColonDB :  0.7023789473684208
epoch: 281, dataset: ETIS-LaribPolypDB, dice: 0.7313714285714288
ETIS-LaribPolypDB :  0.7313714285714288
2023-09-02 11:37:22.856460: train_loss -1.4728
2023-09-02 11:37:22.858346: val_loss -0.9407
2023-09-02 11:37:22.860036: Pseudo dice [0.8319]
2023-09-02 11:37:22.861316: Epoch time: 115.78 s
2023-09-02 11:37:24.113232: 
2023-09-02 11:37:24.115276: Epoch 282
2023-09-02 11:37:24.116575: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-02 11:37:24.118501: start training, 250
================num of epochs: 250================
2023-09-02 11:38:22.846883: finished training
epoch: 282, dataset: CVC-300, dice: 0.8817933333333337
CVC-300 :  0.8817933333333337
epoch: 282, dataset: CVC-ClinicDB, dice: 0.8847177419354836
CVC-ClinicDB :  0.8847177419354836
epoch: 282, dataset: Kvasir, dice: 0.898573
Kvasir :  0.898573
epoch: 282, dataset: CVC-ColonDB, dice: 0.7033192105263163
CVC-ColonDB :  0.7033192105263163
epoch: 282, dataset: ETIS-LaribPolypDB, dice: 0.7309153061224486
ETIS-LaribPolypDB :  0.7309153061224486
2023-09-02 11:39:15.304184: train_loss -1.4729
2023-09-02 11:39:15.306110: val_loss -0.9094
2023-09-02 11:39:15.307775: Pseudo dice [0.8373]
2023-09-02 11:39:15.309117: Epoch time: 111.19 s
2023-09-02 11:39:16.577366: 
2023-09-02 11:39:16.579632: Epoch 283
2023-09-02 11:39:16.581034: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-02 11:39:16.582953: start training, 250
================num of epochs: 250================
2023-09-02 11:40:14.984084: finished training
epoch: 283, dataset: CVC-300, dice: 0.8786833333333336
CVC-300 :  0.8786833333333336
epoch: 283, dataset: CVC-ClinicDB, dice: 0.8835516129032256
CVC-ClinicDB :  0.8835516129032256
epoch: 283, dataset: Kvasir, dice: 0.897957
Kvasir :  0.897957
epoch: 283, dataset: CVC-ColonDB, dice: 0.7028407894736838
CVC-ColonDB :  0.7028407894736838
epoch: 283, dataset: ETIS-LaribPolypDB, dice: 0.7330551020408163
ETIS-LaribPolypDB :  0.7330551020408163
2023-09-02 11:41:08.312371: train_loss -1.4728
2023-09-02 11:41:08.314473: val_loss -0.834
2023-09-02 11:41:08.316089: Pseudo dice [0.8091]
2023-09-02 11:41:08.317410: Epoch time: 111.74 s
2023-09-02 11:41:09.591509: 
2023-09-02 11:41:09.593272: Epoch 284
2023-09-02 11:41:09.594626: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-02 11:41:09.596485: start training, 250
================num of epochs: 250================
2023-09-02 11:42:08.515270: finished training
epoch: 284, dataset: CVC-300, dice: 0.8814566666666664
CVC-300 :  0.8814566666666664
epoch: 284, dataset: CVC-ClinicDB, dice: 0.8851822580645161
CVC-ClinicDB :  0.8851822580645161
epoch: 284, dataset: Kvasir, dice: 0.897207
Kvasir :  0.897207
epoch: 284, dataset: CVC-ColonDB, dice: 0.7027171052631582
CVC-ColonDB :  0.7027171052631582
epoch: 284, dataset: ETIS-LaribPolypDB, dice: 0.7315979591836737
ETIS-LaribPolypDB :  0.7315979591836737
2023-09-02 11:43:02.143269: train_loss -1.4724
2023-09-02 11:43:02.145254: val_loss -0.8244
2023-09-02 11:43:02.147518: Pseudo dice [0.8099]
2023-09-02 11:43:02.149305: Epoch time: 112.55 s
2023-09-02 11:43:03.454238: 
2023-09-02 11:43:03.456313: Epoch 285
2023-09-02 11:43:03.457612: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-02 11:43:03.459559: start training, 250
================num of epochs: 250================
2023-09-02 11:44:01.883217: finished training
epoch: 285, dataset: CVC-300, dice: 0.8780400000000002
CVC-300 :  0.8780400000000002
epoch: 285, dataset: CVC-ClinicDB, dice: 0.8817419354838705
CVC-ClinicDB :  0.8817419354838705
epoch: 285, dataset: Kvasir, dice: 0.896809
Kvasir :  0.896809
epoch: 285, dataset: CVC-ColonDB, dice: 0.7016999999999995
CVC-ColonDB :  0.7016999999999995
epoch: 285, dataset: ETIS-LaribPolypDB, dice: 0.7315872448979586
ETIS-LaribPolypDB :  0.7315872448979586
2023-09-02 11:44:58.638728: train_loss -1.4725
2023-09-02 11:44:58.640805: val_loss -0.7589
2023-09-02 11:44:58.642520: Pseudo dice [0.8111]
2023-09-02 11:44:58.643857: Epoch time: 115.19 s
2023-09-02 11:44:59.881926: 
2023-09-02 11:44:59.883797: Epoch 286
2023-09-02 11:44:59.885307: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-02 11:44:59.887307: start training, 250
================num of epochs: 250================
2023-09-02 11:45:58.415478: finished training
epoch: 286, dataset: CVC-300, dice: 0.8766533333333336
CVC-300 :  0.8766533333333336
epoch: 286, dataset: CVC-ClinicDB, dice: 0.8827596774193548
CVC-ClinicDB :  0.8827596774193548
epoch: 286, dataset: Kvasir, dice: 0.8958179999999999
Kvasir :  0.8958179999999999
epoch: 286, dataset: CVC-ColonDB, dice: 0.6984671052631574
CVC-ColonDB :  0.6984671052631574
epoch: 286, dataset: ETIS-LaribPolypDB, dice: 0.7285581632653064
ETIS-LaribPolypDB :  0.7285581632653064
2023-09-02 11:46:56.116588: train_loss -1.4727
2023-09-02 11:46:56.118800: val_loss -0.801
2023-09-02 11:46:56.120644: Pseudo dice [0.816]
2023-09-02 11:46:56.122159: Epoch time: 116.24 s
2023-09-02 11:46:57.399851: 
2023-09-02 11:46:57.401842: Epoch 287
2023-09-02 11:46:57.403200: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-02 11:46:57.405330: start training, 250
================num of epochs: 250================
2023-09-02 11:47:56.248105: finished training
epoch: 287, dataset: CVC-300, dice: 0.88137
CVC-300 :  0.88137
epoch: 287, dataset: CVC-ClinicDB, dice: 0.8815435483870966
CVC-ClinicDB :  0.8815435483870966
epoch: 287, dataset: Kvasir, dice: 0.8978670000000001
Kvasir :  0.8978670000000001
epoch: 287, dataset: CVC-ColonDB, dice: 0.7027899999999992
CVC-ColonDB :  0.7027899999999992
epoch: 287, dataset: ETIS-LaribPolypDB, dice: 0.7325091836734698
ETIS-LaribPolypDB :  0.7325091836734698
2023-09-02 11:48:51.857917: train_loss -1.4728
2023-09-02 11:48:51.860259: val_loss -0.9583
2023-09-02 11:48:51.862246: Pseudo dice [0.8434]
2023-09-02 11:48:51.863786: Epoch time: 114.46 s
2023-09-02 11:48:53.175482: 
2023-09-02 11:48:53.177508: Epoch 288
2023-09-02 11:48:53.179286: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-02 11:48:53.182244: start training, 250
================num of epochs: 250================
2023-09-02 11:49:51.805790: finished training
epoch: 288, dataset: CVC-300, dice: 0.8860183333333332
CVC-300 :  0.8860183333333332
epoch: 288, dataset: CVC-ClinicDB, dice: 0.8859258064516131
CVC-ClinicDB :  0.8859258064516131
epoch: 288, dataset: Kvasir, dice: 0.8995970000000003
Kvasir :  0.8995970000000003
epoch: 288, dataset: CVC-ColonDB, dice: 0.7060244736842106
CVC-ColonDB :  0.7060244736842106
epoch: 288, dataset: ETIS-LaribPolypDB, dice: 0.7336709183673472
ETIS-LaribPolypDB :  0.7336709183673472
2023-09-02 11:50:49.536289: train_loss -1.4729
2023-09-02 11:50:49.643138: val_loss -0.8651
2023-09-02 11:50:49.645447: Pseudo dice [0.8187]
2023-09-02 11:50:49.647196: Epoch time: 116.36 s
2023-09-02 11:50:50.909148: 
2023-09-02 11:50:50.911126: Epoch 289
2023-09-02 11:50:50.912965: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-02 11:50:50.915509: start training, 250
================num of epochs: 250================
2023-09-02 11:51:48.929020: finished training
epoch: 289, dataset: CVC-300, dice: 0.8831899999999997
CVC-300 :  0.8831899999999997
epoch: 289, dataset: CVC-ClinicDB, dice: 0.8796838709677423
CVC-ClinicDB :  0.8796838709677423
epoch: 289, dataset: Kvasir, dice: 0.9004900000000002
Kvasir :  0.9004900000000002
epoch: 289, dataset: CVC-ColonDB, dice: 0.7054052631578958
CVC-ColonDB :  0.7054052631578958
epoch: 289, dataset: ETIS-LaribPolypDB, dice: 0.7414811224489788
ETIS-LaribPolypDB :  0.7414811224489788
2023-09-02 11:52:47.223716: train_loss -1.4727
2023-09-02 11:52:47.225720: val_loss -0.955
2023-09-02 11:52:47.227287: Pseudo dice [0.8363]
2023-09-02 11:52:47.228575: Epoch time: 116.32 s
2023-09-02 11:52:50.154266: 
2023-09-02 11:52:50.156062: Epoch 290
2023-09-02 11:52:50.157541: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-02 11:52:50.159600: start training, 250
================num of epochs: 250================
2023-09-02 11:53:48.536276: finished training
epoch: 290, dataset: CVC-300, dice: 0.8871516666666664
CVC-300 :  0.8871516666666664
epoch: 290, dataset: CVC-ClinicDB, dice: 0.8851612903225806
CVC-ClinicDB :  0.8851612903225806
epoch: 290, dataset: Kvasir, dice: 0.9014639999999998
Kvasir :  0.9014639999999998
epoch: 290, dataset: CVC-ColonDB, dice: 0.7089184210526324
CVC-ColonDB :  0.7089184210526324
epoch: 290, dataset: ETIS-LaribPolypDB, dice: 0.7419545918367354
ETIS-LaribPolypDB :  0.7419545918367354
2023-09-02 11:54:44.911120: train_loss -1.4727
2023-09-02 11:54:44.913096: val_loss -0.869
2023-09-02 11:54:44.914702: Pseudo dice [0.827]
2023-09-02 11:54:44.915987: Epoch time: 114.76 s
2023-09-02 11:54:46.162274: 
2023-09-02 11:54:46.164162: Epoch 291
2023-09-02 11:54:46.165496: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-02 11:54:46.167237: start training, 250
================num of epochs: 250================
2023-09-02 11:55:44.623174: finished training
epoch: 291, dataset: CVC-300, dice: 0.8785583333333336
CVC-300 :  0.8785583333333336
epoch: 291, dataset: CVC-ClinicDB, dice: 0.8827032258064514
CVC-ClinicDB :  0.8827032258064514
epoch: 291, dataset: Kvasir, dice: 0.8997000000000002
Kvasir :  0.8997000000000002
epoch: 291, dataset: CVC-ColonDB, dice: 0.7062918421052634
CVC-ColonDB :  0.7062918421052634
epoch: 291, dataset: ETIS-LaribPolypDB, dice: 0.7334637755102041
ETIS-LaribPolypDB :  0.7334637755102041
2023-09-02 11:56:37.038364: train_loss -1.4729
2023-09-02 11:56:37.040249: val_loss -0.8813
2023-09-02 11:56:37.041795: Pseudo dice [0.8208]
2023-09-02 11:56:37.043109: Epoch time: 110.88 s
2023-09-02 11:56:38.306506: 
2023-09-02 11:56:38.308432: Epoch 292
2023-09-02 11:56:38.309813: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-02 11:56:38.311566: start training, 250
================num of epochs: 250================
2023-09-02 11:57:36.369166: finished training
epoch: 292, dataset: CVC-300, dice: 0.8858866666666665
CVC-300 :  0.8858866666666665
epoch: 292, dataset: CVC-ClinicDB, dice: 0.8847241935483869
CVC-ClinicDB :  0.8847241935483869
epoch: 292, dataset: Kvasir, dice: 0.901358
Kvasir :  0.901358
epoch: 292, dataset: CVC-ColonDB, dice: 0.7078834210526316
CVC-ColonDB :  0.7078834210526316
epoch: 292, dataset: ETIS-LaribPolypDB, dice: 0.7407454081632655
ETIS-LaribPolypDB :  0.7407454081632655
2023-09-02 11:58:27.711463: train_loss -1.4731
2023-09-02 11:58:27.713214: val_loss -0.9253
2023-09-02 11:58:27.714921: Pseudo dice [0.836]
2023-09-02 11:58:27.716275: Epoch time: 109.41 s
2023-09-02 11:58:28.944548: 
2023-09-02 11:58:28.946520: Epoch 293
2023-09-02 11:58:28.948002: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-02 11:58:28.949761: start training, 250
================num of epochs: 250================
2023-09-02 11:59:27.378431: finished training
epoch: 293, dataset: CVC-300, dice: 0.8821650000000002
CVC-300 :  0.8821650000000002
epoch: 293, dataset: CVC-ClinicDB, dice: 0.881232258064516
CVC-ClinicDB :  0.881232258064516
epoch: 293, dataset: Kvasir, dice: 0.901097
Kvasir :  0.901097
epoch: 293, dataset: CVC-ColonDB, dice: 0.7046631578947361
CVC-ColonDB :  0.7046631578947361
epoch: 293, dataset: ETIS-LaribPolypDB, dice: 0.7341525510204082
ETIS-LaribPolypDB :  0.7341525510204082
2023-09-02 12:00:18.989787: train_loss -1.4727
2023-09-02 12:00:18.991827: val_loss -0.8753
2023-09-02 12:00:18.993612: Pseudo dice [0.8321]
2023-09-02 12:00:18.995151: Epoch time: 110.05 s
2023-09-02 12:00:20.244340: 
2023-09-02 12:00:20.246285: Epoch 294
2023-09-02 12:00:20.247709: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-02 12:00:20.249539: start training, 250
================num of epochs: 250================
2023-09-02 12:01:18.340233: finished training
epoch: 294, dataset: CVC-300, dice: 0.8867166666666662
CVC-300 :  0.8867166666666662
epoch: 294, dataset: CVC-ClinicDB, dice: 0.8845725806451615
CVC-ClinicDB :  0.8845725806451615
epoch: 294, dataset: Kvasir, dice: 0.9018169999999999
Kvasir :  0.9018169999999999
epoch: 294, dataset: CVC-ColonDB, dice: 0.7066065789473686
CVC-ColonDB :  0.7066065789473686
epoch: 294, dataset: ETIS-LaribPolypDB, dice: 0.741806122448979
ETIS-LaribPolypDB :  0.741806122448979
2023-09-02 12:02:09.470143: train_loss -1.4725
2023-09-02 12:02:09.472054: val_loss -0.8907
2023-09-02 12:02:09.473891: Pseudo dice [0.8288]
2023-09-02 12:02:09.475239: Epoch time: 109.23 s
2023-09-02 12:02:10.722876: 
2023-09-02 12:02:10.724681: Epoch 295
2023-09-02 12:02:10.726023: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-02 12:02:10.727755: start training, 250
================num of epochs: 250================
2023-09-02 12:03:08.899449: finished training
epoch: 295, dataset: CVC-300, dice: 0.8849866666666664
CVC-300 :  0.8849866666666664
epoch: 295, dataset: CVC-ClinicDB, dice: 0.881317741935484
CVC-ClinicDB :  0.881317741935484
epoch: 295, dataset: Kvasir, dice: 0.9008100000000002
Kvasir :  0.9008100000000002
epoch: 295, dataset: CVC-ColonDB, dice: 0.7074194736842109
CVC-ColonDB :  0.7074194736842109
epoch: 295, dataset: ETIS-LaribPolypDB, dice: 0.7378923469387756
ETIS-LaribPolypDB :  0.7378923469387756
2023-09-02 12:04:01.076615: train_loss -1.4726
2023-09-02 12:04:01.078688: val_loss -0.9703
2023-09-02 12:04:01.080429: Pseudo dice [0.849]
2023-09-02 12:04:01.081715: Epoch time: 110.36 s
2023-09-02 12:04:02.329078: 
2023-09-02 12:04:02.330946: Epoch 296
2023-09-02 12:04:02.332255: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-02 12:04:02.334062: start training, 250
================num of epochs: 250================
2023-09-02 12:05:01.164114: finished training
epoch: 296, dataset: CVC-300, dice: 0.8835766666666666
CVC-300 :  0.8835766666666666
epoch: 296, dataset: CVC-ClinicDB, dice: 0.8825096774193549
CVC-ClinicDB :  0.8825096774193549
epoch: 296, dataset: Kvasir, dice: 0.9006959999999998
Kvasir :  0.9006959999999998
epoch: 296, dataset: CVC-ColonDB, dice: 0.709377631578947
CVC-ColonDB :  0.709377631578947
epoch: 296, dataset: ETIS-LaribPolypDB, dice: 0.7367163265306121
ETIS-LaribPolypDB :  0.7367163265306121
2023-09-02 12:05:53.918153: train_loss -1.4732
2023-09-02 12:05:53.920223: val_loss -0.9618
2023-09-02 12:05:53.921953: Pseudo dice [0.8439]
2023-09-02 12:05:53.923279: Epoch time: 111.59 s
2023-09-02 12:05:55.186517: 
2023-09-02 12:05:55.188576: Epoch 297
2023-09-02 12:05:55.189925: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-02 12:05:55.192131: start training, 250
================num of epochs: 250================
2023-09-02 12:06:53.696286: finished training
epoch: 297, dataset: CVC-300, dice: 0.8847400000000003
CVC-300 :  0.8847400000000003
epoch: 297, dataset: CVC-ClinicDB, dice: 0.8839806451612906
CVC-ClinicDB :  0.8839806451612906
epoch: 297, dataset: Kvasir, dice: 0.9002400000000002
Kvasir :  0.9002400000000002
epoch: 297, dataset: CVC-ColonDB, dice: 0.708422105263159
CVC-ColonDB :  0.708422105263159
epoch: 297, dataset: ETIS-LaribPolypDB, dice: 0.7357290816326535
ETIS-LaribPolypDB :  0.7357290816326535
2023-09-02 12:07:45.207575: train_loss -1.4731
2023-09-02 12:07:45.209449: val_loss -0.852
2023-09-02 12:07:45.211176: Pseudo dice [0.8211]
2023-09-02 12:07:45.212480: Epoch time: 110.02 s
2023-09-02 12:07:46.456525: 
2023-09-02 12:07:46.458304: Epoch 298
2023-09-02 12:07:46.459589: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-02 12:07:46.461293: start training, 250
================num of epochs: 250================
2023-09-02 12:08:44.917208: finished training
epoch: 298, dataset: CVC-300, dice: 0.8845816666666668
CVC-300 :  0.8845816666666668
epoch: 298, dataset: CVC-ClinicDB, dice: 0.8847564516129034
CVC-ClinicDB :  0.8847564516129034
epoch: 298, dataset: Kvasir, dice: 0.900618
Kvasir :  0.900618
epoch: 298, dataset: CVC-ColonDB, dice: 0.7066102631578952
CVC-ColonDB :  0.7066102631578952
epoch: 298, dataset: ETIS-LaribPolypDB, dice: 0.7359505102040812
ETIS-LaribPolypDB :  0.7359505102040812
2023-09-02 12:09:35.809452: train_loss -1.4729
2023-09-02 12:09:35.811405: val_loss -0.8259
2023-09-02 12:09:35.813043: Pseudo dice [0.8213]
2023-09-02 12:09:35.814507: Epoch time: 109.35 s
2023-09-02 12:09:37.075409: 
2023-09-02 12:09:37.077182: Epoch 299
2023-09-02 12:09:37.078446: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-02 12:09:37.080146: start training, 250
================num of epochs: 250================
2023-09-02 12:10:35.850551: finished training
epoch: 299, dataset: CVC-300, dice: 0.8800233333333332
CVC-300 :  0.8800233333333332
epoch: 299, dataset: CVC-ClinicDB, dice: 0.8826016129032259
CVC-ClinicDB :  0.8826016129032259
epoch: 299, dataset: Kvasir, dice: 0.8998290000000003
Kvasir :  0.8998290000000003
epoch: 299, dataset: CVC-ColonDB, dice: 0.7056844736842105
CVC-ColonDB :  0.7056844736842105
epoch: 299, dataset: ETIS-LaribPolypDB, dice: 0.732314285714286
ETIS-LaribPolypDB :  0.732314285714286
2023-09-02 12:11:32.699550: train_loss -1.4728
2023-09-02 12:11:32.701557: val_loss -0.8349
2023-09-02 12:11:32.703196: Pseudo dice [0.8231]
2023-09-02 12:11:32.704834: Epoch time: 115.63 s
2023-09-02 12:11:35.739601: Training done.
2023-09-02 12:11:44.996943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset123_Polyp/splits_final.json
2023-09-02 12:11:45.001145: The split file contains 1 splits.
2023-09-02 12:11:45.003077: Desired fold for training: 0
2023-09-02 12:11:45.004792: This split has 1450 training and 798 validation cases.
2023-09-02 12:11:45.022215: predicting CVC-300_149
2023-09-02 12:11:47.095697: predicting CVC-300_150
2023-09-02 12:11:47.192465: predicting CVC-300_151
2023-09-02 12:11:47.291440: predicting CVC-300_152
2023-09-02 12:11:47.363905: predicting CVC-300_153
2023-09-02 12:11:47.437631: predicting CVC-300_154
2023-09-02 12:11:47.518019: predicting CVC-300_155
2023-09-02 12:11:47.596127: predicting CVC-300_156
2023-09-02 12:11:47.677763: predicting CVC-300_157
2023-09-02 12:11:47.761435: predicting CVC-300_158
2023-09-02 12:11:47.836688: predicting CVC-300_159
2023-09-02 12:11:47.914501: predicting CVC-300_160
2023-09-02 12:11:47.993718: predicting CVC-300_161
2023-09-02 12:11:48.072136: predicting CVC-300_162
2023-09-02 12:11:48.150448: predicting CVC-300_163
2023-09-02 12:11:48.231104: predicting CVC-300_164
2023-09-02 12:11:48.313931: predicting CVC-300_165
2023-09-02 12:11:48.397137: predicting CVC-300_166
2023-09-02 12:11:48.473600: predicting CVC-300_167
2023-09-02 12:11:48.552515: predicting CVC-300_168
2023-09-02 12:11:48.631628: predicting CVC-300_169
2023-09-02 12:11:48.710713: predicting CVC-300_170
2023-09-02 12:11:48.791422: predicting CVC-300_171
2023-09-02 12:11:48.872576: predicting CVC-300_172
2023-09-02 12:15:28.345417: predicting CVC-300_173
2023-09-02 12:15:28.685662: predicting CVC-300_174
2023-09-02 12:15:28.777765: predicting CVC-300_175
2023-09-02 12:15:28.848453: predicting CVC-300_176
2023-09-02 12:15:28.921107: predicting CVC-300_177
2023-09-02 12:15:28.996858: predicting CVC-300_178
2023-09-02 12:15:29.096881: predicting CVC-300_179
2023-09-02 12:15:29.171147: predicting CVC-300_180
2023-09-02 12:15:29.242495: predicting CVC-300_181
2023-09-02 12:15:29.313463: predicting CVC-300_182
2023-09-02 12:15:29.387145: predicting CVC-300_183
2023-09-02 12:15:29.462868: predicting CVC-300_184
2023-09-02 12:15:29.539052: predicting CVC-300_185
2023-09-02 12:15:29.613521: predicting CVC-300_186
2023-09-02 12:15:29.689246: predicting CVC-300_187
2023-09-02 12:15:29.774204: predicting CVC-300_188
2023-09-02 12:15:29.848144: predicting CVC-300_189
2023-09-02 12:15:29.919794: predicting CVC-300_190
2023-09-02 12:15:29.991653: predicting CVC-300_191
2023-09-02 12:15:30.064464: predicting CVC-300_192
2023-09-02 12:15:30.138003: predicting CVC-300_193
2023-09-02 12:15:30.212019: predicting CVC-300_194
2023-09-02 12:15:30.282339: predicting CVC-300_195
2023-09-02 12:15:30.354976: predicting CVC-300_196
2023-09-02 12:15:30.425646: predicting CVC-300_197
2023-09-02 12:15:30.499766: predicting CVC-300_198
2023-09-02 12:15:30.576679: predicting CVC-300_199
2023-09-02 12:15:30.654511: predicting CVC-300_200
2023-09-02 12:15:30.728420: predicting CVC-300_201
2023-09-02 12:15:30.801709: predicting CVC-300_202
2023-09-02 12:15:30.874277: predicting CVC-300_203
2023-09-02 12:15:30.947971: predicting CVC-300_204
2023-09-02 12:15:31.022637: predicting CVC-300_205
2023-09-02 12:15:31.094936: predicting CVC-300_206
2023-09-02 12:15:31.172696: predicting CVC-300_207
2023-09-02 12:15:31.262067: predicting CVC-300_208
2023-09-02 12:15:31.337080: predicting CVC-ClinicDB_100
2023-09-02 12:15:31.409975: predicting CVC-ClinicDB_106
2023-09-02 12:15:31.484111: predicting CVC-ClinicDB_119
2023-09-02 12:15:31.558007: predicting CVC-ClinicDB_134
2023-09-02 12:15:31.629080: predicting CVC-ClinicDB_14
2023-09-02 12:15:31.702656: predicting CVC-ClinicDB_148
2023-09-02 12:15:31.776197: predicting CVC-ClinicDB_154
2023-09-02 12:15:31.851172: predicting CVC-ClinicDB_163
2023-09-02 12:15:31.928236: predicting CVC-ClinicDB_166
2023-09-02 12:15:32.002437: predicting CVC-ClinicDB_171
2023-09-02 12:15:32.075015: predicting CVC-ClinicDB_179
2023-09-02 12:15:32.147501: predicting CVC-ClinicDB_181
2023-09-02 12:15:32.220674: predicting CVC-ClinicDB_185
2023-09-02 12:15:32.292993: predicting CVC-ClinicDB_191
2023-09-02 12:15:32.364735: predicting CVC-ClinicDB_205
2023-09-02 12:15:32.436189: predicting CVC-ClinicDB_21
2023-09-02 12:15:32.509130: predicting CVC-ClinicDB_240
2023-09-02 12:15:32.588908: predicting CVC-ClinicDB_25
2023-09-02 12:15:32.659984: predicting CVC-ClinicDB_251
2023-09-02 12:15:32.740126: predicting CVC-ClinicDB_266
2023-09-02 12:15:32.810469: predicting CVC-ClinicDB_279
2023-09-02 12:15:32.879411: predicting CVC-ClinicDB_287
2023-09-02 12:15:32.947590: predicting CVC-ClinicDB_300
2023-09-02 12:15:33.017307: predicting CVC-ClinicDB_307
2023-09-02 12:15:33.085903: predicting CVC-ClinicDB_31
2023-09-02 12:15:33.154909: predicting CVC-ClinicDB_349
2023-09-02 12:15:33.241151: predicting CVC-ClinicDB_353
2023-09-02 12:15:33.311852: predicting CVC-ClinicDB_374
2023-09-02 12:15:33.381615: predicting CVC-ClinicDB_381
2023-09-02 12:15:33.449768: predicting CVC-ClinicDB_388
2023-09-02 12:15:33.520544: predicting CVC-ClinicDB_397
2023-09-02 12:15:33.591218: predicting CVC-ClinicDB_400
2023-09-02 12:15:33.658887: predicting CVC-ClinicDB_404
2023-09-02 12:15:33.732676: predicting CVC-ClinicDB_42
2023-09-02 12:15:33.805428: predicting CVC-ClinicDB_425
2023-09-02 12:15:33.876232: predicting CVC-ClinicDB_429
2023-09-02 12:15:33.958081: predicting CVC-ClinicDB_431
2023-09-02 12:15:34.037299: predicting CVC-ClinicDB_442
2023-09-02 12:15:34.108052: predicting CVC-ClinicDB_453
2023-09-02 12:15:34.178932: predicting CVC-ClinicDB_459
2023-09-02 12:15:34.248816: predicting CVC-ClinicDB_464
2023-09-02 12:15:34.317614: predicting CVC-ClinicDB_474
2023-09-02 12:15:34.391248: predicting CVC-ClinicDB_481
2023-09-02 12:15:34.460592: predicting CVC-ClinicDB_483
2023-09-02 12:15:34.530617: predicting CVC-ClinicDB_492
2023-09-02 12:15:34.599404: predicting CVC-ClinicDB_50
2023-09-02 12:15:34.668361: predicting CVC-ClinicDB_52
2023-09-02 12:15:34.746791: predicting CVC-ClinicDB_526
2023-09-02 12:15:34.815789: predicting CVC-ClinicDB_529
2023-09-02 12:15:34.885586: predicting CVC-ClinicDB_545
2023-09-02 12:15:34.955152: predicting CVC-ClinicDB_555
2023-09-02 12:15:35.025188: predicting CVC-ClinicDB_559
2023-09-02 12:15:35.095492: predicting CVC-ClinicDB_561
2023-09-02 12:15:35.164947: predicting CVC-ClinicDB_569
2023-09-02 12:15:35.234101: predicting CVC-ClinicDB_571
2023-09-02 12:15:35.321845: predicting CVC-ClinicDB_575
2023-09-02 12:15:35.391893: predicting CVC-ClinicDB_61
2023-09-02 12:15:35.461982: predicting CVC-ClinicDB_65
2023-09-02 12:15:35.531717: predicting CVC-ClinicDB_66
2023-09-02 12:15:35.606240: predicting CVC-ClinicDB_73
2023-09-02 12:15:35.677332: predicting CVC-ClinicDB_80
2023-09-02 12:15:35.745930: predicting CVC-ClinicDB_89
2023-09-02 12:15:35.814795: predicting CVC-ColonDB_1
2023-09-02 12:15:35.883657: predicting CVC-ColonDB_10
2023-09-02 12:15:35.953264: predicting CVC-ColonDB_100
2023-09-02 12:15:36.037794: predicting CVC-ColonDB_101
2023-09-02 12:15:36.107667: predicting CVC-ColonDB_102
2023-09-02 12:15:36.179164: predicting CVC-ColonDB_103
2023-09-02 12:15:36.248948: predicting CVC-ColonDB_104
2023-09-02 12:15:36.318070: predicting CVC-ColonDB_105
2023-09-02 12:15:36.387289: predicting CVC-ColonDB_106
2023-09-02 12:15:36.456769: predicting CVC-ColonDB_107
2023-09-02 12:15:36.527209: predicting CVC-ColonDB_108
2023-09-02 12:15:36.597558: predicting CVC-ColonDB_109
2023-09-02 12:15:36.668333: predicting CVC-ColonDB_11
2023-09-02 12:15:36.737902: predicting CVC-ColonDB_110
2023-09-02 12:15:36.808662: predicting CVC-ColonDB_111
2023-09-02 12:15:36.878350: predicting CVC-ColonDB_112
2023-09-02 12:15:36.948015: predicting CVC-ColonDB_113
2023-09-02 12:15:37.018623: predicting CVC-ColonDB_114
2023-09-02 12:15:37.090525: predicting CVC-ColonDB_115
2023-09-02 12:15:37.160865: predicting CVC-ColonDB_116
2023-09-02 12:15:37.231616: predicting CVC-ColonDB_117
2023-09-02 12:15:37.304435: predicting CVC-ColonDB_118
2023-09-02 12:15:37.395699: predicting CVC-ColonDB_119
2023-09-02 12:15:37.478538: predicting CVC-ColonDB_12
2023-09-02 12:15:37.561391: predicting CVC-ColonDB_120
2023-09-02 12:15:37.647686: predicting CVC-ColonDB_121
2023-09-02 12:15:37.717957: predicting CVC-ColonDB_122
2023-09-02 12:15:37.788502: predicting CVC-ColonDB_123
2023-09-02 12:15:37.858995: predicting CVC-ColonDB_124
2023-09-02 12:15:37.938246: predicting CVC-ColonDB_125
2023-09-02 12:15:38.018823: predicting CVC-ColonDB_126
2023-09-02 12:15:38.090176: predicting CVC-ColonDB_127
2023-09-02 12:15:38.159934: predicting CVC-ColonDB_128
2023-09-02 12:15:38.247190: predicting CVC-ColonDB_129
2023-09-02 12:15:38.321072: predicting CVC-ColonDB_13
2023-09-02 12:15:38.395581: predicting CVC-ColonDB_130
2023-09-02 12:15:38.465732: predicting CVC-ColonDB_131
2023-09-02 12:15:38.543245: predicting CVC-ColonDB_132
2023-09-02 12:15:38.629970: predicting CVC-ColonDB_133
2023-09-02 12:15:38.715242: predicting CVC-ColonDB_134
2023-09-02 12:15:38.801663: predicting CVC-ColonDB_135
2023-09-02 12:15:38.888546: predicting CVC-ColonDB_136
2023-09-02 12:15:38.973959: predicting CVC-ColonDB_137
2023-09-02 12:15:39.060263: predicting CVC-ColonDB_138
2023-09-02 12:15:39.147086: predicting CVC-ColonDB_139
2023-09-02 12:15:39.228182: predicting CVC-ColonDB_14
2023-09-02 12:15:39.301280: predicting CVC-ColonDB_140
2023-09-02 12:15:39.386400: predicting CVC-ColonDB_141
2023-09-02 12:15:39.458227: predicting CVC-ColonDB_142
2023-09-02 12:15:39.531667: predicting CVC-ColonDB_143
2023-09-02 12:15:39.603686: predicting CVC-ColonDB_144
2023-09-02 12:15:39.677983: predicting CVC-ColonDB_145
2023-09-02 12:15:39.750814: predicting CVC-ColonDB_146
2023-09-02 12:15:39.823753: predicting CVC-ColonDB_147
2023-09-02 12:15:39.895411: predicting CVC-ColonDB_148
2023-09-02 12:15:39.967762: predicting CVC-ColonDB_149
2023-09-02 12:15:40.048202: predicting CVC-ColonDB_15
2023-09-02 12:15:40.121047: predicting CVC-ColonDB_150
2023-09-02 12:15:40.195266: predicting CVC-ColonDB_151
2023-09-02 12:15:40.268400: predicting CVC-ColonDB_152
2023-09-02 12:15:40.340331: predicting CVC-ColonDB_153
2023-09-02 12:15:40.412741: predicting CVC-ColonDB_154
2023-09-02 12:15:40.484473: predicting CVC-ColonDB_155
2023-09-02 12:15:40.556015: predicting CVC-ColonDB_156
2023-09-02 12:15:40.626864: predicting CVC-ColonDB_157
2023-09-02 12:15:40.700734: predicting CVC-ColonDB_158
2023-09-02 12:15:40.772498: predicting CVC-ColonDB_159
2023-09-02 12:15:40.846478: predicting CVC-ColonDB_16
2023-09-02 12:15:40.924406: predicting CVC-ColonDB_160
2023-09-02 12:15:41.017843: predicting CVC-ColonDB_161
2023-09-02 12:15:41.103002: predicting CVC-ColonDB_162
2023-09-02 12:15:41.181075: predicting CVC-ColonDB_163
2023-09-02 12:15:41.252038: predicting CVC-ColonDB_164
2023-09-02 12:15:41.325640: predicting CVC-ColonDB_165
2023-09-02 12:15:41.416743: predicting CVC-ColonDB_166
2023-09-02 12:15:41.488960: predicting CVC-ColonDB_167
2023-09-02 12:15:41.560115: predicting CVC-ColonDB_168
2023-09-02 12:15:41.638035: predicting CVC-ColonDB_169
2023-09-02 12:15:41.709712: predicting CVC-ColonDB_17
2023-09-02 12:15:41.782263: predicting CVC-ColonDB_170
2023-09-02 12:15:41.853212: predicting CVC-ColonDB_171
2023-09-02 12:15:41.924285: predicting CVC-ColonDB_172
2023-09-02 12:15:41.995313: predicting CVC-ColonDB_173
2023-09-02 12:15:42.078328: predicting CVC-ColonDB_174
2023-09-02 12:15:42.150274: predicting CVC-ColonDB_175
2023-09-02 12:15:42.221924: predicting CVC-ColonDB_176
2023-09-02 12:15:42.292744: predicting CVC-ColonDB_177
2023-09-02 12:15:42.363165: predicting CVC-ColonDB_178
2023-09-02 12:15:42.433600: predicting CVC-ColonDB_179
2023-09-02 12:15:42.513354: predicting CVC-ColonDB_18
2023-09-02 12:15:42.586256: predicting CVC-ColonDB_180
2023-09-02 12:15:42.658417: predicting CVC-ColonDB_181
2023-09-02 12:15:42.730807: predicting CVC-ColonDB_182
2023-09-02 12:15:42.803104: predicting CVC-ColonDB_183
2023-09-02 12:15:42.875183: predicting CVC-ColonDB_184
2023-09-02 12:15:42.945876: predicting CVC-ColonDB_185
2023-09-02 12:15:43.015869: predicting CVC-ColonDB_186
2023-09-02 12:15:43.088034: predicting CVC-ColonDB_187
2023-09-02 12:15:43.159322: predicting CVC-ColonDB_188
2023-09-02 12:15:43.230909: predicting CVC-ColonDB_189
2023-09-02 12:15:43.303483: predicting CVC-ColonDB_19
2023-09-02 12:15:43.398738: predicting CVC-ColonDB_190
2023-09-02 12:15:43.471633: predicting CVC-ColonDB_191
2023-09-02 12:15:43.543010: predicting CVC-ColonDB_192
2023-09-02 12:15:43.614204: predicting CVC-ColonDB_193
2023-09-02 12:15:43.685953: predicting CVC-ColonDB_194
2023-09-02 12:15:43.757198: predicting CVC-ColonDB_195
2023-09-02 12:15:43.828579: predicting CVC-ColonDB_196
2023-09-02 12:15:43.900035: predicting CVC-ColonDB_197
2023-09-02 12:15:43.970423: predicting CVC-ColonDB_198
2023-09-02 12:15:44.041691: predicting CVC-ColonDB_199
2023-09-02 12:15:44.111672: predicting CVC-ColonDB_2
2023-09-02 12:15:44.183655: predicting CVC-ColonDB_20
2023-09-02 12:15:44.255211: predicting CVC-ColonDB_200
2023-09-02 12:15:44.327517: predicting CVC-ColonDB_201
2023-09-02 12:15:44.402916: predicting CVC-ColonDB_202
2023-09-02 12:15:44.474775: predicting CVC-ColonDB_203
2023-09-02 12:15:44.552982: predicting CVC-ColonDB_204
2023-09-02 12:15:44.621955: predicting CVC-ColonDB_205
2023-09-02 12:15:44.695674: predicting CVC-ColonDB_206
2023-09-02 12:15:44.767306: predicting CVC-ColonDB_207
2023-09-02 12:15:44.835973: predicting CVC-ColonDB_208
2023-09-02 12:15:44.903576: predicting CVC-ColonDB_209
2023-09-02 12:15:44.970654: predicting CVC-ColonDB_21
2023-09-02 12:15:45.038171: predicting CVC-ColonDB_210
2023-09-02 12:15:45.109110: predicting CVC-ColonDB_211
2023-09-02 12:15:45.180243: predicting CVC-ColonDB_212
2023-09-02 12:15:45.249405: predicting CVC-ColonDB_213
2023-09-02 12:15:45.317196: predicting CVC-ColonDB_214
2023-09-02 12:15:45.386245: predicting CVC-ColonDB_215
2023-09-02 12:15:45.473025: predicting CVC-ColonDB_216
2023-09-02 12:15:45.540459: predicting CVC-ColonDB_217
2023-09-02 12:15:45.608117: predicting CVC-ColonDB_218
2023-09-02 12:15:45.675480: predicting CVC-ColonDB_219
2023-09-02 12:15:45.743176: predicting CVC-ColonDB_22
2023-09-02 12:15:45.812419: predicting CVC-ColonDB_220
2023-09-02 12:15:45.887614: predicting CVC-ColonDB_221
2023-09-02 12:15:45.953713: predicting CVC-ColonDB_222
2023-09-02 12:15:46.021500: predicting CVC-ColonDB_223
2023-09-02 12:15:46.089259: predicting CVC-ColonDB_224
2023-09-02 12:15:46.170872: predicting CVC-ColonDB_225
2023-09-02 12:15:46.238687: predicting CVC-ColonDB_226
2023-09-02 12:15:46.306023: predicting CVC-ColonDB_227
2023-09-02 12:15:46.373632: predicting CVC-ColonDB_228
2023-09-02 12:15:46.441298: predicting CVC-ColonDB_229
2023-09-02 12:15:46.509183: predicting CVC-ColonDB_23
2023-09-02 12:15:46.576343: predicting CVC-ColonDB_230
2023-09-02 12:15:46.642818: predicting CVC-ColonDB_231
2023-09-02 12:15:46.709785: predicting CVC-ColonDB_232
2023-09-02 12:15:46.776514: predicting CVC-ColonDB_233
2023-09-02 12:15:46.843425: predicting CVC-ColonDB_234
2023-09-02 12:15:46.910928: predicting CVC-ColonDB_235
2023-09-02 12:15:46.979942: predicting CVC-ColonDB_236
2023-09-02 12:15:47.047014: predicting CVC-ColonDB_237
2023-09-02 12:15:47.114261: predicting CVC-ColonDB_238
2023-09-02 12:15:47.182128: predicting CVC-ColonDB_239
2023-09-02 12:15:47.249745: predicting CVC-ColonDB_24
2023-09-02 12:15:47.315931: predicting CVC-ColonDB_240
2023-09-02 12:15:47.384150: predicting CVC-ColonDB_241
2023-09-02 12:15:47.458016: predicting CVC-ColonDB_242
2023-09-02 12:15:47.525761: predicting CVC-ColonDB_243
2023-09-02 12:15:47.593145: predicting CVC-ColonDB_244
2023-09-02 12:15:47.660798: predicting CVC-ColonDB_245
2023-09-02 12:15:47.728161: predicting CVC-ColonDB_246
2023-09-02 12:15:47.795656: predicting CVC-ColonDB_247
2023-09-02 12:15:47.864947: predicting CVC-ColonDB_248
2023-09-02 12:15:47.931842: predicting CVC-ColonDB_249
2023-09-02 12:15:47.999137: predicting CVC-ColonDB_25
2023-09-02 12:15:48.069030: predicting CVC-ColonDB_250
2023-09-02 12:15:48.145971: predicting CVC-ColonDB_251
2023-09-02 12:15:48.223841: predicting CVC-ColonDB_252
2023-09-02 12:15:48.293666: predicting CVC-ColonDB_253
2023-09-02 12:15:48.370667: predicting CVC-ColonDB_254
2023-09-02 12:15:48.438699: predicting CVC-ColonDB_255
2023-09-02 12:15:48.506926: predicting CVC-ColonDB_256
2023-09-02 12:15:48.593073: predicting CVC-ColonDB_257
2023-09-02 12:15:48.670900: predicting CVC-ColonDB_258
2023-09-02 12:15:48.763235: predicting CVC-ColonDB_259
2023-09-02 12:15:48.843817: predicting CVC-ColonDB_26
2023-09-02 12:15:48.915829: predicting CVC-ColonDB_260
2023-09-02 12:15:48.987290: predicting CVC-ColonDB_261
2023-09-02 12:15:49.060347: predicting CVC-ColonDB_262
2023-09-02 12:15:49.133058: predicting CVC-ColonDB_263
2023-09-02 12:15:49.204062: predicting CVC-ColonDB_264
2023-09-02 12:15:49.276417: predicting CVC-ColonDB_265
2023-09-02 12:15:49.349938: predicting CVC-ColonDB_266
2023-09-02 12:15:49.422127: predicting CVC-ColonDB_267
2023-09-02 12:15:49.494604: predicting CVC-ColonDB_268
2023-09-02 12:15:49.566155: predicting CVC-ColonDB_269
2023-09-02 12:15:49.637921: predicting CVC-ColonDB_27
2023-09-02 12:15:49.709996: predicting CVC-ColonDB_270
2023-09-02 12:15:49.784634: predicting CVC-ColonDB_271
2023-09-02 12:15:49.857846: predicting CVC-ColonDB_272
2023-09-02 12:15:49.930528: predicting CVC-ColonDB_273
2023-09-02 12:15:50.002670: predicting CVC-ColonDB_274
2023-09-02 12:15:50.075607: predicting CVC-ColonDB_275
2023-09-02 12:15:50.146982: predicting CVC-ColonDB_276
2023-09-02 12:15:50.225706: predicting CVC-ColonDB_277
2023-09-02 12:15:50.298906: predicting CVC-ColonDB_278
2023-09-02 12:15:50.369168: predicting CVC-ColonDB_279
2023-09-02 12:15:50.440422: predicting CVC-ColonDB_28
2023-09-02 12:15:50.514709: predicting CVC-ColonDB_280
2023-09-02 12:15:50.586875: predicting CVC-ColonDB_281
2023-09-02 12:15:50.670936: predicting CVC-ColonDB_282
2023-09-02 12:15:50.740892: predicting CVC-ColonDB_283
2023-09-02 12:15:50.812802: predicting CVC-ColonDB_284
2023-09-02 12:15:50.884270: predicting CVC-ColonDB_285
2023-09-02 12:15:50.954600: predicting CVC-ColonDB_286
2023-09-02 12:15:51.046386: predicting CVC-ColonDB_287
2023-09-02 12:15:51.123713: predicting CVC-ColonDB_288
2023-09-02 12:15:51.195515: predicting CVC-ColonDB_289
2023-09-02 12:15:51.267639: predicting CVC-ColonDB_29
2023-09-02 12:15:51.339036: predicting CVC-ColonDB_290
2023-09-02 12:15:51.410681: predicting CVC-ColonDB_291
2023-09-02 12:15:51.482793: predicting CVC-ColonDB_292
2023-09-02 12:15:51.568166: predicting CVC-ColonDB_293
2023-09-02 12:15:51.642101: predicting CVC-ColonDB_294
2023-09-02 12:15:51.714044: predicting CVC-ColonDB_295
2023-09-02 12:15:51.786256: predicting CVC-ColonDB_296
2023-09-02 12:15:51.858537: predicting CVC-ColonDB_297
2023-09-02 12:15:51.930345: predicting CVC-ColonDB_298
2023-09-02 12:15:52.002422: predicting CVC-ColonDB_299
2023-09-02 12:15:52.073480: predicting CVC-ColonDB_3
2023-09-02 12:15:52.145121: predicting CVC-ColonDB_30
2023-09-02 12:15:52.234178: predicting CVC-ColonDB_300
2023-09-02 12:15:52.306952: predicting CVC-ColonDB_301
2023-09-02 12:15:52.378901: predicting CVC-ColonDB_302
2023-09-02 12:15:52.451829: predicting CVC-ColonDB_303
2023-09-02 12:15:52.523825: predicting CVC-ColonDB_304
2023-09-02 12:15:52.605021: predicting CVC-ColonDB_305
2023-09-02 12:15:52.683849: predicting CVC-ColonDB_306
2023-09-02 12:15:52.757681: predicting CVC-ColonDB_307
2023-09-02 12:15:52.829888: predicting CVC-ColonDB_308
2023-09-02 12:15:52.903057: predicting CVC-ColonDB_309
2023-09-02 12:15:52.976687: predicting CVC-ColonDB_31
2023-09-02 12:15:53.058148: predicting CVC-ColonDB_310
2023-09-02 12:15:53.128872: predicting CVC-ColonDB_311
2023-09-02 12:15:53.197819: predicting CVC-ColonDB_312
2023-09-02 12:15:53.265461: predicting CVC-ColonDB_313
2023-09-02 12:15:53.334055: predicting CVC-ColonDB_314
2023-09-02 12:15:53.405111: predicting CVC-ColonDB_315
2023-09-02 12:15:53.473090: predicting CVC-ColonDB_316
2023-09-02 12:15:53.540698: predicting CVC-ColonDB_317
2023-09-02 12:15:53.609459: predicting CVC-ColonDB_318
2023-09-02 12:15:53.702938: predicting CVC-ColonDB_319
2023-09-02 12:15:53.771596: predicting CVC-ColonDB_32
2023-09-02 12:15:53.838526: predicting CVC-ColonDB_320
2023-09-02 12:15:53.907083: predicting CVC-ColonDB_321
2023-09-02 12:15:53.975083: predicting CVC-ColonDB_322
2023-09-02 12:15:54.042716: predicting CVC-ColonDB_323
2023-09-02 12:15:54.110837: predicting CVC-ColonDB_324
2023-09-02 12:15:54.178323: predicting CVC-ColonDB_325
2023-09-02 12:15:54.263240: predicting CVC-ColonDB_326
2023-09-02 12:15:54.331015: predicting CVC-ColonDB_327
2023-09-02 12:15:54.398632: predicting CVC-ColonDB_328
2023-09-02 12:15:54.465874: predicting CVC-ColonDB_329
2023-09-02 12:15:54.534740: predicting CVC-ColonDB_33
2023-09-02 12:15:54.601888: predicting CVC-ColonDB_330
2023-09-02 12:15:54.670082: predicting CVC-ColonDB_331
2023-09-02 12:15:54.737820: predicting CVC-ColonDB_332
2023-09-02 12:15:54.808087: predicting CVC-ColonDB_333
2023-09-02 12:15:54.877622: predicting CVC-ColonDB_334
2023-09-02 12:15:54.946790: predicting CVC-ColonDB_335
2023-09-02 12:15:55.022858: predicting CVC-ColonDB_336
2023-09-02 12:15:55.108590: predicting CVC-ColonDB_337
2023-09-02 12:15:55.180793: predicting CVC-ColonDB_338
2023-09-02 12:15:55.254899: predicting CVC-ColonDB_339
2023-09-02 12:15:55.330872: predicting CVC-ColonDB_34
2023-09-02 12:15:55.403118: predicting CVC-ColonDB_340
2023-09-02 12:15:55.474285: predicting CVC-ColonDB_341
2023-09-02 12:15:55.545369: predicting CVC-ColonDB_342
2023-09-02 12:15:55.615656: predicting CVC-ColonDB_343
2023-09-02 12:15:55.685601: predicting CVC-ColonDB_344
2023-09-02 12:15:55.780875: predicting CVC-ColonDB_345
2023-09-02 12:15:55.852058: predicting CVC-ColonDB_346
2023-09-02 12:15:55.923458: predicting CVC-ColonDB_347
2023-09-02 12:15:55.994401: predicting CVC-ColonDB_348
2023-09-02 12:15:56.065629: predicting CVC-ColonDB_349
2023-09-02 12:15:56.136414: predicting CVC-ColonDB_35
2023-09-02 12:15:56.205362: predicting CVC-ColonDB_350
2023-09-02 12:15:56.292810: predicting CVC-ColonDB_351
2023-09-02 12:15:56.371998: predicting CVC-ColonDB_352
2023-09-02 12:15:56.456099: predicting CVC-ColonDB_353
2023-09-02 12:15:56.541795: predicting CVC-ColonDB_354
2023-09-02 12:15:56.627835: predicting CVC-ColonDB_355
2023-09-02 12:15:56.704882: predicting CVC-ColonDB_356
2023-09-02 12:15:56.774715: predicting CVC-ColonDB_357
2023-09-02 12:15:56.844001: predicting CVC-ColonDB_358
2023-09-02 12:15:56.911146: predicting CVC-ColonDB_359
2023-09-02 12:15:56.980831: predicting CVC-ColonDB_36
2023-09-02 12:15:57.050068: predicting CVC-ColonDB_360
2023-09-02 12:15:57.120964: predicting CVC-ColonDB_361
2023-09-02 12:15:57.190366: predicting CVC-ColonDB_362
2023-09-02 12:15:57.263934: predicting CVC-ColonDB_363
2023-09-02 12:15:57.336062: predicting CVC-ColonDB_364
2023-09-02 12:15:57.404794: predicting CVC-ColonDB_365
2023-09-02 12:15:57.474342: predicting CVC-ColonDB_366
2023-09-02 12:15:57.544911: predicting CVC-ColonDB_367
2023-09-02 12:15:57.614863: predicting CVC-ColonDB_368
2023-09-02 12:15:57.685691: predicting CVC-ColonDB_369
2023-09-02 12:15:57.763196: predicting CVC-ColonDB_37
2023-09-02 12:15:57.834419: predicting CVC-ColonDB_370
2023-09-02 12:15:57.905594: predicting CVC-ColonDB_371
2023-09-02 12:15:57.977527: predicting CVC-ColonDB_372
2023-09-02 12:15:58.046735: predicting CVC-ColonDB_373
2023-09-02 12:15:58.125234: predicting CVC-ColonDB_374
2023-09-02 12:15:58.196798: predicting CVC-ColonDB_375
2023-09-02 12:15:58.267304: predicting CVC-ColonDB_376
2023-09-02 12:15:58.371492: predicting CVC-ColonDB_377
2023-09-02 12:15:58.442879: predicting CVC-ColonDB_378
2023-09-02 12:15:58.515719: predicting CVC-ColonDB_379
2023-09-02 12:15:58.587821: predicting CVC-ColonDB_38
2023-09-02 12:15:58.664135: predicting CVC-ColonDB_380
2023-09-02 12:15:58.752528: predicting CVC-ColonDB_39
2023-09-02 12:15:58.823584: predicting CVC-ColonDB_4
2023-09-02 12:15:58.897743: predicting CVC-ColonDB_40
2023-09-02 12:15:58.968699: predicting CVC-ColonDB_41
2023-09-02 12:15:59.039521: predicting CVC-ColonDB_42
2023-09-02 12:15:59.110483: predicting CVC-ColonDB_43
2023-09-02 12:15:59.181372: predicting CVC-ColonDB_44
2023-09-02 12:15:59.251652: predicting CVC-ColonDB_45
2023-09-02 12:15:59.321355: predicting CVC-ColonDB_46
2023-09-02 12:15:59.392620: predicting CVC-ColonDB_47
2023-09-02 12:15:59.468573: predicting CVC-ColonDB_48
2023-09-02 12:15:59.539594: predicting CVC-ColonDB_49
2023-09-02 12:15:59.609637: predicting CVC-ColonDB_5
2023-09-02 12:15:59.680324: predicting CVC-ColonDB_50
2023-09-02 12:15:59.750599: predicting CVC-ColonDB_51
2023-09-02 12:15:59.853250: predicting CVC-ColonDB_52
2023-09-02 12:15:59.935064: predicting CVC-ColonDB_53
2023-09-02 12:16:00.008456: predicting CVC-ColonDB_54
2023-09-02 12:16:00.083084: predicting CVC-ColonDB_55
2023-09-02 12:16:00.154306: predicting CVC-ColonDB_56
2023-09-02 12:16:00.225466: predicting CVC-ColonDB_57
2023-09-02 12:16:00.304811: predicting CVC-ColonDB_58
2023-09-02 12:16:00.400330: predicting CVC-ColonDB_59
2023-09-02 12:16:00.470345: predicting CVC-ColonDB_6
2023-09-02 12:16:00.539161: predicting CVC-ColonDB_60
2023-09-02 12:16:00.607088: predicting CVC-ColonDB_61
2023-09-02 12:16:00.674722: predicting CVC-ColonDB_62
2023-09-02 12:16:00.742789: predicting CVC-ColonDB_63
2023-09-02 12:16:00.811260: predicting CVC-ColonDB_64
2023-09-02 12:16:00.879523: predicting CVC-ColonDB_65
2023-09-02 12:16:00.948013: predicting CVC-ColonDB_66
2023-09-02 12:16:01.016365: predicting CVC-ColonDB_67
2023-09-02 12:16:01.084728: predicting CVC-ColonDB_68
2023-09-02 12:16:01.152809: predicting CVC-ColonDB_69
2023-09-02 12:16:01.220421: predicting CVC-ColonDB_7
2023-09-02 12:16:01.289814: predicting CVC-ColonDB_70
2023-09-02 12:16:01.358422: predicting CVC-ColonDB_71
2023-09-02 12:16:01.429166: predicting CVC-ColonDB_72
2023-09-02 12:16:01.498013: predicting CVC-ColonDB_73
2023-09-02 12:16:01.573947: predicting CVC-ColonDB_74
2023-09-02 12:16:01.646435: predicting CVC-ColonDB_75
2023-09-02 12:16:01.716173: predicting CVC-ColonDB_76
2023-09-02 12:16:01.787580: predicting CVC-ColonDB_77
2023-09-02 12:16:01.889214: predicting CVC-ColonDB_78
2023-09-02 12:16:01.967190: predicting CVC-ColonDB_79
2023-09-02 12:16:02.040128: predicting CVC-ColonDB_8
2023-09-02 12:16:02.109532: predicting CVC-ColonDB_80
2023-09-02 12:16:02.177464: predicting CVC-ColonDB_81
2023-09-02 12:16:02.252886: predicting CVC-ColonDB_82
2023-09-02 12:16:02.331580: predicting CVC-ColonDB_83
2023-09-02 12:16:02.402771: predicting CVC-ColonDB_84
2023-09-02 12:16:02.493245: predicting CVC-ColonDB_85
2023-09-02 12:16:02.571508: predicting CVC-ColonDB_86
2023-09-02 12:16:02.640542: predicting CVC-ColonDB_87
2023-09-02 12:16:02.711657: predicting CVC-ColonDB_88
2023-09-02 12:16:02.779775: predicting CVC-ColonDB_89
2023-09-02 12:16:02.848803: predicting CVC-ColonDB_9
2023-09-02 12:16:02.916038: predicting CVC-ColonDB_90
2023-09-02 12:16:02.983792: predicting CVC-ColonDB_91
2023-09-02 12:16:03.051469: predicting CVC-ColonDB_92
2023-09-02 12:16:03.119008: predicting CVC-ColonDB_93
2023-09-02 12:16:03.185876: predicting CVC-ColonDB_94
2023-09-02 12:16:03.254949: predicting CVC-ColonDB_95
2023-09-02 12:16:03.323564: predicting CVC-ColonDB_96
2023-09-02 12:16:03.393703: predicting CVC-ColonDB_97
2023-09-02 12:16:03.461317: predicting CVC-ColonDB_98
2023-09-02 12:16:03.537080: predicting CVC-ColonDB_99
2023-09-02 12:16:03.615327: predicting ETIS-LaribPolypDB_1
2023-09-02 12:16:03.688205: predicting ETIS-LaribPolypDB_10
2023-09-02 12:16:03.755665: predicting ETIS-LaribPolypDB_100
2023-09-02 12:16:03.860100: predicting ETIS-LaribPolypDB_101
2023-09-02 12:16:03.930820: predicting ETIS-LaribPolypDB_102
2023-09-02 12:16:04.000699: predicting ETIS-LaribPolypDB_103
2023-09-02 12:16:04.072924: predicting ETIS-LaribPolypDB_104
2023-09-02 12:16:04.144617: predicting ETIS-LaribPolypDB_105
2023-09-02 12:16:04.215212: predicting ETIS-LaribPolypDB_106
2023-09-02 12:16:04.285280: predicting ETIS-LaribPolypDB_107
2023-09-02 12:16:04.355953: predicting ETIS-LaribPolypDB_108
2023-09-02 12:16:04.425069: predicting ETIS-LaribPolypDB_109
2023-09-02 12:16:04.496705: predicting ETIS-LaribPolypDB_11
2023-09-02 12:16:04.584411: predicting ETIS-LaribPolypDB_110
2023-09-02 12:16:04.655049: predicting ETIS-LaribPolypDB_111
2023-09-02 12:16:04.725953: predicting ETIS-LaribPolypDB_112
2023-09-02 12:16:04.795974: predicting ETIS-LaribPolypDB_113
2023-09-02 12:16:04.866849: predicting ETIS-LaribPolypDB_114
2023-09-02 12:16:04.937672: predicting ETIS-LaribPolypDB_115
2023-09-02 12:16:05.008625: predicting ETIS-LaribPolypDB_116
2023-09-02 12:16:05.081187: predicting ETIS-LaribPolypDB_117
2023-09-02 12:16:05.155708: predicting ETIS-LaribPolypDB_118
2023-09-02 12:16:05.229414: predicting ETIS-LaribPolypDB_119
2023-09-02 12:16:05.297708: predicting ETIS-LaribPolypDB_12
2023-09-02 12:16:05.387643: predicting ETIS-LaribPolypDB_120
2023-09-02 12:16:05.466479: predicting ETIS-LaribPolypDB_121
2023-09-02 12:16:05.538043: predicting ETIS-LaribPolypDB_122
2023-09-02 12:16:05.608708: predicting ETIS-LaribPolypDB_123
2023-09-02 12:16:05.679918: predicting ETIS-LaribPolypDB_124
2023-09-02 12:16:05.767453: predicting ETIS-LaribPolypDB_125
2023-09-02 12:16:05.852013: predicting ETIS-LaribPolypDB_126
2023-09-02 12:16:05.949545: predicting ETIS-LaribPolypDB_127
2023-09-02 12:16:06.033953: predicting ETIS-LaribPolypDB_128
2023-09-02 12:16:06.117661: predicting ETIS-LaribPolypDB_129
2023-09-02 12:16:06.201833: predicting ETIS-LaribPolypDB_13
2023-09-02 12:16:06.286850: predicting ETIS-LaribPolypDB_130
2023-09-02 12:16:06.371331: predicting ETIS-LaribPolypDB_131
2023-09-02 12:16:06.459378: predicting ETIS-LaribPolypDB_132
2023-09-02 12:16:06.548259: predicting ETIS-LaribPolypDB_133
2023-09-02 12:16:06.639215: predicting ETIS-LaribPolypDB_134
2023-09-02 12:16:06.729273: predicting ETIS-LaribPolypDB_135
2023-09-02 12:16:06.814249: predicting ETIS-LaribPolypDB_136
2023-09-02 12:16:06.898011: predicting ETIS-LaribPolypDB_137
2023-09-02 12:16:06.983506: predicting ETIS-LaribPolypDB_138
2023-09-02 12:16:07.059427: predicting ETIS-LaribPolypDB_139
2023-09-02 12:16:07.129231: predicting ETIS-LaribPolypDB_14
2023-09-02 12:16:07.200787: predicting ETIS-LaribPolypDB_140
2023-09-02 12:16:07.271615: predicting ETIS-LaribPolypDB_141
2023-09-02 12:16:07.342368: predicting ETIS-LaribPolypDB_142
2023-09-02 12:16:07.413022: predicting ETIS-LaribPolypDB_143
2023-09-02 12:16:07.483062: predicting ETIS-LaribPolypDB_144
2023-09-02 12:16:07.553576: predicting ETIS-LaribPolypDB_145
2023-09-02 12:16:07.623722: predicting ETIS-LaribPolypDB_146
2023-09-02 12:16:07.692799: predicting ETIS-LaribPolypDB_147
2023-09-02 12:16:07.764683: predicting ETIS-LaribPolypDB_148
2023-09-02 12:16:07.836601: predicting ETIS-LaribPolypDB_149
2023-09-02 12:16:07.919715: predicting ETIS-LaribPolypDB_15
2023-09-02 12:16:07.990797: predicting ETIS-LaribPolypDB_150
2023-09-02 12:16:08.061149: predicting ETIS-LaribPolypDB_151
2023-09-02 12:16:08.130882: predicting ETIS-LaribPolypDB_152
2023-09-02 12:16:08.202322: predicting ETIS-LaribPolypDB_153
2023-09-02 12:16:08.272527: predicting ETIS-LaribPolypDB_154
2023-09-02 12:16:08.348556: predicting ETIS-LaribPolypDB_155
2023-09-02 12:16:08.419494: predicting ETIS-LaribPolypDB_156
2023-09-02 12:16:08.490530: predicting ETIS-LaribPolypDB_157
2023-09-02 12:16:08.565720: predicting ETIS-LaribPolypDB_158
2023-09-02 12:16:08.646984: predicting ETIS-LaribPolypDB_159
2023-09-02 12:16:08.716911: predicting ETIS-LaribPolypDB_16
2023-09-02 12:16:08.786522: predicting ETIS-LaribPolypDB_160
2023-09-02 12:16:08.861096: predicting ETIS-LaribPolypDB_161
2023-09-02 12:16:08.940915: predicting ETIS-LaribPolypDB_162
2023-09-02 12:16:09.024827: predicting ETIS-LaribPolypDB_163
2023-09-02 12:16:09.110803: predicting ETIS-LaribPolypDB_164
2023-09-02 12:16:09.189677: predicting ETIS-LaribPolypDB_165
2023-09-02 12:16:09.260719: predicting ETIS-LaribPolypDB_166
2023-09-02 12:16:09.332052: predicting ETIS-LaribPolypDB_167
2023-09-02 12:16:09.403868: predicting ETIS-LaribPolypDB_168
2023-09-02 12:16:09.475604: predicting ETIS-LaribPolypDB_169
2023-09-02 12:16:09.547060: predicting ETIS-LaribPolypDB_17
2023-09-02 12:16:09.618540: predicting ETIS-LaribPolypDB_170
2023-09-02 12:16:09.690718: predicting ETIS-LaribPolypDB_171
2023-09-02 12:16:09.762081: predicting ETIS-LaribPolypDB_172
2023-09-02 12:16:09.837420: predicting ETIS-LaribPolypDB_173
2023-09-02 12:16:09.909095: predicting ETIS-LaribPolypDB_174
2023-09-02 12:16:10.002689: predicting ETIS-LaribPolypDB_175
2023-09-02 12:16:10.075742: predicting ETIS-LaribPolypDB_176
2023-09-02 12:16:10.149017: predicting ETIS-LaribPolypDB_177
2023-09-02 12:16:10.234389: predicting ETIS-LaribPolypDB_178
2023-09-02 12:16:10.315546: predicting ETIS-LaribPolypDB_179
2023-09-02 12:16:10.394097: predicting ETIS-LaribPolypDB_18
2023-09-02 12:16:10.464969: predicting ETIS-LaribPolypDB_180
2023-09-02 12:16:10.534150: predicting ETIS-LaribPolypDB_181
2023-09-02 12:16:10.620406: predicting ETIS-LaribPolypDB_182
2023-09-02 12:16:10.706733: predicting ETIS-LaribPolypDB_183
2023-09-02 12:16:10.777412: predicting ETIS-LaribPolypDB_184
2023-09-02 12:16:10.849219: predicting ETIS-LaribPolypDB_185
2023-09-02 12:16:10.920287: predicting ETIS-LaribPolypDB_186
2023-09-02 12:16:10.991893: predicting ETIS-LaribPolypDB_187
2023-09-02 12:16:11.063521: predicting ETIS-LaribPolypDB_188
2023-09-02 12:16:11.135456: predicting ETIS-LaribPolypDB_189
2023-09-02 12:16:11.206360: predicting ETIS-LaribPolypDB_19
2023-09-02 12:16:11.278100: predicting ETIS-LaribPolypDB_190
2023-09-02 12:16:11.349225: predicting ETIS-LaribPolypDB_191
2023-09-02 12:16:11.428708: predicting ETIS-LaribPolypDB_192
2023-09-02 12:16:11.496804: predicting ETIS-LaribPolypDB_193
2023-09-02 12:16:11.565346: predicting ETIS-LaribPolypDB_194
2023-09-02 12:16:11.633893: predicting ETIS-LaribPolypDB_195
2023-09-02 12:16:11.703402: predicting ETIS-LaribPolypDB_196
2023-09-02 12:16:11.771113: predicting ETIS-LaribPolypDB_2
2023-09-02 12:16:11.838258: predicting ETIS-LaribPolypDB_20
2023-09-02 12:16:11.906935: predicting ETIS-LaribPolypDB_21
2023-09-02 12:16:11.981496: predicting ETIS-LaribPolypDB_22
2023-09-02 12:16:12.049735: predicting ETIS-LaribPolypDB_23
2023-09-02 12:16:12.117369: predicting ETIS-LaribPolypDB_24
2023-09-02 12:16:12.184870: predicting ETIS-LaribPolypDB_25
2023-09-02 12:16:12.258336: predicting ETIS-LaribPolypDB_26
2023-09-02 12:16:12.326411: predicting ETIS-LaribPolypDB_27
2023-09-02 12:16:12.394249: predicting ETIS-LaribPolypDB_28
2023-09-02 12:16:12.461264: predicting ETIS-LaribPolypDB_29
2023-09-02 12:16:12.528756: predicting ETIS-LaribPolypDB_3
2023-09-02 12:16:12.604632: predicting ETIS-LaribPolypDB_30
2023-09-02 12:16:12.672772: predicting ETIS-LaribPolypDB_31
2023-09-02 12:16:12.757679: predicting ETIS-LaribPolypDB_32
2023-09-02 12:16:12.825806: predicting ETIS-LaribPolypDB_33
2023-09-02 12:16:12.896347: predicting ETIS-LaribPolypDB_34
2023-09-02 12:16:12.964672: predicting ETIS-LaribPolypDB_35
2023-09-02 12:16:13.037413: predicting ETIS-LaribPolypDB_36
2023-09-02 12:16:13.105989: predicting ETIS-LaribPolypDB_37
2023-09-02 12:16:13.184843: predicting ETIS-LaribPolypDB_38
2023-09-02 12:16:13.262354: predicting ETIS-LaribPolypDB_39
2023-09-02 12:16:13.332972: predicting ETIS-LaribPolypDB_4
2023-09-02 12:16:13.402952: predicting ETIS-LaribPolypDB_40
2023-09-02 12:16:13.475152: predicting ETIS-LaribPolypDB_41
2023-09-02 12:16:13.546659: predicting ETIS-LaribPolypDB_42
2023-09-02 12:16:13.616917: predicting ETIS-LaribPolypDB_43
2023-09-02 12:16:13.688017: predicting ETIS-LaribPolypDB_44
2023-09-02 12:16:13.780381: predicting ETIS-LaribPolypDB_45
2023-09-02 12:16:13.865433: predicting ETIS-LaribPolypDB_46
2023-09-02 12:16:13.953497: predicting ETIS-LaribPolypDB_47
2023-09-02 12:16:14.057711: predicting ETIS-LaribPolypDB_48
2023-09-02 12:16:14.128444: predicting ETIS-LaribPolypDB_49
2023-09-02 12:16:14.200006: predicting ETIS-LaribPolypDB_5
2023-09-02 12:16:14.270779: predicting ETIS-LaribPolypDB_50
2023-09-02 12:16:14.352148: predicting ETIS-LaribPolypDB_51
2023-09-02 12:16:14.437243: predicting ETIS-LaribPolypDB_52
2023-09-02 12:16:14.521011: predicting ETIS-LaribPolypDB_53
2023-09-02 12:16:14.606570: predicting ETIS-LaribPolypDB_54
2023-09-02 12:16:14.691105: predicting ETIS-LaribPolypDB_55
2023-09-02 12:16:14.795903: predicting ETIS-LaribPolypDB_56
2023-09-02 12:16:14.881503: predicting ETIS-LaribPolypDB_57
2023-09-02 12:16:14.966162: predicting ETIS-LaribPolypDB_58
2023-09-02 12:16:15.045546: predicting ETIS-LaribPolypDB_59
2023-09-02 12:16:15.126072: predicting ETIS-LaribPolypDB_6
2023-09-02 12:16:15.197922: predicting ETIS-LaribPolypDB_60
2023-09-02 12:16:15.270439: predicting ETIS-LaribPolypDB_61
2023-09-02 12:16:15.341594: predicting ETIS-LaribPolypDB_62
2023-09-02 12:16:15.414901: predicting ETIS-LaribPolypDB_63
2023-09-02 12:16:15.491671: predicting ETIS-LaribPolypDB_64
2023-09-02 12:16:15.565534: predicting ETIS-LaribPolypDB_65
2023-09-02 12:16:15.639062: predicting ETIS-LaribPolypDB_66
2023-09-02 12:16:15.712396: predicting ETIS-LaribPolypDB_67
2023-09-02 12:16:15.783738: predicting ETIS-LaribPolypDB_68
2023-09-02 12:16:15.855830: predicting ETIS-LaribPolypDB_69
2023-09-02 12:16:15.927841: predicting ETIS-LaribPolypDB_7
2023-09-02 12:16:16.000712: predicting ETIS-LaribPolypDB_70
2023-09-02 12:16:16.097656: predicting ETIS-LaribPolypDB_71
2023-09-02 12:16:16.169867: predicting ETIS-LaribPolypDB_72
2023-09-02 12:16:16.240607: predicting ETIS-LaribPolypDB_73
2023-09-02 12:16:16.312057: predicting ETIS-LaribPolypDB_74
2023-09-02 12:16:16.383183: predicting ETIS-LaribPolypDB_75
2023-09-02 12:16:16.455543: predicting ETIS-LaribPolypDB_76
2023-09-02 12:16:16.526337: predicting ETIS-LaribPolypDB_77
2023-09-02 12:16:16.599447: predicting ETIS-LaribPolypDB_78
2023-09-02 12:16:16.671724: predicting ETIS-LaribPolypDB_79
2023-09-02 12:16:16.772271: predicting ETIS-LaribPolypDB_8
2023-09-02 12:16:16.844037: predicting ETIS-LaribPolypDB_80
2023-09-02 12:16:16.917751: predicting ETIS-LaribPolypDB_81
2023-09-02 12:16:16.989852: predicting ETIS-LaribPolypDB_82
2023-09-02 12:16:17.061181: predicting ETIS-LaribPolypDB_83
2023-09-02 12:16:17.132631: predicting ETIS-LaribPolypDB_84
2023-09-02 12:16:17.205194: predicting ETIS-LaribPolypDB_85
2023-09-02 12:16:17.277824: predicting ETIS-LaribPolypDB_86
2023-09-02 12:16:17.350208: predicting ETIS-LaribPolypDB_87
2023-09-02 12:16:17.421121: predicting ETIS-LaribPolypDB_88
2023-09-02 12:16:17.493972: predicting ETIS-LaribPolypDB_89
2023-09-02 12:16:17.565574: predicting ETIS-LaribPolypDB_9
2023-09-02 12:16:17.637392: predicting ETIS-LaribPolypDB_90
2023-09-02 12:16:17.708874: predicting ETIS-LaribPolypDB_91
2023-09-02 12:16:17.778792: predicting ETIS-LaribPolypDB_92
2023-09-02 12:16:17.849934: predicting ETIS-LaribPolypDB_93
2023-09-02 12:16:17.919147: predicting ETIS-LaribPolypDB_94
2023-09-02 12:16:17.990656: predicting ETIS-LaribPolypDB_95
2023-09-02 12:16:18.083721: predicting ETIS-LaribPolypDB_96
2023-09-02 12:16:18.154083: predicting ETIS-LaribPolypDB_97
2023-09-02 12:16:18.226404: predicting ETIS-LaribPolypDB_98
2023-09-02 12:16:18.297037: predicting ETIS-LaribPolypDB_99
2023-09-02 12:16:18.367387: predicting Kvasir_cju0u82z3cuma0835wlxrnrjv
2023-09-02 12:16:18.437839: predicting Kvasir_cju15wdt3zla10801odjiw7sy
2023-09-02 12:16:18.513198: predicting Kvasir_cju16ach3m1da0993r1dq3sn2
2023-09-02 12:16:18.582933: predicting Kvasir_cju16whaj0e7n0855q7b6cjkm
2023-09-02 12:16:18.674390: predicting Kvasir_cju17z0qongpa0993de4boim4
2023-09-02 12:16:18.756171: predicting Kvasir_cju1amqw6p8pw0993d9gc5crl
2023-09-02 12:16:18.862167: predicting Kvasir_cju1bm8063nmh07996rsjjemq
2023-09-02 12:16:18.946872: predicting Kvasir_cju1c3218411b08014g9f6gig
2023-09-02 12:16:19.030982: predicting Kvasir_cju1cbokpuiw70988j4lq1fpi
2023-09-02 12:16:19.126403: predicting Kvasir_cju1cj3f0qi5n0993ut8f49rj
2023-09-02 12:16:19.214214: predicting Kvasir_cju1cqc7n4gpy0855jt246k68
2023-09-02 12:16:19.295904: predicting Kvasir_cju1ddr6p4k5z08780uuuzit2
2023-09-02 12:16:19.391095: predicting Kvasir_cju1f8w0t65en0799m9oacq0q
2023-09-02 12:16:19.474227: predicting Kvasir_cju1h89h6xbnx08352k2790o9
2023-09-02 12:16:19.558934: predicting Kvasir_cju1hp9i2xu8e0988u2dazk7m
2023-09-02 12:16:19.643553: predicting Kvasir_cju2hfqnmhisa0993gpleeldd
2023-09-02 12:16:19.713152: predicting Kvasir_cju2hjrqcvi2j0801bx1i6gxg
2023-09-02 12:16:19.784690: predicting Kvasir_cju2hos57llxm08359g92p6jj
2023-09-02 12:16:19.856971: predicting Kvasir_cju2hqt33lmra0988fr5ijv8j
2023-09-02 12:16:19.944020: predicting Kvasir_cju2lberzkdzm09938cl40pog
2023-09-02 12:16:20.021904: predicting Kvasir_cju2mh8t6p07008350e01tx2a
2023-09-02 12:16:20.114202: predicting Kvasir_cju2nnqrqzp580855z8mhzgd6
2023-09-02 12:16:20.186617: predicting Kvasir_cju2np2k9zi3v079992ypxqkn
2023-09-02 12:16:20.261744: predicting Kvasir_cju2omjpeqj5a0988pjdlb8l1
2023-09-02 12:16:20.335722: predicting Kvasir_cju2osuru0ki00855txo0n3uu
2023-09-02 12:16:20.411748: predicting Kvasir_cju2pag1f0s4r0878h52uq83s
2023-09-02 12:16:20.486492: predicting Kvasir_cju2rga4psq9n09881z519xx0
2023-09-02 12:16:20.567720: predicting Kvasir_cju2rmd2rsw9g09888hh1efu0
2023-09-02 12:16:20.643008: predicting Kvasir_cju2rqo702wpx0855fn7d5cxh
2023-09-02 12:16:20.723775: predicting Kvasir_cju2top2ruxxy0988p1svx36g
2023-09-02 12:16:20.801568: predicting Kvasir_cju2wve9v7esz0878mxsdcy04
2023-09-02 12:16:20.886389: predicting Kvasir_cju2y40d8ulqo0993q0adtgtb
2023-09-02 12:16:20.964931: predicting Kvasir_cju2yi9tz8vky0801yqip0xyl
2023-09-02 12:16:21.049549: predicting Kvasir_cju2yo1j1v0qz09934o0e683p
2023-09-02 12:16:21.129837: predicting Kvasir_cju2yv4imv6cz099314jveiib
2023-09-02 12:16:21.208290: predicting Kvasir_cju2zp89k9q1g0855k1x0f1xa
2023-09-02 12:16:21.288782: predicting Kvasir_cju2zwg05a0oy0801yr73ig7g
2023-09-02 12:16:21.368387: predicting Kvasir_cju30ajhw09sx0988qyahx9s8
2023-09-02 12:16:21.450468: predicting Kvasir_cju30gxjq0djk0988jytm49rs
2023-09-02 12:16:21.533852: predicting Kvasir_cju30j1rgadut0801vuyrsnt8
2023-09-02 12:16:21.605366: predicting Kvasir_cju31w6goazci0799n014ly1q
2023-09-02 12:16:21.675759: predicting Kvasir_cju32srle1xfq083575i3fl75
2023-09-02 12:16:21.748321: predicting Kvasir_cju34m7h536wq0988xz7gx79v
2023-09-02 12:16:21.819234: predicting Kvasir_cju34xspwzenf0993cyzajv9n
2023-09-02 12:16:21.909462: predicting Kvasir_cju3tp94kfstl08181awh6z49
2023-09-02 12:16:21.985858: predicting Kvasir_cju3uhb79gcgr0871orbrbi3x
2023-09-02 12:16:22.065069: predicting Kvasir_cju3v11mrgwwb0755u242ygye
2023-09-02 12:16:22.154996: predicting Kvasir_cju3x5u2tiihx0818914gzxy1
2023-09-02 12:16:22.231504: predicting Kvasir_cju3xga12iixg0817dijbvjxw
2023-09-02 12:16:22.309977: predicting Kvasir_cju3ya7goj6at0818v2l5ay7f
2023-09-02 12:16:22.389955: predicting Kvasir_cju3ykamdj9u208503pygyuc8
2023-09-02 12:16:22.468108: predicting Kvasir_cju40m0rjkpw80871z6n6yg1u
2023-09-02 12:16:22.546894: predicting Kvasir_cju42qet0lsq90871e50xbnuv
2023-09-02 12:16:22.627087: predicting Kvasir_cju42wamblrqn098798r2yyok
2023-09-02 12:16:22.705377: predicting Kvasir_cju43jcqim2cp08172dvjvyui
2023-09-02 12:16:22.787348: predicting Kvasir_cju45rj7ln8980850a7821fov
2023-09-02 12:16:22.876060: predicting Kvasir_cju45ty6zn9oz0850qy4qnck1
2023-09-02 12:16:22.956741: predicting Kvasir_cju45v0pungu40871acnwtmu5
2023-09-02 12:16:23.042231: predicting Kvasir_cju5cky5xb0ay0801oxet697t
2023-09-02 12:16:23.124704: predicting Kvasir_cju5clr68b48r0755cmuvponm
2023-09-02 12:16:23.208646: predicting Kvasir_cju5hi52odyf90817prvcwg45
2023-09-02 12:16:23.292533: predicting Kvasir_cju5hyi9yegob0755ho3do8en
2023-09-02 12:16:23.377144: predicting Kvasir_cju5k3j3uf6de0817hszzfr7n
2023-09-02 12:16:23.471803: predicting Kvasir_cju5o4pk9h0720755lgp9jq8m
2023-09-02 12:16:23.562191: predicting Kvasir_cju5wrrs0m2af0818vmnajbtw
2023-09-02 12:16:23.640361: predicting Kvasir_cju5x00l6m5j608503k78ptee
2023-09-02 12:16:23.718289: predicting Kvasir_cju5xjn5mm78b09871spyqhhr
2023-09-02 12:16:23.790170: predicting Kvasir_cju5xkwzxmf0z0818gk4xabdm
2023-09-02 12:16:23.859156: predicting Kvasir_cju5xq3tdm9fn0987pbedxdg5
2023-09-02 12:16:23.929229: predicting Kvasir_cju5y4hgqmk0i08180rjhbwvp
2023-09-02 12:16:23.997302: predicting Kvasir_cju5yeqiwmkgl0801fzv2douc
2023-09-02 12:16:24.064414: predicting Kvasir_cju6us80mv1b50871ebyq2wxa
2023-09-02 12:16:24.131821: predicting Kvasir_cju6uy20suzbl0987rzuhz7z9
2023-09-02 12:16:24.199836: predicting Kvasir_cju6v1m1xv07w09870ah3njy1
2023-09-02 12:16:24.277256: predicting Kvasir_cju6vifjlv55z0987un6y4zdo
2023-09-02 12:16:24.357570: predicting Kvasir_cju6vrs1ov8cr098788h8gs6j
2023-09-02 12:16:24.426097: predicting Kvasir_cju6x0yqbvxqt0755dhxislgb
2023-09-02 12:16:24.493345: predicting Kvasir_cju7ajnbo1gvm098749rdouk0
2023-09-02 12:16:24.561821: predicting Kvasir_cju7awzmu1ncs0871hziy65zx
2023-09-02 12:16:24.629094: predicting Kvasir_cju7bd1qu1mx409877xjxibox
2023-09-02 12:16:24.697422: predicting Kvasir_cju7bgnvb1sf808717qa799ir
2023-09-02 12:16:24.764937: predicting Kvasir_cju7crgxa28550755wbsgqkel
2023-09-02 12:16:24.833009: predicting Kvasir_cju7da88w2eod0755wejzynvt
2023-09-02 12:16:24.903840: predicting Kvasir_cju7ddtz729960801uazp1knc
2023-09-02 12:16:24.971076: predicting Kvasir_cju7do8c72dbo0801vxfzxdc4
2023-09-02 12:16:25.037142: predicting Kvasir_cju7dymur2od30755eg8yv2ht
2023-09-02 12:16:25.104660: predicting Kvasir_cju7ecl9i2i060987xawjp4l0
2023-09-02 12:16:25.172424: predicting Kvasir_cju7fbndk2sl608015ravktum
2023-09-02 12:16:25.240219: predicting Kvasir_cju7fcgbe2z3p07550vaflqdb
2023-09-02 12:16:25.308017: predicting Kvasir_cju7fpfzq2wyf0818xxd1oziv
2023-09-02 12:16:25.375770: predicting Kvasir_cju84hibuktj80871u519o71q
2023-09-02 12:16:25.443164: predicting Kvasir_cju88cddensj00987788yotmg
2023-09-02 12:16:25.510857: predicting Kvasir_cju88t4fvokxf07558ymyh281
2023-09-02 12:16:25.579277: predicting Kvasir_cju88vx2uoocy075531lc63n3
2023-09-02 12:16:25.646839: predicting Kvasir_cju8alhigqn2h0801zksudldd
2023-09-02 12:16:25.714247: predicting Kvasir_cju8aqq8uqmoq0987hphto9gg
2023-09-02 12:16:25.781545: predicting Kvasir_cju8bk8oirjhw0817hgkua2w8
2023-09-02 12:16:25.849816: predicting Kvasir_cju8c2rqzs5t80850d0zky5dy
2023-09-02 12:16:25.919719: predicting Kvasir_cju8d4jgatgpj0871q2ophhkm
2023-09-02 12:16:25.988018: predicting Kvasir_cju8dqkrqu83i0818ev74qpxq
2023-09-02 12:17:05.958458: Validation complete
2023-09-02 12:17:05.960096: Mean Validation Dice:  0.8043197882502466
