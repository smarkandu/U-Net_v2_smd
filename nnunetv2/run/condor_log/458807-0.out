OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-02 02:40:15.865816: I am training on qa-rtx6k-006.crc.nd.edu
2023-09-02 02:40:15.866581: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset123_Polyp/PolypTrainer__nnUNetPlans__2d/458807_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

model: Res2Network(
  (backbone): Res2Net(
    (conv1): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(64, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(256, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottle2neck(
        (conv1): Conv2d(512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(512, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottle2neck(
        (conv1): Conv2d(1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottle2neck(
        (conv1): Conv2d(1024, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)
          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottle2neck(
        (conv1): Conv2d(2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottle2neck(
        (conv1): Conv2d(2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (convs): ModuleList(
          (0-2): 3 x Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        )
        (bns): ModuleList(
          (0-2): 3 x BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (ca_1): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_1): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_2): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_2): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_3): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_3): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_4): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_4): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(2048, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv5): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
)
===========<class 'nnunetv2.training.network.model.dim2.res2net.res2unetv2.Res2Network'>============
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 22, 'patch_size': [352, 352], 'median_image_size_in_voxels': [352.0, 352.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'Res2UNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset123_Polyp', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 352, 352], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 194.9335479736328, 'median': 205.0, 'min': 0.0, 'percentile_00_5': 59.0, 'percentile_99_5': 255.0, 'std': 45.12168884277344}, '1': {'max': 255.0, 'mean': 118.9454574584961, 'median': 114.0, 'min': 0.0, 'percentile_00_5': 24.0, 'percentile_99_5': 250.0, 'std': 45.21835708618164}, '2': {'max': 255.0, 'mean': 85.0717544555664, 'median': 79.0, 'min': 0.0, 'percentile_00_5': 10.0, 'percentile_99_5': 238.0, 'std': 40.7197151184082}}} 

2023-09-02 02:40:19.097403: unpacking dataset...
2023-09-02 02:40:44.388580: unpacking done...
2023-09-02 02:40:44.390136: do_dummy_2d_data_aug: False
2023-09-02 02:40:44.407671: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset123_Polyp/splits_final.json
2023-09-02 02:40:44.408725: The split file contains 1 splits.
2023-09-02 02:40:44.409138: Desired fold for training: 0
2023-09-02 02:40:44.409507: This split has 1450 training and 798 validation cases.
==================batch size: 22==================
2023-09-02 02:40:44.438255: Unable to plot network architecture:
2023-09-02 02:40:44.438645: No module named 'hiddenlayer'
===================debug: False===================
2023-09-02 02:40:46.364776: 
2023-09-02 02:40:46.365599: Epoch 0
2023-09-02 02:40:46.366328: Current learning rate: backbone 0.001, others 0.001
2023-09-02 02:40:46.366865: start training, 250
================num of epochs: 250================
using pin_memory on device 0
2023-09-02 02:41:53.839422: finished training
epoch: 0, dataset: CVC-300, dice: 0.6268050000000003
CVC-300 :  0.6268050000000003
epoch: 0, dataset: CVC-ClinicDB, dice: 0.6408919354838709
CVC-ClinicDB :  0.6408919354838709
epoch: 0, dataset: Kvasir, dice: 0.7149240000000002
Kvasir :  0.7149240000000002
epoch: 0, dataset: CVC-ColonDB, dice: 0.4055963157894737
CVC-ColonDB :  0.4055963157894737
epoch: 0, dataset: ETIS-LaribPolypDB, dice: 0.3049867346938779
ETIS-LaribPolypDB :  0.3049867346938779
using pin_memory on device 0
2023-09-02 02:42:52.097153: train_loss -0.0069
2023-09-02 02:42:52.098397: val_loss -0.5302
2023-09-02 02:42:52.100008: Pseudo dice [0.6583]
2023-09-02 02:42:52.100692: Epoch time: 125.73 s
2023-09-02 02:42:52.101293: Yayy! New best EMA pseudo Dice: 0.6583
2023-09-02 02:42:54.631079: 
2023-09-02 02:42:54.632335: Epoch 1
2023-09-02 02:42:54.633087: Current learning rate: backbone 0.000997, others 0.000997
2023-09-02 02:42:54.634470: start training, 250
================num of epochs: 250================
2023-09-02 02:43:52.636498: finished training
epoch: 1, dataset: CVC-300, dice: 0.8167633333333331
CVC-300 :  0.8167633333333331
epoch: 1, dataset: CVC-ClinicDB, dice: 0.746691935483871
CVC-ClinicDB :  0.746691935483871
epoch: 1, dataset: Kvasir, dice: 0.7291270000000002
Kvasir :  0.7291270000000002
epoch: 1, dataset: CVC-ColonDB, dice: 0.5956839473684221
CVC-ColonDB :  0.5956839473684221
epoch: 1, dataset: ETIS-LaribPolypDB, dice: 0.4522336734693878
ETIS-LaribPolypDB :  0.4522336734693878
2023-09-02 02:44:46.818899: train_loss -1.0832
2023-09-02 02:44:46.819986: val_loss -1.0072
2023-09-02 02:44:46.820824: Pseudo dice [0.7729]
2023-09-02 02:44:46.821476: Epoch time: 112.19 s
2023-09-02 02:44:46.822121: Yayy! New best EMA pseudo Dice: 0.6698
2023-09-02 02:44:49.656446: 
2023-09-02 02:44:49.657655: Epoch 2
2023-09-02 02:44:49.658381: Current learning rate: backbone 0.000994, others 0.000994
2023-09-02 02:44:49.659437: start training, 250
================num of epochs: 250================
2023-09-02 02:45:47.577541: finished training
epoch: 2, dataset: CVC-300, dice: 0.8452199999999996
CVC-300 :  0.8452199999999996
epoch: 2, dataset: CVC-ClinicDB, dice: 0.7839322580645159
CVC-ClinicDB :  0.7839322580645159
epoch: 2, dataset: Kvasir, dice: 0.848643
Kvasir :  0.848643
epoch: 2, dataset: CVC-ColonDB, dice: 0.6510663157894747
CVC-ColonDB :  0.6510663157894747
epoch: 2, dataset: ETIS-LaribPolypDB, dice: 0.6241301020408166
ETIS-LaribPolypDB :  0.6241301020408166
2023-09-02 02:46:42.145781: train_loss -1.1784
2023-09-02 02:46:42.146903: val_loss -0.9853
2023-09-02 02:46:42.147909: Pseudo dice [0.7638]
2023-09-02 02:46:42.148633: Epoch time: 112.49 s
2023-09-02 02:46:42.149262: Yayy! New best EMA pseudo Dice: 0.6792
2023-09-02 02:46:45.024183: 
2023-09-02 02:46:45.025361: Epoch 3
2023-09-02 02:46:45.026095: Current learning rate: backbone 0.000991, others 0.000991
2023-09-02 02:46:45.027108: start training, 250
================num of epochs: 250================
2023-09-02 02:47:42.933489: finished training
epoch: 3, dataset: CVC-300, dice: 0.8494033333333336
CVC-300 :  0.8494033333333336
epoch: 3, dataset: CVC-ClinicDB, dice: 0.7649838709677422
CVC-ClinicDB :  0.7649838709677422
epoch: 3, dataset: Kvasir, dice: 0.8344379999999997
Kvasir :  0.8344379999999997
epoch: 3, dataset: CVC-ColonDB, dice: 0.6691781578947378
CVC-ColonDB :  0.6691781578947378
epoch: 3, dataset: ETIS-LaribPolypDB, dice: 0.6123500000000001
ETIS-LaribPolypDB :  0.6123500000000001
2023-09-02 02:48:37.287141: train_loss -1.2543
2023-09-02 02:48:37.288215: val_loss -1.0355
2023-09-02 02:48:37.289152: Pseudo dice [0.7933]
2023-09-02 02:48:37.289801: Epoch time: 112.26 s
2023-09-02 02:48:37.290387: Yayy! New best EMA pseudo Dice: 0.6906
2023-09-02 02:48:40.101328: 
2023-09-02 02:48:40.102445: Epoch 4
2023-09-02 02:48:40.103070: Current learning rate: backbone 0.00098799, others 0.00098799
2023-09-02 02:48:40.104036: start training, 250
================num of epochs: 250================
2023-09-02 02:49:38.180898: finished training
epoch: 4, dataset: CVC-300, dice: 0.8481266666666668
CVC-300 :  0.8481266666666668
epoch: 4, dataset: CVC-ClinicDB, dice: 0.7966548387096773
CVC-ClinicDB :  0.7966548387096773
epoch: 4, dataset: Kvasir, dice: 0.8790800000000003
Kvasir :  0.8790800000000003
epoch: 4, dataset: CVC-ColonDB, dice: 0.6469386842105272
CVC-ColonDB :  0.6469386842105272
epoch: 4, dataset: ETIS-LaribPolypDB, dice: 0.6518581632653064
ETIS-LaribPolypDB :  0.6518581632653064
2023-09-02 02:50:32.251806: train_loss -1.2883
2023-09-02 02:50:32.252997: val_loss -0.9907
2023-09-02 02:50:32.253988: Pseudo dice [0.7617]
2023-09-02 02:50:32.254650: Epoch time: 112.15 s
2023-09-02 02:50:32.255267: Yayy! New best EMA pseudo Dice: 0.6977
2023-09-02 02:50:35.096161: 
2023-09-02 02:50:35.097398: Epoch 5
2023-09-02 02:50:35.098098: Current learning rate: backbone 0.00098499, others 0.00098499
2023-09-02 02:50:35.099054: start training, 250
================num of epochs: 250================
2023-09-02 02:51:33.014425: finished training
epoch: 5, dataset: CVC-300, dice: 0.7922183333333336
CVC-300 :  0.7922183333333336
epoch: 5, dataset: CVC-ClinicDB, dice: 0.7595580645161292
CVC-ClinicDB :  0.7595580645161292
epoch: 5, dataset: Kvasir, dice: 0.830501
Kvasir :  0.830501
epoch: 5, dataset: CVC-ColonDB, dice: 0.606351578947369
CVC-ColonDB :  0.606351578947369
epoch: 5, dataset: ETIS-LaribPolypDB, dice: 0.6292994897959184
ETIS-LaribPolypDB :  0.6292994897959184
2023-09-02 02:52:27.404292: train_loss -1.3086
2023-09-02 02:52:27.405519: val_loss -1.0396
2023-09-02 02:52:27.406411: Pseudo dice [0.793]
2023-09-02 02:52:27.407088: Epoch time: 112.31 s
2023-09-02 02:52:27.407687: Yayy! New best EMA pseudo Dice: 0.7072
2023-09-02 02:52:30.275551: 
2023-09-02 02:52:30.276783: Epoch 6
2023-09-02 02:52:30.277480: Current learning rate: backbone 0.00098198, others 0.00098198
2023-09-02 02:52:30.278480: start training, 250
================num of epochs: 250================
2023-09-02 02:53:28.354257: finished training
epoch: 6, dataset: CVC-300, dice: 0.8519150000000003
CVC-300 :  0.8519150000000003
epoch: 6, dataset: CVC-ClinicDB, dice: 0.8389016129032255
CVC-ClinicDB :  0.8389016129032255
epoch: 6, dataset: Kvasir, dice: 0.8757120000000002
Kvasir :  0.8757120000000002
epoch: 6, dataset: CVC-ColonDB, dice: 0.6758028947368424
CVC-ColonDB :  0.6758028947368424
epoch: 6, dataset: ETIS-LaribPolypDB, dice: 0.6848010204081633
ETIS-LaribPolypDB :  0.6848010204081633
2023-09-02 02:54:22.893398: train_loss -1.324
2023-09-02 02:54:22.894514: val_loss -1.1129
2023-09-02 02:54:22.895441: Pseudo dice [0.8198]
2023-09-02 02:54:22.896174: Epoch time: 112.62 s
2023-09-02 02:54:22.896754: Yayy! New best EMA pseudo Dice: 0.7185
2023-09-02 02:54:25.710537: 
2023-09-02 02:54:25.711850: Epoch 7
2023-09-02 02:54:25.712531: Current learning rate: backbone 0.00097898, others 0.00097898
2023-09-02 02:54:25.713556: start training, 250
================num of epochs: 250================
2023-09-02 02:55:23.853030: finished training
epoch: 7, dataset: CVC-300, dice: 0.7592883333333332
CVC-300 :  0.7592883333333332
epoch: 7, dataset: CVC-ClinicDB, dice: 0.8441903225806451
CVC-ClinicDB :  0.8441903225806451
epoch: 7, dataset: Kvasir, dice: 0.8325230000000003
Kvasir :  0.8325230000000003
epoch: 7, dataset: CVC-ColonDB, dice: 0.6238068421052627
CVC-ColonDB :  0.6238068421052627
epoch: 7, dataset: ETIS-LaribPolypDB, dice: 0.6107530612244897
ETIS-LaribPolypDB :  0.6107530612244897
2023-09-02 02:56:17.916386: train_loss -1.3443
2023-09-02 02:56:17.917537: val_loss -1.0756
2023-09-02 02:56:17.918482: Pseudo dice [0.8102]
2023-09-02 02:56:17.919202: Epoch time: 112.21 s
2023-09-02 02:56:17.919805: Yayy! New best EMA pseudo Dice: 0.7277
2023-09-02 02:56:20.762254: 
2023-09-02 02:56:20.763566: Epoch 8
2023-09-02 02:56:20.764300: Current learning rate: backbone 0.00097597, others 0.00097597
2023-09-02 02:56:20.765492: start training, 250
================num of epochs: 250================
2023-09-02 02:57:18.682163: finished training
epoch: 8, dataset: CVC-300, dice: 0.8140033333333335
CVC-300 :  0.8140033333333335
epoch: 8, dataset: CVC-ClinicDB, dice: 0.8383145161290322
CVC-ClinicDB :  0.8383145161290322
epoch: 8, dataset: Kvasir, dice: 0.8625080000000004
Kvasir :  0.8625080000000004
epoch: 8, dataset: CVC-ColonDB, dice: 0.6149794736842114
CVC-ColonDB :  0.6149794736842114
epoch: 8, dataset: ETIS-LaribPolypDB, dice: 0.6665535714285715
ETIS-LaribPolypDB :  0.6665535714285715
2023-09-02 02:58:16.030056: train_loss -1.3603
2023-09-02 02:58:16.031304: val_loss -1.0069
2023-09-02 02:58:16.032597: Pseudo dice [0.7818]
2023-09-02 02:58:16.033531: Epoch time: 115.27 s
2023-09-02 02:58:16.034755: Yayy! New best EMA pseudo Dice: 0.7331
2023-09-02 02:58:19.122277: 
2023-09-02 02:58:19.123595: Epoch 9
2023-09-02 02:58:19.124290: Current learning rate: backbone 0.00097296, others 0.00097296
2023-09-02 02:58:19.125369: start training, 250
================num of epochs: 250================
2023-09-02 02:59:17.092984: finished training
epoch: 9, dataset: CVC-300, dice: 0.8513916666666669
CVC-300 :  0.8513916666666669
epoch: 9, dataset: CVC-ClinicDB, dice: 0.8581516129032256
CVC-ClinicDB :  0.8581516129032256
epoch: 9, dataset: Kvasir, dice: 0.8745040000000002
Kvasir :  0.8745040000000002
epoch: 9, dataset: CVC-ColonDB, dice: 0.661263947368421
CVC-ColonDB :  0.661263947368421
epoch: 9, dataset: ETIS-LaribPolypDB, dice: 0.7251479591836735
ETIS-LaribPolypDB :  0.7251479591836735
2023-09-02 03:00:11.226861: train_loss -1.363
2023-09-02 03:00:11.228125: val_loss -0.9926
2023-09-02 03:00:11.229180: Pseudo dice [0.7788]
2023-09-02 03:00:11.229881: Epoch time: 112.11 s
2023-09-02 03:00:12.757368: Yayy! New best EMA pseudo Dice: 0.7377
2023-09-02 03:00:16.027818: 
2023-09-02 03:00:16.029119: Epoch 10
2023-09-02 03:00:16.029782: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-02 03:00:16.030831: start training, 250
================num of epochs: 250================
2023-09-02 03:01:14.391423: finished training
epoch: 10, dataset: CVC-300, dice: 0.8607883333333335
CVC-300 :  0.8607883333333335
epoch: 10, dataset: CVC-ClinicDB, dice: 0.8201838709677416
CVC-ClinicDB :  0.8201838709677416
epoch: 10, dataset: Kvasir, dice: 0.8676410000000003
Kvasir :  0.8676410000000003
epoch: 10, dataset: CVC-ColonDB, dice: 0.6142400000000009
CVC-ColonDB :  0.6142400000000009
epoch: 10, dataset: ETIS-LaribPolypDB, dice: 0.7302178571428571
ETIS-LaribPolypDB :  0.7302178571428571
2023-09-02 03:02:08.475206: train_loss -1.371
2023-09-02 03:02:08.476412: val_loss -0.9944
2023-09-02 03:02:08.477263: Pseudo dice [0.7786]
2023-09-02 03:02:08.477894: Epoch time: 112.45 s
2023-09-02 03:02:08.478461: Yayy! New best EMA pseudo Dice: 0.7418
2023-09-02 03:02:11.324695: 
2023-09-02 03:02:11.325916: Epoch 11
2023-09-02 03:02:11.326645: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-02 03:02:11.327760: start training, 250
================num of epochs: 250================
2023-09-02 03:03:09.547301: finished training
epoch: 11, dataset: CVC-300, dice: 0.8212366666666665
CVC-300 :  0.8212366666666665
epoch: 11, dataset: CVC-ClinicDB, dice: 0.8651483870967743
CVC-ClinicDB :  0.8651483870967743
epoch: 11, dataset: Kvasir, dice: 0.8789810000000001
Kvasir :  0.8789810000000001
epoch: 11, dataset: CVC-ColonDB, dice: 0.6842247368421044
CVC-ColonDB :  0.6842247368421044
epoch: 11, dataset: ETIS-LaribPolypDB, dice: 0.7042295918367345
ETIS-LaribPolypDB :  0.7042295918367345
2023-09-02 03:04:04.011481: train_loss -1.3748
2023-09-02 03:04:04.012748: val_loss -1.0536
2023-09-02 03:04:04.013785: Pseudo dice [0.7992]
2023-09-02 03:04:04.014910: Epoch time: 112.69 s
2023-09-02 03:04:04.015993: Yayy! New best EMA pseudo Dice: 0.7475
2023-09-02 03:04:06.842192: 
2023-09-02 03:04:06.843268: Epoch 12
2023-09-02 03:04:06.843938: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-02 03:04:06.845035: start training, 250
================num of epochs: 250================
2023-09-02 03:05:05.422576: finished training
epoch: 12, dataset: CVC-300, dice: 0.8453799999999998
CVC-300 :  0.8453799999999998
epoch: 12, dataset: CVC-ClinicDB, dice: 0.8596838709677417
CVC-ClinicDB :  0.8596838709677417
epoch: 12, dataset: Kvasir, dice: 0.8824949999999997
Kvasir :  0.8824949999999997
epoch: 12, dataset: CVC-ColonDB, dice: 0.6722376315789473
CVC-ColonDB :  0.6722376315789473
epoch: 12, dataset: ETIS-LaribPolypDB, dice: 0.6591326530612246
ETIS-LaribPolypDB :  0.6591326530612246
2023-09-02 03:06:00.933303: train_loss -1.3846
2023-09-02 03:06:00.934586: val_loss -0.8704
2023-09-02 03:06:00.935639: Pseudo dice [0.7328]
2023-09-02 03:06:00.936409: Epoch time: 114.09 s
2023-09-02 03:06:02.161741: 
2023-09-02 03:06:02.163042: Epoch 13
2023-09-02 03:06:02.163772: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-02 03:06:02.165041: start training, 250
================num of epochs: 250================
2023-09-02 03:07:00.134019: finished training
epoch: 13, dataset: CVC-300, dice: 0.8017183333333334
CVC-300 :  0.8017183333333334
epoch: 13, dataset: CVC-ClinicDB, dice: 0.8400758064516127
CVC-ClinicDB :  0.8400758064516127
epoch: 13, dataset: Kvasir, dice: 0.8758480000000002
Kvasir :  0.8758480000000002
epoch: 13, dataset: CVC-ColonDB, dice: 0.6211439473684217
CVC-ColonDB :  0.6211439473684217
epoch: 13, dataset: ETIS-LaribPolypDB, dice: 0.6506775510204084
ETIS-LaribPolypDB :  0.6506775510204084
2023-09-02 03:07:55.622877: train_loss -1.3842
2023-09-02 03:07:55.623955: val_loss -0.9439
2023-09-02 03:07:55.624918: Pseudo dice [0.7527]
2023-09-02 03:07:55.625713: Epoch time: 113.46 s
2023-09-02 03:07:56.851352: 
2023-09-02 03:07:56.852634: Epoch 14
2023-09-02 03:07:56.853500: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-02 03:07:56.854804: start training, 250
================num of epochs: 250================
2023-09-02 03:08:54.843878: finished training
epoch: 14, dataset: CVC-300, dice: 0.8104683333333331
CVC-300 :  0.8104683333333331
epoch: 14, dataset: CVC-ClinicDB, dice: 0.8107435483870968
CVC-ClinicDB :  0.8107435483870968
epoch: 14, dataset: Kvasir, dice: 0.87105
Kvasir :  0.87105
epoch: 14, dataset: CVC-ColonDB, dice: 0.6578884210526321
CVC-ColonDB :  0.6578884210526321
epoch: 14, dataset: ETIS-LaribPolypDB, dice: 0.6310607142857146
ETIS-LaribPolypDB :  0.6310607142857146
2023-09-02 03:09:50.942827: train_loss -1.3754
2023-09-02 03:09:50.944239: val_loss -1.014
2023-09-02 03:09:50.945479: Pseudo dice [0.7898]
2023-09-02 03:09:50.946343: Epoch time: 114.09 s
2023-09-02 03:09:50.947012: Yayy! New best EMA pseudo Dice: 0.751
2023-09-02 03:09:54.048561: 
2023-09-02 03:09:54.050112: Epoch 15
2023-09-02 03:09:54.050902: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-02 03:09:54.052041: start training, 250
================num of epochs: 250================
2023-09-02 03:10:52.205235: finished training
epoch: 15, dataset: CVC-300, dice: 0.7875166666666665
CVC-300 :  0.7875166666666665
epoch: 15, dataset: CVC-ClinicDB, dice: 0.8305354838709675
CVC-ClinicDB :  0.8305354838709675
epoch: 15, dataset: Kvasir, dice: 0.8807870000000001
Kvasir :  0.8807870000000001
epoch: 15, dataset: CVC-ColonDB, dice: 0.6365773684210524
CVC-ColonDB :  0.6365773684210524
epoch: 15, dataset: ETIS-LaribPolypDB, dice: 0.6283357142857142
ETIS-LaribPolypDB :  0.6283357142857142
2023-09-02 03:11:46.128097: train_loss -1.3817
2023-09-02 03:11:46.129330: val_loss -1.0865
2023-09-02 03:11:46.130301: Pseudo dice [0.8077]
2023-09-02 03:11:46.131100: Epoch time: 112.08 s
2023-09-02 03:11:46.131774: Yayy! New best EMA pseudo Dice: 0.7567
2023-09-02 03:11:48.931964: 
2023-09-02 03:11:48.933222: Epoch 16
2023-09-02 03:11:48.934030: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-02 03:11:48.935209: start training, 250
================num of epochs: 250================
2023-09-02 03:12:46.828068: finished training
epoch: 16, dataset: CVC-300, dice: 0.5776433333333332
CVC-300 :  0.5776433333333332
epoch: 16, dataset: CVC-ClinicDB, dice: 0.800590322580645
CVC-ClinicDB :  0.800590322580645
epoch: 16, dataset: Kvasir, dice: 0.8663139999999997
Kvasir :  0.8663139999999997
epoch: 16, dataset: CVC-ColonDB, dice: 0.5086071052631579
CVC-ColonDB :  0.5086071052631579
epoch: 16, dataset: ETIS-LaribPolypDB, dice: 0.6646408163265306
ETIS-LaribPolypDB :  0.6646408163265306
2023-09-02 03:13:41.170612: train_loss -1.3941
2023-09-02 03:13:41.171752: val_loss -1.0513
2023-09-02 03:13:41.172717: Pseudo dice [0.7995]
2023-09-02 03:13:41.173528: Epoch time: 112.24 s
2023-09-02 03:13:41.174200: Yayy! New best EMA pseudo Dice: 0.761
2023-09-02 03:13:44.049619: 
2023-09-02 03:13:44.050813: Epoch 17
2023-09-02 03:13:44.051517: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-02 03:13:44.052683: start training, 250
================num of epochs: 250================
2023-09-02 03:14:41.980074: finished training
epoch: 17, dataset: CVC-300, dice: 0.8360449999999997
CVC-300 :  0.8360449999999997
epoch: 17, dataset: CVC-ClinicDB, dice: 0.8477241935483871
CVC-ClinicDB :  0.8477241935483871
epoch: 17, dataset: Kvasir, dice: 0.8858300000000002
Kvasir :  0.8858300000000002
epoch: 17, dataset: CVC-ColonDB, dice: 0.6637771052631577
CVC-ColonDB :  0.6637771052631577
epoch: 17, dataset: ETIS-LaribPolypDB, dice: 0.6878352040816326
ETIS-LaribPolypDB :  0.6878352040816326
2023-09-02 03:15:35.942583: train_loss -1.3952
2023-09-02 03:15:35.943842: val_loss -1.0275
2023-09-02 03:15:35.944810: Pseudo dice [0.7881]
2023-09-02 03:15:35.945519: Epoch time: 111.89 s
2023-09-02 03:15:35.946185: Yayy! New best EMA pseudo Dice: 0.7637
2023-09-02 03:15:38.758939: 
2023-09-02 03:15:38.760175: Epoch 18
2023-09-02 03:15:38.760905: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-02 03:15:38.762087: start training, 250
================num of epochs: 250================
2023-09-02 03:16:36.893260: finished training
epoch: 18, dataset: CVC-300, dice: 0.8508866666666669
CVC-300 :  0.8508866666666669
epoch: 18, dataset: CVC-ClinicDB, dice: 0.8350709677419352
CVC-ClinicDB :  0.8350709677419352
epoch: 18, dataset: Kvasir, dice: 0.8723270000000004
Kvasir :  0.8723270000000004
epoch: 18, dataset: CVC-ColonDB, dice: 0.6726326315789479
CVC-ColonDB :  0.6726326315789479
epoch: 18, dataset: ETIS-LaribPolypDB, dice: 0.6762311224489798
ETIS-LaribPolypDB :  0.6762311224489798
2023-09-02 03:17:30.691558: train_loss -1.3942
2023-09-02 03:17:30.692737: val_loss -1.0972
2023-09-02 03:17:30.693814: Pseudo dice [0.8155]
2023-09-02 03:17:30.695212: Epoch time: 111.93 s
2023-09-02 03:17:30.696248: Yayy! New best EMA pseudo Dice: 0.7689
2023-09-02 03:17:33.568752: 
2023-09-02 03:17:33.569936: Epoch 19
2023-09-02 03:17:33.570641: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-02 03:17:33.571798: start training, 250
================num of epochs: 250================
2023-09-02 03:18:31.589278: finished training
epoch: 19, dataset: CVC-300, dice: 0.7591899999999997
CVC-300 :  0.7591899999999997
epoch: 19, dataset: CVC-ClinicDB, dice: 0.7958467741935485
CVC-ClinicDB :  0.7958467741935485
epoch: 19, dataset: Kvasir, dice: 0.8626310000000007
Kvasir :  0.8626310000000007
epoch: 19, dataset: CVC-ColonDB, dice: 0.5492084210526315
CVC-ColonDB :  0.5492084210526315
epoch: 19, dataset: ETIS-LaribPolypDB, dice: 0.6205872448979592
ETIS-LaribPolypDB :  0.6205872448979592
2023-09-02 03:19:26.096401: train_loss -1.3987
2023-09-02 03:19:26.097632: val_loss -1.0479
2023-09-02 03:19:26.098596: Pseudo dice [0.8007]
2023-09-02 03:19:26.099405: Epoch time: 112.53 s
2023-09-02 03:19:27.733050: Yayy! New best EMA pseudo Dice: 0.772
2023-09-02 03:19:30.709541: 
2023-09-02 03:19:30.711659: Epoch 20
2023-09-02 03:19:30.712963: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-02 03:19:30.714870: start training, 250
================num of epochs: 250================
2023-09-02 03:20:28.721783: finished training
epoch: 20, dataset: CVC-300, dice: 0.8400433333333334
CVC-300 :  0.8400433333333334
epoch: 20, dataset: CVC-ClinicDB, dice: 0.8265290322580646
CVC-ClinicDB :  0.8265290322580646
epoch: 20, dataset: Kvasir, dice: 0.8704550000000003
Kvasir :  0.8704550000000003
epoch: 20, dataset: CVC-ColonDB, dice: 0.6642652631578939
CVC-ColonDB :  0.6642652631578939
epoch: 20, dataset: ETIS-LaribPolypDB, dice: 0.7233306122448985
ETIS-LaribPolypDB :  0.7233306122448985
2023-09-02 03:21:23.161655: train_loss -1.4061
2023-09-02 03:21:23.162907: val_loss -1.1223
2023-09-02 03:21:23.163881: Pseudo dice [0.834]
2023-09-02 03:21:23.164623: Epoch time: 112.45 s
2023-09-02 03:21:23.165266: Yayy! New best EMA pseudo Dice: 0.7782
2023-09-02 03:21:26.255733: 
2023-09-02 03:21:26.256899: Epoch 21
2023-09-02 03:21:26.257653: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-02 03:21:26.258818: start training, 250
================num of epochs: 250================
2023-09-02 03:22:24.159138: finished training
epoch: 21, dataset: CVC-300, dice: 0.856573333333333
CVC-300 :  0.856573333333333
epoch: 21, dataset: CVC-ClinicDB, dice: 0.8447241935483869
CVC-ClinicDB :  0.8447241935483869
epoch: 21, dataset: Kvasir, dice: 0.867423
Kvasir :  0.867423
epoch: 21, dataset: CVC-ColonDB, dice: 0.6222744736842108
CVC-ColonDB :  0.6222744736842108
epoch: 21, dataset: ETIS-LaribPolypDB, dice: 0.6925918367346937
ETIS-LaribPolypDB :  0.6925918367346937
2023-09-02 03:23:18.320348: train_loss -1.4075
2023-09-02 03:23:18.321618: val_loss -1.0946
2023-09-02 03:23:18.322728: Pseudo dice [0.816]
2023-09-02 03:23:18.323481: Epoch time: 112.07 s
2023-09-02 03:23:18.324118: Yayy! New best EMA pseudo Dice: 0.782
2023-09-02 03:23:21.187865: 
2023-09-02 03:23:21.189211: Epoch 22
2023-09-02 03:23:21.189942: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-02 03:23:21.191010: start training, 250
================num of epochs: 250================
2023-09-02 03:24:19.176880: finished training
epoch: 22, dataset: CVC-300, dice: 0.8024633333333334
CVC-300 :  0.8024633333333334
epoch: 22, dataset: CVC-ClinicDB, dice: 0.8522580645161287
CVC-ClinicDB :  0.8522580645161287
epoch: 22, dataset: Kvasir, dice: 0.8578079999999999
Kvasir :  0.8578079999999999
epoch: 22, dataset: CVC-ColonDB, dice: 0.6787155263157899
CVC-ColonDB :  0.6787155263157899
epoch: 22, dataset: ETIS-LaribPolypDB, dice: 0.6767576530612243
ETIS-LaribPolypDB :  0.6767576530612243
2023-09-02 03:25:15.828278: train_loss -1.4079
2023-09-02 03:25:15.829843: val_loss -1.0648
2023-09-02 03:25:15.831152: Pseudo dice [0.8083]
2023-09-02 03:25:15.832218: Epoch time: 114.64 s
2023-09-02 03:25:15.833463: Yayy! New best EMA pseudo Dice: 0.7846
2023-09-02 03:25:18.632550: 
2023-09-02 03:25:18.633837: Epoch 23
2023-09-02 03:25:18.635006: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-02 03:25:18.636909: start training, 250
================num of epochs: 250================
2023-09-02 03:26:16.977443: finished training
epoch: 23, dataset: CVC-300, dice: 0.48196999999999984
CVC-300 :  0.48196999999999984
epoch: 23, dataset: CVC-ClinicDB, dice: 0.8019435483870964
CVC-ClinicDB :  0.8019435483870964
epoch: 23, dataset: Kvasir, dice: 0.8259449999999998
Kvasir :  0.8259449999999998
epoch: 23, dataset: CVC-ColonDB, dice: 0.45404631578947285
CVC-ColonDB :  0.45404631578947285
epoch: 23, dataset: ETIS-LaribPolypDB, dice: 0.5681423469387754
ETIS-LaribPolypDB :  0.5681423469387754
2023-09-02 03:27:13.340852: train_loss -1.4099
2023-09-02 03:27:13.342307: val_loss -1.0822
2023-09-02 03:27:13.343531: Pseudo dice [0.814]
2023-09-02 03:27:13.344373: Epoch time: 114.71 s
2023-09-02 03:27:13.345093: Yayy! New best EMA pseudo Dice: 0.7876
2023-09-02 03:27:16.209075: 
2023-09-02 03:27:16.210418: Epoch 24
2023-09-02 03:27:16.211202: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-02 03:27:16.212406: start training, 250
================num of epochs: 250================
2023-09-02 03:28:14.155715: finished training
epoch: 24, dataset: CVC-300, dice: 0.817971666666667
CVC-300 :  0.817971666666667
epoch: 24, dataset: CVC-ClinicDB, dice: 0.8499596774193547
CVC-ClinicDB :  0.8499596774193547
epoch: 24, dataset: Kvasir, dice: 0.8689989999999999
Kvasir :  0.8689989999999999
epoch: 24, dataset: CVC-ColonDB, dice: 0.6718897368421052
CVC-ColonDB :  0.6718897368421052
epoch: 24, dataset: ETIS-LaribPolypDB, dice: 0.6937000000000001
ETIS-LaribPolypDB :  0.6937000000000001
2023-09-02 03:29:09.375830: train_loss -1.4059
2023-09-02 03:29:09.377138: val_loss -1.1151
2023-09-02 03:29:09.378073: Pseudo dice [0.8355]
2023-09-02 03:29:09.378794: Epoch time: 113.17 s
2023-09-02 03:29:09.379523: Yayy! New best EMA pseudo Dice: 0.7924
2023-09-02 03:29:12.266510: 
2023-09-02 03:29:12.267644: Epoch 25
2023-09-02 03:29:12.268373: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-02 03:29:12.269513: start training, 250
================num of epochs: 250================
2023-09-02 03:30:10.185164: finished training
epoch: 25, dataset: CVC-300, dice: 0.8623600000000001
CVC-300 :  0.8623600000000001
epoch: 25, dataset: CVC-ClinicDB, dice: 0.8421064516129032
CVC-ClinicDB :  0.8421064516129032
epoch: 25, dataset: Kvasir, dice: 0.875718
Kvasir :  0.875718
epoch: 25, dataset: CVC-ColonDB, dice: 0.6821584210526319
CVC-ColonDB :  0.6821584210526319
epoch: 25, dataset: ETIS-LaribPolypDB, dice: 0.7393505102040818
ETIS-LaribPolypDB :  0.7393505102040818
2023-09-02 03:31:06.165796: train_loss -1.4095
2023-09-02 03:31:06.167100: val_loss -1.063
2023-09-02 03:31:06.168044: Pseudo dice [0.8001]
2023-09-02 03:31:06.168889: Epoch time: 113.9 s
2023-09-02 03:31:06.169644: Yayy! New best EMA pseudo Dice: 0.7931
2023-09-02 03:31:08.989784: 
2023-09-02 03:31:08.990981: Epoch 26
2023-09-02 03:31:08.991740: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-02 03:31:08.992890: start training, 250
================num of epochs: 250================
2023-09-02 03:32:07.091130: finished training
epoch: 26, dataset: CVC-300, dice: 0.8753416666666668
CVC-300 :  0.8753416666666668
epoch: 26, dataset: CVC-ClinicDB, dice: 0.8512612903225808
CVC-ClinicDB :  0.8512612903225808
epoch: 26, dataset: Kvasir, dice: 0.8796350000000001
Kvasir :  0.8796350000000001
epoch: 26, dataset: CVC-ColonDB, dice: 0.6946889473684216
CVC-ColonDB :  0.6946889473684216
epoch: 26, dataset: ETIS-LaribPolypDB, dice: 0.7628862244897963
ETIS-LaribPolypDB :  0.7628862244897963
2023-09-02 03:33:02.004814: train_loss -1.4164
2023-09-02 03:33:02.006155: val_loss -1.0677
2023-09-02 03:33:02.007164: Pseudo dice [0.8113]
2023-09-02 03:33:02.007952: Epoch time: 113.02 s
2023-09-02 03:33:02.008699: Yayy! New best EMA pseudo Dice: 0.795
2023-09-02 03:33:04.837931: 
2023-09-02 03:33:04.839137: Epoch 27
2023-09-02 03:33:04.839965: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-02 03:33:04.841145: start training, 250
================num of epochs: 250================
2023-09-02 03:34:02.976347: finished training
epoch: 27, dataset: CVC-300, dice: 0.8434849999999997
CVC-300 :  0.8434849999999997
epoch: 27, dataset: CVC-ClinicDB, dice: 0.8448790322580644
CVC-ClinicDB :  0.8448790322580644
epoch: 27, dataset: Kvasir, dice: 0.8768600000000003
Kvasir :  0.8768600000000003
epoch: 27, dataset: CVC-ColonDB, dice: 0.6805836842105265
CVC-ColonDB :  0.6805836842105265
epoch: 27, dataset: ETIS-LaribPolypDB, dice: 0.738566326530612
ETIS-LaribPolypDB :  0.738566326530612
2023-09-02 03:34:57.733251: train_loss -1.4124
2023-09-02 03:34:57.734555: val_loss -1.1177
2023-09-02 03:34:57.735740: Pseudo dice [0.8312]
2023-09-02 03:34:57.736668: Epoch time: 112.9 s
2023-09-02 03:34:57.737517: Yayy! New best EMA pseudo Dice: 0.7986
2023-09-02 03:35:00.546360: 
2023-09-02 03:35:00.547546: Epoch 28
2023-09-02 03:35:00.548336: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-02 03:35:00.549510: start training, 250
================num of epochs: 250================
2023-09-02 03:35:58.435037: finished training
epoch: 28, dataset: CVC-300, dice: 0.86984
CVC-300 :  0.86984
epoch: 28, dataset: CVC-ClinicDB, dice: 0.861898387096774
CVC-ClinicDB :  0.861898387096774
epoch: 28, dataset: Kvasir, dice: 0.867359
Kvasir :  0.867359
epoch: 28, dataset: CVC-ColonDB, dice: 0.6730310526315796
CVC-ColonDB :  0.6730310526315796
epoch: 28, dataset: ETIS-LaribPolypDB, dice: 0.7493969387755097
ETIS-LaribPolypDB :  0.7493969387755097
2023-09-02 03:36:53.426879: train_loss -1.4205
2023-09-02 03:36:53.428137: val_loss -1.0853
2023-09-02 03:36:53.429156: Pseudo dice [0.814]
2023-09-02 03:36:53.429961: Epoch time: 112.88 s
2023-09-02 03:36:53.430720: Yayy! New best EMA pseudo Dice: 0.8001
2023-09-02 03:36:56.366521: 
2023-09-02 03:36:56.367990: Epoch 29
2023-09-02 03:36:56.368757: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-02 03:36:56.370000: start training, 250
================num of epochs: 250================
2023-09-02 03:37:54.526269: finished training
epoch: 29, dataset: CVC-300, dice: 0.8595183333333333
CVC-300 :  0.8595183333333333
epoch: 29, dataset: CVC-ClinicDB, dice: 0.8488290322580645
CVC-ClinicDB :  0.8488290322580645
epoch: 29, dataset: Kvasir, dice: 0.8740939999999999
Kvasir :  0.8740939999999999
epoch: 29, dataset: CVC-ColonDB, dice: 0.6642686842105273
CVC-ColonDB :  0.6642686842105273
epoch: 29, dataset: ETIS-LaribPolypDB, dice: 0.7290255102040826
ETIS-LaribPolypDB :  0.7290255102040826
2023-09-02 03:38:49.164705: train_loss -1.4214
2023-09-02 03:38:49.166177: val_loss -1.0931
2023-09-02 03:38:49.167184: Pseudo dice [0.8182]
2023-09-02 03:38:49.167969: Epoch time: 112.8 s
2023-09-02 03:38:50.780041: Yayy! New best EMA pseudo Dice: 0.8019
2023-09-02 03:38:53.592438: 
2023-09-02 03:38:53.593861: Epoch 30
2023-09-02 03:38:53.594642: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-02 03:38:53.595826: start training, 250
================num of epochs: 250================
2023-09-02 03:39:51.650039: finished training
epoch: 30, dataset: CVC-300, dice: 0.8581166666666667
CVC-300 :  0.8581166666666667
epoch: 30, dataset: CVC-ClinicDB, dice: 0.8704693548387098
CVC-ClinicDB :  0.8704693548387098
epoch: 30, dataset: Kvasir, dice: 0.8929339999999999
Kvasir :  0.8929339999999999
epoch: 30, dataset: CVC-ColonDB, dice: 0.7349431578947372
CVC-ColonDB :  0.7349431578947372
epoch: 30, dataset: ETIS-LaribPolypDB, dice: 0.7545081632653056
ETIS-LaribPolypDB :  0.7545081632653056
2023-09-02 03:40:46.142122: train_loss -1.4146
2023-09-02 03:40:46.143461: val_loss -1.1018
2023-09-02 03:40:46.144510: Pseudo dice [0.8218]
2023-09-02 03:40:46.145299: Epoch time: 112.55 s
2023-09-02 03:40:46.145967: Yayy! New best EMA pseudo Dice: 0.8039
2023-09-02 03:40:48.940765: 
2023-09-02 03:40:48.941994: Epoch 31
2023-09-02 03:40:48.942761: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-02 03:40:48.943976: start training, 250
================num of epochs: 250================
2023-09-02 03:41:46.885444: finished training
epoch: 31, dataset: CVC-300, dice: 0.8738383333333334
CVC-300 :  0.8738383333333334
epoch: 31, dataset: CVC-ClinicDB, dice: 0.8593758064516127
CVC-ClinicDB :  0.8593758064516127
epoch: 31, dataset: Kvasir, dice: 0.8769009999999998
Kvasir :  0.8769009999999998
epoch: 31, dataset: CVC-ColonDB, dice: 0.6909078947368424
CVC-ColonDB :  0.6909078947368424
epoch: 31, dataset: ETIS-LaribPolypDB, dice: 0.7200010204081636
ETIS-LaribPolypDB :  0.7200010204081636
2023-09-02 03:42:41.148985: train_loss -1.4203
2023-09-02 03:42:41.150134: val_loss -1.0648
2023-09-02 03:42:41.151159: Pseudo dice [0.8104]
2023-09-02 03:42:41.151959: Epoch time: 112.21 s
2023-09-02 03:42:41.152644: Yayy! New best EMA pseudo Dice: 0.8046
2023-09-02 03:42:44.192188: 
2023-09-02 03:42:44.193462: Epoch 32
2023-09-02 03:42:44.194209: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-02 03:42:44.195284: start training, 250
================num of epochs: 250================
2023-09-02 03:43:42.123456: finished training
epoch: 32, dataset: CVC-300, dice: 0.84524
CVC-300 :  0.84524
epoch: 32, dataset: CVC-ClinicDB, dice: 0.8639112903225807
CVC-ClinicDB :  0.8639112903225807
epoch: 32, dataset: Kvasir, dice: 0.8895470000000002
Kvasir :  0.8895470000000002
epoch: 32, dataset: CVC-ColonDB, dice: 0.6882905263157897
CVC-ColonDB :  0.6882905263157897
epoch: 32, dataset: ETIS-LaribPolypDB, dice: 0.7274545918367351
ETIS-LaribPolypDB :  0.7274545918367351
2023-09-02 03:44:37.672893: train_loss -1.4253
2023-09-02 03:44:37.674185: val_loss -1.1398
2023-09-02 03:44:37.675321: Pseudo dice [0.8417]
2023-09-02 03:44:37.676056: Epoch time: 113.48 s
2023-09-02 03:44:37.676717: Yayy! New best EMA pseudo Dice: 0.8083
2023-09-02 03:44:40.512303: 
2023-09-02 03:44:40.513647: Epoch 33
2023-09-02 03:44:40.514439: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-02 03:44:40.515640: start training, 250
================num of epochs: 250================
2023-09-02 03:45:38.501204: finished training
epoch: 33, dataset: CVC-300, dice: 0.8662133333333332
CVC-300 :  0.8662133333333332
epoch: 33, dataset: CVC-ClinicDB, dice: 0.8464677419354842
CVC-ClinicDB :  0.8464677419354842
epoch: 33, dataset: Kvasir, dice: 0.8802859999999997
Kvasir :  0.8802859999999997
epoch: 33, dataset: CVC-ColonDB, dice: 0.6913028947368421
CVC-ColonDB :  0.6913028947368421
epoch: 33, dataset: ETIS-LaribPolypDB, dice: 0.7379117346938774
ETIS-LaribPolypDB :  0.7379117346938774
2023-09-02 03:46:35.153812: train_loss -1.4292
2023-09-02 03:46:35.155213: val_loss -1.0461
2023-09-02 03:46:35.156456: Pseudo dice [0.8056]
2023-09-02 03:46:35.157434: Epoch time: 114.64 s
2023-09-02 03:46:36.353664: 
2023-09-02 03:46:36.354843: Epoch 34
2023-09-02 03:46:36.355559: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-02 03:46:36.356786: start training, 250
================num of epochs: 250================
2023-09-02 03:47:34.457811: finished training
epoch: 34, dataset: CVC-300, dice: 0.8685950000000002
CVC-300 :  0.8685950000000002
epoch: 34, dataset: CVC-ClinicDB, dice: 0.8540887096774193
CVC-ClinicDB :  0.8540887096774193
epoch: 34, dataset: Kvasir, dice: 0.8853930000000005
Kvasir :  0.8853930000000005
epoch: 34, dataset: CVC-ColonDB, dice: 0.6533349999999999
CVC-ColonDB :  0.6533349999999999
epoch: 34, dataset: ETIS-LaribPolypDB, dice: 0.7385816326530611
ETIS-LaribPolypDB :  0.7385816326530611
2023-09-02 03:48:30.237450: train_loss -1.4287
2023-09-02 03:48:30.238842: val_loss -1.0209
2023-09-02 03:48:30.239852: Pseudo dice [0.8007]
2023-09-02 03:48:30.240638: Epoch time: 113.89 s
2023-09-02 03:48:31.675086: 
2023-09-02 03:48:31.676474: Epoch 35
2023-09-02 03:48:31.677276: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-02 03:48:31.678407: start training, 250
================num of epochs: 250================
2023-09-02 03:49:29.682225: finished training
epoch: 35, dataset: CVC-300, dice: 0.8554383333333335
CVC-300 :  0.8554383333333335
epoch: 35, dataset: CVC-ClinicDB, dice: 0.8178935483870967
CVC-ClinicDB :  0.8178935483870967
epoch: 35, dataset: Kvasir, dice: 0.8728680000000003
Kvasir :  0.8728680000000003
epoch: 35, dataset: CVC-ColonDB, dice: 0.6614818421052633
CVC-ColonDB :  0.6614818421052633
epoch: 35, dataset: ETIS-LaribPolypDB, dice: 0.7310933673469392
ETIS-LaribPolypDB :  0.7310933673469392
2023-09-02 03:50:24.571641: train_loss -1.4261
2023-09-02 03:50:24.572938: val_loss -1.0962
2023-09-02 03:50:24.574049: Pseudo dice [0.8265]
2023-09-02 03:50:24.574862: Epoch time: 112.9 s
2023-09-02 03:50:24.575569: Yayy! New best EMA pseudo Dice: 0.8092
2023-09-02 03:50:27.395765: 
2023-09-02 03:50:27.397177: Epoch 36
2023-09-02 03:50:27.397975: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-02 03:50:27.399240: start training, 250
================num of epochs: 250================
2023-09-02 03:51:25.299644: finished training
epoch: 36, dataset: CVC-300, dice: 0.8487466666666666
CVC-300 :  0.8487466666666666
epoch: 36, dataset: CVC-ClinicDB, dice: 0.8429338709677419
CVC-ClinicDB :  0.8429338709677419
epoch: 36, dataset: Kvasir, dice: 0.8793399999999998
Kvasir :  0.8793399999999998
epoch: 36, dataset: CVC-ColonDB, dice: 0.6840723684210528
CVC-ColonDB :  0.6840723684210528
epoch: 36, dataset: ETIS-LaribPolypDB, dice: 0.7269551020408167
ETIS-LaribPolypDB :  0.7269551020408167
2023-09-02 03:52:20.884890: train_loss -1.4278
2023-09-02 03:52:20.886155: val_loss -1.1218
2023-09-02 03:52:20.887194: Pseudo dice [0.8342]
2023-09-02 03:52:20.888016: Epoch time: 113.49 s
2023-09-02 03:52:20.888751: Yayy! New best EMA pseudo Dice: 0.8117
2023-09-02 03:52:23.715195: 
2023-09-02 03:52:23.716599: Epoch 37
2023-09-02 03:52:23.717431: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-02 03:52:23.718587: start training, 250
================num of epochs: 250================
2023-09-02 03:53:21.863701: finished training
epoch: 37, dataset: CVC-300, dice: 0.8493633333333329
CVC-300 :  0.8493633333333329
epoch: 37, dataset: CVC-ClinicDB, dice: 0.8502080645161291
CVC-ClinicDB :  0.8502080645161291
epoch: 37, dataset: Kvasir, dice: 0.88064
Kvasir :  0.88064
epoch: 37, dataset: CVC-ColonDB, dice: 0.6950907894736836
CVC-ColonDB :  0.6950907894736836
epoch: 37, dataset: ETIS-LaribPolypDB, dice: 0.7624071428571426
ETIS-LaribPolypDB :  0.7624071428571426
2023-09-02 03:54:16.197676: train_loss -1.4301
2023-09-02 03:54:16.198954: val_loss -1.0588
2023-09-02 03:54:16.199965: Pseudo dice [0.8117]
2023-09-02 03:54:16.200769: Epoch time: 112.48 s
2023-09-02 03:54:17.673659: 
2023-09-02 03:54:17.674933: Epoch 38
2023-09-02 03:54:17.675818: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-02 03:54:17.677010: start training, 250
================num of epochs: 250================
2023-09-02 03:55:15.948588: finished training
epoch: 38, dataset: CVC-300, dice: 0.8567266666666666
CVC-300 :  0.8567266666666666
epoch: 38, dataset: CVC-ClinicDB, dice: 0.8516306451612898
CVC-ClinicDB :  0.8516306451612898
epoch: 38, dataset: Kvasir, dice: 0.886014
Kvasir :  0.886014
epoch: 38, dataset: CVC-ColonDB, dice: 0.6582594736842113
CVC-ColonDB :  0.6582594736842113
epoch: 38, dataset: ETIS-LaribPolypDB, dice: 0.7397775510204085
ETIS-LaribPolypDB :  0.7397775510204085
2023-09-02 03:56:11.581765: train_loss -1.4313
2023-09-02 03:56:11.583121: val_loss -1.0631
2023-09-02 03:56:11.584216: Pseudo dice [0.8119]
2023-09-02 03:56:11.585062: Epoch time: 113.91 s
2023-09-02 03:56:11.585796: Yayy! New best EMA pseudo Dice: 0.8117
2023-09-02 03:56:14.518977: 
2023-09-02 03:56:14.520148: Epoch 39
2023-09-02 03:56:14.520942: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-02 03:56:14.522184: start training, 250
================num of epochs: 250================
2023-09-02 03:57:12.429584: finished training
epoch: 39, dataset: CVC-300, dice: 0.8877699999999997
CVC-300 :  0.8877699999999997
epoch: 39, dataset: CVC-ClinicDB, dice: 0.8544274193548387
CVC-ClinicDB :  0.8544274193548387
epoch: 39, dataset: Kvasir, dice: 0.886921
Kvasir :  0.886921
epoch: 39, dataset: CVC-ColonDB, dice: 0.6866136842105267
CVC-ColonDB :  0.6866136842105267
epoch: 39, dataset: ETIS-LaribPolypDB, dice: 0.7503321428571433
ETIS-LaribPolypDB :  0.7503321428571433
2023-09-02 03:58:06.605414: train_loss -1.4334
2023-09-02 03:58:06.606886: val_loss -1.0383
2023-09-02 03:58:06.607882: Pseudo dice [0.8148]
2023-09-02 03:58:06.608676: Epoch time: 112.09 s
2023-09-02 03:58:08.238894: Yayy! New best EMA pseudo Dice: 0.812
2023-09-02 03:58:11.073834: 
2023-09-02 03:58:11.075330: Epoch 40
2023-09-02 03:58:11.076143: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-02 03:58:11.077328: start training, 250
================num of epochs: 250================
2023-09-02 03:59:09.257801: finished training
epoch: 40, dataset: CVC-300, dice: 0.8840866666666667
CVC-300 :  0.8840866666666667
epoch: 40, dataset: CVC-ClinicDB, dice: 0.8529419354838711
CVC-ClinicDB :  0.8529419354838711
epoch: 40, dataset: Kvasir, dice: 0.88952
Kvasir :  0.88952
epoch: 40, dataset: CVC-ColonDB, dice: 0.6817981578947364
CVC-ColonDB :  0.6817981578947364
epoch: 40, dataset: ETIS-LaribPolypDB, dice: 0.7387051020408171
ETIS-LaribPolypDB :  0.7387051020408171
2023-09-02 04:00:03.853324: train_loss -1.4325
2023-09-02 04:00:03.854759: val_loss -1.1131
2023-09-02 04:00:03.855929: Pseudo dice [0.8388]
2023-09-02 04:00:03.856785: Epoch time: 112.78 s
2023-09-02 04:00:03.857589: Yayy! New best EMA pseudo Dice: 0.8147
2023-09-02 04:00:06.686767: 
2023-09-02 04:00:06.688107: Epoch 41
2023-09-02 04:00:06.688981: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-02 04:00:06.690282: start training, 250
================num of epochs: 250================
2023-09-02 04:01:04.667475: finished training
epoch: 41, dataset: CVC-300, dice: 0.8727216666666667
CVC-300 :  0.8727216666666667
epoch: 41, dataset: CVC-ClinicDB, dice: 0.8542741935483871
CVC-ClinicDB :  0.8542741935483871
epoch: 41, dataset: Kvasir, dice: 0.876895
Kvasir :  0.876895
epoch: 41, dataset: CVC-ColonDB, dice: 0.7070436842105267
CVC-ColonDB :  0.7070436842105267
epoch: 41, dataset: ETIS-LaribPolypDB, dice: 0.7192698979591838
ETIS-LaribPolypDB :  0.7192698979591838
2023-09-02 04:02:04.404454: train_loss -1.4346
2023-09-02 04:02:04.406638: val_loss -1.1291
2023-09-02 04:02:04.408619: Pseudo dice [0.8465]
2023-09-02 04:02:04.409503: Epoch time: 117.72 s
2023-09-02 04:02:04.410236: Yayy! New best EMA pseudo Dice: 0.8179
2023-09-02 04:02:07.309776: 
2023-09-02 04:02:07.311099: Epoch 42
2023-09-02 04:02:07.312027: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-02 04:02:07.313284: start training, 250
================num of epochs: 250================
2023-09-02 04:03:05.550724: finished training
epoch: 42, dataset: CVC-300, dice: 0.8611749999999998
CVC-300 :  0.8611749999999998
epoch: 42, dataset: CVC-ClinicDB, dice: 0.8515774193548382
CVC-ClinicDB :  0.8515774193548382
epoch: 42, dataset: Kvasir, dice: 0.8752499999999998
Kvasir :  0.8752499999999998
epoch: 42, dataset: CVC-ColonDB, dice: 0.711962368421053
CVC-ColonDB :  0.711962368421053
epoch: 42, dataset: ETIS-LaribPolypDB, dice: 0.7348270408163269
ETIS-LaribPolypDB :  0.7348270408163269
2023-09-02 04:04:03.191536: train_loss -1.4347
2023-09-02 04:04:03.192793: val_loss -1.138
2023-09-02 04:04:03.193783: Pseudo dice [0.8396]
2023-09-02 04:04:03.194583: Epoch time: 115.88 s
2023-09-02 04:04:03.195532: Yayy! New best EMA pseudo Dice: 0.8201
2023-09-02 04:04:06.031024: 
2023-09-02 04:04:06.032390: Epoch 43
2023-09-02 04:04:06.033257: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-02 04:04:06.034442: start training, 250
================num of epochs: 250================
2023-09-02 04:05:04.416873: finished training
epoch: 43, dataset: CVC-300, dice: 0.870606666666667
CVC-300 :  0.870606666666667
epoch: 43, dataset: CVC-ClinicDB, dice: 0.8617596774193546
CVC-ClinicDB :  0.8617596774193546
epoch: 43, dataset: Kvasir, dice: 0.8822419999999999
Kvasir :  0.8822419999999999
epoch: 43, dataset: CVC-ColonDB, dice: 0.7014102631578955
CVC-ColonDB :  0.7014102631578955
epoch: 43, dataset: ETIS-LaribPolypDB, dice: 0.737138775510204
ETIS-LaribPolypDB :  0.737138775510204
2023-09-02 04:05:58.524051: train_loss -1.4364
2023-09-02 04:05:58.525252: val_loss -1.0749
2023-09-02 04:05:58.526238: Pseudo dice [0.8173]
2023-09-02 04:05:58.526995: Epoch time: 112.49 s
2023-09-02 04:05:59.691279: 
2023-09-02 04:05:59.692631: Epoch 44
2023-09-02 04:05:59.693424: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-02 04:05:59.694662: start training, 250
================num of epochs: 250================
2023-09-02 04:06:57.817707: finished training
epoch: 44, dataset: CVC-300, dice: 0.8671083333333331
CVC-300 :  0.8671083333333331
epoch: 44, dataset: CVC-ClinicDB, dice: 0.861609677419355
CVC-ClinicDB :  0.861609677419355
epoch: 44, dataset: Kvasir, dice: 0.878394
Kvasir :  0.878394
epoch: 44, dataset: CVC-ColonDB, dice: 0.6982886842105267
CVC-ColonDB :  0.6982886842105267
epoch: 44, dataset: ETIS-LaribPolypDB, dice: 0.7298428571428573
ETIS-LaribPolypDB :  0.7298428571428573
2023-09-02 04:07:52.818061: train_loss -1.4339
2023-09-02 04:07:52.819434: val_loss -1.0382
2023-09-02 04:07:52.820487: Pseudo dice [0.8163]
2023-09-02 04:07:52.821270: Epoch time: 113.13 s
2023-09-02 04:07:53.986212: 
2023-09-02 04:07:53.987520: Epoch 45
2023-09-02 04:07:53.988364: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-02 04:07:53.989599: start training, 250
================num of epochs: 250================
2023-09-02 04:08:52.077905: finished training
epoch: 45, dataset: CVC-300, dice: 0.8507666666666669
CVC-300 :  0.8507666666666669
epoch: 45, dataset: CVC-ClinicDB, dice: 0.8635790322580644
CVC-ClinicDB :  0.8635790322580644
epoch: 45, dataset: Kvasir, dice: 0.8670370000000002
Kvasir :  0.8670370000000002
epoch: 45, dataset: CVC-ColonDB, dice: 0.6547705263157899
CVC-ColonDB :  0.6547705263157899
epoch: 45, dataset: ETIS-LaribPolypDB, dice: 0.7401112244897964
ETIS-LaribPolypDB :  0.7401112244897964
2023-09-02 04:09:45.941627: train_loss -1.4346
2023-09-02 04:09:45.942941: val_loss -1.0881
2023-09-02 04:09:45.944036: Pseudo dice [0.83]
2023-09-02 04:09:45.944951: Epoch time: 111.96 s
2023-09-02 04:09:45.945723: Yayy! New best EMA pseudo Dice: 0.8205
2023-09-02 04:09:48.731984: 
2023-09-02 04:09:48.733430: Epoch 46
2023-09-02 04:09:48.734268: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-02 04:09:48.735522: start training, 250
================num of epochs: 250================
2023-09-02 04:10:47.418773: finished training
epoch: 46, dataset: CVC-300, dice: 0.8608616666666669
CVC-300 :  0.8608616666666669
epoch: 46, dataset: CVC-ClinicDB, dice: 0.8691854838709677
CVC-ClinicDB :  0.8691854838709677
epoch: 46, dataset: Kvasir, dice: 0.891327
Kvasir :  0.891327
epoch: 46, dataset: CVC-ColonDB, dice: 0.7146776315789478
CVC-ColonDB :  0.7146776315789478
epoch: 46, dataset: ETIS-LaribPolypDB, dice: 0.7449862244897958
ETIS-LaribPolypDB :  0.7449862244897958
2023-09-02 04:11:42.332834: train_loss -1.4351
2023-09-02 04:11:42.334225: val_loss -1.0759
2023-09-02 04:11:42.335517: Pseudo dice [0.8246]
2023-09-02 04:11:42.336476: Epoch time: 113.6 s
2023-09-02 04:11:42.337276: Yayy! New best EMA pseudo Dice: 0.8209
2023-09-02 04:11:45.183396: 
2023-09-02 04:11:45.185261: Epoch 47
2023-09-02 04:11:45.186165: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-02 04:11:45.187553: start training, 250
================num of epochs: 250================
2023-09-02 04:12:43.309991: finished training
epoch: 47, dataset: CVC-300, dice: 0.8780049999999998
CVC-300 :  0.8780049999999998
epoch: 47, dataset: CVC-ClinicDB, dice: 0.8709967741935487
CVC-ClinicDB :  0.8709967741935487
epoch: 47, dataset: Kvasir, dice: 0.9013679999999998
Kvasir :  0.9013679999999998
epoch: 47, dataset: CVC-ColonDB, dice: 0.7064573684210531
CVC-ColonDB :  0.7064573684210531
epoch: 47, dataset: ETIS-LaribPolypDB, dice: 0.7487178571428568
ETIS-LaribPolypDB :  0.7487178571428568
2023-09-02 04:13:36.485419: train_loss -1.4391
2023-09-02 04:13:36.486977: val_loss -1.0518
2023-09-02 04:13:36.488137: Pseudo dice [0.8128]
2023-09-02 04:13:36.488995: Epoch time: 111.3 s
2023-09-02 04:13:37.660479: 
2023-09-02 04:13:37.662088: Epoch 48
2023-09-02 04:13:37.662924: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-02 04:13:37.664077: start training, 250
================num of epochs: 250================
2023-09-02 04:14:35.645327: finished training
epoch: 48, dataset: CVC-300, dice: 0.8762683333333333
CVC-300 :  0.8762683333333333
epoch: 48, dataset: CVC-ClinicDB, dice: 0.8704112903225806
CVC-ClinicDB :  0.8704112903225806
epoch: 48, dataset: Kvasir, dice: 0.8912929999999999
Kvasir :  0.8912929999999999
epoch: 48, dataset: CVC-ColonDB, dice: 0.6982784210526322
CVC-ColonDB :  0.6982784210526322
epoch: 48, dataset: ETIS-LaribPolypDB, dice: 0.7462545918367348
ETIS-LaribPolypDB :  0.7462545918367348
2023-09-02 04:15:28.804697: train_loss -1.4412
2023-09-02 04:15:28.806223: val_loss -1.0582
2023-09-02 04:15:28.807315: Pseudo dice [0.8191]
2023-09-02 04:15:28.808140: Epoch time: 111.15 s
2023-09-02 04:15:30.000202: 
2023-09-02 04:15:30.001476: Epoch 49
2023-09-02 04:15:30.002291: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-02 04:15:30.003573: start training, 250
================num of epochs: 250================
2023-09-02 04:16:28.250966: finished training
epoch: 49, dataset: CVC-300, dice: 0.8417033333333332
CVC-300 :  0.8417033333333332
epoch: 49, dataset: CVC-ClinicDB, dice: 0.8723177419354838
CVC-ClinicDB :  0.8723177419354838
epoch: 49, dataset: Kvasir, dice: 0.89248
Kvasir :  0.89248
epoch: 49, dataset: CVC-ColonDB, dice: 0.6721734210526323
CVC-ColonDB :  0.6721734210526323
epoch: 49, dataset: ETIS-LaribPolypDB, dice: 0.7152454081632655
ETIS-LaribPolypDB :  0.7152454081632655
2023-09-02 04:17:21.317438: train_loss -1.4422
2023-09-02 04:17:21.318743: val_loss -1.0297
2023-09-02 04:17:21.319821: Pseudo dice [0.8139]
2023-09-02 04:17:21.320700: Epoch time: 111.32 s
2023-09-02 04:17:24.123976: 
2023-09-02 04:17:24.125290: Epoch 50
2023-09-02 04:17:24.126122: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-02 04:17:24.127229: start training, 250
================num of epochs: 250================
2023-09-02 04:18:22.105881: finished training
epoch: 50, dataset: CVC-300, dice: 0.8857166666666668
CVC-300 :  0.8857166666666668
epoch: 50, dataset: CVC-ClinicDB, dice: 0.8500983870967743
CVC-ClinicDB :  0.8500983870967743
epoch: 50, dataset: Kvasir, dice: 0.8943070000000003
Kvasir :  0.8943070000000003
epoch: 50, dataset: CVC-ColonDB, dice: 0.7089865789473683
CVC-ColonDB :  0.7089865789473683
epoch: 50, dataset: ETIS-LaribPolypDB, dice: 0.7509367346938775
ETIS-LaribPolypDB :  0.7509367346938775
2023-09-02 04:19:15.573214: train_loss -1.442
2023-09-02 04:19:15.574741: val_loss -1.0205
2023-09-02 04:19:15.576032: Pseudo dice [0.8071]
2023-09-02 04:19:15.576913: Epoch time: 111.45 s
2023-09-02 04:19:16.772115: 
2023-09-02 04:19:16.773383: Epoch 51
2023-09-02 04:19:16.774244: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-02 04:19:16.775449: start training, 250
================num of epochs: 250================
2023-09-02 04:20:14.751872: finished training
epoch: 51, dataset: CVC-300, dice: 0.8832533333333333
CVC-300 :  0.8832533333333333
epoch: 51, dataset: CVC-ClinicDB, dice: 0.8717209677419354
CVC-ClinicDB :  0.8717209677419354
epoch: 51, dataset: Kvasir, dice: 0.9001210000000001
Kvasir :  0.9001210000000001
epoch: 51, dataset: CVC-ColonDB, dice: 0.6954436842105275
CVC-ColonDB :  0.6954436842105275
epoch: 51, dataset: ETIS-LaribPolypDB, dice: 0.73844081632653
ETIS-LaribPolypDB :  0.73844081632653
2023-09-02 04:21:07.917425: train_loss -1.4434
2023-09-02 04:21:07.919007: val_loss -1.0379
2023-09-02 04:21:07.920180: Pseudo dice [0.816]
2023-09-02 04:21:07.920999: Epoch time: 111.15 s
2023-09-02 04:21:09.113967: 
2023-09-02 04:21:09.115513: Epoch 52
2023-09-02 04:21:09.116374: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-02 04:21:09.117558: start training, 250
================num of epochs: 250================
2023-09-02 04:22:07.809620: finished training
epoch: 52, dataset: CVC-300, dice: 0.8735650000000003
CVC-300 :  0.8735650000000003
epoch: 52, dataset: CVC-ClinicDB, dice: 0.8762951612903225
CVC-ClinicDB :  0.8762951612903225
epoch: 52, dataset: Kvasir, dice: 0.901136
Kvasir :  0.901136
epoch: 52, dataset: CVC-ColonDB, dice: 0.7194710526315782
CVC-ColonDB :  0.7194710526315782
epoch: 52, dataset: ETIS-LaribPolypDB, dice: 0.730088775510204
ETIS-LaribPolypDB :  0.730088775510204
2023-09-02 04:23:02.682569: train_loss -1.4447
2023-09-02 04:23:02.684016: val_loss -1.0411
2023-09-02 04:23:02.685050: Pseudo dice [0.824]
2023-09-02 04:23:02.685865: Epoch time: 113.57 s
2023-09-02 04:23:03.881960: 
2023-09-02 04:23:03.883307: Epoch 53
2023-09-02 04:23:03.884202: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-02 04:23:03.885435: start training, 250
================num of epochs: 250================
2023-09-02 04:24:01.955108: finished training
epoch: 53, dataset: CVC-300, dice: 0.8642533333333332
CVC-300 :  0.8642533333333332
epoch: 53, dataset: CVC-ClinicDB, dice: 0.8708241935483867
CVC-ClinicDB :  0.8708241935483867
epoch: 53, dataset: Kvasir, dice: 0.8829120000000005
Kvasir :  0.8829120000000005
epoch: 53, dataset: CVC-ColonDB, dice: 0.6901105263157896
CVC-ColonDB :  0.6901105263157896
epoch: 53, dataset: ETIS-LaribPolypDB, dice: 0.7301234693877552
ETIS-LaribPolypDB :  0.7301234693877552
2023-09-02 04:24:54.999510: train_loss -1.445
2023-09-02 04:24:55.000739: val_loss -1.1058
2023-09-02 04:24:55.001746: Pseudo dice [0.8363]
2023-09-02 04:24:55.002611: Epoch time: 111.12 s
2023-09-02 04:24:56.196068: 
2023-09-02 04:24:56.197403: Epoch 54
2023-09-02 04:24:56.198239: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-02 04:24:56.199436: start training, 250
================num of epochs: 250================
2023-09-02 04:25:54.225529: finished training
epoch: 54, dataset: CVC-300, dice: 0.8605400000000002
CVC-300 :  0.8605400000000002
epoch: 54, dataset: CVC-ClinicDB, dice: 0.8604241935483868
CVC-ClinicDB :  0.8604241935483868
epoch: 54, dataset: Kvasir, dice: 0.8898810000000004
Kvasir :  0.8898810000000004
epoch: 54, dataset: CVC-ColonDB, dice: 0.6972813157894738
CVC-ColonDB :  0.6972813157894738
epoch: 54, dataset: ETIS-LaribPolypDB, dice: 0.7528795918367345
ETIS-LaribPolypDB :  0.7528795918367345
2023-09-02 04:26:48.095454: train_loss -1.4446
2023-09-02 04:26:48.096715: val_loss -1.1175
2023-09-02 04:26:48.097784: Pseudo dice [0.849]
2023-09-02 04:26:48.098620: Epoch time: 111.9 s
2023-09-02 04:26:48.099390: Yayy! New best EMA pseudo Dice: 0.8232
2023-09-02 04:26:51.258399: 
2023-09-02 04:26:51.259744: Epoch 55
2023-09-02 04:26:51.260596: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-02 04:26:51.261759: start training, 250
================num of epochs: 250================
2023-09-02 04:27:49.342033: finished training
epoch: 55, dataset: CVC-300, dice: 0.8746200000000001
CVC-300 :  0.8746200000000001
epoch: 55, dataset: CVC-ClinicDB, dice: 0.8643000000000005
CVC-ClinicDB :  0.8643000000000005
epoch: 55, dataset: Kvasir, dice: 0.8942510000000001
Kvasir :  0.8942510000000001
epoch: 55, dataset: CVC-ColonDB, dice: 0.6830821052631584
CVC-ColonDB :  0.6830821052631584
epoch: 55, dataset: ETIS-LaribPolypDB, dice: 0.7135234693877559
ETIS-LaribPolypDB :  0.7135234693877559
2023-09-02 04:28:46.582732: train_loss -1.4445
2023-09-02 04:28:46.584227: val_loss -1.0339
2023-09-02 04:28:46.585459: Pseudo dice [0.8169]
2023-09-02 04:28:46.586344: Epoch time: 115.33 s
2023-09-02 04:28:47.774771: 
2023-09-02 04:28:47.776126: Epoch 56
2023-09-02 04:28:47.776988: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-02 04:28:47.778284: start training, 250
================num of epochs: 250================
2023-09-02 04:29:45.889246: finished training
epoch: 56, dataset: CVC-300, dice: 0.8785916666666668
CVC-300 :  0.8785916666666668
epoch: 56, dataset: CVC-ClinicDB, dice: 0.8677564516129036
CVC-ClinicDB :  0.8677564516129036
epoch: 56, dataset: Kvasir, dice: 0.9014900000000005
Kvasir :  0.9014900000000005
epoch: 56, dataset: CVC-ColonDB, dice: 0.7087173684210527
CVC-ColonDB :  0.7087173684210527
epoch: 56, dataset: ETIS-LaribPolypDB, dice: 0.7171857142857136
ETIS-LaribPolypDB :  0.7171857142857136
2023-09-02 04:30:41.883424: train_loss -1.4463
2023-09-02 04:30:41.884701: val_loss -0.9727
2023-09-02 04:30:41.885716: Pseudo dice [0.8023]
2023-09-02 04:30:41.886539: Epoch time: 114.11 s
2023-09-02 04:30:43.082138: 
2023-09-02 04:30:43.084326: Epoch 57
2023-09-02 04:30:43.086134: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-02 04:30:43.088319: start training, 250
================num of epochs: 250================
2023-09-02 04:31:41.332511: finished training
epoch: 57, dataset: CVC-300, dice: 0.8845066666666666
CVC-300 :  0.8845066666666666
epoch: 57, dataset: CVC-ClinicDB, dice: 0.8624451612903224
CVC-ClinicDB :  0.8624451612903224
epoch: 57, dataset: Kvasir, dice: 0.9056330000000001
Kvasir :  0.9056330000000001
epoch: 57, dataset: CVC-ColonDB, dice: 0.7006936842105274
CVC-ColonDB :  0.7006936842105274
epoch: 57, dataset: ETIS-LaribPolypDB, dice: 0.7198510204081634
ETIS-LaribPolypDB :  0.7198510204081634
2023-09-02 04:32:36.698970: train_loss -1.4469
2023-09-02 04:32:36.700316: val_loss -1.0708
2023-09-02 04:32:36.701469: Pseudo dice [0.828]
2023-09-02 04:32:36.702356: Epoch time: 113.62 s
2023-09-02 04:32:37.962039: 
2023-09-02 04:32:37.963604: Epoch 58
2023-09-02 04:32:37.964601: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-02 04:32:37.966291: start training, 250
================num of epochs: 250================
2023-09-02 04:33:36.238544: finished training
epoch: 58, dataset: CVC-300, dice: 0.8725466666666666
CVC-300 :  0.8725466666666666
epoch: 58, dataset: CVC-ClinicDB, dice: 0.8644080645161287
CVC-ClinicDB :  0.8644080645161287
epoch: 58, dataset: Kvasir, dice: 0.8933060000000002
Kvasir :  0.8933060000000002
epoch: 58, dataset: CVC-ColonDB, dice: 0.6931000000000003
CVC-ColonDB :  0.6931000000000003
epoch: 58, dataset: ETIS-LaribPolypDB, dice: 0.741127040816327
ETIS-LaribPolypDB :  0.741127040816327
2023-09-02 04:34:26.830824: train_loss -1.4483
2023-09-02 04:34:26.832529: val_loss -1.0582
2023-09-02 04:34:26.833636: Pseudo dice [0.828]
2023-09-02 04:34:26.834521: Epoch time: 108.87 s
2023-09-02 04:34:28.055236: 
2023-09-02 04:34:28.056742: Epoch 59
2023-09-02 04:34:28.057627: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-02 04:34:28.058849: start training, 250
================num of epochs: 250================
2023-09-02 04:35:26.128489: finished training
epoch: 59, dataset: CVC-300, dice: 0.8807216666666666
CVC-300 :  0.8807216666666666
epoch: 59, dataset: CVC-ClinicDB, dice: 0.8675177419354838
CVC-ClinicDB :  0.8675177419354838
epoch: 59, dataset: Kvasir, dice: 0.9010490000000003
Kvasir :  0.9010490000000003
epoch: 59, dataset: CVC-ColonDB, dice: 0.7078036842105269
CVC-ColonDB :  0.7078036842105269
epoch: 59, dataset: ETIS-LaribPolypDB, dice: 0.7289872448979599
ETIS-LaribPolypDB :  0.7289872448979599
2023-09-02 04:36:18.467782: train_loss -1.4484
2023-09-02 04:36:18.469325: val_loss -1.0684
2023-09-02 04:36:18.470446: Pseudo dice [0.8281]
2023-09-02 04:36:18.471360: Epoch time: 110.41 s
2023-09-02 04:36:21.300315: 
2023-09-02 04:36:21.301807: Epoch 60
2023-09-02 04:36:21.302677: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-02 04:36:21.303880: start training, 250
================num of epochs: 250================
2023-09-02 04:37:19.288219: finished training
epoch: 60, dataset: CVC-300, dice: 0.88234
CVC-300 :  0.88234
epoch: 60, dataset: CVC-ClinicDB, dice: 0.8647483870967739
CVC-ClinicDB :  0.8647483870967739
epoch: 60, dataset: Kvasir, dice: 0.9046379999999995
Kvasir :  0.9046379999999995
epoch: 60, dataset: CVC-ColonDB, dice: 0.7028694736842105
CVC-ColonDB :  0.7028694736842105
epoch: 60, dataset: ETIS-LaribPolypDB, dice: 0.726939285714286
ETIS-LaribPolypDB :  0.726939285714286
2023-09-02 04:38:11.013542: train_loss -1.4497
2023-09-02 04:38:11.014981: val_loss -1.0554
2023-09-02 04:38:11.016012: Pseudo dice [0.8216]
2023-09-02 04:38:11.016840: Epoch time: 109.71 s
2023-09-02 04:38:12.238116: 
2023-09-02 04:38:12.243390: Epoch 61
2023-09-02 04:38:12.244288: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-02 04:38:12.245577: start training, 250
================num of epochs: 250================
2023-09-02 04:39:10.387152: finished training
epoch: 61, dataset: CVC-300, dice: 0.8782400000000001
CVC-300 :  0.8782400000000001
epoch: 61, dataset: CVC-ClinicDB, dice: 0.8644580645161289
CVC-ClinicDB :  0.8644580645161289
epoch: 61, dataset: Kvasir, dice: 0.8975899999999997
Kvasir :  0.8975899999999997
epoch: 61, dataset: CVC-ColonDB, dice: 0.7012507894736851
CVC-ColonDB :  0.7012507894736851
epoch: 61, dataset: ETIS-LaribPolypDB, dice: 0.7308306122448984
ETIS-LaribPolypDB :  0.7308306122448984
2023-09-02 04:40:02.614463: train_loss -1.4493
2023-09-02 04:40:02.615822: val_loss -1.0536
2023-09-02 04:40:02.616891: Pseudo dice [0.8309]
2023-09-02 04:40:02.617768: Epoch time: 110.38 s
2023-09-02 04:40:02.618561: Yayy! New best EMA pseudo Dice: 0.8233
2023-09-02 04:40:05.542680: 
2023-09-02 04:40:05.544119: Epoch 62
2023-09-02 04:40:05.544960: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-02 04:40:05.546157: start training, 250
================num of epochs: 250================
2023-09-02 04:41:03.587245: finished training
epoch: 62, dataset: CVC-300, dice: 0.8863383333333336
CVC-300 :  0.8863383333333336
epoch: 62, dataset: CVC-ClinicDB, dice: 0.8634048387096774
CVC-ClinicDB :  0.8634048387096774
epoch: 62, dataset: Kvasir, dice: 0.8970589999999997
Kvasir :  0.8970589999999997
epoch: 62, dataset: CVC-ColonDB, dice: 0.7047155263157893
CVC-ColonDB :  0.7047155263157893
epoch: 62, dataset: ETIS-LaribPolypDB, dice: 0.7440923469387757
ETIS-LaribPolypDB :  0.7440923469387757
2023-09-02 04:41:55.165855: train_loss -1.45
2023-09-02 04:41:55.167357: val_loss -1.0221
2023-09-02 04:41:55.168470: Pseudo dice [0.8193]
2023-09-02 04:41:55.169298: Epoch time: 109.62 s
2023-09-02 04:41:56.371532: 
2023-09-02 04:41:56.372900: Epoch 63
2023-09-02 04:41:56.373752: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-02 04:41:56.374960: start training, 250
================num of epochs: 250================
2023-09-02 04:42:54.499228: finished training
epoch: 63, dataset: CVC-300, dice: 0.8791783333333332
CVC-300 :  0.8791783333333332
epoch: 63, dataset: CVC-ClinicDB, dice: 0.8637854838709678
CVC-ClinicDB :  0.8637854838709678
epoch: 63, dataset: Kvasir, dice: 0.8908879999999998
Kvasir :  0.8908879999999998
epoch: 63, dataset: CVC-ColonDB, dice: 0.7074755263157892
CVC-ColonDB :  0.7074755263157892
epoch: 63, dataset: ETIS-LaribPolypDB, dice: 0.7479566326530611
ETIS-LaribPolypDB :  0.7479566326530611
2023-09-02 04:43:46.327613: train_loss -1.4496
2023-09-02 04:43:46.328940: val_loss -1.121
2023-09-02 04:43:46.330058: Pseudo dice [0.8477]
2023-09-02 04:43:46.330896: Epoch time: 109.96 s
2023-09-02 04:43:46.331649: Yayy! New best EMA pseudo Dice: 0.8254
2023-09-02 04:43:49.197389: 
2023-09-02 04:43:49.198750: Epoch 64
2023-09-02 04:43:49.199596: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-02 04:43:49.200793: start training, 250
================num of epochs: 250================
2023-09-02 04:44:47.375359: finished training
epoch: 64, dataset: CVC-300, dice: 0.8625633333333333
CVC-300 :  0.8625633333333333
epoch: 64, dataset: CVC-ClinicDB, dice: 0.8356516129032255
CVC-ClinicDB :  0.8356516129032255
epoch: 64, dataset: Kvasir, dice: 0.860008
Kvasir :  0.860008
epoch: 64, dataset: CVC-ColonDB, dice: 0.666447631578947
CVC-ColonDB :  0.666447631578947
epoch: 64, dataset: ETIS-LaribPolypDB, dice: 0.7083051020408168
ETIS-LaribPolypDB :  0.7083051020408168
2023-09-02 04:45:40.017364: train_loss -1.4462
2023-09-02 04:45:40.018733: val_loss -1.1605
2023-09-02 04:45:40.019790: Pseudo dice [0.8612]
2023-09-02 04:45:40.020610: Epoch time: 110.82 s
2023-09-02 04:45:40.021364: Yayy! New best EMA pseudo Dice: 0.829
2023-09-02 04:45:42.842069: 
2023-09-02 04:45:42.843435: Epoch 65
2023-09-02 04:45:42.844320: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-02 04:45:42.845597: start training, 250
================num of epochs: 250================
2023-09-02 04:46:40.802166: finished training
epoch: 65, dataset: CVC-300, dice: 0.8665916666666665
CVC-300 :  0.8665916666666665
epoch: 65, dataset: CVC-ClinicDB, dice: 0.8554709677419355
CVC-ClinicDB :  0.8554709677419355
epoch: 65, dataset: Kvasir, dice: 0.8888430000000005
Kvasir :  0.8888430000000005
epoch: 65, dataset: CVC-ColonDB, dice: 0.6775136842105267
CVC-ColonDB :  0.6775136842105267
epoch: 65, dataset: ETIS-LaribPolypDB, dice: 0.7117612244897962
ETIS-LaribPolypDB :  0.7117612244897962
2023-09-02 04:47:33.299113: train_loss -1.4406
2023-09-02 04:47:33.300476: val_loss -0.9885
2023-09-02 04:47:33.301604: Pseudo dice [0.7943]
2023-09-02 04:47:33.302545: Epoch time: 110.46 s
2023-09-02 04:47:34.510453: 
2023-09-02 04:47:34.511743: Epoch 66
2023-09-02 04:47:34.512821: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-02 04:47:34.514063: start training, 250
================num of epochs: 250================
2023-09-02 04:48:32.463430: finished training
epoch: 66, dataset: CVC-300, dice: 0.8642399999999998
CVC-300 :  0.8642399999999998
epoch: 66, dataset: CVC-ClinicDB, dice: 0.8573677419354837
CVC-ClinicDB :  0.8573677419354837
epoch: 66, dataset: Kvasir, dice: 0.8939770000000001
Kvasir :  0.8939770000000001
epoch: 66, dataset: CVC-ColonDB, dice: 0.7040236842105267
CVC-ColonDB :  0.7040236842105267
epoch: 66, dataset: ETIS-LaribPolypDB, dice: 0.7353913265306125
ETIS-LaribPolypDB :  0.7353913265306125
2023-09-02 04:49:25.636787: train_loss -1.446
2023-09-02 04:49:25.638117: val_loss -0.9849
2023-09-02 04:49:25.639199: Pseudo dice [0.7977]
2023-09-02 04:49:25.640027: Epoch time: 111.13 s
2023-09-02 04:49:26.844985: 
2023-09-02 04:49:26.846411: Epoch 67
2023-09-02 04:49:26.847307: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-02 04:49:26.848560: start training, 250
================num of epochs: 250================
2023-09-02 04:50:25.055950: finished training
epoch: 67, dataset: CVC-300, dice: 0.8747749999999997
CVC-300 :  0.8747749999999997
epoch: 67, dataset: CVC-ClinicDB, dice: 0.834274193548387
CVC-ClinicDB :  0.834274193548387
epoch: 67, dataset: Kvasir, dice: 0.884441
Kvasir :  0.884441
epoch: 67, dataset: CVC-ColonDB, dice: 0.6951513157894738
CVC-ColonDB :  0.6951513157894738
epoch: 67, dataset: ETIS-LaribPolypDB, dice: 0.7229311224489801
ETIS-LaribPolypDB :  0.7229311224489801
2023-09-02 04:51:20.271803: train_loss -1.4415
2023-09-02 04:51:20.273277: val_loss -1.0331
2023-09-02 04:51:20.274493: Pseudo dice [0.8089]
2023-09-02 04:51:20.275438: Epoch time: 113.43 s
2023-09-02 04:51:21.500212: 
2023-09-02 04:51:21.501646: Epoch 68
2023-09-02 04:51:21.502512: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-02 04:51:21.503808: start training, 250
================num of epochs: 250================
2023-09-02 04:52:19.446516: finished training
epoch: 68, dataset: CVC-300, dice: 0.8440366666666667
CVC-300 :  0.8440366666666667
epoch: 68, dataset: CVC-ClinicDB, dice: 0.8559435483870966
CVC-ClinicDB :  0.8559435483870966
epoch: 68, dataset: Kvasir, dice: 0.8917930000000002
Kvasir :  0.8917930000000002
epoch: 68, dataset: CVC-ColonDB, dice: 0.7196371052631587
CVC-ColonDB :  0.7196371052631587
epoch: 68, dataset: ETIS-LaribPolypDB, dice: 0.7190591836734693
ETIS-LaribPolypDB :  0.7190591836734693
2023-09-02 04:53:13.434120: train_loss -1.4457
2023-09-02 04:53:13.435802: val_loss -1.0332
2023-09-02 04:53:13.436941: Pseudo dice [0.8062]
2023-09-02 04:53:13.437873: Epoch time: 111.94 s
2023-09-02 04:53:14.646212: 
2023-09-02 04:53:14.647650: Epoch 69
2023-09-02 04:53:14.648531: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-02 04:53:14.649755: start training, 250
================num of epochs: 250================
2023-09-02 04:54:12.569540: finished training
epoch: 69, dataset: CVC-300, dice: 0.8460916666666668
CVC-300 :  0.8460916666666668
epoch: 69, dataset: CVC-ClinicDB, dice: 0.8507387096774194
CVC-ClinicDB :  0.8507387096774194
epoch: 69, dataset: Kvasir, dice: 0.8888300000000002
Kvasir :  0.8888300000000002
epoch: 69, dataset: CVC-ColonDB, dice: 0.719235000000001
CVC-ColonDB :  0.719235000000001
epoch: 69, dataset: ETIS-LaribPolypDB, dice: 0.7157443877551019
ETIS-LaribPolypDB :  0.7157443877551019
2023-09-02 04:55:06.417792: train_loss -1.4491
2023-09-02 04:55:06.419156: val_loss -1.1046
2023-09-02 04:55:06.420282: Pseudo dice [0.8408]
2023-09-02 04:55:06.421169: Epoch time: 111.77 s
2023-09-02 04:55:09.475941: 
2023-09-02 04:55:09.477220: Epoch 70
2023-09-02 04:55:09.478278: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-02 04:55:09.479456: start training, 250
================num of epochs: 250================
2023-09-02 04:56:07.524991: finished training
epoch: 70, dataset: CVC-300, dice: 0.8631899999999998
CVC-300 :  0.8631899999999998
epoch: 70, dataset: CVC-ClinicDB, dice: 0.8481919354838708
CVC-ClinicDB :  0.8481919354838708
epoch: 70, dataset: Kvasir, dice: 0.891909
Kvasir :  0.891909
epoch: 70, dataset: CVC-ColonDB, dice: 0.7087436842105256
CVC-ColonDB :  0.7087436842105256
epoch: 70, dataset: ETIS-LaribPolypDB, dice: 0.7245586734693877
ETIS-LaribPolypDB :  0.7245586734693877
2023-09-02 04:57:02.036668: train_loss -1.4521
2023-09-02 04:57:02.038065: val_loss -1.063
2023-09-02 04:57:02.039247: Pseudo dice [0.825]
2023-09-02 04:57:02.040159: Epoch time: 112.56 s
2023-09-02 04:57:03.256729: 
2023-09-02 04:57:03.258193: Epoch 71
2023-09-02 04:57:03.259100: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-02 04:57:03.260379: start training, 250
================num of epochs: 250================
2023-09-02 04:58:01.196481: finished training
epoch: 71, dataset: CVC-300, dice: 0.8586383333333335
CVC-300 :  0.8586383333333335
epoch: 71, dataset: CVC-ClinicDB, dice: 0.8498967741935483
CVC-ClinicDB :  0.8498967741935483
epoch: 71, dataset: Kvasir, dice: 0.8942859999999999
Kvasir :  0.8942859999999999
epoch: 71, dataset: CVC-ColonDB, dice: 0.7155871052631587
CVC-ColonDB :  0.7155871052631587
epoch: 71, dataset: ETIS-LaribPolypDB, dice: 0.714766836734694
ETIS-LaribPolypDB :  0.714766836734694
2023-09-02 04:58:55.848932: train_loss -1.452
2023-09-02 04:58:55.850330: val_loss -1.0829
2023-09-02 04:58:55.851392: Pseudo dice [0.8414]
2023-09-02 04:58:55.852263: Epoch time: 112.59 s
2023-09-02 04:58:57.058467: 
2023-09-02 04:58:57.059807: Epoch 72
2023-09-02 04:58:57.060782: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-02 04:58:57.062100: start training, 250
================num of epochs: 250================
2023-09-02 04:59:55.239400: finished training
epoch: 72, dataset: CVC-300, dice: 0.8815316666666667
CVC-300 :  0.8815316666666667
epoch: 72, dataset: CVC-ClinicDB, dice: 0.8524951612903225
CVC-ClinicDB :  0.8524951612903225
epoch: 72, dataset: Kvasir, dice: 0.8979180000000001
Kvasir :  0.8979180000000001
epoch: 72, dataset: CVC-ColonDB, dice: 0.7253210526315785
CVC-ColonDB :  0.7253210526315785
epoch: 72, dataset: ETIS-LaribPolypDB, dice: 0.7244076530612248
ETIS-LaribPolypDB :  0.7244076530612248
2023-09-02 05:00:49.930697: train_loss -1.4509
2023-09-02 05:00:49.932110: val_loss -1.0496
2023-09-02 05:00:49.933219: Pseudo dice [0.8213]
2023-09-02 05:00:49.934120: Epoch time: 112.87 s
2023-09-02 05:00:51.144048: 
2023-09-02 05:00:51.145387: Epoch 73
2023-09-02 05:00:51.146291: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-02 05:00:51.147674: start training, 250
================num of epochs: 250================
2023-09-02 05:01:49.344505: finished training
epoch: 73, dataset: CVC-300, dice: 0.8456083333333333
CVC-300 :  0.8456083333333333
epoch: 73, dataset: CVC-ClinicDB, dice: 0.8455209677419353
CVC-ClinicDB :  0.8455209677419353
epoch: 73, dataset: Kvasir, dice: 0.884498
Kvasir :  0.884498
epoch: 73, dataset: CVC-ColonDB, dice: 0.6916634210526315
CVC-ColonDB :  0.6916634210526315
epoch: 73, dataset: ETIS-LaribPolypDB, dice: 0.6939908163265303
ETIS-LaribPolypDB :  0.6939908163265303
2023-09-02 05:02:43.552934: train_loss -1.4436
2023-09-02 05:02:43.554405: val_loss -0.9979
2023-09-02 05:02:43.555605: Pseudo dice [0.7859]
2023-09-02 05:02:43.556503: Epoch time: 112.41 s
2023-09-02 05:02:44.770190: 
2023-09-02 05:02:44.771764: Epoch 74
2023-09-02 05:02:44.772693: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-02 05:02:44.774001: start training, 250
================num of epochs: 250================
2023-09-02 05:03:42.621532: finished training
epoch: 74, dataset: CVC-300, dice: 0.7105049999999999
CVC-300 :  0.7105049999999999
epoch: 74, dataset: CVC-ClinicDB, dice: 0.8268129032258067
CVC-ClinicDB :  0.8268129032258067
epoch: 74, dataset: Kvasir, dice: 0.8691840000000007
Kvasir :  0.8691840000000007
epoch: 74, dataset: CVC-ColonDB, dice: 0.628490263157895
CVC-ColonDB :  0.628490263157895
epoch: 74, dataset: ETIS-LaribPolypDB, dice: 0.6250183673469388
ETIS-LaribPolypDB :  0.6250183673469388
2023-09-02 05:04:36.810954: train_loss -1.4439
2023-09-02 05:04:36.812906: val_loss -1.0239
2023-09-02 05:04:36.814595: Pseudo dice [0.8045]
2023-09-02 05:04:36.815603: Epoch time: 112.04 s
2023-09-02 05:04:38.045695: 
2023-09-02 05:04:38.047184: Epoch 75
2023-09-02 05:04:38.048076: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-02 05:04:38.049272: start training, 250
================num of epochs: 250================
2023-09-02 05:05:35.958440: finished training
epoch: 75, dataset: CVC-300, dice: 0.8703383333333331
CVC-300 :  0.8703383333333331
epoch: 75, dataset: CVC-ClinicDB, dice: 0.8537193548387095
CVC-ClinicDB :  0.8537193548387095
epoch: 75, dataset: Kvasir, dice: 0.894884
Kvasir :  0.894884
epoch: 75, dataset: CVC-ColonDB, dice: 0.7200513157894732
CVC-ColonDB :  0.7200513157894732
epoch: 75, dataset: ETIS-LaribPolypDB, dice: 0.7115596938775509
ETIS-LaribPolypDB :  0.7115596938775509
2023-09-02 05:06:30.607720: train_loss -1.4428
2023-09-02 05:06:30.609122: val_loss -1.1067
2023-09-02 05:06:30.610249: Pseudo dice [0.8368]
2023-09-02 05:06:30.611157: Epoch time: 112.56 s
2023-09-02 05:06:31.842249: 
2023-09-02 05:06:31.843590: Epoch 76
2023-09-02 05:06:31.844654: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-02 05:06:31.845911: start training, 250
================num of epochs: 250================
2023-09-02 05:07:29.955467: finished training
epoch: 76, dataset: CVC-300, dice: 0.8227816666666664
CVC-300 :  0.8227816666666664
epoch: 76, dataset: CVC-ClinicDB, dice: 0.8707016129032258
CVC-ClinicDB :  0.8707016129032258
epoch: 76, dataset: Kvasir, dice: 0.8854359999999997
Kvasir :  0.8854359999999997
epoch: 76, dataset: CVC-ColonDB, dice: 0.7044550000000002
CVC-ColonDB :  0.7044550000000002
epoch: 76, dataset: ETIS-LaribPolypDB, dice: 0.7281025510204083
ETIS-LaribPolypDB :  0.7281025510204083
2023-09-02 05:08:24.220673: train_loss -1.446
2023-09-02 05:08:24.222196: val_loss -1.0801
2023-09-02 05:08:24.223434: Pseudo dice [0.8308]
2023-09-02 05:08:24.224411: Epoch time: 112.38 s
2023-09-02 05:08:25.486941: 
2023-09-02 05:08:25.488440: Epoch 77
2023-09-02 05:08:25.489323: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-02 05:08:25.490648: start training, 250
================num of epochs: 250================
2023-09-02 05:09:23.347411: finished training
epoch: 77, dataset: CVC-300, dice: 0.8352033333333336
CVC-300 :  0.8352033333333336
epoch: 77, dataset: CVC-ClinicDB, dice: 0.8646322580645165
CVC-ClinicDB :  0.8646322580645165
epoch: 77, dataset: Kvasir, dice: 0.8897290000000001
Kvasir :  0.8897290000000001
epoch: 77, dataset: CVC-ColonDB, dice: 0.7299702631578949
CVC-ColonDB :  0.7299702631578949
epoch: 77, dataset: ETIS-LaribPolypDB, dice: 0.7052474489795922
ETIS-LaribPolypDB :  0.7052474489795922
2023-09-02 05:10:16.479412: train_loss -1.4494
2023-09-02 05:10:16.480919: val_loss -1.0216
2023-09-02 05:10:16.482155: Pseudo dice [0.81]
2023-09-02 05:10:16.483058: Epoch time: 110.99 s
2023-09-02 05:10:17.730540: 
2023-09-02 05:10:17.732043: Epoch 78
2023-09-02 05:10:17.732973: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-02 05:10:17.734227: start training, 250
================num of epochs: 250================
2023-09-02 05:11:15.614532: finished training
epoch: 78, dataset: CVC-300, dice: 0.8583399999999999
CVC-300 :  0.8583399999999999
epoch: 78, dataset: CVC-ClinicDB, dice: 0.8577354838709677
CVC-ClinicDB :  0.8577354838709677
epoch: 78, dataset: Kvasir, dice: 0.8944489999999999
Kvasir :  0.8944489999999999
epoch: 78, dataset: CVC-ColonDB, dice: 0.7307905263157892
CVC-ColonDB :  0.7307905263157892
epoch: 78, dataset: ETIS-LaribPolypDB, dice: 0.7228423469387758
ETIS-LaribPolypDB :  0.7228423469387758
2023-09-02 05:12:09.138538: train_loss -1.451
2023-09-02 05:12:09.139878: val_loss -1.1068
2023-09-02 05:12:09.141004: Pseudo dice [0.8419]
2023-09-02 05:12:09.141941: Epoch time: 111.41 s
2023-09-02 05:12:10.395175: 
2023-09-02 05:12:10.396703: Epoch 79
2023-09-02 05:12:10.397632: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-02 05:12:10.398947: start training, 250
================num of epochs: 250================
2023-09-02 05:13:08.630618: finished training
epoch: 79, dataset: CVC-300, dice: 0.8562116666666666
CVC-300 :  0.8562116666666666
epoch: 79, dataset: CVC-ClinicDB, dice: 0.8553306451612902
CVC-ClinicDB :  0.8553306451612902
epoch: 79, dataset: Kvasir, dice: 0.898881
Kvasir :  0.898881
epoch: 79, dataset: CVC-ColonDB, dice: 0.7229905263157902
CVC-ColonDB :  0.7229905263157902
epoch: 79, dataset: ETIS-LaribPolypDB, dice: 0.7067234693877551
ETIS-LaribPolypDB :  0.7067234693877551
2023-09-02 05:14:02.051163: train_loss -1.4521
2023-09-02 05:14:02.052692: val_loss -1.087
2023-09-02 05:14:02.053850: Pseudo dice [0.832]
2023-09-02 05:14:02.054725: Epoch time: 111.66 s
2023-09-02 05:14:04.925722: 
2023-09-02 05:14:04.927176: Epoch 80
2023-09-02 05:14:04.928087: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-02 05:14:04.929502: start training, 250
================num of epochs: 250================
2023-09-02 05:15:02.866148: finished training
epoch: 80, dataset: CVC-300, dice: 0.8610716666666666
CVC-300 :  0.8610716666666666
epoch: 80, dataset: CVC-ClinicDB, dice: 0.8617258064516128
CVC-ClinicDB :  0.8617258064516128
epoch: 80, dataset: Kvasir, dice: 0.8899219999999995
Kvasir :  0.8899219999999995
epoch: 80, dataset: CVC-ColonDB, dice: 0.7265702631578953
CVC-ColonDB :  0.7265702631578953
epoch: 80, dataset: ETIS-LaribPolypDB, dice: 0.7268602040816324
ETIS-LaribPolypDB :  0.7268602040816324
2023-09-02 05:15:56.438125: train_loss -1.4539
2023-09-02 05:15:56.439675: val_loss -1.0668
2023-09-02 05:15:56.440810: Pseudo dice [0.8278]
2023-09-02 05:15:56.441680: Epoch time: 111.51 s
2023-09-02 05:15:57.701434: 
2023-09-02 05:15:57.702944: Epoch 81
2023-09-02 05:15:57.703854: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-02 05:15:57.705118: start training, 250
================num of epochs: 250================
2023-09-02 05:16:55.708958: finished training
epoch: 81, dataset: CVC-300, dice: 0.8698333333333336
CVC-300 :  0.8698333333333336
epoch: 81, dataset: CVC-ClinicDB, dice: 0.8475177419354839
CVC-ClinicDB :  0.8475177419354839
epoch: 81, dataset: Kvasir, dice: 0.8964960000000005
Kvasir :  0.8964960000000005
epoch: 81, dataset: CVC-ColonDB, dice: 0.7055560526315793
CVC-ColonDB :  0.7055560526315793
epoch: 81, dataset: ETIS-LaribPolypDB, dice: 0.7205653061224492
ETIS-LaribPolypDB :  0.7205653061224492
2023-09-02 05:17:48.460592: train_loss -1.4538
2023-09-02 05:17:48.461896: val_loss -0.9896
2023-09-02 05:17:48.463024: Pseudo dice [0.8208]
2023-09-02 05:17:48.463860: Epoch time: 110.76 s
2023-09-02 05:17:49.718526: 
2023-09-02 05:17:49.719836: Epoch 82
2023-09-02 05:17:49.720808: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-02 05:17:49.722091: start training, 250
================num of epochs: 250================
2023-09-02 05:18:48.027425: finished training
epoch: 82, dataset: CVC-300, dice: 0.8625666666666665
CVC-300 :  0.8625666666666665
epoch: 82, dataset: CVC-ClinicDB, dice: 0.8554048387096774
CVC-ClinicDB :  0.8554048387096774
epoch: 82, dataset: Kvasir, dice: 0.8992789999999999
Kvasir :  0.8992789999999999
epoch: 82, dataset: CVC-ColonDB, dice: 0.7064202631578951
CVC-ColonDB :  0.7064202631578951
epoch: 82, dataset: ETIS-LaribPolypDB, dice: 0.7223663265306125
ETIS-LaribPolypDB :  0.7223663265306125
2023-09-02 05:19:41.483960: train_loss -1.4549
2023-09-02 05:19:41.485390: val_loss -1.0175
2023-09-02 05:19:41.486490: Pseudo dice [0.8169]
2023-09-02 05:19:41.487367: Epoch time: 111.77 s
2023-09-02 05:19:42.674117: 
2023-09-02 05:19:42.675621: Epoch 83
2023-09-02 05:19:42.676502: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-02 05:19:42.677707: start training, 250
================num of epochs: 250================
2023-09-02 05:20:40.758285: finished training
epoch: 83, dataset: CVC-300, dice: 0.8504816666666668
CVC-300 :  0.8504816666666668
epoch: 83, dataset: CVC-ClinicDB, dice: 0.8503096774193546
CVC-ClinicDB :  0.8503096774193546
epoch: 83, dataset: Kvasir, dice: 0.8921950000000001
Kvasir :  0.8921950000000001
epoch: 83, dataset: CVC-ColonDB, dice: 0.7092802631578947
CVC-ColonDB :  0.7092802631578947
epoch: 83, dataset: ETIS-LaribPolypDB, dice: 0.7197586734693877
ETIS-LaribPolypDB :  0.7197586734693877
2023-09-02 05:21:34.065556: train_loss -1.4546
2023-09-02 05:21:34.067025: val_loss -1.0829
2023-09-02 05:21:34.068218: Pseudo dice [0.8373]
2023-09-02 05:21:34.069323: Epoch time: 111.39 s
2023-09-02 05:21:35.254216: 
2023-09-02 05:21:35.255834: Epoch 84
2023-09-02 05:21:35.256833: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-02 05:21:35.258074: start training, 250
================num of epochs: 250================
2023-09-02 05:22:33.241061: finished training
epoch: 84, dataset: CVC-300, dice: 0.8601233333333335
CVC-300 :  0.8601233333333335
epoch: 84, dataset: CVC-ClinicDB, dice: 0.8590241935483869
CVC-ClinicDB :  0.8590241935483869
epoch: 84, dataset: Kvasir, dice: 0.8958020000000001
Kvasir :  0.8958020000000001
epoch: 84, dataset: CVC-ColonDB, dice: 0.7254005263157898
CVC-ColonDB :  0.7254005263157898
epoch: 84, dataset: ETIS-LaribPolypDB, dice: 0.7197918367346943
ETIS-LaribPolypDB :  0.7197918367346943
2023-09-02 05:23:26.300921: train_loss -1.4554
2023-09-02 05:23:26.302475: val_loss -1.0055
2023-09-02 05:23:26.303572: Pseudo dice [0.8062]
2023-09-02 05:23:26.304462: Epoch time: 111.05 s
2023-09-02 05:23:27.507062: 
2023-09-02 05:23:27.511731: Epoch 85
2023-09-02 05:23:27.512587: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-02 05:23:27.513829: start training, 250
================num of epochs: 250================
2023-09-02 05:24:25.730097: finished training
epoch: 85, dataset: CVC-300, dice: 0.8648750000000003
CVC-300 :  0.8648750000000003
epoch: 85, dataset: CVC-ClinicDB, dice: 0.8534258064516131
CVC-ClinicDB :  0.8534258064516131
epoch: 85, dataset: Kvasir, dice: 0.8964179999999999
Kvasir :  0.8964179999999999
epoch: 85, dataset: CVC-ColonDB, dice: 0.7188234210526324
CVC-ColonDB :  0.7188234210526324
epoch: 85, dataset: ETIS-LaribPolypDB, dice: 0.7286785714285718
ETIS-LaribPolypDB :  0.7286785714285718
2023-09-02 05:25:19.085873: train_loss -1.4551
2023-09-02 05:25:19.087355: val_loss -1.0891
2023-09-02 05:25:19.088535: Pseudo dice [0.8358]
2023-09-02 05:25:19.089507: Epoch time: 111.58 s
2023-09-02 05:25:20.267558: 
2023-09-02 05:25:20.269120: Epoch 86
2023-09-02 05:25:20.270059: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-02 05:25:20.271382: start training, 250
================num of epochs: 250================
2023-09-02 05:26:18.297608: finished training
epoch: 86, dataset: CVC-300, dice: 0.8678466666666667
CVC-300 :  0.8678466666666667
epoch: 86, dataset: CVC-ClinicDB, dice: 0.8552370967741935
CVC-ClinicDB :  0.8552370967741935
epoch: 86, dataset: Kvasir, dice: 0.8958000000000003
Kvasir :  0.8958000000000003
epoch: 86, dataset: CVC-ColonDB, dice: 0.7151823684210526
CVC-ColonDB :  0.7151823684210526
epoch: 86, dataset: ETIS-LaribPolypDB, dice: 0.7163423469387761
ETIS-LaribPolypDB :  0.7163423469387761
2023-09-02 05:27:11.226837: train_loss -1.4557
2023-09-02 05:27:11.228278: val_loss -1.0839
2023-09-02 05:27:11.229422: Pseudo dice [0.8292]
2023-09-02 05:27:11.230361: Epoch time: 110.96 s
2023-09-02 05:27:12.457013: 
2023-09-02 05:27:12.459448: Epoch 87
2023-09-02 05:27:12.460592: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-02 05:27:12.462152: start training, 250
================num of epochs: 250================
2023-09-02 05:28:10.499595: finished training
epoch: 87, dataset: CVC-300, dice: 0.851885
CVC-300 :  0.851885
epoch: 87, dataset: CVC-ClinicDB, dice: 0.8487112903225807
CVC-ClinicDB :  0.8487112903225807
epoch: 87, dataset: Kvasir, dice: 0.8984630000000001
Kvasir :  0.8984630000000001
epoch: 87, dataset: CVC-ColonDB, dice: 0.6993550000000005
CVC-ColonDB :  0.6993550000000005
epoch: 87, dataset: ETIS-LaribPolypDB, dice: 0.7120387755102038
ETIS-LaribPolypDB :  0.7120387755102038
2023-09-02 05:29:03.622475: train_loss -1.4554
2023-09-02 05:29:03.624011: val_loss -0.9079
2023-09-02 05:29:03.625196: Pseudo dice [0.7947]
2023-09-02 05:29:03.626094: Epoch time: 111.17 s
2023-09-02 05:29:04.855472: 
2023-09-02 05:29:04.857008: Epoch 88
2023-09-02 05:29:04.858082: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-02 05:29:04.859462: start training, 250
================num of epochs: 250================
2023-09-02 05:30:03.154176: finished training
epoch: 88, dataset: CVC-300, dice: 0.8516683333333332
CVC-300 :  0.8516683333333332
epoch: 88, dataset: CVC-ClinicDB, dice: 0.8500370967741934
CVC-ClinicDB :  0.8500370967741934
epoch: 88, dataset: Kvasir, dice: 0.8866010000000002
Kvasir :  0.8866010000000002
epoch: 88, dataset: CVC-ColonDB, dice: 0.6967507894736843
CVC-ColonDB :  0.6967507894736843
epoch: 88, dataset: ETIS-LaribPolypDB, dice: 0.6745403061224492
ETIS-LaribPolypDB :  0.6745403061224492
2023-09-02 05:30:56.280367: train_loss -1.4539
2023-09-02 05:30:56.281701: val_loss -1.0044
2023-09-02 05:30:56.282809: Pseudo dice [0.8199]
2023-09-02 05:30:56.283686: Epoch time: 111.43 s
2023-09-02 05:30:57.472512: 
2023-09-02 05:30:57.473997: Epoch 89
2023-09-02 05:30:57.474903: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-02 05:30:57.476221: start training, 250
================num of epochs: 250================
2023-09-02 05:31:55.523556: finished training
epoch: 89, dataset: CVC-300, dice: 0.8659766666666667
CVC-300 :  0.8659766666666667
epoch: 89, dataset: CVC-ClinicDB, dice: 0.8516435483870969
CVC-ClinicDB :  0.8516435483870969
epoch: 89, dataset: Kvasir, dice: 0.8871800000000003
Kvasir :  0.8871800000000003
epoch: 89, dataset: CVC-ColonDB, dice: 0.6945005263157895
CVC-ColonDB :  0.6945005263157895
epoch: 89, dataset: ETIS-LaribPolypDB, dice: 0.6842464285714286
ETIS-LaribPolypDB :  0.6842464285714286
2023-09-02 05:32:48.406274: train_loss -1.4553
2023-09-02 05:32:48.407711: val_loss -1.0298
2023-09-02 05:32:48.408967: Pseudo dice [0.815]
2023-09-02 05:32:48.409906: Epoch time: 110.93 s
2023-09-02 05:32:51.226467: 
2023-09-02 05:32:51.227797: Epoch 90
2023-09-02 05:32:51.228722: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-02 05:32:51.229981: start training, 250
================num of epochs: 250================
2023-09-02 05:33:49.572631: finished training
epoch: 90, dataset: CVC-300, dice: 0.8659033333333334
CVC-300 :  0.8659033333333334
epoch: 90, dataset: CVC-ClinicDB, dice: 0.8430677419354841
CVC-ClinicDB :  0.8430677419354841
epoch: 90, dataset: Kvasir, dice: 0.877545
Kvasir :  0.877545
epoch: 90, dataset: CVC-ColonDB, dice: 0.7037405263157895
CVC-ColonDB :  0.7037405263157895
epoch: 90, dataset: ETIS-LaribPolypDB, dice: 0.6955540816326533
ETIS-LaribPolypDB :  0.6955540816326533
2023-09-02 05:34:41.166255: train_loss -1.4553
2023-09-02 05:34:41.167899: val_loss -1.0841
2023-09-02 05:34:41.169025: Pseudo dice [0.8425]
2023-09-02 05:34:41.169917: Epoch time: 109.94 s
2023-09-02 05:34:42.378803: 
2023-09-02 05:34:42.380270: Epoch 91
2023-09-02 05:34:42.381352: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-02 05:34:42.383793: start training, 250
================num of epochs: 250================
2023-09-02 05:35:41.350759: finished training
epoch: 91, dataset: CVC-300, dice: 0.7394199999999996
CVC-300 :  0.7394199999999996
epoch: 91, dataset: CVC-ClinicDB, dice: 0.853064516129032
CVC-ClinicDB :  0.853064516129032
epoch: 91, dataset: Kvasir, dice: 0.8827929999999999
Kvasir :  0.8827929999999999
epoch: 91, dataset: CVC-ColonDB, dice: 0.6626186842105268
CVC-ColonDB :  0.6626186842105268
epoch: 91, dataset: ETIS-LaribPolypDB, dice: 0.6141438775510205
ETIS-LaribPolypDB :  0.6141438775510205
2023-09-02 05:36:35.660877: train_loss -1.4561
2023-09-02 05:36:35.662463: val_loss -0.9476
2023-09-02 05:36:35.663689: Pseudo dice [0.7757]
2023-09-02 05:36:35.664573: Epoch time: 113.28 s
2023-09-02 05:36:36.914557: 
2023-09-02 05:36:36.916521: Epoch 92
2023-09-02 05:36:36.917847: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-02 05:36:36.920245: start training, 250
================num of epochs: 250================
2023-09-02 05:37:35.495511: finished training
epoch: 92, dataset: CVC-300, dice: 0.8773783333333334
CVC-300 :  0.8773783333333334
epoch: 92, dataset: CVC-ClinicDB, dice: 0.8444403225806452
CVC-ClinicDB :  0.8444403225806452
epoch: 92, dataset: Kvasir, dice: 0.8772410000000004
Kvasir :  0.8772410000000004
epoch: 92, dataset: CVC-ColonDB, dice: 0.6802397368421065
CVC-ColonDB :  0.6802397368421065
epoch: 92, dataset: ETIS-LaribPolypDB, dice: 0.6978765306122449
ETIS-LaribPolypDB :  0.6978765306122449
2023-09-02 05:38:31.511597: train_loss -1.4549
2023-09-02 05:38:31.513203: val_loss -1.0942
2023-09-02 05:38:31.514404: Pseudo dice [0.8386]
2023-09-02 05:38:31.515372: Epoch time: 114.6 s
2023-09-02 05:38:32.732869: 
2023-09-02 05:38:32.734428: Epoch 93
2023-09-02 05:38:32.735414: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-02 05:38:32.737068: start training, 250
================num of epochs: 250================
2023-09-02 05:39:30.907383: finished training
epoch: 93, dataset: CVC-300, dice: 0.8687800000000002
CVC-300 :  0.8687800000000002
epoch: 93, dataset: CVC-ClinicDB, dice: 0.8393499999999998
CVC-ClinicDB :  0.8393499999999998
epoch: 93, dataset: Kvasir, dice: 0.8869750000000002
Kvasir :  0.8869750000000002
epoch: 93, dataset: CVC-ColonDB, dice: 0.6868842105263161
CVC-ColonDB :  0.6868842105263161
epoch: 93, dataset: ETIS-LaribPolypDB, dice: 0.7151545918367347
ETIS-LaribPolypDB :  0.7151545918367347
2023-09-02 05:40:24.158000: train_loss -1.4564
2023-09-02 05:40:24.159523: val_loss -1.0344
2023-09-02 05:40:24.160736: Pseudo dice [0.824]
2023-09-02 05:40:24.161674: Epoch time: 111.43 s
2023-09-02 05:40:25.376339: 
2023-09-02 05:40:25.377728: Epoch 94
2023-09-02 05:40:25.378660: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-02 05:40:25.380229: start training, 250
================num of epochs: 250================
2023-09-02 05:41:23.684573: finished training
epoch: 94, dataset: CVC-300, dice: 0.880125
CVC-300 :  0.880125
epoch: 94, dataset: CVC-ClinicDB, dice: 0.8591903225806452
CVC-ClinicDB :  0.8591903225806452
epoch: 94, dataset: Kvasir, dice: 0.8919460000000002
Kvasir :  0.8919460000000002
epoch: 94, dataset: CVC-ColonDB, dice: 0.7121144736842105
CVC-ColonDB :  0.7121144736842105
epoch: 94, dataset: ETIS-LaribPolypDB, dice: 0.7153984693877552
ETIS-LaribPolypDB :  0.7153984693877552
2023-09-02 05:42:16.655595: train_loss -1.4559
2023-09-02 05:42:16.657043: val_loss -0.9972
2023-09-02 05:42:16.658227: Pseudo dice [0.8173]
2023-09-02 05:42:16.659163: Epoch time: 111.28 s
2023-09-02 05:42:17.850704: 
2023-09-02 05:42:17.852366: Epoch 95
2023-09-02 05:42:17.853314: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-02 05:42:17.854711: start training, 250
================num of epochs: 250================
2023-09-02 05:43:15.926738: finished training
epoch: 95, dataset: CVC-300, dice: 0.8693166666666663
CVC-300 :  0.8693166666666663
epoch: 95, dataset: CVC-ClinicDB, dice: 0.8531790322580646
CVC-ClinicDB :  0.8531790322580646
epoch: 95, dataset: Kvasir, dice: 0.8834089999999998
Kvasir :  0.8834089999999998
epoch: 95, dataset: CVC-ColonDB, dice: 0.6970984210526318
CVC-ColonDB :  0.6970984210526318
epoch: 95, dataset: ETIS-LaribPolypDB, dice: 0.7004673469387752
ETIS-LaribPolypDB :  0.7004673469387752
2023-09-02 05:44:08.490655: train_loss -1.4572
2023-09-02 05:44:08.492237: val_loss -1.0126
2023-09-02 05:44:08.493512: Pseudo dice [0.8126]
2023-09-02 05:44:08.494429: Epoch time: 110.64 s
2023-09-02 05:44:09.707340: 
2023-09-02 05:44:09.708787: Epoch 96
2023-09-02 05:44:09.709759: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-02 05:44:09.711057: start training, 250
================num of epochs: 250================
2023-09-02 05:45:07.829022: finished training
epoch: 96, dataset: CVC-300, dice: 0.8783183333333332
CVC-300 :  0.8783183333333332
epoch: 96, dataset: CVC-ClinicDB, dice: 0.8592612903225806
CVC-ClinicDB :  0.8592612903225806
epoch: 96, dataset: Kvasir, dice: 0.8939809999999998
Kvasir :  0.8939809999999998
epoch: 96, dataset: CVC-ColonDB, dice: 0.6987950000000003
CVC-ColonDB :  0.6987950000000003
epoch: 96, dataset: ETIS-LaribPolypDB, dice: 0.7157005102040821
ETIS-LaribPolypDB :  0.7157005102040821
2023-09-02 05:46:00.680444: train_loss -1.4574
2023-09-02 05:46:00.681969: val_loss -1.1031
2023-09-02 05:46:00.683233: Pseudo dice [0.8452]
2023-09-02 05:46:00.684208: Epoch time: 110.97 s
2023-09-02 05:46:01.901678: 
2023-09-02 05:46:01.903181: Epoch 97
2023-09-02 05:46:01.904141: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-02 05:46:01.905461: start training, 250
================num of epochs: 250================
2023-09-02 05:47:00.331450: finished training
epoch: 97, dataset: CVC-300, dice: 0.8736916666666666
CVC-300 :  0.8736916666666666
epoch: 97, dataset: CVC-ClinicDB, dice: 0.857474193548387
CVC-ClinicDB :  0.857474193548387
epoch: 97, dataset: Kvasir, dice: 0.8942659999999996
Kvasir :  0.8942659999999996
epoch: 97, dataset: CVC-ColonDB, dice: 0.7078802631578951
CVC-ColonDB :  0.7078802631578951
epoch: 97, dataset: ETIS-LaribPolypDB, dice: 0.7182836734693883
ETIS-LaribPolypDB :  0.7182836734693883
2023-09-02 05:47:56.615884: train_loss -1.4575
2023-09-02 05:47:56.617485: val_loss -1.07
2023-09-02 05:47:56.618804: Pseudo dice [0.8346]
2023-09-02 05:47:56.619708: Epoch time: 114.72 s
2023-09-02 05:47:57.851055: 
2023-09-02 05:47:57.852476: Epoch 98
2023-09-02 05:47:57.853363: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-02 05:47:57.854820: start training, 250
================num of epochs: 250================
2023-09-02 05:48:56.039806: finished training
epoch: 98, dataset: CVC-300, dice: 0.8831766666666667
CVC-300 :  0.8831766666666667
epoch: 98, dataset: CVC-ClinicDB, dice: 0.864690322580645
CVC-ClinicDB :  0.864690322580645
epoch: 98, dataset: Kvasir, dice: 0.8992269999999998
Kvasir :  0.8992269999999998
epoch: 98, dataset: CVC-ColonDB, dice: 0.7112065789473695
CVC-ColonDB :  0.7112065789473695
epoch: 98, dataset: ETIS-LaribPolypDB, dice: 0.7186260204081629
ETIS-LaribPolypDB :  0.7186260204081629
2023-09-02 05:49:51.112064: train_loss -1.4579
2023-09-02 05:49:51.113590: val_loss -1.0706
2023-09-02 05:49:51.114839: Pseudo dice [0.8343]
2023-09-02 05:49:51.115803: Epoch time: 113.26 s
2023-09-02 05:49:52.441608: 
2023-09-02 05:49:52.444330: Epoch 99
2023-09-02 05:49:52.445719: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-02 05:49:52.448906: start training, 250
================num of epochs: 250================
2023-09-02 05:50:50.999925: finished training
epoch: 99, dataset: CVC-300, dice: 0.8733283333333333
CVC-300 :  0.8733283333333333
epoch: 99, dataset: CVC-ClinicDB, dice: 0.8585758064516128
CVC-ClinicDB :  0.8585758064516128
epoch: 99, dataset: Kvasir, dice: 0.8883160000000003
Kvasir :  0.8883160000000003
epoch: 99, dataset: CVC-ColonDB, dice: 0.7011121052631589
CVC-ColonDB :  0.7011121052631589
epoch: 99, dataset: ETIS-LaribPolypDB, dice: 0.7128561224489799
ETIS-LaribPolypDB :  0.7128561224489799
2023-09-02 05:51:42.711025: train_loss -1.4585
2023-09-02 05:51:42.712535: val_loss -1.0225
2023-09-02 05:51:42.713724: Pseudo dice [0.8204]
2023-09-02 05:51:42.714943: Epoch time: 110.27 s
2023-09-02 05:51:45.550150: 
2023-09-02 05:51:45.551514: Epoch 100
2023-09-02 05:51:45.552464: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-02 05:51:45.553961: start training, 250
================num of epochs: 250================
2023-09-02 05:52:44.579097: finished training
epoch: 100, dataset: CVC-300, dice: 0.8601949999999999
CVC-300 :  0.8601949999999999
epoch: 100, dataset: CVC-ClinicDB, dice: 0.8349693548387096
CVC-ClinicDB :  0.8349693548387096
epoch: 100, dataset: Kvasir, dice: 0.8645719999999997
Kvasir :  0.8645719999999997
epoch: 100, dataset: CVC-ColonDB, dice: 0.6597192105263161
CVC-ColonDB :  0.6597192105263161
epoch: 100, dataset: ETIS-LaribPolypDB, dice: 0.7166224489795918
ETIS-LaribPolypDB :  0.7166224489795918
2023-09-02 05:53:38.594993: train_loss -1.4565
2023-09-02 05:53:38.596601: val_loss -1.0368
2023-09-02 05:53:38.598114: Pseudo dice [0.8247]
2023-09-02 05:53:38.599173: Epoch time: 113.05 s
2023-09-02 05:53:39.841570: 
2023-09-02 05:53:39.843319: Epoch 101
2023-09-02 05:53:39.844300: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-02 05:53:39.846574: start training, 250
================num of epochs: 250================
2023-09-02 05:54:38.521116: finished training
epoch: 101, dataset: CVC-300, dice: 0.887335
CVC-300 :  0.887335
epoch: 101, dataset: CVC-ClinicDB, dice: 0.8516790322580646
CVC-ClinicDB :  0.8516790322580646
epoch: 101, dataset: Kvasir, dice: 0.8849689999999997
Kvasir :  0.8849689999999997
epoch: 101, dataset: CVC-ColonDB, dice: 0.6990834210526324
CVC-ColonDB :  0.6990834210526324
epoch: 101, dataset: ETIS-LaribPolypDB, dice: 0.7238142857142861
ETIS-LaribPolypDB :  0.7238142857142861
2023-09-02 05:55:30.520718: train_loss -1.4566
2023-09-02 05:55:30.522496: val_loss -1.0455
2023-09-02 05:55:30.524365: Pseudo dice [0.8213]
2023-09-02 05:55:30.525340: Epoch time: 110.68 s
2023-09-02 05:55:31.742273: 
2023-09-02 05:55:31.745585: Epoch 102
2023-09-02 05:55:31.747778: Current learning rate: backbone 0.000688, others 0.000688
2023-09-02 05:55:31.751446: start training, 250
================num of epochs: 250================
2023-09-02 05:56:30.397670: finished training
epoch: 102, dataset: CVC-300, dice: 0.8898783333333334
CVC-300 :  0.8898783333333334
epoch: 102, dataset: CVC-ClinicDB, dice: 0.858659677419355
CVC-ClinicDB :  0.858659677419355
epoch: 102, dataset: Kvasir, dice: 0.9054370000000002
Kvasir :  0.9054370000000002
epoch: 102, dataset: CVC-ColonDB, dice: 0.6982400000000002
CVC-ColonDB :  0.6982400000000002
epoch: 102, dataset: ETIS-LaribPolypDB, dice: 0.7209326530612249
ETIS-LaribPolypDB :  0.7209326530612249
2023-09-02 05:57:29.699327: train_loss -1.4586
2023-09-02 05:57:29.700916: val_loss -0.997
2023-09-02 05:57:29.702102: Pseudo dice [0.8083]
2023-09-02 05:57:29.703066: Epoch time: 117.96 s
2023-09-02 05:57:30.982524: 
2023-09-02 05:57:30.984144: Epoch 103
2023-09-02 05:57:30.985211: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-02 05:57:30.987157: start training, 250
================num of epochs: 250================
2023-09-02 05:58:29.963743: finished training
epoch: 103, dataset: CVC-300, dice: 0.8839883333333332
CVC-300 :  0.8839883333333332
epoch: 103, dataset: CVC-ClinicDB, dice: 0.8625209677419354
CVC-ClinicDB :  0.8625209677419354
epoch: 103, dataset: Kvasir, dice: 0.9026309999999995
Kvasir :  0.9026309999999995
epoch: 103, dataset: CVC-ColonDB, dice: 0.6996865789473685
CVC-ColonDB :  0.6996865789473685
epoch: 103, dataset: ETIS-LaribPolypDB, dice: 0.7295872448979598
ETIS-LaribPolypDB :  0.7295872448979598
2023-09-02 05:59:29.472165: train_loss -1.4594
2023-09-02 05:59:29.474024: val_loss -1.0738
2023-09-02 05:59:29.475240: Pseudo dice [0.8403]
2023-09-02 05:59:29.476178: Epoch time: 118.49 s
2023-09-02 05:59:30.767918: 
2023-09-02 05:59:30.769875: Epoch 104
2023-09-02 05:59:30.770978: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-02 05:59:30.772512: start training, 250
================num of epochs: 250================
2023-09-02 06:00:29.196064: finished training
epoch: 104, dataset: CVC-300, dice: 0.8830916666666666
CVC-300 :  0.8830916666666666
epoch: 104, dataset: CVC-ClinicDB, dice: 0.8564935483870967
CVC-ClinicDB :  0.8564935483870967
epoch: 104, dataset: Kvasir, dice: 0.9012050000000004
Kvasir :  0.9012050000000004
epoch: 104, dataset: CVC-ColonDB, dice: 0.6950571052631588
CVC-ColonDB :  0.6950571052631588
epoch: 104, dataset: ETIS-LaribPolypDB, dice: 0.7278459183673468
ETIS-LaribPolypDB :  0.7278459183673468
2023-09-02 06:01:25.020279: train_loss -1.4596
2023-09-02 06:01:25.021822: val_loss -1.0243
2023-09-02 06:01:25.023203: Pseudo dice [0.82]
2023-09-02 06:01:25.024201: Epoch time: 114.25 s
2023-09-02 06:01:26.239003: 
2023-09-02 06:01:26.240673: Epoch 105
2023-09-02 06:01:26.241623: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-02 06:01:26.243042: start training, 250
================num of epochs: 250================
2023-09-02 06:02:24.924857: finished training
epoch: 105, dataset: CVC-300, dice: 0.8827166666666666
CVC-300 :  0.8827166666666666
epoch: 105, dataset: CVC-ClinicDB, dice: 0.8610516129032256
CVC-ClinicDB :  0.8610516129032256
epoch: 105, dataset: Kvasir, dice: 0.9035179999999998
Kvasir :  0.9035179999999998
epoch: 105, dataset: CVC-ColonDB, dice: 0.7112086842105271
CVC-ColonDB :  0.7112086842105271
epoch: 105, dataset: ETIS-LaribPolypDB, dice: 0.7247821428571432
ETIS-LaribPolypDB :  0.7247821428571432
2023-09-02 06:03:20.693598: train_loss -1.4602
2023-09-02 06:03:20.695637: val_loss -1.0608
2023-09-02 06:03:20.698021: Pseudo dice [0.8362]
2023-09-02 06:03:20.699650: Epoch time: 114.46 s
2023-09-02 06:03:21.950136: 
2023-09-02 06:03:21.951533: Epoch 106
2023-09-02 06:03:21.952480: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-02 06:03:21.953900: start training, 250
================num of epochs: 250================
2023-09-02 06:04:20.650944: finished training
epoch: 106, dataset: CVC-300, dice: 0.8800366666666666
CVC-300 :  0.8800366666666666
epoch: 106, dataset: CVC-ClinicDB, dice: 0.8550306451612901
CVC-ClinicDB :  0.8550306451612901
epoch: 106, dataset: Kvasir, dice: 0.893365
Kvasir :  0.893365
epoch: 106, dataset: CVC-ColonDB, dice: 0.7025718421052625
CVC-ColonDB :  0.7025718421052625
epoch: 106, dataset: ETIS-LaribPolypDB, dice: 0.7184846938775509
ETIS-LaribPolypDB :  0.7184846938775509
2023-09-02 06:05:18.195803: train_loss -1.4603
2023-09-02 06:05:18.198045: val_loss -1.0594
2023-09-02 06:05:18.200226: Pseudo dice [0.8327]
2023-09-02 06:05:18.201823: Epoch time: 116.25 s
2023-09-02 06:05:19.454435: 
2023-09-02 06:05:19.456057: Epoch 107
2023-09-02 06:05:19.457121: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-02 06:05:19.458742: start training, 250
================num of epochs: 250================
2023-09-02 06:06:17.698828: finished training
epoch: 107, dataset: CVC-300, dice: 0.8912100000000002
CVC-300 :  0.8912100000000002
epoch: 107, dataset: CVC-ClinicDB, dice: 0.8491016129032255
CVC-ClinicDB :  0.8491016129032255
epoch: 107, dataset: Kvasir, dice: 0.89113
Kvasir :  0.89113
epoch: 107, dataset: CVC-ColonDB, dice: 0.7032200000000001
CVC-ColonDB :  0.7032200000000001
epoch: 107, dataset: ETIS-LaribPolypDB, dice: 0.717562755102041
ETIS-LaribPolypDB :  0.717562755102041
2023-09-02 06:07:15.978910: train_loss -1.4602
2023-09-02 06:07:15.980437: val_loss -1.0723
2023-09-02 06:07:15.981583: Pseudo dice [0.8366]
2023-09-02 06:07:15.982532: Epoch time: 116.53 s
2023-09-02 06:07:17.230495: 
2023-09-02 06:07:17.232433: Epoch 108
2023-09-02 06:07:17.233533: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-02 06:07:17.235554: start training, 250
================num of epochs: 250================
2023-09-02 06:08:15.726069: finished training
epoch: 108, dataset: CVC-300, dice: 0.8919983333333331
CVC-300 :  0.8919983333333331
epoch: 108, dataset: CVC-ClinicDB, dice: 0.8511193548387095
CVC-ClinicDB :  0.8511193548387095
epoch: 108, dataset: Kvasir, dice: 0.8899609999999999
Kvasir :  0.8899609999999999
epoch: 108, dataset: CVC-ColonDB, dice: 0.6921686842105264
CVC-ColonDB :  0.6921686842105264
epoch: 108, dataset: ETIS-LaribPolypDB, dice: 0.7062857142857142
ETIS-LaribPolypDB :  0.7062857142857142
2023-09-02 06:09:14.753009: train_loss -1.4598
2023-09-02 06:09:14.754771: val_loss -1.0605
2023-09-02 06:09:14.756582: Pseudo dice [0.832]
2023-09-02 06:09:14.757916: Epoch time: 117.53 s
2023-09-02 06:09:15.999541: 
2023-09-02 06:09:16.001142: Epoch 109
2023-09-02 06:09:16.002171: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-02 06:09:16.003815: start training, 250
================num of epochs: 250================
2023-09-02 06:10:14.651046: finished training
epoch: 109, dataset: CVC-300, dice: 0.8609983333333334
CVC-300 :  0.8609983333333334
epoch: 109, dataset: CVC-ClinicDB, dice: 0.8612354838709678
CVC-ClinicDB :  0.8612354838709678
epoch: 109, dataset: Kvasir, dice: 0.8724750000000001
Kvasir :  0.8724750000000001
epoch: 109, dataset: CVC-ColonDB, dice: 0.6934392105263159
CVC-ColonDB :  0.6934392105263159
epoch: 109, dataset: ETIS-LaribPolypDB, dice: 0.6836887755102039
ETIS-LaribPolypDB :  0.6836887755102039
2023-09-02 06:11:15.680853: train_loss -1.4601
2023-09-02 06:11:15.682414: val_loss -0.9298
2023-09-02 06:11:15.683758: Pseudo dice [0.8094]
2023-09-02 06:11:15.684739: Epoch time: 119.68 s
2023-09-02 06:11:18.850165: 
2023-09-02 06:11:18.852493: Epoch 110
2023-09-02 06:11:18.853588: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-02 06:11:18.855994: start training, 250
================num of epochs: 250================
2023-09-02 06:12:17.090026: finished training
epoch: 110, dataset: CVC-300, dice: 0.8799133333333331
CVC-300 :  0.8799133333333331
epoch: 110, dataset: CVC-ClinicDB, dice: 0.8582112903225806
CVC-ClinicDB :  0.8582112903225806
epoch: 110, dataset: Kvasir, dice: 0.8958630000000002
Kvasir :  0.8958630000000002
epoch: 110, dataset: CVC-ColonDB, dice: 0.7258768421052643
CVC-ColonDB :  0.7258768421052643
epoch: 110, dataset: ETIS-LaribPolypDB, dice: 0.7220321428571428
ETIS-LaribPolypDB :  0.7220321428571428
2023-09-02 06:13:19.359113: train_loss -1.4608
2023-09-02 06:13:19.360764: val_loss -1.0872
2023-09-02 06:13:19.362145: Pseudo dice [0.8456]
2023-09-02 06:13:19.363133: Epoch time: 120.51 s
2023-09-02 06:13:20.572677: 
2023-09-02 06:13:20.574179: Epoch 111
2023-09-02 06:13:20.575339: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-02 06:13:20.577250: start training, 250
================num of epochs: 250================
2023-09-02 06:14:19.158382: finished training
epoch: 111, dataset: CVC-300, dice: 0.8842066666666668
CVC-300 :  0.8842066666666668
epoch: 111, dataset: CVC-ClinicDB, dice: 0.8598096774193549
CVC-ClinicDB :  0.8598096774193549
epoch: 111, dataset: Kvasir, dice: 0.8891489999999999
Kvasir :  0.8891489999999999
epoch: 111, dataset: CVC-ColonDB, dice: 0.7173826315789471
CVC-ColonDB :  0.7173826315789471
epoch: 111, dataset: ETIS-LaribPolypDB, dice: 0.720125
ETIS-LaribPolypDB :  0.720125
2023-09-02 06:15:17.879093: train_loss -1.4612
2023-09-02 06:15:17.880887: val_loss -1.0483
2023-09-02 06:15:17.882198: Pseudo dice [0.8345]
2023-09-02 06:15:17.883236: Epoch time: 117.31 s
2023-09-02 06:15:19.118532: 
2023-09-02 06:15:19.119962: Epoch 112
2023-09-02 06:15:19.121092: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-02 06:15:19.122812: start training, 250
================num of epochs: 250================
2023-09-02 06:16:17.564291: finished training
epoch: 112, dataset: CVC-300, dice: 0.8874883333333334
CVC-300 :  0.8874883333333334
epoch: 112, dataset: CVC-ClinicDB, dice: 0.8580580645161291
CVC-ClinicDB :  0.8580580645161291
epoch: 112, dataset: Kvasir, dice: 0.892068
Kvasir :  0.892068
epoch: 112, dataset: CVC-ColonDB, dice: 0.7001860526315795
CVC-ColonDB :  0.7001860526315795
epoch: 112, dataset: ETIS-LaribPolypDB, dice: 0.7187030612244901
ETIS-LaribPolypDB :  0.7187030612244901
2023-09-02 06:17:16.217993: train_loss -1.4617
2023-09-02 06:17:16.219642: val_loss -1.0085
2023-09-02 06:17:16.221174: Pseudo dice [0.8243]
2023-09-02 06:17:16.222405: Epoch time: 117.1 s
2023-09-02 06:17:17.469898: 
2023-09-02 06:17:17.471301: Epoch 113
2023-09-02 06:17:17.472268: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-02 06:17:17.474154: start training, 250
================num of epochs: 250================
2023-09-02 06:18:16.019383: finished training
epoch: 113, dataset: CVC-300, dice: 0.8867700000000003
CVC-300 :  0.8867700000000003
epoch: 113, dataset: CVC-ClinicDB, dice: 0.853232258064516
CVC-ClinicDB :  0.853232258064516
epoch: 113, dataset: Kvasir, dice: 0.901567
Kvasir :  0.901567
epoch: 113, dataset: CVC-ColonDB, dice: 0.7101089473684211
CVC-ColonDB :  0.7101089473684211
epoch: 113, dataset: ETIS-LaribPolypDB, dice: 0.7100469387755102
ETIS-LaribPolypDB :  0.7100469387755102
2023-09-02 06:19:14.441290: train_loss -1.4617
2023-09-02 06:19:14.443015: val_loss -1.1036
2023-09-02 06:19:14.444272: Pseudo dice [0.8613]
2023-09-02 06:19:14.445305: Epoch time: 116.97 s
2023-09-02 06:19:14.446198: Yayy! New best EMA pseudo Dice: 0.8312
2023-09-02 06:19:17.306842: 
2023-09-02 06:19:17.308352: Epoch 114
2023-09-02 06:19:17.309414: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-02 06:19:17.310975: start training, 250
================num of epochs: 250================
2023-09-02 06:20:15.592132: finished training
epoch: 114, dataset: CVC-300, dice: 0.8816583333333333
CVC-300 :  0.8816583333333333
epoch: 114, dataset: CVC-ClinicDB, dice: 0.8555080645161294
CVC-ClinicDB :  0.8555080645161294
epoch: 114, dataset: Kvasir, dice: 0.9049469999999998
Kvasir :  0.9049469999999998
epoch: 114, dataset: CVC-ColonDB, dice: 0.7283976315789479
CVC-ColonDB :  0.7283976315789479
epoch: 114, dataset: ETIS-LaribPolypDB, dice: 0.7159724489795916
ETIS-LaribPolypDB :  0.7159724489795916
2023-09-02 06:21:10.807361: train_loss -1.4616
2023-09-02 06:21:10.810817: val_loss -1.057
2023-09-02 06:21:10.812565: Pseudo dice [0.8391]
2023-09-02 06:21:10.813987: Epoch time: 113.5 s
2023-09-02 06:21:10.815085: Yayy! New best EMA pseudo Dice: 0.832
2023-09-02 06:21:13.789064: 
2023-09-02 06:21:13.791378: Epoch 115
2023-09-02 06:21:13.794144: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-02 06:21:13.797229: start training, 250
================num of epochs: 250================
2023-09-02 06:22:12.130761: finished training
epoch: 115, dataset: CVC-300, dice: 0.8822949999999999
CVC-300 :  0.8822949999999999
epoch: 115, dataset: CVC-ClinicDB, dice: 0.8621354838709678
CVC-ClinicDB :  0.8621354838709678
epoch: 115, dataset: Kvasir, dice: 0.8988289999999998
Kvasir :  0.8988289999999998
epoch: 115, dataset: CVC-ColonDB, dice: 0.7283934210526318
CVC-ColonDB :  0.7283934210526318
epoch: 115, dataset: ETIS-LaribPolypDB, dice: 0.7258836734693885
ETIS-LaribPolypDB :  0.7258836734693885
2023-09-02 06:23:06.865373: train_loss -1.4621
2023-09-02 06:23:06.866923: val_loss -1.0259
2023-09-02 06:23:06.868177: Pseudo dice [0.8327]
2023-09-02 06:23:06.869195: Epoch time: 113.08 s
2023-09-02 06:23:06.870139: Yayy! New best EMA pseudo Dice: 0.832
2023-09-02 06:23:09.877467: 
2023-09-02 06:23:09.878914: Epoch 116
2023-09-02 06:23:09.879904: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-02 06:23:09.881609: start training, 250
================num of epochs: 250================
2023-09-02 06:24:08.010453: finished training
epoch: 116, dataset: CVC-300, dice: 0.8882783333333334
CVC-300 :  0.8882783333333334
epoch: 116, dataset: CVC-ClinicDB, dice: 0.8531677419354837
CVC-ClinicDB :  0.8531677419354837
epoch: 116, dataset: Kvasir, dice: 0.903739
Kvasir :  0.903739
epoch: 116, dataset: CVC-ColonDB, dice: 0.7281105263157897
CVC-ColonDB :  0.7281105263157897
epoch: 116, dataset: ETIS-LaribPolypDB, dice: 0.7281122448979592
ETIS-LaribPolypDB :  0.7281122448979592
2023-09-02 06:25:05.931418: train_loss -1.4623
2023-09-02 06:25:05.933198: val_loss -1.0513
2023-09-02 06:25:05.934576: Pseudo dice [0.8333]
2023-09-02 06:25:05.935600: Epoch time: 116.06 s
2023-09-02 06:25:05.936554: Yayy! New best EMA pseudo Dice: 0.8322
2023-09-02 06:25:08.788234: 
2023-09-02 06:25:08.789587: Epoch 117
2023-09-02 06:25:08.790572: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-02 06:25:08.791928: start training, 250
================num of epochs: 250================
2023-09-02 06:26:06.967181: finished training
epoch: 117, dataset: CVC-300, dice: 0.8918150000000004
CVC-300 :  0.8918150000000004
epoch: 117, dataset: CVC-ClinicDB, dice: 0.8541483870967742
CVC-ClinicDB :  0.8541483870967742
epoch: 117, dataset: Kvasir, dice: 0.8959450000000002
Kvasir :  0.8959450000000002
epoch: 117, dataset: CVC-ColonDB, dice: 0.7220494736842102
CVC-ColonDB :  0.7220494736842102
epoch: 117, dataset: ETIS-LaribPolypDB, dice: 0.7284887755102044
ETIS-LaribPolypDB :  0.7284887755102044
2023-09-02 06:27:00.118221: train_loss -1.4629
2023-09-02 06:27:00.119736: val_loss -1.1241
2023-09-02 06:27:00.120988: Pseudo dice [0.8617]
2023-09-02 06:27:00.121961: Epoch time: 111.33 s
2023-09-02 06:27:00.122895: Yayy! New best EMA pseudo Dice: 0.8351
2023-09-02 06:27:02.944954: 
2023-09-02 06:27:02.946426: Epoch 118
2023-09-02 06:27:02.947477: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-02 06:27:02.948851: start training, 250
================num of epochs: 250================
2023-09-02 06:28:01.202108: finished training
epoch: 118, dataset: CVC-300, dice: 0.8789400000000002
CVC-300 :  0.8789400000000002
epoch: 118, dataset: CVC-ClinicDB, dice: 0.8524322580645163
CVC-ClinicDB :  0.8524322580645163
epoch: 118, dataset: Kvasir, dice: 0.8904469999999997
Kvasir :  0.8904469999999997
epoch: 118, dataset: CVC-ColonDB, dice: 0.7056636842105255
CVC-ColonDB :  0.7056636842105255
epoch: 118, dataset: ETIS-LaribPolypDB, dice: 0.7076607142857139
ETIS-LaribPolypDB :  0.7076607142857139
2023-09-02 06:28:55.131320: train_loss -1.4631
2023-09-02 06:28:55.132737: val_loss -1.1055
2023-09-02 06:28:55.133932: Pseudo dice [0.8539]
2023-09-02 06:28:55.134856: Epoch time: 112.19 s
2023-09-02 06:28:55.135753: Yayy! New best EMA pseudo Dice: 0.837
2023-09-02 06:28:57.963020: 
2023-09-02 06:28:57.964713: Epoch 119
2023-09-02 06:28:57.965733: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-02 06:28:57.967113: start training, 250
================num of epochs: 250================
2023-09-02 06:29:56.283091: finished training
epoch: 119, dataset: CVC-300, dice: 0.8563983333333334
CVC-300 :  0.8563983333333334
epoch: 119, dataset: CVC-ClinicDB, dice: 0.8594774193548388
CVC-ClinicDB :  0.8594774193548388
epoch: 119, dataset: Kvasir, dice: 0.8943819999999996
Kvasir :  0.8943819999999996
epoch: 119, dataset: CVC-ColonDB, dice: 0.6983836842105262
CVC-ColonDB :  0.6983836842105262
epoch: 119, dataset: ETIS-LaribPolypDB, dice: 0.6987367346938776
ETIS-LaribPolypDB :  0.6987367346938776
2023-09-02 06:30:54.860057: train_loss -1.463
2023-09-02 06:30:54.861800: val_loss -0.9943
2023-09-02 06:30:54.863280: Pseudo dice [0.8238]
2023-09-02 06:30:54.864389: Epoch time: 116.9 s
2023-09-02 06:30:57.722518: 
2023-09-02 06:30:57.724145: Epoch 120
2023-09-02 06:30:57.725110: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-02 06:30:57.726551: start training, 250
================num of epochs: 250================
2023-09-02 06:31:56.473467: finished training
epoch: 120, dataset: CVC-300, dice: 0.892615
CVC-300 :  0.892615
epoch: 120, dataset: CVC-ClinicDB, dice: 0.8492290322580643
CVC-ClinicDB :  0.8492290322580643
epoch: 120, dataset: Kvasir, dice: 0.8903710000000002
Kvasir :  0.8903710000000002
epoch: 120, dataset: CVC-ColonDB, dice: 0.7019705263157898
CVC-ColonDB :  0.7019705263157898
epoch: 120, dataset: ETIS-LaribPolypDB, dice: 0.7161719387755102
ETIS-LaribPolypDB :  0.7161719387755102
2023-09-02 06:32:57.217296: train_loss -1.4626
2023-09-02 06:32:57.218993: val_loss -1.0773
2023-09-02 06:32:57.220285: Pseudo dice [0.8543]
2023-09-02 06:32:57.221236: Epoch time: 119.5 s
2023-09-02 06:32:57.222114: Yayy! New best EMA pseudo Dice: 0.8375
2023-09-02 06:33:00.304615: 
2023-09-02 06:33:00.306167: Epoch 121
2023-09-02 06:33:00.307084: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-02 06:33:00.308328: start training, 250
================num of epochs: 250================
2023-09-02 06:33:59.077254: finished training
epoch: 121, dataset: CVC-300, dice: 0.8822066666666665
CVC-300 :  0.8822066666666665
epoch: 121, dataset: CVC-ClinicDB, dice: 0.8556016129032258
CVC-ClinicDB :  0.8556016129032258
epoch: 121, dataset: Kvasir, dice: 0.8756660000000003
Kvasir :  0.8756660000000003
epoch: 121, dataset: CVC-ColonDB, dice: 0.718828684210527
CVC-ColonDB :  0.718828684210527
epoch: 121, dataset: ETIS-LaribPolypDB, dice: 0.7312642857142857
ETIS-LaribPolypDB :  0.7312642857142857
2023-09-02 06:34:53.916991: train_loss -1.463
2023-09-02 06:34:53.918645: val_loss -1.0229
2023-09-02 06:34:53.919933: Pseudo dice [0.833]
2023-09-02 06:34:53.920863: Epoch time: 113.61 s
2023-09-02 06:34:55.165848: 
2023-09-02 06:34:55.167412: Epoch 122
2023-09-02 06:34:55.168411: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-02 06:34:55.169902: start training, 250
================num of epochs: 250================
2023-09-02 06:35:53.255153: finished training
epoch: 122, dataset: CVC-300, dice: 0.8747616666666667
CVC-300 :  0.8747616666666667
epoch: 122, dataset: CVC-ClinicDB, dice: 0.8549209677419353
CVC-ClinicDB :  0.8549209677419353
epoch: 122, dataset: Kvasir, dice: 0.8890329999999999
Kvasir :  0.8890329999999999
epoch: 122, dataset: CVC-ColonDB, dice: 0.7214623684210528
CVC-ColonDB :  0.7214623684210528
epoch: 122, dataset: ETIS-LaribPolypDB, dice: 0.7386846938775512
ETIS-LaribPolypDB :  0.7386846938775512
2023-09-02 06:36:45.886605: train_loss -1.4624
2023-09-02 06:36:45.887932: val_loss -1.1319
2023-09-02 06:36:45.889070: Pseudo dice [0.8675]
2023-09-02 06:36:45.889954: Epoch time: 110.72 s
2023-09-02 06:36:45.890792: Yayy! New best EMA pseudo Dice: 0.8401
2023-09-02 06:36:48.713185: 
2023-09-02 06:36:48.714928: Epoch 123
2023-09-02 06:36:48.716023: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-02 06:36:48.717388: start training, 250
================num of epochs: 250================
2023-09-02 06:37:46.750210: finished training
epoch: 123, dataset: CVC-300, dice: 0.8816783333333336
CVC-300 :  0.8816783333333336
epoch: 123, dataset: CVC-ClinicDB, dice: 0.8498112903225804
CVC-ClinicDB :  0.8498112903225804
epoch: 123, dataset: Kvasir, dice: 0.8963299999999996
Kvasir :  0.8963299999999996
epoch: 123, dataset: CVC-ColonDB, dice: 0.7025663157894749
CVC-ColonDB :  0.7025663157894749
epoch: 123, dataset: ETIS-LaribPolypDB, dice: 0.7330923469387755
ETIS-LaribPolypDB :  0.7330923469387755
2023-09-02 06:38:39.439192: train_loss -1.4628
2023-09-02 06:38:39.440761: val_loss -1.0342
2023-09-02 06:38:39.442213: Pseudo dice [0.826]
2023-09-02 06:38:39.443379: Epoch time: 110.73 s
2023-09-02 06:38:40.690328: 
2023-09-02 06:38:40.691854: Epoch 124
2023-09-02 06:38:40.692852: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-02 06:38:40.694239: start training, 250
================num of epochs: 250================
2023-09-02 06:39:39.043577: finished training
epoch: 124, dataset: CVC-300, dice: 0.8783050000000003
CVC-300 :  0.8783050000000003
epoch: 124, dataset: CVC-ClinicDB, dice: 0.8548548387096772
CVC-ClinicDB :  0.8548548387096772
epoch: 124, dataset: Kvasir, dice: 0.8848370000000001
Kvasir :  0.8848370000000001
epoch: 124, dataset: CVC-ColonDB, dice: 0.7076944736842107
CVC-ColonDB :  0.7076944736842107
epoch: 124, dataset: ETIS-LaribPolypDB, dice: 0.7251591836734695
ETIS-LaribPolypDB :  0.7251591836734695
2023-09-02 06:40:32.366175: train_loss -1.4636
2023-09-02 06:40:32.367985: val_loss -1.1028
2023-09-02 06:40:32.369320: Pseudo dice [0.858]
2023-09-02 06:40:32.370334: Epoch time: 111.68 s
2023-09-02 06:40:32.371235: Yayy! New best EMA pseudo Dice: 0.8406
2023-09-02 06:40:35.237292: 
2023-09-02 06:40:35.238887: Epoch 125
2023-09-02 06:40:35.239831: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-02 06:40:35.241077: start training, 250
================num of epochs: 250================
2023-09-02 06:41:33.747516: finished training
epoch: 125, dataset: CVC-300, dice: 0.8723199999999998
CVC-300 :  0.8723199999999998
epoch: 125, dataset: CVC-ClinicDB, dice: 0.8556677419354839
CVC-ClinicDB :  0.8556677419354839
epoch: 125, dataset: Kvasir, dice: 0.8886600000000001
Kvasir :  0.8886600000000001
epoch: 125, dataset: CVC-ColonDB, dice: 0.7229147368421062
CVC-ColonDB :  0.7229147368421062
epoch: 125, dataset: ETIS-LaribPolypDB, dice: 0.7362158163265308
ETIS-LaribPolypDB :  0.7362158163265308
2023-09-02 06:42:30.107936: train_loss -1.4634
2023-09-02 06:42:30.109616: val_loss -1.0056
2023-09-02 06:42:30.110730: Pseudo dice [0.8252]
2023-09-02 06:42:30.111629: Epoch time: 114.87 s
2023-09-02 06:42:31.333653: 
2023-09-02 06:42:31.335174: Epoch 126
2023-09-02 06:42:31.336200: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-02 06:42:31.337540: start training, 250
================num of epochs: 250================
2023-09-02 06:43:29.583473: finished training
epoch: 126, dataset: CVC-300, dice: 0.8758083333333335
CVC-300 :  0.8758083333333335
epoch: 126, dataset: CVC-ClinicDB, dice: 0.8571435483870964
CVC-ClinicDB :  0.8571435483870964
epoch: 126, dataset: Kvasir, dice: 0.8951839999999999
Kvasir :  0.8951839999999999
epoch: 126, dataset: CVC-ColonDB, dice: 0.715177105263159
CVC-ColonDB :  0.715177105263159
epoch: 126, dataset: ETIS-LaribPolypDB, dice: 0.7242071428571427
ETIS-LaribPolypDB :  0.7242071428571427
2023-09-02 06:44:26.273196: train_loss -1.4641
2023-09-02 06:44:26.275094: val_loss -1.0276
2023-09-02 06:44:26.276487: Pseudo dice [0.8309]
2023-09-02 06:44:26.277567: Epoch time: 114.94 s
2023-09-02 06:44:27.529077: 
2023-09-02 06:44:27.530647: Epoch 127
2023-09-02 06:44:27.531658: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-02 06:44:27.533095: start training, 250
================num of epochs: 250================
2023-09-02 06:45:25.779182: finished training
epoch: 127, dataset: CVC-300, dice: 0.8825949999999998
CVC-300 :  0.8825949999999998
epoch: 127, dataset: CVC-ClinicDB, dice: 0.8547032258064516
CVC-ClinicDB :  0.8547032258064516
epoch: 127, dataset: Kvasir, dice: 0.890978
Kvasir :  0.890978
epoch: 127, dataset: CVC-ColonDB, dice: 0.7100205263157902
CVC-ColonDB :  0.7100205263157902
epoch: 127, dataset: ETIS-LaribPolypDB, dice: 0.720795918367347
ETIS-LaribPolypDB :  0.720795918367347
2023-09-02 06:46:19.282876: train_loss -1.4646
2023-09-02 06:46:19.284357: val_loss -1.0699
2023-09-02 06:46:19.285567: Pseudo dice [0.8431]
2023-09-02 06:46:19.286946: Epoch time: 111.76 s
2023-09-02 06:46:20.532940: 
2023-09-02 06:46:20.534511: Epoch 128
2023-09-02 06:46:20.535468: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-02 06:46:20.536911: start training, 250
================num of epochs: 250================
2023-09-02 06:47:18.832371: finished training
epoch: 128, dataset: CVC-300, dice: 0.8793466666666667
CVC-300 :  0.8793466666666667
epoch: 128, dataset: CVC-ClinicDB, dice: 0.8510129032258064
CVC-ClinicDB :  0.8510129032258064
epoch: 128, dataset: Kvasir, dice: 0.8986890000000004
Kvasir :  0.8986890000000004
epoch: 128, dataset: CVC-ColonDB, dice: 0.6832160526315799
CVC-ColonDB :  0.6832160526315799
epoch: 128, dataset: ETIS-LaribPolypDB, dice: 0.7198714285714289
ETIS-LaribPolypDB :  0.7198714285714289
2023-09-02 06:48:12.306832: train_loss -1.4638
2023-09-02 06:48:12.308324: val_loss -0.9894
2023-09-02 06:48:12.309667: Pseudo dice [0.8153]
2023-09-02 06:48:12.310698: Epoch time: 111.78 s
2023-09-02 06:48:13.545558: 
2023-09-02 06:48:13.547161: Epoch 129
2023-09-02 06:48:13.548140: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-02 06:48:13.549437: start training, 250
================num of epochs: 250================
2023-09-02 06:49:11.570368: finished training
epoch: 129, dataset: CVC-300, dice: 0.8725716666666666
CVC-300 :  0.8725716666666666
epoch: 129, dataset: CVC-ClinicDB, dice: 0.8561145161290322
CVC-ClinicDB :  0.8561145161290322
epoch: 129, dataset: Kvasir, dice: 0.9021559999999998
Kvasir :  0.9021559999999998
epoch: 129, dataset: CVC-ColonDB, dice: 0.7064792105263161
CVC-ColonDB :  0.7064792105263161
epoch: 129, dataset: ETIS-LaribPolypDB, dice: 0.7198627551020408
ETIS-LaribPolypDB :  0.7198627551020408
2023-09-02 06:50:04.683332: train_loss -1.4636
2023-09-02 06:50:04.685069: val_loss -1.0366
2023-09-02 06:50:04.686540: Pseudo dice [0.8283]
2023-09-02 06:50:04.687611: Epoch time: 111.14 s
2023-09-02 06:50:07.601500: 
2023-09-02 06:50:07.603186: Epoch 130
2023-09-02 06:50:07.604222: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-02 06:50:07.605610: start training, 250
================num of epochs: 250================
2023-09-02 06:51:05.840813: finished training
epoch: 130, dataset: CVC-300, dice: 0.8806133333333334
CVC-300 :  0.8806133333333334
epoch: 130, dataset: CVC-ClinicDB, dice: 0.8577774193548385
CVC-ClinicDB :  0.8577774193548385
epoch: 130, dataset: Kvasir, dice: 0.9031299999999998
Kvasir :  0.9031299999999998
epoch: 130, dataset: CVC-ColonDB, dice: 0.7183521052631583
CVC-ColonDB :  0.7183521052631583
epoch: 130, dataset: ETIS-LaribPolypDB, dice: 0.7292704081632655
ETIS-LaribPolypDB :  0.7292704081632655
2023-09-02 06:51:59.209597: train_loss -1.4642
2023-09-02 06:51:59.211089: val_loss -1.0463
2023-09-02 06:51:59.212242: Pseudo dice [0.8405]
2023-09-02 06:51:59.213171: Epoch time: 111.61 s
2023-09-02 06:52:00.441900: 
2023-09-02 06:52:00.443342: Epoch 131
2023-09-02 06:52:00.444781: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-02 06:52:00.446826: start training, 250
================num of epochs: 250================
2023-09-02 06:52:58.558622: finished training
epoch: 131, dataset: CVC-300, dice: 0.8896599999999999
CVC-300 :  0.8896599999999999
epoch: 131, dataset: CVC-ClinicDB, dice: 0.8408387096774194
CVC-ClinicDB :  0.8408387096774194
epoch: 131, dataset: Kvasir, dice: 0.893246
Kvasir :  0.893246
epoch: 131, dataset: CVC-ColonDB, dice: 0.7037605263157892
CVC-ColonDB :  0.7037605263157892
epoch: 131, dataset: ETIS-LaribPolypDB, dice: 0.7238943877551026
ETIS-LaribPolypDB :  0.7238943877551026
2023-09-02 06:53:56.480609: train_loss -1.4641
2023-09-02 06:53:56.482373: val_loss -1.0182
2023-09-02 06:53:56.483747: Pseudo dice [0.8355]
2023-09-02 06:53:56.484796: Epoch time: 116.04 s
2023-09-02 06:53:57.711664: 
2023-09-02 06:53:57.713139: Epoch 132
2023-09-02 06:53:57.714097: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-02 06:53:57.715464: start training, 250
================num of epochs: 250================
2023-09-02 06:54:55.715564: finished training
epoch: 132, dataset: CVC-300, dice: 0.8900966666666668
CVC-300 :  0.8900966666666668
epoch: 132, dataset: CVC-ClinicDB, dice: 0.8307016129032259
CVC-ClinicDB :  0.8307016129032259
epoch: 132, dataset: Kvasir, dice: 0.8944450000000002
Kvasir :  0.8944450000000002
epoch: 132, dataset: CVC-ColonDB, dice: 0.6844373684210534
CVC-ColonDB :  0.6844373684210534
epoch: 132, dataset: ETIS-LaribPolypDB, dice: 0.7193984693877553
ETIS-LaribPolypDB :  0.7193984693877553
2023-09-02 06:55:48.914004: train_loss -1.4641
2023-09-02 06:55:48.915600: val_loss -0.9264
2023-09-02 06:55:48.916943: Pseudo dice [0.7995]
2023-09-02 06:55:48.918016: Epoch time: 111.2 s
2023-09-02 06:55:50.151488: 
2023-09-02 06:55:50.153224: Epoch 133
2023-09-02 06:55:50.154280: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-02 06:55:50.155689: start training, 250
================num of epochs: 250================
2023-09-02 06:56:48.428867: finished training
epoch: 133, dataset: CVC-300, dice: 0.8813200000000002
CVC-300 :  0.8813200000000002
epoch: 133, dataset: CVC-ClinicDB, dice: 0.8510370967741935
CVC-ClinicDB :  0.8510370967741935
epoch: 133, dataset: Kvasir, dice: 0.8965309999999999
Kvasir :  0.8965309999999999
epoch: 133, dataset: CVC-ColonDB, dice: 0.7105021052631574
CVC-ColonDB :  0.7105021052631574
epoch: 133, dataset: ETIS-LaribPolypDB, dice: 0.7348316326530612
ETIS-LaribPolypDB :  0.7348316326530612
2023-09-02 06:57:42.078302: train_loss -1.4648
2023-09-02 06:57:42.079975: val_loss -0.9953
2023-09-02 06:57:42.081384: Pseudo dice [0.8189]
2023-09-02 06:57:42.082436: Epoch time: 111.93 s
2023-09-02 06:57:43.294870: 
2023-09-02 06:57:43.296539: Epoch 134
2023-09-02 06:57:43.297556: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-02 06:57:43.298990: start training, 250
================num of epochs: 250================
2023-09-02 06:58:41.347573: finished training
epoch: 134, dataset: CVC-300, dice: 0.866111666666667
CVC-300 :  0.866111666666667
epoch: 134, dataset: CVC-ClinicDB, dice: 0.857632258064516
CVC-ClinicDB :  0.857632258064516
epoch: 134, dataset: Kvasir, dice: 0.8935290000000004
Kvasir :  0.8935290000000004
epoch: 134, dataset: CVC-ColonDB, dice: 0.7168468421052626
CVC-ColonDB :  0.7168468421052626
epoch: 134, dataset: ETIS-LaribPolypDB, dice: 0.7253897959183674
ETIS-LaribPolypDB :  0.7253897959183674
2023-09-02 06:59:34.590855: train_loss -1.4642
2023-09-02 06:59:34.592516: val_loss -1.0271
2023-09-02 06:59:34.593957: Pseudo dice [0.8389]
2023-09-02 06:59:34.595001: Epoch time: 111.3 s
2023-09-02 06:59:35.825650: 
2023-09-02 06:59:35.827290: Epoch 135
2023-09-02 06:59:35.828299: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-02 06:59:35.829710: start training, 250
================num of epochs: 250================
2023-09-02 07:00:33.847794: finished training
epoch: 135, dataset: CVC-300, dice: 0.8678083333333337
CVC-300 :  0.8678083333333337
epoch: 135, dataset: CVC-ClinicDB, dice: 0.8577580645161289
CVC-ClinicDB :  0.8577580645161289
epoch: 135, dataset: Kvasir, dice: 0.8985570000000002
Kvasir :  0.8985570000000002
epoch: 135, dataset: CVC-ColonDB, dice: 0.7040273684210532
CVC-ColonDB :  0.7040273684210532
epoch: 135, dataset: ETIS-LaribPolypDB, dice: 0.728889795918367
ETIS-LaribPolypDB :  0.728889795918367
2023-09-02 07:01:26.826529: train_loss -1.4653
2023-09-02 07:01:26.828043: val_loss -1.0735
2023-09-02 07:01:26.829213: Pseudo dice [0.8489]
2023-09-02 07:01:26.830208: Epoch time: 111.0 s
2023-09-02 07:01:28.063530: 
2023-09-02 07:01:28.065018: Epoch 136
2023-09-02 07:01:28.066029: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-02 07:01:28.067383: start training, 250
================num of epochs: 250================
2023-09-02 07:02:26.262155: finished training
epoch: 136, dataset: CVC-300, dice: 0.870703333333333
CVC-300 :  0.870703333333333
epoch: 136, dataset: CVC-ClinicDB, dice: 0.8563612903225805
CVC-ClinicDB :  0.8563612903225805
epoch: 136, dataset: Kvasir, dice: 0.8924279999999999
Kvasir :  0.8924279999999999
epoch: 136, dataset: CVC-ColonDB, dice: 0.7008313157894743
CVC-ColonDB :  0.7008313157894743
epoch: 136, dataset: ETIS-LaribPolypDB, dice: 0.7230535714285712
ETIS-LaribPolypDB :  0.7230535714285712
2023-09-02 07:03:19.200519: train_loss -1.4655
2023-09-02 07:03:19.202197: val_loss -0.9989
2023-09-02 07:03:19.203516: Pseudo dice [0.8173]
2023-09-02 07:03:19.204594: Epoch time: 111.14 s
2023-09-02 07:03:20.431399: 
2023-09-02 07:03:20.433047: Epoch 137
2023-09-02 07:03:20.434098: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-02 07:03:20.435524: start training, 250
================num of epochs: 250================
2023-09-02 07:04:18.662830: finished training
epoch: 137, dataset: CVC-300, dice: 0.8796583333333337
CVC-300 :  0.8796583333333337
epoch: 137, dataset: CVC-ClinicDB, dice: 0.8516564516129032
CVC-ClinicDB :  0.8516564516129032
epoch: 137, dataset: Kvasir, dice: 0.8975970000000002
Kvasir :  0.8975970000000002
epoch: 137, dataset: CVC-ColonDB, dice: 0.6976318421052627
CVC-ColonDB :  0.6976318421052627
epoch: 137, dataset: ETIS-LaribPolypDB, dice: 0.7258760204081636
ETIS-LaribPolypDB :  0.7258760204081636
2023-09-02 07:05:15.520820: train_loss -1.4661
2023-09-02 07:05:15.522458: val_loss -1.0451
2023-09-02 07:05:15.523697: Pseudo dice [0.8397]
2023-09-02 07:05:15.524710: Epoch time: 115.09 s
2023-09-02 07:05:16.759608: 
2023-09-02 07:05:16.761234: Epoch 138
2023-09-02 07:05:16.762321: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-02 07:05:16.763871: start training, 250
================num of epochs: 250================
2023-09-02 07:06:15.172739: finished training
epoch: 138, dataset: CVC-300, dice: 0.8731033333333335
CVC-300 :  0.8731033333333335
epoch: 138, dataset: CVC-ClinicDB, dice: 0.8551064516129032
CVC-ClinicDB :  0.8551064516129032
epoch: 138, dataset: Kvasir, dice: 0.8970710000000001
Kvasir :  0.8970710000000001
epoch: 138, dataset: CVC-ColonDB, dice: 0.6997186842105266
CVC-ColonDB :  0.6997186842105266
epoch: 138, dataset: ETIS-LaribPolypDB, dice: 0.7141678571428575
ETIS-LaribPolypDB :  0.7141678571428575
2023-09-02 07:07:11.131634: train_loss -1.4656
2023-09-02 07:07:11.133139: val_loss -1.0258
2023-09-02 07:07:11.134365: Pseudo dice [0.8338]
2023-09-02 07:07:11.135444: Epoch time: 114.37 s
2023-09-02 07:07:12.360382: 
2023-09-02 07:07:12.361905: Epoch 139
2023-09-02 07:07:12.362986: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-02 07:07:12.364474: start training, 250
================num of epochs: 250================
2023-09-02 07:08:10.933171: finished training
epoch: 139, dataset: CVC-300, dice: 0.8575983333333331
CVC-300 :  0.8575983333333331
epoch: 139, dataset: CVC-ClinicDB, dice: 0.8522870967741936
CVC-ClinicDB :  0.8522870967741936
epoch: 139, dataset: Kvasir, dice: 0.8900320000000002
Kvasir :  0.8900320000000002
epoch: 139, dataset: CVC-ColonDB, dice: 0.6967218421052639
CVC-ColonDB :  0.6967218421052639
epoch: 139, dataset: ETIS-LaribPolypDB, dice: 0.7101750000000004
ETIS-LaribPolypDB :  0.7101750000000004
2023-09-02 07:09:06.967537: train_loss -1.4656
2023-09-02 07:09:06.969217: val_loss -1.0603
2023-09-02 07:09:06.970618: Pseudo dice [0.8434]
2023-09-02 07:09:06.971664: Epoch time: 114.61 s
2023-09-02 07:09:09.844095: 
2023-09-02 07:09:09.845722: Epoch 140
2023-09-02 07:09:09.846714: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-02 07:09:09.848134: start training, 250
================num of epochs: 250================
2023-09-02 07:10:08.148195: finished training
epoch: 140, dataset: CVC-300, dice: 0.8571533333333334
CVC-300 :  0.8571533333333334
epoch: 140, dataset: CVC-ClinicDB, dice: 0.8486322580645166
CVC-ClinicDB :  0.8486322580645166
epoch: 140, dataset: Kvasir, dice: 0.8948319999999998
Kvasir :  0.8948319999999998
epoch: 140, dataset: CVC-ColonDB, dice: 0.7075181578947379
CVC-ColonDB :  0.7075181578947379
epoch: 140, dataset: ETIS-LaribPolypDB, dice: 0.7201224489795919
ETIS-LaribPolypDB :  0.7201224489795919
2023-09-02 07:11:05.525613: train_loss -1.4661
2023-09-02 07:11:05.527164: val_loss -1.0436
2023-09-02 07:11:05.528611: Pseudo dice [0.8405]
2023-09-02 07:11:05.529825: Epoch time: 115.68 s
2023-09-02 07:11:06.753774: 
2023-09-02 07:11:06.755560: Epoch 141
2023-09-02 07:11:06.756656: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-02 07:11:06.758558: start training, 250
================num of epochs: 250================
2023-09-02 07:12:05.081475: finished training
epoch: 141, dataset: CVC-300, dice: 0.8627516666666667
CVC-300 :  0.8627516666666667
epoch: 141, dataset: CVC-ClinicDB, dice: 0.8518709677419355
CVC-ClinicDB :  0.8518709677419355
epoch: 141, dataset: Kvasir, dice: 0.8980040000000001
Kvasir :  0.8980040000000001
epoch: 141, dataset: CVC-ColonDB, dice: 0.7038484210526325
CVC-ColonDB :  0.7038484210526325
epoch: 141, dataset: ETIS-LaribPolypDB, dice: 0.7224397959183668
ETIS-LaribPolypDB :  0.7224397959183668
2023-09-02 07:13:03.502547: train_loss -1.4666
2023-09-02 07:13:03.504571: val_loss -0.9976
2023-09-02 07:13:03.506156: Pseudo dice [0.8299]
2023-09-02 07:13:03.507307: Epoch time: 116.75 s
2023-09-02 07:13:04.775423: 
2023-09-02 07:13:04.777073: Epoch 142
2023-09-02 07:13:04.778083: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-02 07:13:04.779821: start training, 250
================num of epochs: 250================
2023-09-02 07:14:03.562448: finished training
epoch: 142, dataset: CVC-300, dice: 0.8736150000000001
CVC-300 :  0.8736150000000001
epoch: 142, dataset: CVC-ClinicDB, dice: 0.8532516129032259
CVC-ClinicDB :  0.8532516129032259
epoch: 142, dataset: Kvasir, dice: 0.8997709999999998
Kvasir :  0.8997709999999998
epoch: 142, dataset: CVC-ColonDB, dice: 0.7022884210526317
CVC-ColonDB :  0.7022884210526317
epoch: 142, dataset: ETIS-LaribPolypDB, dice: 0.7170943877551021
ETIS-LaribPolypDB :  0.7170943877551021
2023-09-02 07:15:04.543509: train_loss -1.4665
2023-09-02 07:15:04.545416: val_loss -1.0403
2023-09-02 07:15:04.546936: Pseudo dice [0.8369]
2023-09-02 07:15:04.547954: Epoch time: 119.77 s
2023-09-02 07:15:05.809549: 
2023-09-02 07:15:05.811142: Epoch 143
2023-09-02 07:15:05.812143: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-02 07:15:05.813909: start training, 250
================num of epochs: 250================
2023-09-02 07:16:04.265657: finished training
epoch: 143, dataset: CVC-300, dice: 0.8827250000000001
CVC-300 :  0.8827250000000001
epoch: 143, dataset: CVC-ClinicDB, dice: 0.854332258064516
CVC-ClinicDB :  0.854332258064516
epoch: 143, dataset: Kvasir, dice: 0.9052979999999995
Kvasir :  0.9052979999999995
epoch: 143, dataset: CVC-ColonDB, dice: 0.7098723684210528
CVC-ColonDB :  0.7098723684210528
epoch: 143, dataset: ETIS-LaribPolypDB, dice: 0.7264903061224488
ETIS-LaribPolypDB :  0.7264903061224488
2023-09-02 07:17:04.814874: train_loss -1.4665
2023-09-02 07:17:04.816708: val_loss -1.036
2023-09-02 07:17:04.818230: Pseudo dice [0.8407]
2023-09-02 07:17:04.819382: Epoch time: 119.01 s
2023-09-02 07:17:06.067153: 
2023-09-02 07:17:06.068682: Epoch 144
2023-09-02 07:17:06.069866: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-02 07:17:06.071440: start training, 250
================num of epochs: 250================
2023-09-02 07:18:04.136670: finished training
epoch: 144, dataset: CVC-300, dice: 0.8854366666666664
CVC-300 :  0.8854366666666664
epoch: 144, dataset: CVC-ClinicDB, dice: 0.8551564516129028
CVC-ClinicDB :  0.8551564516129028
epoch: 144, dataset: Kvasir, dice: 0.902103
Kvasir :  0.902103
epoch: 144, dataset: CVC-ColonDB, dice: 0.7153147368421058
CVC-ColonDB :  0.7153147368421058
epoch: 144, dataset: ETIS-LaribPolypDB, dice: 0.7252387755102044
ETIS-LaribPolypDB :  0.7252387755102044
2023-09-02 07:19:02.968376: train_loss -1.4666
2023-09-02 07:19:02.969927: val_loss -1.1085
2023-09-02 07:19:02.971181: Pseudo dice [0.8659]
2023-09-02 07:19:02.972241: Epoch time: 116.9 s
2023-09-02 07:19:04.226672: 
2023-09-02 07:19:04.229181: Epoch 145
2023-09-02 07:19:04.231105: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-02 07:19:04.233406: start training, 250
================num of epochs: 250================
2023-09-02 07:20:03.087023: finished training
epoch: 145, dataset: CVC-300, dice: 0.8821233333333333
CVC-300 :  0.8821233333333333
epoch: 145, dataset: CVC-ClinicDB, dice: 0.851782258064516
CVC-ClinicDB :  0.851782258064516
epoch: 145, dataset: Kvasir, dice: 0.9015639999999998
Kvasir :  0.9015639999999998
epoch: 145, dataset: CVC-ColonDB, dice: 0.7061736842105265
CVC-ColonDB :  0.7061736842105265
epoch: 145, dataset: ETIS-LaribPolypDB, dice: 0.7285780612244902
ETIS-LaribPolypDB :  0.7285780612244902
2023-09-02 07:20:59.806153: train_loss -1.4668
2023-09-02 07:20:59.807763: val_loss -1.029
2023-09-02 07:20:59.809047: Pseudo dice [0.8393]
2023-09-02 07:20:59.810119: Epoch time: 115.58 s
2023-09-02 07:21:01.025437: 
2023-09-02 07:21:01.027140: Epoch 146
2023-09-02 07:21:01.028169: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-02 07:21:01.029670: start training, 250
================num of epochs: 250================
2023-09-02 07:21:59.261365: finished training
epoch: 146, dataset: CVC-300, dice: 0.8774916666666666
CVC-300 :  0.8774916666666666
epoch: 146, dataset: CVC-ClinicDB, dice: 0.8545387096774195
CVC-ClinicDB :  0.8545387096774195
epoch: 146, dataset: Kvasir, dice: 0.9044810000000002
Kvasir :  0.9044810000000002
epoch: 146, dataset: CVC-ColonDB, dice: 0.7110426315789479
CVC-ColonDB :  0.7110426315789479
epoch: 146, dataset: ETIS-LaribPolypDB, dice: 0.7279372448979591
ETIS-LaribPolypDB :  0.7279372448979591
2023-09-02 07:22:57.511906: train_loss -1.4665
2023-09-02 07:22:57.513807: val_loss -0.9479
2023-09-02 07:22:57.515211: Pseudo dice [0.8235]
2023-09-02 07:22:57.516213: Epoch time: 116.49 s
2023-09-02 07:22:58.801567: 
2023-09-02 07:22:58.803167: Epoch 147
2023-09-02 07:22:58.804182: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-02 07:22:58.805666: start training, 250
================num of epochs: 250================
2023-09-02 07:23:57.171611: finished training
epoch: 147, dataset: CVC-300, dice: 0.8747383333333332
CVC-300 :  0.8747383333333332
epoch: 147, dataset: CVC-ClinicDB, dice: 0.854133870967742
CVC-ClinicDB :  0.854133870967742
epoch: 147, dataset: Kvasir, dice: 0.9042879999999998
Kvasir :  0.9042879999999998
epoch: 147, dataset: CVC-ColonDB, dice: 0.7073163157894731
CVC-ColonDB :  0.7073163157894731
epoch: 147, dataset: ETIS-LaribPolypDB, dice: 0.7178484693877552
ETIS-LaribPolypDB :  0.7178484693877552
2023-09-02 07:24:54.912934: train_loss -1.467
2023-09-02 07:24:54.914642: val_loss -0.9809
2023-09-02 07:24:54.915896: Pseudo dice [0.8269]
2023-09-02 07:24:54.916926: Epoch time: 116.11 s
2023-09-02 07:24:56.156430: 
2023-09-02 07:24:56.158026: Epoch 148
2023-09-02 07:24:56.159109: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-02 07:24:56.160733: start training, 250
================num of epochs: 250================
2023-09-02 07:25:54.195667: finished training
epoch: 148, dataset: CVC-300, dice: 0.8779183333333335
CVC-300 :  0.8779183333333335
epoch: 148, dataset: CVC-ClinicDB, dice: 0.8519596774193549
CVC-ClinicDB :  0.8519596774193549
epoch: 148, dataset: Kvasir, dice: 0.8970640000000006
Kvasir :  0.8970640000000006
epoch: 148, dataset: CVC-ColonDB, dice: 0.6993036842105271
CVC-ColonDB :  0.6993036842105271
epoch: 148, dataset: ETIS-LaribPolypDB, dice: 0.7158316326530612
ETIS-LaribPolypDB :  0.7158316326530612
2023-09-02 07:26:54.103836: train_loss -1.4666
2023-09-02 07:26:54.105780: val_loss -0.9902
2023-09-02 07:26:54.107199: Pseudo dice [0.822]
2023-09-02 07:26:54.108255: Epoch time: 117.95 s
2023-09-02 07:26:55.663482: 
2023-09-02 07:26:55.665034: Epoch 149
2023-09-02 07:26:55.666180: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-02 07:26:55.667593: start training, 250
================num of epochs: 250================
2023-09-02 07:27:54.245554: finished training
epoch: 149, dataset: CVC-300, dice: 0.8743783333333329
CVC-300 :  0.8743783333333329
epoch: 149, dataset: CVC-ClinicDB, dice: 0.8543709677419354
CVC-ClinicDB :  0.8543709677419354
epoch: 149, dataset: Kvasir, dice: 0.9011270000000003
Kvasir :  0.9011270000000003
epoch: 149, dataset: CVC-ColonDB, dice: 0.702385263157895
CVC-ColonDB :  0.702385263157895
epoch: 149, dataset: ETIS-LaribPolypDB, dice: 0.7119352040816327
ETIS-LaribPolypDB :  0.7119352040816327
2023-09-02 07:28:49.076621: train_loss -1.4662
2023-09-02 07:28:49.078177: val_loss -1.1294
2023-09-02 07:28:49.079593: Pseudo dice [0.8614]
2023-09-02 07:28:49.080668: Epoch time: 113.41 s
2023-09-02 07:28:51.936148: 
2023-09-02 07:28:51.937601: Epoch 150
2023-09-02 07:28:51.938664: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-02 07:28:51.940209: start training, 250
================num of epochs: 250================
2023-09-02 07:29:49.865403: finished training
epoch: 150, dataset: CVC-300, dice: 0.8672766666666671
CVC-300 :  0.8672766666666671
epoch: 150, dataset: CVC-ClinicDB, dice: 0.8572806451612902
CVC-ClinicDB :  0.8572806451612902
epoch: 150, dataset: Kvasir, dice: 0.8984289999999996
Kvasir :  0.8984289999999996
epoch: 150, dataset: CVC-ColonDB, dice: 0.7133565789473679
CVC-ColonDB :  0.7133565789473679
epoch: 150, dataset: ETIS-LaribPolypDB, dice: 0.7255612244897961
ETIS-LaribPolypDB :  0.7255612244897961
2023-09-02 07:30:44.617434: train_loss -1.4669
2023-09-02 07:30:44.619080: val_loss -0.901
2023-09-02 07:30:44.620336: Pseudo dice [0.8017]
2023-09-02 07:30:44.621387: Epoch time: 112.68 s
2023-09-02 07:30:45.826182: 
2023-09-02 07:30:45.827708: Epoch 151
2023-09-02 07:30:45.828783: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-02 07:30:45.830260: start training, 250
================num of epochs: 250================
2023-09-02 07:31:43.729140: finished training
epoch: 151, dataset: CVC-300, dice: 0.8665916666666668
CVC-300 :  0.8665916666666668
epoch: 151, dataset: CVC-ClinicDB, dice: 0.8529258064516128
CVC-ClinicDB :  0.8529258064516128
epoch: 151, dataset: Kvasir, dice: 0.8977339999999997
Kvasir :  0.8977339999999997
epoch: 151, dataset: CVC-ColonDB, dice: 0.7068278947368425
CVC-ColonDB :  0.7068278947368425
epoch: 151, dataset: ETIS-LaribPolypDB, dice: 0.724776530612245
ETIS-LaribPolypDB :  0.724776530612245
2023-09-02 07:32:38.183793: train_loss -1.4674
2023-09-02 07:32:38.185449: val_loss -1.1094
2023-09-02 07:32:38.186785: Pseudo dice [0.8665]
2023-09-02 07:32:38.187872: Epoch time: 112.36 s
2023-09-02 07:32:39.675120: 
2023-09-02 07:32:39.676638: Epoch 152
2023-09-02 07:32:39.677778: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-02 07:32:39.679234: start training, 250
================num of epochs: 250================
2023-09-02 07:33:37.658721: finished training
epoch: 152, dataset: CVC-300, dice: 0.8659000000000001
CVC-300 :  0.8659000000000001
epoch: 152, dataset: CVC-ClinicDB, dice: 0.8567161290322581
CVC-ClinicDB :  0.8567161290322581
epoch: 152, dataset: Kvasir, dice: 0.8989900000000002
Kvasir :  0.8989900000000002
epoch: 152, dataset: CVC-ColonDB, dice: 0.7065292105263157
CVC-ColonDB :  0.7065292105263157
epoch: 152, dataset: ETIS-LaribPolypDB, dice: 0.7227989795918371
ETIS-LaribPolypDB :  0.7227989795918371
2023-09-02 07:34:31.648853: train_loss -1.4672
2023-09-02 07:34:31.650343: val_loss -1.0531
2023-09-02 07:34:31.651587: Pseudo dice [0.8527]
2023-09-02 07:34:31.652631: Epoch time: 111.98 s
2023-09-02 07:34:32.862300: 
2023-09-02 07:34:32.863950: Epoch 153
2023-09-02 07:34:32.865037: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-02 07:34:32.866427: start training, 250
================num of epochs: 250================
2023-09-02 07:35:30.815235: finished training
epoch: 153, dataset: CVC-300, dice: 0.8741399999999995
CVC-300 :  0.8741399999999995
epoch: 153, dataset: CVC-ClinicDB, dice: 0.8535016129032258
CVC-ClinicDB :  0.8535016129032258
epoch: 153, dataset: Kvasir, dice: 0.903
Kvasir :  0.903
epoch: 153, dataset: CVC-ColonDB, dice: 0.7069899999999999
CVC-ColonDB :  0.7069899999999999
epoch: 153, dataset: ETIS-LaribPolypDB, dice: 0.7222117346938778
ETIS-LaribPolypDB :  0.7222117346938778
2023-09-02 07:36:25.089660: train_loss -1.4674
2023-09-02 07:36:25.091482: val_loss -0.9915
2023-09-02 07:36:25.092787: Pseudo dice [0.8343]
2023-09-02 07:36:25.093841: Epoch time: 112.23 s
2023-09-02 07:36:26.316504: 
2023-09-02 07:36:26.318105: Epoch 154
2023-09-02 07:36:26.319169: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-02 07:36:26.320609: start training, 250
================num of epochs: 250================
2023-09-02 07:37:24.255184: finished training
epoch: 154, dataset: CVC-300, dice: 0.8681250000000001
CVC-300 :  0.8681250000000001
epoch: 154, dataset: CVC-ClinicDB, dice: 0.8512274193548385
CVC-ClinicDB :  0.8512274193548385
epoch: 154, dataset: Kvasir, dice: 0.9016740000000003
Kvasir :  0.9016740000000003
epoch: 154, dataset: CVC-ColonDB, dice: 0.7048465789473687
CVC-ColonDB :  0.7048465789473687
epoch: 154, dataset: ETIS-LaribPolypDB, dice: 0.7248270408163267
ETIS-LaribPolypDB :  0.7248270408163267
2023-09-02 07:38:18.402832: train_loss -1.4679
2023-09-02 07:38:18.404411: val_loss -1.0528
2023-09-02 07:38:18.405658: Pseudo dice [0.8523]
2023-09-02 07:38:18.406644: Epoch time: 112.09 s
2023-09-02 07:38:19.641580: 
2023-09-02 07:38:19.643107: Epoch 155
2023-09-02 07:38:19.644130: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-02 07:38:19.645586: start training, 250
================num of epochs: 250================
2023-09-02 07:39:17.812261: finished training
epoch: 155, dataset: CVC-300, dice: 0.8751350000000001
CVC-300 :  0.8751350000000001
epoch: 155, dataset: CVC-ClinicDB, dice: 0.8540435483870971
CVC-ClinicDB :  0.8540435483870971
epoch: 155, dataset: Kvasir, dice: 0.9031640000000002
Kvasir :  0.9031640000000002
epoch: 155, dataset: CVC-ColonDB, dice: 0.7099213157894733
CVC-ColonDB :  0.7099213157894733
epoch: 155, dataset: ETIS-LaribPolypDB, dice: 0.7357260204081635
ETIS-LaribPolypDB :  0.7357260204081635
2023-09-02 07:40:16.638700: train_loss -1.4674
2023-09-02 07:40:16.640207: val_loss -1.0267
2023-09-02 07:40:16.642124: Pseudo dice [0.8407]
2023-09-02 07:40:16.643586: Epoch time: 117.0 s
2023-09-02 07:40:17.909246: 
2023-09-02 07:40:17.910787: Epoch 156
2023-09-02 07:40:17.911868: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-02 07:40:17.913500: start training, 250
================num of epochs: 250================
2023-09-02 07:41:16.349186: finished training
epoch: 156, dataset: CVC-300, dice: 0.885085
CVC-300 :  0.885085
epoch: 156, dataset: CVC-ClinicDB, dice: 0.8509370967741934
CVC-ClinicDB :  0.8509370967741934
epoch: 156, dataset: Kvasir, dice: 0.9005669999999995
Kvasir :  0.9005669999999995
epoch: 156, dataset: CVC-ColonDB, dice: 0.710421315789474
CVC-ColonDB :  0.710421315789474
epoch: 156, dataset: ETIS-LaribPolypDB, dice: 0.7256755102040814
ETIS-LaribPolypDB :  0.7256755102040814
2023-09-02 07:42:11.113203: train_loss -1.4676
2023-09-02 07:42:11.114969: val_loss -1.0737
2023-09-02 07:42:11.116369: Pseudo dice [0.8572]
2023-09-02 07:42:11.117465: Epoch time: 113.21 s
2023-09-02 07:42:11.118495: Yayy! New best EMA pseudo Dice: 0.8413
2023-09-02 07:42:13.974660: 
2023-09-02 07:42:13.976243: Epoch 157
2023-09-02 07:42:13.977678: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-02 07:42:13.979099: start training, 250
================num of epochs: 250================
2023-09-02 07:43:11.947554: finished training
epoch: 157, dataset: CVC-300, dice: 0.8832000000000001
CVC-300 :  0.8832000000000001
epoch: 157, dataset: CVC-ClinicDB, dice: 0.8540612903225806
CVC-ClinicDB :  0.8540612903225806
epoch: 157, dataset: Kvasir, dice: 0.901842
Kvasir :  0.901842
epoch: 157, dataset: CVC-ColonDB, dice: 0.7045994736842109
CVC-ColonDB :  0.7045994736842109
epoch: 157, dataset: ETIS-LaribPolypDB, dice: 0.7310025510204081
ETIS-LaribPolypDB :  0.7310025510204081
2023-09-02 07:44:09.335771: train_loss -1.4675
2023-09-02 07:44:09.338002: val_loss -1.0426
2023-09-02 07:44:09.339699: Pseudo dice [0.8418]
2023-09-02 07:44:09.340819: Epoch time: 115.36 s
2023-09-02 07:44:09.341867: Yayy! New best EMA pseudo Dice: 0.8414
2023-09-02 07:44:12.637300: 
2023-09-02 07:44:12.638838: Epoch 158
2023-09-02 07:44:12.639993: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-02 07:44:12.641623: start training, 250
================num of epochs: 250================
2023-09-02 07:45:11.026425: finished training
epoch: 158, dataset: CVC-300, dice: 0.8792650000000004
CVC-300 :  0.8792650000000004
epoch: 158, dataset: CVC-ClinicDB, dice: 0.8558919354838711
CVC-ClinicDB :  0.8558919354838711
epoch: 158, dataset: Kvasir, dice: 0.9059929999999998
Kvasir :  0.9059929999999998
epoch: 158, dataset: CVC-ColonDB, dice: 0.7030789473684207
CVC-ColonDB :  0.7030789473684207
epoch: 158, dataset: ETIS-LaribPolypDB, dice: 0.7249158163265306
ETIS-LaribPolypDB :  0.7249158163265306
2023-09-02 07:46:05.262168: train_loss -1.4681
2023-09-02 07:46:05.263736: val_loss -0.9899
2023-09-02 07:46:05.264992: Pseudo dice [0.833]
2023-09-02 07:46:05.266014: Epoch time: 112.63 s
2023-09-02 07:46:06.487684: 
2023-09-02 07:46:06.489375: Epoch 159
2023-09-02 07:46:06.490408: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-02 07:46:06.491792: start training, 250
================num of epochs: 250================
2023-09-02 07:47:04.397496: finished training
epoch: 159, dataset: CVC-300, dice: 0.8790000000000001
CVC-300 :  0.8790000000000001
epoch: 159, dataset: CVC-ClinicDB, dice: 0.8518999999999999
CVC-ClinicDB :  0.8518999999999999
epoch: 159, dataset: Kvasir, dice: 0.9078339999999997
Kvasir :  0.9078339999999997
epoch: 159, dataset: CVC-ColonDB, dice: 0.7025505263157892
CVC-ColonDB :  0.7025505263157892
epoch: 159, dataset: ETIS-LaribPolypDB, dice: 0.729332142857143
ETIS-LaribPolypDB :  0.729332142857143
2023-09-02 07:47:58.372786: train_loss -1.4677
2023-09-02 07:47:58.374413: val_loss -1.0399
2023-09-02 07:47:58.375677: Pseudo dice [0.8406]
2023-09-02 07:47:58.376707: Epoch time: 111.89 s
2023-09-02 07:48:01.330885: 
2023-09-02 07:48:01.332348: Epoch 160
2023-09-02 07:48:01.333416: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-02 07:48:01.335169: start training, 250
================num of epochs: 250================
2023-09-02 07:48:59.304567: finished training
epoch: 160, dataset: CVC-300, dice: 0.8777133333333331
CVC-300 :  0.8777133333333331
epoch: 160, dataset: CVC-ClinicDB, dice: 0.8428596774193547
CVC-ClinicDB :  0.8428596774193547
epoch: 160, dataset: Kvasir, dice: 0.9044140000000003
Kvasir :  0.9044140000000003
epoch: 160, dataset: CVC-ColonDB, dice: 0.6980952631578954
CVC-ColonDB :  0.6980952631578954
epoch: 160, dataset: ETIS-LaribPolypDB, dice: 0.7332494897959183
ETIS-LaribPolypDB :  0.7332494897959183
2023-09-02 07:49:53.884478: train_loss -1.4684
2023-09-02 07:49:53.886683: val_loss -1.1003
2023-09-02 07:49:53.888836: Pseudo dice [0.8588]
2023-09-02 07:49:53.890946: Epoch time: 112.55 s
2023-09-02 07:49:53.893835: Yayy! New best EMA pseudo Dice: 0.8424
2023-09-02 07:49:57.232677: 
2023-09-02 07:49:57.234185: Epoch 161
2023-09-02 07:49:57.235560: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-02 07:49:57.237130: start training, 250
================num of epochs: 250================
2023-09-02 07:50:55.216800: finished training
epoch: 161, dataset: CVC-300, dice: 0.8733183333333334
CVC-300 :  0.8733183333333334
epoch: 161, dataset: CVC-ClinicDB, dice: 0.8540306451612908
CVC-ClinicDB :  0.8540306451612908
epoch: 161, dataset: Kvasir, dice: 0.9041340000000007
Kvasir :  0.9041340000000007
epoch: 161, dataset: CVC-ColonDB, dice: 0.7041260526315791
CVC-ColonDB :  0.7041260526315791
epoch: 161, dataset: ETIS-LaribPolypDB, dice: 0.7388897959183676
ETIS-LaribPolypDB :  0.7388897959183676
2023-09-02 07:51:49.718716: train_loss -1.4672
2023-09-02 07:51:49.720344: val_loss -1.0557
2023-09-02 07:51:49.721648: Pseudo dice [0.8523]
2023-09-02 07:51:49.722734: Epoch time: 112.49 s
2023-09-02 07:51:49.723761: Yayy! New best EMA pseudo Dice: 0.8434
2023-09-02 07:51:52.563462: 
2023-09-02 07:51:52.564991: Epoch 162
2023-09-02 07:51:52.566035: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-02 07:51:52.567543: start training, 250
================num of epochs: 250================
2023-09-02 07:52:50.530002: finished training
epoch: 162, dataset: CVC-300, dice: 0.8728666666666666
CVC-300 :  0.8728666666666666
epoch: 162, dataset: CVC-ClinicDB, dice: 0.8530048387096774
CVC-ClinicDB :  0.8530048387096774
epoch: 162, dataset: Kvasir, dice: 0.9041609999999999
Kvasir :  0.9041609999999999
epoch: 162, dataset: CVC-ColonDB, dice: 0.708463157894737
CVC-ColonDB :  0.708463157894737
epoch: 162, dataset: ETIS-LaribPolypDB, dice: 0.7267122448979595
ETIS-LaribPolypDB :  0.7267122448979595
2023-09-02 07:53:45.136569: train_loss -1.4678
2023-09-02 07:53:45.138041: val_loss -1.0693
2023-09-02 07:53:45.139214: Pseudo dice [0.8503]
2023-09-02 07:53:45.140195: Epoch time: 112.57 s
2023-09-02 07:53:45.141090: Yayy! New best EMA pseudo Dice: 0.8441
2023-09-02 07:53:48.096805: 
2023-09-02 07:53:48.098319: Epoch 163
2023-09-02 07:53:48.099425: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-02 07:53:48.100894: start training, 250
================num of epochs: 250================
2023-09-02 07:54:46.019015: finished training
epoch: 163, dataset: CVC-300, dice: 0.8734583333333333
CVC-300 :  0.8734583333333333
epoch: 163, dataset: CVC-ClinicDB, dice: 0.8510483870967743
CVC-ClinicDB :  0.8510483870967743
epoch: 163, dataset: Kvasir, dice: 0.9029110000000005
Kvasir :  0.9029110000000005
epoch: 163, dataset: CVC-ColonDB, dice: 0.7012871052631584
CVC-ColonDB :  0.7012871052631584
epoch: 163, dataset: ETIS-LaribPolypDB, dice: 0.7312377551020405
ETIS-LaribPolypDB :  0.7312377551020405
2023-09-02 07:55:40.260851: train_loss -1.4679
2023-09-02 07:55:40.262461: val_loss -0.9988
2023-09-02 07:55:40.263804: Pseudo dice [0.8377]
2023-09-02 07:55:40.264885: Epoch time: 112.17 s
2023-09-02 07:55:41.492234: 
2023-09-02 07:55:41.493763: Epoch 164
2023-09-02 07:55:41.494853: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-02 07:55:41.496374: start training, 250
================num of epochs: 250================
2023-09-02 07:56:39.637744: finished training
epoch: 164, dataset: CVC-300, dice: 0.8832216666666667
CVC-300 :  0.8832216666666667
epoch: 164, dataset: CVC-ClinicDB, dice: 0.8551193548387097
CVC-ClinicDB :  0.8551193548387097
epoch: 164, dataset: Kvasir, dice: 0.9048960000000005
Kvasir :  0.9048960000000005
epoch: 164, dataset: CVC-ColonDB, dice: 0.708931578947369
CVC-ColonDB :  0.708931578947369
epoch: 164, dataset: ETIS-LaribPolypDB, dice: 0.7302566326530611
ETIS-LaribPolypDB :  0.7302566326530611
2023-09-02 07:57:34.046549: train_loss -1.468
2023-09-02 07:57:34.048196: val_loss -0.955
2023-09-02 07:57:34.049593: Pseudo dice [0.8209]
2023-09-02 07:57:34.050745: Epoch time: 112.56 s
2023-09-02 07:57:35.254231: 
2023-09-02 07:57:35.255899: Epoch 165
2023-09-02 07:57:35.257212: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-02 07:57:35.258723: start training, 250
================num of epochs: 250================
2023-09-02 07:58:34.374040: finished training
epoch: 165, dataset: CVC-300, dice: 0.8811166666666667
CVC-300 :  0.8811166666666667
epoch: 165, dataset: CVC-ClinicDB, dice: 0.854027419354839
CVC-ClinicDB :  0.854027419354839
epoch: 165, dataset: Kvasir, dice: 0.9038060000000001
Kvasir :  0.9038060000000001
epoch: 165, dataset: CVC-ColonDB, dice: 0.7138913157894736
CVC-ColonDB :  0.7138913157894736
epoch: 165, dataset: ETIS-LaribPolypDB, dice: 0.7349954081632654
ETIS-LaribPolypDB :  0.7349954081632654
2023-09-02 07:59:29.520943: train_loss -1.4688
2023-09-02 07:59:29.522594: val_loss -1.0028
2023-09-02 07:59:29.523984: Pseudo dice [0.8387]
2023-09-02 07:59:29.525041: Epoch time: 114.27 s
2023-09-02 07:59:30.840961: 
2023-09-02 07:59:30.842687: Epoch 166
2023-09-02 07:59:30.843796: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-02 07:59:30.846702: start training, 250
================num of epochs: 250================
2023-09-02 08:00:28.716755: finished training
epoch: 166, dataset: CVC-300, dice: 0.8748666666666665
CVC-300 :  0.8748666666666665
epoch: 166, dataset: CVC-ClinicDB, dice: 0.8541403225806452
CVC-ClinicDB :  0.8541403225806452
epoch: 166, dataset: Kvasir, dice: 0.9063580000000002
Kvasir :  0.9063580000000002
epoch: 166, dataset: CVC-ColonDB, dice: 0.7067786842105263
CVC-ColonDB :  0.7067786842105263
epoch: 166, dataset: ETIS-LaribPolypDB, dice: 0.73275
ETIS-LaribPolypDB :  0.73275
2023-09-02 08:01:22.772298: train_loss -1.4684
2023-09-02 08:01:22.774089: val_loss -1.0374
2023-09-02 08:01:22.775424: Pseudo dice [0.8462]
2023-09-02 08:01:22.776697: Epoch time: 111.93 s
2023-09-02 08:01:24.018139: 
2023-09-02 08:01:24.019718: Epoch 167
2023-09-02 08:01:24.020843: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-02 08:01:24.022274: start training, 250
================num of epochs: 250================
2023-09-02 08:02:22.124806: finished training
epoch: 167, dataset: CVC-300, dice: 0.882981666666667
CVC-300 :  0.882981666666667
epoch: 167, dataset: CVC-ClinicDB, dice: 0.8564806451612906
CVC-ClinicDB :  0.8564806451612906
epoch: 167, dataset: Kvasir, dice: 0.904764
Kvasir :  0.904764
epoch: 167, dataset: CVC-ColonDB, dice: 0.7163373684210533
CVC-ColonDB :  0.7163373684210533
epoch: 167, dataset: ETIS-LaribPolypDB, dice: 0.7424964285714286
ETIS-LaribPolypDB :  0.7424964285714286
2023-09-02 08:03:16.810165: train_loss -1.4682
2023-09-02 08:03:16.811719: val_loss -0.9769
2023-09-02 08:03:16.813020: Pseudo dice [0.8288]
2023-09-02 08:03:16.814133: Epoch time: 112.79 s
2023-09-02 08:03:18.020625: 
2023-09-02 08:03:18.022198: Epoch 168
2023-09-02 08:03:18.023288: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-02 08:03:18.024754: start training, 250
================num of epochs: 250================
2023-09-02 08:04:15.911158: finished training
epoch: 168, dataset: CVC-300, dice: 0.8802799999999998
CVC-300 :  0.8802799999999998
epoch: 168, dataset: CVC-ClinicDB, dice: 0.8554983870967742
CVC-ClinicDB :  0.8554983870967742
epoch: 168, dataset: Kvasir, dice: 0.9055879999999997
Kvasir :  0.9055879999999997
epoch: 168, dataset: CVC-ColonDB, dice: 0.7148063157894741
CVC-ColonDB :  0.7148063157894741
epoch: 168, dataset: ETIS-LaribPolypDB, dice: 0.7446071428571432
ETIS-LaribPolypDB :  0.7446071428571432
2023-09-02 08:05:13.209027: train_loss -1.4685
2023-09-02 08:05:13.210717: val_loss -1.0169
2023-09-02 08:05:13.212039: Pseudo dice [0.8414]
2023-09-02 08:05:13.213120: Epoch time: 115.19 s
2023-09-02 08:05:14.429372: 
2023-09-02 08:05:14.430856: Epoch 169
2023-09-02 08:05:14.432051: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-02 08:05:14.433532: start training, 250
================num of epochs: 250================
2023-09-02 08:06:12.382000: finished training
epoch: 169, dataset: CVC-300, dice: 0.8804966666666669
CVC-300 :  0.8804966666666669
epoch: 169, dataset: CVC-ClinicDB, dice: 0.8546064516129032
CVC-ClinicDB :  0.8546064516129032
epoch: 169, dataset: Kvasir, dice: 0.9058940000000005
Kvasir :  0.9058940000000005
epoch: 169, dataset: CVC-ColonDB, dice: 0.7092465789473691
CVC-ColonDB :  0.7092465789473691
epoch: 169, dataset: ETIS-LaribPolypDB, dice: 0.7359688775510209
ETIS-LaribPolypDB :  0.7359688775510209
2023-09-02 08:07:07.565421: train_loss -1.4685
2023-09-02 08:07:07.567061: val_loss -1.0742
2023-09-02 08:07:07.568614: Pseudo dice [0.8569]
2023-09-02 08:07:07.569801: Epoch time: 113.14 s
2023-09-02 08:07:10.411788: 
2023-09-02 08:07:10.413333: Epoch 170
2023-09-02 08:07:10.414340: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-02 08:07:10.415723: start training, 250
================num of epochs: 250================
2023-09-02 08:08:08.570023: finished training
epoch: 170, dataset: CVC-300, dice: 0.8762733333333333
CVC-300 :  0.8762733333333333
epoch: 170, dataset: CVC-ClinicDB, dice: 0.8551774193548383
CVC-ClinicDB :  0.8551774193548383
epoch: 170, dataset: Kvasir, dice: 0.9056409999999997
Kvasir :  0.9056409999999997
epoch: 170, dataset: CVC-ColonDB, dice: 0.7221571052631578
CVC-ColonDB :  0.7221571052631578
epoch: 170, dataset: ETIS-LaribPolypDB, dice: 0.7440489795918368
ETIS-LaribPolypDB :  0.7440489795918368
2023-09-02 08:09:02.964478: train_loss -1.4683
2023-09-02 08:09:02.966117: val_loss -1.0411
2023-09-02 08:09:02.967474: Pseudo dice [0.8457]
2023-09-02 08:09:02.968529: Epoch time: 112.55 s
2023-09-02 08:09:04.172224: 
2023-09-02 08:09:04.173714: Epoch 171
2023-09-02 08:09:04.174792: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-02 08:09:04.176234: start training, 250
================num of epochs: 250================
2023-09-02 08:10:02.368611: finished training
epoch: 171, dataset: CVC-300, dice: 0.8667899999999998
CVC-300 :  0.8667899999999998
epoch: 171, dataset: CVC-ClinicDB, dice: 0.8552354838709676
CVC-ClinicDB :  0.8552354838709676
epoch: 171, dataset: Kvasir, dice: 0.9054949999999997
Kvasir :  0.9054949999999997
epoch: 171, dataset: CVC-ColonDB, dice: 0.7141310526315795
CVC-ColonDB :  0.7141310526315795
epoch: 171, dataset: ETIS-LaribPolypDB, dice: 0.724535204081633
ETIS-LaribPolypDB :  0.724535204081633
2023-09-02 08:10:56.425450: train_loss -1.4687
2023-09-02 08:10:56.427162: val_loss -0.9774
2023-09-02 08:10:56.428531: Pseudo dice [0.8251]
2023-09-02 08:10:56.429623: Epoch time: 112.25 s
2023-09-02 08:10:57.646775: 
2023-09-02 08:10:57.648202: Epoch 172
2023-09-02 08:10:57.649364: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-02 08:10:57.651079: start training, 250
================num of epochs: 250================
2023-09-02 08:11:55.565737: finished training
epoch: 172, dataset: CVC-300, dice: 0.8701883333333335
CVC-300 :  0.8701883333333335
epoch: 172, dataset: CVC-ClinicDB, dice: 0.8572161290322579
CVC-ClinicDB :  0.8572161290322579
epoch: 172, dataset: Kvasir, dice: 0.9033059999999999
Kvasir :  0.9033059999999999
epoch: 172, dataset: CVC-ColonDB, dice: 0.7061244736842106
CVC-ColonDB :  0.7061244736842106
epoch: 172, dataset: ETIS-LaribPolypDB, dice: 0.7197183673469392
ETIS-LaribPolypDB :  0.7197183673469392
2023-09-02 08:12:51.878086: train_loss -1.4681
2023-09-02 08:12:51.879699: val_loss -1.0216
2023-09-02 08:12:51.881073: Pseudo dice [0.8399]
2023-09-02 08:12:51.882224: Epoch time: 114.23 s
2023-09-02 08:12:53.105397: 
2023-09-02 08:12:53.107054: Epoch 173
2023-09-02 08:12:53.108162: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-02 08:12:53.109721: start training, 250
================num of epochs: 250================
2023-09-02 08:13:51.873019: finished training
epoch: 173, dataset: CVC-300, dice: 0.8694583333333336
CVC-300 :  0.8694583333333336
epoch: 173, dataset: CVC-ClinicDB, dice: 0.8598467741935483
CVC-ClinicDB :  0.8598467741935483
epoch: 173, dataset: Kvasir, dice: 0.9059610000000003
Kvasir :  0.9059610000000003
epoch: 173, dataset: CVC-ColonDB, dice: 0.7079978947368427
CVC-ColonDB :  0.7079978947368427
epoch: 173, dataset: ETIS-LaribPolypDB, dice: 0.723429591836735
ETIS-LaribPolypDB :  0.723429591836735
2023-09-02 08:14:47.057546: train_loss -1.4684
2023-09-02 08:14:47.059536: val_loss -0.9812
2023-09-02 08:14:47.060878: Pseudo dice [0.828]
2023-09-02 08:14:47.062001: Epoch time: 113.95 s
2023-09-02 08:14:48.270972: 
2023-09-02 08:14:48.272636: Epoch 174
2023-09-02 08:14:48.273785: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-02 08:14:48.275330: start training, 250
================num of epochs: 250================
2023-09-02 08:15:46.243280: finished training
epoch: 174, dataset: CVC-300, dice: 0.8638183333333331
CVC-300 :  0.8638183333333331
epoch: 174, dataset: CVC-ClinicDB, dice: 0.8607306451612902
CVC-ClinicDB :  0.8607306451612902
epoch: 174, dataset: Kvasir, dice: 0.9072599999999995
Kvasir :  0.9072599999999995
epoch: 174, dataset: CVC-ColonDB, dice: 0.7002405263157894
CVC-ColonDB :  0.7002405263157894
epoch: 174, dataset: ETIS-LaribPolypDB, dice: 0.7055755102040816
ETIS-LaribPolypDB :  0.7055755102040816
2023-09-02 08:16:43.202885: train_loss -1.4686
2023-09-02 08:16:43.204454: val_loss -1.0187
2023-09-02 08:16:43.205719: Pseudo dice [0.8402]
2023-09-02 08:16:43.206769: Epoch time: 114.93 s
2023-09-02 08:16:44.424437: 
2023-09-02 08:16:44.426029: Epoch 175
2023-09-02 08:16:44.427141: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-02 08:16:44.428539: start training, 250
================num of epochs: 250================
2023-09-02 08:17:42.363689: finished training
epoch: 175, dataset: CVC-300, dice: 0.8847766666666668
CVC-300 :  0.8847766666666668
epoch: 175, dataset: CVC-ClinicDB, dice: 0.8553032258064516
CVC-ClinicDB :  0.8553032258064516
epoch: 175, dataset: Kvasir, dice: 0.9064019999999996
Kvasir :  0.9064019999999996
epoch: 175, dataset: CVC-ColonDB, dice: 0.7084405263157897
CVC-ColonDB :  0.7084405263157897
epoch: 175, dataset: ETIS-LaribPolypDB, dice: 0.7418775510204082
ETIS-LaribPolypDB :  0.7418775510204082
2023-09-02 08:18:36.626719: train_loss -1.4685
2023-09-02 08:18:36.628288: val_loss -1.0101
2023-09-02 08:18:36.629625: Pseudo dice [0.8372]
2023-09-02 08:18:36.630730: Epoch time: 112.2 s
2023-09-02 08:18:37.844758: 
2023-09-02 08:18:37.846333: Epoch 176
2023-09-02 08:18:37.847501: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-02 08:18:37.849060: start training, 250
================num of epochs: 250================
2023-09-02 08:19:36.041773: finished training
epoch: 176, dataset: CVC-300, dice: 0.8851483333333334
CVC-300 :  0.8851483333333334
epoch: 176, dataset: CVC-ClinicDB, dice: 0.8563967741935483
CVC-ClinicDB :  0.8563967741935483
epoch: 176, dataset: Kvasir, dice: 0.9046459999999996
Kvasir :  0.9046459999999996
epoch: 176, dataset: CVC-ColonDB, dice: 0.7077539473684218
CVC-ColonDB :  0.7077539473684218
epoch: 176, dataset: ETIS-LaribPolypDB, dice: 0.7405693877551022
ETIS-LaribPolypDB :  0.7405693877551022
2023-09-02 08:20:29.962443: train_loss -1.4688
2023-09-02 08:20:29.963997: val_loss -0.9795
2023-09-02 08:20:29.965236: Pseudo dice [0.8248]
2023-09-02 08:20:29.966281: Epoch time: 112.12 s
2023-09-02 08:20:31.178062: 
2023-09-02 08:20:31.179576: Epoch 177
2023-09-02 08:20:31.180650: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-02 08:20:31.182112: start training, 250
================num of epochs: 250================
2023-09-02 08:21:29.255342: finished training
epoch: 177, dataset: CVC-300, dice: 0.8734749999999998
CVC-300 :  0.8734749999999998
epoch: 177, dataset: CVC-ClinicDB, dice: 0.8564838709677419
CVC-ClinicDB :  0.8564838709677419
epoch: 177, dataset: Kvasir, dice: 0.902403
Kvasir :  0.902403
epoch: 177, dataset: CVC-ColonDB, dice: 0.7032228947368421
CVC-ColonDB :  0.7032228947368421
epoch: 177, dataset: ETIS-LaribPolypDB, dice: 0.7362841836734699
ETIS-LaribPolypDB :  0.7362841836734699
2023-09-02 08:22:22.982129: train_loss -1.469
2023-09-02 08:22:22.985550: val_loss -0.9936
2023-09-02 08:22:22.987343: Pseudo dice [0.8348]
2023-09-02 08:22:22.988560: Epoch time: 111.81 s
2023-09-02 08:22:24.206237: 
2023-09-02 08:22:24.207891: Epoch 178
2023-09-02 08:22:24.209065: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-02 08:22:24.210603: start training, 250
================num of epochs: 250================
2023-09-02 08:23:22.023515: finished training
epoch: 178, dataset: CVC-300, dice: 0.8792616666666665
CVC-300 :  0.8792616666666665
epoch: 178, dataset: CVC-ClinicDB, dice: 0.8568064516129031
CVC-ClinicDB :  0.8568064516129031
epoch: 178, dataset: Kvasir, dice: 0.9031910000000003
Kvasir :  0.9031910000000003
epoch: 178, dataset: CVC-ColonDB, dice: 0.7091271052631577
CVC-ColonDB :  0.7091271052631577
epoch: 178, dataset: ETIS-LaribPolypDB, dice: 0.7384923469387756
ETIS-LaribPolypDB :  0.7384923469387756
2023-09-02 08:24:20.151202: train_loss -1.469
2023-09-02 08:24:20.153021: val_loss -1.0224
2023-09-02 08:24:20.154639: Pseudo dice [0.8384]
2023-09-02 08:24:20.155799: Epoch time: 115.95 s
2023-09-02 08:24:21.373711: 
2023-09-02 08:24:21.375341: Epoch 179
2023-09-02 08:24:21.376481: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-02 08:24:21.377995: start training, 250
================num of epochs: 250================
2023-09-02 08:25:19.509623: finished training
epoch: 179, dataset: CVC-300, dice: 0.8625183333333335
CVC-300 :  0.8625183333333335
epoch: 179, dataset: CVC-ClinicDB, dice: 0.8521983870967744
CVC-ClinicDB :  0.8521983870967744
epoch: 179, dataset: Kvasir, dice: 0.901374
Kvasir :  0.901374
epoch: 179, dataset: CVC-ColonDB, dice: 0.6876536842105271
CVC-ColonDB :  0.6876536842105271
epoch: 179, dataset: ETIS-LaribPolypDB, dice: 0.719561734693878
ETIS-LaribPolypDB :  0.719561734693878
2023-09-02 08:26:14.565155: train_loss -1.4667
2023-09-02 08:26:14.566731: val_loss -1.0401
2023-09-02 08:26:14.568077: Pseudo dice [0.8449]
2023-09-02 08:26:14.569139: Epoch time: 113.19 s
2023-09-02 08:26:17.505839: 
2023-09-02 08:26:17.507692: Epoch 180
2023-09-02 08:26:17.508839: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-02 08:26:17.510471: start training, 250
================num of epochs: 250================
2023-09-02 08:27:15.397370: finished training
epoch: 180, dataset: CVC-300, dice: 0.8631616666666666
CVC-300 :  0.8631616666666666
epoch: 180, dataset: CVC-ClinicDB, dice: 0.8499306451612901
CVC-ClinicDB :  0.8499306451612901
epoch: 180, dataset: Kvasir, dice: 0.8973079999999998
Kvasir :  0.8973079999999998
epoch: 180, dataset: CVC-ColonDB, dice: 0.683174210526316
CVC-ColonDB :  0.683174210526316
epoch: 180, dataset: ETIS-LaribPolypDB, dice: 0.7260255102040819
ETIS-LaribPolypDB :  0.7260255102040819
2023-09-02 08:28:11.507322: train_loss -1.4672
2023-09-02 08:28:11.508979: val_loss -0.9523
2023-09-02 08:28:11.510398: Pseudo dice [0.8249]
2023-09-02 08:28:11.511634: Epoch time: 114.0 s
2023-09-02 08:28:12.715257: 
2023-09-02 08:28:12.716730: Epoch 181
2023-09-02 08:28:12.717788: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-02 08:28:12.719368: start training, 250
================num of epochs: 250================
2023-09-02 08:29:10.509663: finished training
epoch: 181, dataset: CVC-300, dice: 0.8594383333333333
CVC-300 :  0.8594383333333333
epoch: 181, dataset: CVC-ClinicDB, dice: 0.8476870967741934
CVC-ClinicDB :  0.8476870967741934
epoch: 181, dataset: Kvasir, dice: 0.9043519999999999
Kvasir :  0.9043519999999999
epoch: 181, dataset: CVC-ColonDB, dice: 0.6946323684210531
CVC-ColonDB :  0.6946323684210531
epoch: 181, dataset: ETIS-LaribPolypDB, dice: 0.7278413265306122
ETIS-LaribPolypDB :  0.7278413265306122
2023-09-02 08:30:04.974703: train_loss -1.4679
2023-09-02 08:30:04.976511: val_loss -0.9718
2023-09-02 08:30:04.977911: Pseudo dice [0.8319]
2023-09-02 08:30:04.979081: Epoch time: 112.26 s
2023-09-02 08:30:06.208657: 
2023-09-02 08:30:06.210265: Epoch 182
2023-09-02 08:30:06.211975: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-02 08:30:06.214211: start training, 250
================num of epochs: 250================
2023-09-02 08:31:04.305957: finished training
epoch: 182, dataset: CVC-300, dice: 0.8619049999999998
CVC-300 :  0.8619049999999998
epoch: 182, dataset: CVC-ClinicDB, dice: 0.8547999999999999
CVC-ClinicDB :  0.8547999999999999
epoch: 182, dataset: Kvasir, dice: 0.8995949999999995
Kvasir :  0.8995949999999995
epoch: 182, dataset: CVC-ColonDB, dice: 0.6936147368421062
CVC-ColonDB :  0.6936147368421062
epoch: 182, dataset: ETIS-LaribPolypDB, dice: 0.7282872448979594
ETIS-LaribPolypDB :  0.7282872448979594
2023-09-02 08:31:58.822017: train_loss -1.4683
2023-09-02 08:31:58.823574: val_loss -1.0526
2023-09-02 08:31:58.824941: Pseudo dice [0.8571]
2023-09-02 08:31:58.826061: Epoch time: 112.61 s
2023-09-02 08:32:00.064640: 
2023-09-02 08:32:00.066322: Epoch 183
2023-09-02 08:32:00.067383: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-02 08:32:00.068842: start training, 250
================num of epochs: 250================
2023-09-02 08:32:57.927129: finished training
epoch: 183, dataset: CVC-300, dice: 0.8684433333333331
CVC-300 :  0.8684433333333331
epoch: 183, dataset: CVC-ClinicDB, dice: 0.8519080645161289
CVC-ClinicDB :  0.8519080645161289
epoch: 183, dataset: Kvasir, dice: 0.9059420000000001
Kvasir :  0.9059420000000001
epoch: 183, dataset: CVC-ColonDB, dice: 0.7011728947368422
CVC-ColonDB :  0.7011728947368422
epoch: 183, dataset: ETIS-LaribPolypDB, dice: 0.7350193877551022
ETIS-LaribPolypDB :  0.7350193877551022
2023-09-02 08:33:51.623802: train_loss -1.4686
2023-09-02 08:33:51.625385: val_loss -0.9853
2023-09-02 08:33:51.626726: Pseudo dice [0.8329]
2023-09-02 08:33:51.627845: Epoch time: 111.56 s
2023-09-02 08:33:52.863460: 
2023-09-02 08:33:52.865321: Epoch 184
2023-09-02 08:33:52.866431: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-02 08:33:52.868502: start training, 250
================num of epochs: 250================
2023-09-02 08:34:50.810576: finished training
epoch: 184, dataset: CVC-300, dice: 0.8699233333333333
CVC-300 :  0.8699233333333333
epoch: 184, dataset: CVC-ClinicDB, dice: 0.8572629032258061
CVC-ClinicDB :  0.8572629032258061
epoch: 184, dataset: Kvasir, dice: 0.9068159999999996
Kvasir :  0.9068159999999996
epoch: 184, dataset: CVC-ColonDB, dice: 0.7039889473684207
CVC-ColonDB :  0.7039889473684207
epoch: 184, dataset: ETIS-LaribPolypDB, dice: 0.7391066326530615
ETIS-LaribPolypDB :  0.7391066326530615
2023-09-02 08:35:44.842902: train_loss -1.4691
2023-09-02 08:35:44.844473: val_loss -0.9088
2023-09-02 08:35:44.845963: Pseudo dice [0.8135]
2023-09-02 08:35:44.847078: Epoch time: 111.98 s
2023-09-02 08:35:46.106822: 
2023-09-02 08:35:46.108505: Epoch 185
2023-09-02 08:35:46.109633: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-02 08:35:46.111078: start training, 250
================num of epochs: 250================
2023-09-02 08:36:44.204926: finished training
epoch: 185, dataset: CVC-300, dice: 0.8718283333333334
CVC-300 :  0.8718283333333334
epoch: 185, dataset: CVC-ClinicDB, dice: 0.8578516129032259
CVC-ClinicDB :  0.8578516129032259
epoch: 185, dataset: Kvasir, dice: 0.905095
Kvasir :  0.905095
epoch: 185, dataset: CVC-ColonDB, dice: 0.7011376315789478
CVC-ColonDB :  0.7011376315789478
epoch: 185, dataset: ETIS-LaribPolypDB, dice: 0.7397846938775514
ETIS-LaribPolypDB :  0.7397846938775514
2023-09-02 08:37:37.688107: train_loss -1.4696
2023-09-02 08:37:37.689804: val_loss -1.0811
2023-09-02 08:37:37.691190: Pseudo dice [0.8563]
2023-09-02 08:37:37.692252: Epoch time: 111.58 s
2023-09-02 08:37:39.225678: 
2023-09-02 08:37:39.227426: Epoch 186
2023-09-02 08:37:39.228565: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-02 08:37:39.230135: start training, 250
================num of epochs: 250================
2023-09-02 08:38:37.193603: finished training
epoch: 186, dataset: CVC-300, dice: 0.8681899999999998
CVC-300 :  0.8681899999999998
epoch: 186, dataset: CVC-ClinicDB, dice: 0.8564999999999999
CVC-ClinicDB :  0.8564999999999999
epoch: 186, dataset: Kvasir, dice: 0.9046770000000001
Kvasir :  0.9046770000000001
epoch: 186, dataset: CVC-ColonDB, dice: 0.6954076315789481
CVC-ColonDB :  0.6954076315789481
epoch: 186, dataset: ETIS-LaribPolypDB, dice: 0.7383397959183674
ETIS-LaribPolypDB :  0.7383397959183674
2023-09-02 08:39:36.854703: train_loss -1.4692
2023-09-02 08:39:36.856358: val_loss -1.0148
2023-09-02 08:39:36.857790: Pseudo dice [0.8358]
2023-09-02 08:39:36.859103: Epoch time: 117.63 s
2023-09-02 08:39:38.112162: 
2023-09-02 08:39:38.114007: Epoch 187
2023-09-02 08:39:38.115222: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-02 08:39:38.116879: start training, 250
================num of epochs: 250================
2023-09-02 08:40:36.523275: finished training
epoch: 187, dataset: CVC-300, dice: 0.8755433333333333
CVC-300 :  0.8755433333333333
epoch: 187, dataset: CVC-ClinicDB, dice: 0.8533612903225807
CVC-ClinicDB :  0.8533612903225807
epoch: 187, dataset: Kvasir, dice: 0.9047879999999999
Kvasir :  0.9047879999999999
epoch: 187, dataset: CVC-ColonDB, dice: 0.6965492105263165
CVC-ColonDB :  0.6965492105263165
epoch: 187, dataset: ETIS-LaribPolypDB, dice: 0.7368255102040822
ETIS-LaribPolypDB :  0.7368255102040822
2023-09-02 08:41:37.123266: train_loss -1.4697
2023-09-02 08:41:37.125269: val_loss -0.9261
2023-09-02 08:41:37.126806: Pseudo dice [0.8151]
2023-09-02 08:41:37.127905: Epoch time: 119.01 s
2023-09-02 08:41:38.405101: 
2023-09-02 08:41:38.406848: Epoch 188
2023-09-02 08:41:38.408035: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-02 08:41:38.409776: start training, 250
================num of epochs: 250================
2023-09-02 08:42:37.107306: finished training
epoch: 188, dataset: CVC-300, dice: 0.868785
CVC-300 :  0.868785
epoch: 188, dataset: CVC-ClinicDB, dice: 0.8569274193548387
CVC-ClinicDB :  0.8569274193548387
epoch: 188, dataset: Kvasir, dice: 0.9041809999999999
Kvasir :  0.9041809999999999
epoch: 188, dataset: CVC-ColonDB, dice: 0.6999886842105261
CVC-ColonDB :  0.6999886842105261
epoch: 188, dataset: ETIS-LaribPolypDB, dice: 0.7448066326530616
ETIS-LaribPolypDB :  0.7448066326530616
2023-09-02 08:43:37.772493: train_loss -1.4693
2023-09-02 08:43:37.774198: val_loss -1.0381
2023-09-02 08:43:37.775799: Pseudo dice [0.8424]
2023-09-02 08:43:37.776942: Epoch time: 119.37 s
2023-09-02 08:43:39.082564: 
2023-09-02 08:43:39.084716: Epoch 189
2023-09-02 08:43:39.086040: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-02 08:43:39.088366: start training, 250
================num of epochs: 250================
2023-09-02 08:44:37.600791: finished training
epoch: 189, dataset: CVC-300, dice: 0.8593449999999999
CVC-300 :  0.8593449999999999
epoch: 189, dataset: CVC-ClinicDB, dice: 0.8547451612903224
CVC-ClinicDB :  0.8547451612903224
epoch: 189, dataset: Kvasir, dice: 0.9073250000000005
Kvasir :  0.9073250000000005
epoch: 189, dataset: CVC-ColonDB, dice: 0.696135
CVC-ColonDB :  0.696135
epoch: 189, dataset: ETIS-LaribPolypDB, dice: 0.742012755102041
ETIS-LaribPolypDB :  0.742012755102041
2023-09-02 08:45:36.178886: train_loss -1.4688
2023-09-02 08:45:36.182122: val_loss -0.9421
2023-09-02 08:45:36.184582: Pseudo dice [0.8177]
2023-09-02 08:45:36.185887: Epoch time: 117.1 s
2023-09-02 08:45:39.322324: 
2023-09-02 08:45:39.324325: Epoch 190
2023-09-02 08:45:39.325518: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-02 08:45:39.327453: start training, 250
================num of epochs: 250================
2023-09-02 08:46:37.777379: finished training
epoch: 190, dataset: CVC-300, dice: 0.8703466666666669
CVC-300 :  0.8703466666666669
epoch: 190, dataset: CVC-ClinicDB, dice: 0.8175193548387099
CVC-ClinicDB :  0.8175193548387099
epoch: 190, dataset: Kvasir, dice: 0.8941070000000002
Kvasir :  0.8941070000000002
epoch: 190, dataset: CVC-ColonDB, dice: 0.6870100000000005
CVC-ColonDB :  0.6870100000000005
epoch: 190, dataset: ETIS-LaribPolypDB, dice: 0.7301091836734694
ETIS-LaribPolypDB :  0.7301091836734694
2023-09-02 08:47:38.236850: train_loss -1.4691
2023-09-02 08:47:38.238692: val_loss -0.8598
2023-09-02 08:47:38.240361: Pseudo dice [0.8004]
2023-09-02 08:47:38.241884: Epoch time: 118.92 s
2023-09-02 08:47:39.480616: 
2023-09-02 08:47:39.482184: Epoch 191
2023-09-02 08:47:39.483292: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-02 08:47:39.485042: start training, 250
================num of epochs: 250================
2023-09-02 08:48:38.272681: finished training
epoch: 191, dataset: CVC-300, dice: 0.8676916666666664
CVC-300 :  0.8676916666666664
epoch: 191, dataset: CVC-ClinicDB, dice: 0.8295338709677422
CVC-ClinicDB :  0.8295338709677422
epoch: 191, dataset: Kvasir, dice: 0.8988619999999996
Kvasir :  0.8988619999999996
epoch: 191, dataset: CVC-ColonDB, dice: 0.6901928947368424
CVC-ColonDB :  0.6901928947368424
epoch: 191, dataset: ETIS-LaribPolypDB, dice: 0.7398867346938778
ETIS-LaribPolypDB :  0.7398867346938778
2023-09-02 08:49:35.377302: train_loss -1.4688
2023-09-02 08:49:35.379081: val_loss -0.9796
2023-09-02 08:49:35.380502: Pseudo dice [0.8273]
2023-09-02 08:49:35.381708: Epoch time: 115.9 s
2023-09-02 08:49:36.640031: 
2023-09-02 08:49:36.641839: Epoch 192
2023-09-02 08:49:36.643009: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-02 08:49:36.644707: start training, 250
================num of epochs: 250================
2023-09-02 08:50:34.871369: finished training
epoch: 192, dataset: CVC-300, dice: 0.8647366666666667
CVC-300 :  0.8647366666666667
epoch: 192, dataset: CVC-ClinicDB, dice: 0.8331258064516128
CVC-ClinicDB :  0.8331258064516128
epoch: 192, dataset: Kvasir, dice: 0.8956829999999999
Kvasir :  0.8956829999999999
epoch: 192, dataset: CVC-ColonDB, dice: 0.6915747368421049
CVC-ColonDB :  0.6915747368421049
epoch: 192, dataset: ETIS-LaribPolypDB, dice: 0.7270729591836735
ETIS-LaribPolypDB :  0.7270729591836735
2023-09-02 08:51:29.328862: train_loss -1.4698
2023-09-02 08:51:29.330818: val_loss -0.9995
2023-09-02 08:51:29.332330: Pseudo dice [0.8357]
2023-09-02 08:51:29.333448: Epoch time: 112.69 s
2023-09-02 08:51:30.571944: 
2023-09-02 08:51:30.573455: Epoch 193
2023-09-02 08:51:30.574570: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-02 08:51:30.576106: start training, 250
================num of epochs: 250================
2023-09-02 08:52:28.470861: finished training
epoch: 193, dataset: CVC-300, dice: 0.8700383333333332
CVC-300 :  0.8700383333333332
epoch: 193, dataset: CVC-ClinicDB, dice: 0.8460241935483871
CVC-ClinicDB :  0.8460241935483871
epoch: 193, dataset: Kvasir, dice: 0.8955930000000001
Kvasir :  0.8955930000000001
epoch: 193, dataset: CVC-ColonDB, dice: 0.7014850000000009
CVC-ColonDB :  0.7014850000000009
epoch: 193, dataset: ETIS-LaribPolypDB, dice: 0.7356214285714288
ETIS-LaribPolypDB :  0.7356214285714288
2023-09-02 08:53:22.694641: train_loss -1.4699
2023-09-02 08:53:22.696304: val_loss -1.0268
2023-09-02 08:53:22.698063: Pseudo dice [0.844]
2023-09-02 08:53:22.699365: Epoch time: 112.12 s
2023-09-02 08:53:23.932172: 
2023-09-02 08:53:23.933653: Epoch 194
2023-09-02 08:53:23.934756: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-02 08:53:23.936268: start training, 250
================num of epochs: 250================
2023-09-02 08:54:22.111897: finished training
epoch: 194, dataset: CVC-300, dice: 0.8719333333333332
CVC-300 :  0.8719333333333332
epoch: 194, dataset: CVC-ClinicDB, dice: 0.8431532258064512
CVC-ClinicDB :  0.8431532258064512
epoch: 194, dataset: Kvasir, dice: 0.9003069999999995
Kvasir :  0.9003069999999995
epoch: 194, dataset: CVC-ColonDB, dice: 0.693617368421053
CVC-ColonDB :  0.693617368421053
epoch: 194, dataset: ETIS-LaribPolypDB, dice: 0.7316928571428571
ETIS-LaribPolypDB :  0.7316928571428571
2023-09-02 08:55:16.415374: train_loss -1.4698
2023-09-02 08:55:16.417134: val_loss -0.9686
2023-09-02 08:55:16.418495: Pseudo dice [0.8241]
2023-09-02 08:55:16.419633: Epoch time: 112.48 s
2023-09-02 08:55:17.649414: 
2023-09-02 08:55:17.650968: Epoch 195
2023-09-02 08:55:17.652088: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-02 08:55:17.653566: start training, 250
================num of epochs: 250================
2023-09-02 08:56:15.603390: finished training
epoch: 195, dataset: CVC-300, dice: 0.8674166666666665
CVC-300 :  0.8674166666666665
epoch: 195, dataset: CVC-ClinicDB, dice: 0.8478032258064514
CVC-ClinicDB :  0.8478032258064514
epoch: 195, dataset: Kvasir, dice: 0.8989950000000003
Kvasir :  0.8989950000000003
epoch: 195, dataset: CVC-ColonDB, dice: 0.6915850000000003
CVC-ColonDB :  0.6915850000000003
epoch: 195, dataset: ETIS-LaribPolypDB, dice: 0.7298035714285716
ETIS-LaribPolypDB :  0.7298035714285716
2023-09-02 08:57:11.885479: train_loss -1.4699
2023-09-02 08:57:11.887295: val_loss -0.9821
2023-09-02 08:57:11.888765: Pseudo dice [0.8369]
2023-09-02 08:57:11.889976: Epoch time: 114.24 s
2023-09-02 08:57:13.121426: 
2023-09-02 08:57:13.123084: Epoch 196
2023-09-02 08:57:13.124357: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-02 08:57:13.125872: start training, 250
================num of epochs: 250================
2023-09-02 08:58:11.086389: finished training
epoch: 196, dataset: CVC-300, dice: 0.8693866666666664
CVC-300 :  0.8693866666666664
epoch: 196, dataset: CVC-ClinicDB, dice: 0.8475629032258065
CVC-ClinicDB :  0.8475629032258065
epoch: 196, dataset: Kvasir, dice: 0.9015049999999999
Kvasir :  0.9015049999999999
epoch: 196, dataset: CVC-ColonDB, dice: 0.6931247368421057
CVC-ColonDB :  0.6931247368421057
epoch: 196, dataset: ETIS-LaribPolypDB, dice: 0.7241923469387758
ETIS-LaribPolypDB :  0.7241923469387758
2023-09-02 08:59:04.945220: train_loss -1.4699
2023-09-02 08:59:04.946904: val_loss -1.0462
2023-09-02 08:59:04.948234: Pseudo dice [0.8472]
2023-09-02 08:59:04.949334: Epoch time: 111.83 s
2023-09-02 08:59:06.179760: 
2023-09-02 08:59:06.181621: Epoch 197
2023-09-02 08:59:06.182763: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-02 08:59:06.184226: start training, 250
================num of epochs: 250================
2023-09-02 09:00:04.300764: finished training
epoch: 197, dataset: CVC-300, dice: 0.869545
CVC-300 :  0.869545
epoch: 197, dataset: CVC-ClinicDB, dice: 0.8509967741935484
CVC-ClinicDB :  0.8509967741935484
epoch: 197, dataset: Kvasir, dice: 0.9032469999999999
Kvasir :  0.9032469999999999
epoch: 197, dataset: CVC-ColonDB, dice: 0.6937071052631588
CVC-ColonDB :  0.6937071052631588
epoch: 197, dataset: ETIS-LaribPolypDB, dice: 0.72721887755102
ETIS-LaribPolypDB :  0.72721887755102
2023-09-02 09:00:58.609982: train_loss -1.4698
2023-09-02 09:00:58.611574: val_loss -0.9542
2023-09-02 09:00:58.612941: Pseudo dice [0.8268]
2023-09-02 09:00:58.614064: Epoch time: 112.43 s
2023-09-02 09:00:59.850441: 
2023-09-02 09:00:59.852016: Epoch 198
2023-09-02 09:00:59.853206: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-02 09:00:59.854710: start training, 250
================num of epochs: 250================
2023-09-02 09:01:57.798924: finished training
epoch: 198, dataset: CVC-300, dice: 0.8677716666666667
CVC-300 :  0.8677716666666667
epoch: 198, dataset: CVC-ClinicDB, dice: 0.8574838709677419
CVC-ClinicDB :  0.8574838709677419
epoch: 198, dataset: Kvasir, dice: 0.9035090000000006
Kvasir :  0.9035090000000006
epoch: 198, dataset: CVC-ColonDB, dice: 0.6999644736842109
CVC-ColonDB :  0.6999644736842109
epoch: 198, dataset: ETIS-LaribPolypDB, dice: 0.7384698979591833
ETIS-LaribPolypDB :  0.7384698979591833
2023-09-02 09:02:52.101763: train_loss -1.4697
2023-09-02 09:02:52.103392: val_loss -1.0333
2023-09-02 09:02:52.104842: Pseudo dice [0.8473]
2023-09-02 09:02:52.105958: Epoch time: 112.25 s
2023-09-02 09:02:53.339832: 
2023-09-02 09:02:53.341400: Epoch 199
2023-09-02 09:02:53.342513: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-02 09:02:53.343950: start training, 250
================num of epochs: 250================
2023-09-02 09:03:51.238959: finished training
epoch: 199, dataset: CVC-300, dice: 0.8615783333333334
CVC-300 :  0.8615783333333334
epoch: 199, dataset: CVC-ClinicDB, dice: 0.854567741935484
CVC-ClinicDB :  0.854567741935484
epoch: 199, dataset: Kvasir, dice: 0.9031629999999998
Kvasir :  0.9031629999999998
epoch: 199, dataset: CVC-ColonDB, dice: 0.6960757894736835
CVC-ColonDB :  0.6960757894736835
epoch: 199, dataset: ETIS-LaribPolypDB, dice: 0.7270617346938778
ETIS-LaribPolypDB :  0.7270617346938778
2023-09-02 09:04:45.007475: train_loss -1.4701
2023-09-02 09:04:45.009086: val_loss -1.0186
2023-09-02 09:04:45.010393: Pseudo dice [0.8447]
2023-09-02 09:04:45.011522: Epoch time: 111.67 s
2023-09-02 09:04:47.818236: 
2023-09-02 09:04:47.819838: Epoch 200
2023-09-02 09:04:47.821049: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-02 09:04:47.822572: start training, 250
================num of epochs: 250================
2023-09-02 09:05:45.869627: finished training
epoch: 200, dataset: CVC-300, dice: 0.8669216666666668
CVC-300 :  0.8669216666666668
epoch: 200, dataset: CVC-ClinicDB, dice: 0.8535790322580644
CVC-ClinicDB :  0.8535790322580644
epoch: 200, dataset: Kvasir, dice: 0.9017310000000001
Kvasir :  0.9017310000000001
epoch: 200, dataset: CVC-ColonDB, dice: 0.6955268421052638
CVC-ColonDB :  0.6955268421052638
epoch: 200, dataset: ETIS-LaribPolypDB, dice: 0.7354724489795919
ETIS-LaribPolypDB :  0.7354724489795919
2023-09-02 09:06:39.722520: train_loss -1.4701
2023-09-02 09:06:39.724141: val_loss -0.9881
2023-09-02 09:06:39.725766: Pseudo dice [0.8346]
2023-09-02 09:06:39.726962: Epoch time: 111.91 s
2023-09-02 09:06:40.934875: 
2023-09-02 09:06:40.936435: Epoch 201
2023-09-02 09:06:40.937559: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-02 09:06:40.939050: start training, 250
================num of epochs: 250================
2023-09-02 09:07:38.790940: finished training
epoch: 201, dataset: CVC-300, dice: 0.8655600000000002
CVC-300 :  0.8655600000000002
epoch: 201, dataset: CVC-ClinicDB, dice: 0.8566790322580644
CVC-ClinicDB :  0.8566790322580644
epoch: 201, dataset: Kvasir, dice: 0.9038129999999999
Kvasir :  0.9038129999999999
epoch: 201, dataset: CVC-ColonDB, dice: 0.6958452631578947
CVC-ColonDB :  0.6958452631578947
epoch: 201, dataset: ETIS-LaribPolypDB, dice: 0.7376000000000005
ETIS-LaribPolypDB :  0.7376000000000005
2023-09-02 09:08:33.355723: train_loss -1.4708
2023-09-02 09:08:33.357581: val_loss -1.0038
2023-09-02 09:08:33.358973: Pseudo dice [0.8384]
2023-09-02 09:08:33.360108: Epoch time: 112.42 s
2023-09-02 09:08:34.601817: 
2023-09-02 09:08:34.603662: Epoch 202
2023-09-02 09:08:34.604865: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-02 09:08:34.606565: start training, 250
================num of epochs: 250================
2023-09-02 09:09:32.443554: finished training
epoch: 202, dataset: CVC-300, dice: 0.8592000000000001
CVC-300 :  0.8592000000000001
epoch: 202, dataset: CVC-ClinicDB, dice: 0.8566709677419355
CVC-ClinicDB :  0.8566709677419355
epoch: 202, dataset: Kvasir, dice: 0.9036269999999998
Kvasir :  0.9036269999999998
epoch: 202, dataset: CVC-ColonDB, dice: 0.6960176315789475
CVC-ColonDB :  0.6960176315789475
epoch: 202, dataset: ETIS-LaribPolypDB, dice: 0.7375928571428573
ETIS-LaribPolypDB :  0.7375928571428573
2023-09-02 09:10:27.306414: train_loss -1.4707
2023-09-02 09:10:27.308085: val_loss -0.9989
2023-09-02 09:10:27.309508: Pseudo dice [0.8363]
2023-09-02 09:10:27.310621: Epoch time: 112.71 s
2023-09-02 09:10:28.569412: 
2023-09-02 09:10:28.571019: Epoch 203
2023-09-02 09:10:28.572150: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-02 09:10:28.573702: start training, 250
================num of epochs: 250================
2023-09-02 09:11:26.560851: finished training
epoch: 203, dataset: CVC-300, dice: 0.8669516666666668
CVC-300 :  0.8669516666666668
epoch: 203, dataset: CVC-ClinicDB, dice: 0.8553870967741934
CVC-ClinicDB :  0.8553870967741934
epoch: 203, dataset: Kvasir, dice: 0.9054659999999999
Kvasir :  0.9054659999999999
epoch: 203, dataset: CVC-ColonDB, dice: 0.7028839473684217
CVC-ColonDB :  0.7028839473684217
epoch: 203, dataset: ETIS-LaribPolypDB, dice: 0.7420438775510202
ETIS-LaribPolypDB :  0.7420438775510202
2023-09-02 09:12:20.391145: train_loss -1.4705
2023-09-02 09:12:20.392889: val_loss -1.0252
2023-09-02 09:12:20.394353: Pseudo dice [0.8476]
2023-09-02 09:12:20.395604: Epoch time: 111.82 s
2023-09-02 09:12:21.636059: 
2023-09-02 09:12:21.637839: Epoch 204
2023-09-02 09:12:21.638992: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-02 09:12:21.640548: start training, 250
================num of epochs: 250================
2023-09-02 09:13:19.483182: finished training
epoch: 204, dataset: CVC-300, dice: 0.8581450000000003
CVC-300 :  0.8581450000000003
epoch: 204, dataset: CVC-ClinicDB, dice: 0.8546919354838706
CVC-ClinicDB :  0.8546919354838706
epoch: 204, dataset: Kvasir, dice: 0.9054540000000002
Kvasir :  0.9054540000000002
epoch: 204, dataset: CVC-ColonDB, dice: 0.6875357894736838
CVC-ColonDB :  0.6875357894736838
epoch: 204, dataset: ETIS-LaribPolypDB, dice: 0.7414627551020411
ETIS-LaribPolypDB :  0.7414627551020411
2023-09-02 09:14:13.222793: train_loss -1.4706
2023-09-02 09:14:13.224450: val_loss -1.0045
2023-09-02 09:14:13.225833: Pseudo dice [0.8388]
2023-09-02 09:14:13.227008: Epoch time: 111.59 s
2023-09-02 09:14:14.473479: 
2023-09-02 09:14:14.475465: Epoch 205
2023-09-02 09:14:14.477111: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-02 09:14:14.479114: start training, 250
================num of epochs: 250================
2023-09-02 09:15:12.759296: finished training
epoch: 205, dataset: CVC-300, dice: 0.8639083333333333
CVC-300 :  0.8639083333333333
epoch: 205, dataset: CVC-ClinicDB, dice: 0.8551645161290322
CVC-ClinicDB :  0.8551645161290322
epoch: 205, dataset: Kvasir, dice: 0.9034390000000001
Kvasir :  0.9034390000000001
epoch: 205, dataset: CVC-ColonDB, dice: 0.6906023684210534
CVC-ColonDB :  0.6906023684210534
epoch: 205, dataset: ETIS-LaribPolypDB, dice: 0.7301724489795918
ETIS-LaribPolypDB :  0.7301724489795918
2023-09-02 09:16:07.359435: train_loss -1.4707
2023-09-02 09:16:07.361081: val_loss -0.9888
2023-09-02 09:16:07.362435: Pseudo dice [0.829]
2023-09-02 09:16:07.363574: Epoch time: 112.89 s
2023-09-02 09:16:08.611873: 
2023-09-02 09:16:08.613808: Epoch 206
2023-09-02 09:16:08.615115: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-02 09:16:08.617097: start training, 250
================num of epochs: 250================
2023-09-02 09:17:07.103920: finished training
epoch: 206, dataset: CVC-300, dice: 0.8604516666666667
CVC-300 :  0.8604516666666667
epoch: 206, dataset: CVC-ClinicDB, dice: 0.8594096774193547
CVC-ClinicDB :  0.8594096774193547
epoch: 206, dataset: Kvasir, dice: 0.9047139999999999
Kvasir :  0.9047139999999999
epoch: 206, dataset: CVC-ColonDB, dice: 0.6900663157894742
CVC-ColonDB :  0.6900663157894742
epoch: 206, dataset: ETIS-LaribPolypDB, dice: 0.7204923469387757
ETIS-LaribPolypDB :  0.7204923469387757
2023-09-02 09:17:59.734979: train_loss -1.4706
2023-09-02 09:17:59.736659: val_loss -0.9686
2023-09-02 09:17:59.738008: Pseudo dice [0.8351]
2023-09-02 09:17:59.739157: Epoch time: 111.12 s
2023-09-02 09:18:00.937974: 
2023-09-02 09:18:00.939677: Epoch 207
2023-09-02 09:18:00.941097: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-02 09:18:00.942878: start training, 250
================num of epochs: 250================
2023-09-02 09:18:58.873418: finished training
epoch: 207, dataset: CVC-300, dice: 0.8644383333333335
CVC-300 :  0.8644383333333335
epoch: 207, dataset: CVC-ClinicDB, dice: 0.8560838709677421
CVC-ClinicDB :  0.8560838709677421
epoch: 207, dataset: Kvasir, dice: 0.9035000000000001
Kvasir :  0.9035000000000001
epoch: 207, dataset: CVC-ColonDB, dice: 0.6922465789473692
CVC-ColonDB :  0.6922465789473692
epoch: 207, dataset: ETIS-LaribPolypDB, dice: 0.7379556122448979
ETIS-LaribPolypDB :  0.7379556122448979
2023-09-02 09:19:51.448752: train_loss -1.4706
2023-09-02 09:19:51.450522: val_loss -0.9903
2023-09-02 09:19:51.451920: Pseudo dice [0.838]
2023-09-02 09:19:51.453053: Epoch time: 110.51 s
2023-09-02 09:19:52.671753: 
2023-09-02 09:19:52.673666: Epoch 208
2023-09-02 09:19:52.674958: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-02 09:19:52.676808: start training, 250
================num of epochs: 250================
2023-09-02 09:20:50.689292: finished training
epoch: 208, dataset: CVC-300, dice: 0.8650416666666667
CVC-300 :  0.8650416666666667
epoch: 208, dataset: CVC-ClinicDB, dice: 0.8587854838709675
CVC-ClinicDB :  0.8587854838709675
epoch: 208, dataset: Kvasir, dice: 0.9065939999999999
Kvasir :  0.9065939999999999
epoch: 208, dataset: CVC-ColonDB, dice: 0.6931415789473682
CVC-ColonDB :  0.6931415789473682
epoch: 208, dataset: ETIS-LaribPolypDB, dice: 0.73975
ETIS-LaribPolypDB :  0.73975
2023-09-02 09:21:42.453891: train_loss -1.4707
2023-09-02 09:21:42.455772: val_loss -0.9849
2023-09-02 09:21:42.457580: Pseudo dice [0.8396]
2023-09-02 09:21:42.459060: Epoch time: 109.78 s
2023-09-02 09:21:43.664893: 
2023-09-02 09:21:43.666855: Epoch 209
2023-09-02 09:21:43.668084: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-02 09:21:43.669646: start training, 250
================num of epochs: 250================
2023-09-02 09:22:41.866232: finished training
epoch: 209, dataset: CVC-300, dice: 0.8681066666666666
CVC-300 :  0.8681066666666666
epoch: 209, dataset: CVC-ClinicDB, dice: 0.8580370967741936
CVC-ClinicDB :  0.8580370967741936
epoch: 209, dataset: Kvasir, dice: 0.9043160000000001
Kvasir :  0.9043160000000001
epoch: 209, dataset: CVC-ColonDB, dice: 0.6932050000000002
CVC-ColonDB :  0.6932050000000002
epoch: 209, dataset: ETIS-LaribPolypDB, dice: 0.7391709183673474
ETIS-LaribPolypDB :  0.7391709183673474
2023-09-02 09:23:32.927436: train_loss -1.4705
2023-09-02 09:23:32.929220: val_loss -1.0383
2023-09-02 09:23:32.930645: Pseudo dice [0.8451]
2023-09-02 09:23:32.931946: Epoch time: 109.26 s
2023-09-02 09:23:35.762174: 
2023-09-02 09:23:35.763914: Epoch 210
2023-09-02 09:23:35.765071: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-02 09:23:35.766597: start training, 250
================num of epochs: 250================
2023-09-02 09:24:33.752451: finished training
epoch: 210, dataset: CVC-300, dice: 0.8774066666666666
CVC-300 :  0.8774066666666666
epoch: 210, dataset: CVC-ClinicDB, dice: 0.8550596774193548
CVC-ClinicDB :  0.8550596774193548
epoch: 210, dataset: Kvasir, dice: 0.9040700000000003
Kvasir :  0.9040700000000003
epoch: 210, dataset: CVC-ColonDB, dice: 0.6995036842105272
CVC-ColonDB :  0.6995036842105272
epoch: 210, dataset: ETIS-LaribPolypDB, dice: 0.723830612244898
ETIS-LaribPolypDB :  0.723830612244898
2023-09-02 09:25:24.583519: train_loss -1.4702
2023-09-02 09:25:24.585156: val_loss -1.0075
2023-09-02 09:25:24.586960: Pseudo dice [0.8404]
2023-09-02 09:25:24.588159: Epoch time: 108.82 s
2023-09-02 09:25:25.789508: 
2023-09-02 09:25:25.791426: Epoch 211
2023-09-02 09:25:25.792707: Current learning rate: backbone 0.000335, others 0.000335
2023-09-02 09:25:25.794440: start training, 250
================num of epochs: 250================
2023-09-02 09:26:23.787048: finished training
epoch: 211, dataset: CVC-300, dice: 0.8735466666666667
CVC-300 :  0.8735466666666667
epoch: 211, dataset: CVC-ClinicDB, dice: 0.8549403225806452
CVC-ClinicDB :  0.8549403225806452
epoch: 211, dataset: Kvasir, dice: 0.9043399999999994
Kvasir :  0.9043399999999994
epoch: 211, dataset: CVC-ColonDB, dice: 0.7014768421052633
CVC-ColonDB :  0.7014768421052633
epoch: 211, dataset: ETIS-LaribPolypDB, dice: 0.7308877551020407
ETIS-LaribPolypDB :  0.7308877551020407
2023-09-02 09:27:16.610164: train_loss -1.4706
2023-09-02 09:27:16.611835: val_loss -0.9978
2023-09-02 09:27:16.613208: Pseudo dice [0.8362]
2023-09-02 09:27:16.614396: Epoch time: 110.82 s
2023-09-02 09:27:17.806148: 
2023-09-02 09:27:17.807681: Epoch 212
2023-09-02 09:27:17.808846: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-02 09:27:17.810325: start training, 250
================num of epochs: 250================
2023-09-02 09:28:16.061123: finished training
epoch: 212, dataset: CVC-300, dice: 0.8684883333333332
CVC-300 :  0.8684883333333332
epoch: 212, dataset: CVC-ClinicDB, dice: 0.8567919354838713
CVC-ClinicDB :  0.8567919354838713
epoch: 212, dataset: Kvasir, dice: 0.9031480000000001
Kvasir :  0.9031480000000001
epoch: 212, dataset: CVC-ColonDB, dice: 0.6957723684210528
CVC-ColonDB :  0.6957723684210528
epoch: 212, dataset: ETIS-LaribPolypDB, dice: 0.7325102040816331
ETIS-LaribPolypDB :  0.7325102040816331
2023-09-02 09:29:08.973678: train_loss -1.471
2023-09-02 09:29:08.975377: val_loss -0.9848
2023-09-02 09:29:08.976868: Pseudo dice [0.8347]
2023-09-02 09:29:08.978035: Epoch time: 111.17 s
2023-09-02 09:29:10.208749: 
2023-09-02 09:29:10.210451: Epoch 213
2023-09-02 09:29:10.211638: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-02 09:29:10.213383: start training, 250
================num of epochs: 250================
2023-09-02 09:30:08.302706: finished training
epoch: 213, dataset: CVC-300, dice: 0.8709616666666664
CVC-300 :  0.8709616666666664
epoch: 213, dataset: CVC-ClinicDB, dice: 0.857332258064516
CVC-ClinicDB :  0.857332258064516
epoch: 213, dataset: Kvasir, dice: 0.9027869999999999
Kvasir :  0.9027869999999999
epoch: 213, dataset: CVC-ColonDB, dice: 0.6952536842105265
CVC-ColonDB :  0.6952536842105265
epoch: 213, dataset: ETIS-LaribPolypDB, dice: 0.7291505102040817
ETIS-LaribPolypDB :  0.7291505102040817
2023-09-02 09:31:01.217473: train_loss -1.4711
2023-09-02 09:31:01.219550: val_loss -0.9864
2023-09-02 09:31:01.221386: Pseudo dice [0.8347]
2023-09-02 09:31:01.222989: Epoch time: 111.01 s
2023-09-02 09:31:02.441389: 
2023-09-02 09:31:02.443341: Epoch 214
2023-09-02 09:31:02.444770: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-02 09:31:02.446456: start training, 250
================num of epochs: 250================
2023-09-02 09:32:00.888754: finished training
epoch: 214, dataset: CVC-300, dice: 0.8714950000000001
CVC-300 :  0.8714950000000001
epoch: 214, dataset: CVC-ClinicDB, dice: 0.855767741935484
CVC-ClinicDB :  0.855767741935484
epoch: 214, dataset: Kvasir, dice: 0.9036900000000003
Kvasir :  0.9036900000000003
epoch: 214, dataset: CVC-ColonDB, dice: 0.69721552631579
CVC-ColonDB :  0.69721552631579
epoch: 214, dataset: ETIS-LaribPolypDB, dice: 0.7335964285714288
ETIS-LaribPolypDB :  0.7335964285714288
2023-09-02 09:32:54.229187: train_loss -1.4711
2023-09-02 09:32:54.230955: val_loss -1.0359
2023-09-02 09:32:54.232464: Pseudo dice [0.839]
2023-09-02 09:32:54.233728: Epoch time: 111.79 s
2023-09-02 09:32:55.492332: 
2023-09-02 09:32:55.494587: Epoch 215
2023-09-02 09:32:55.495785: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-02 09:32:55.497718: start training, 250
================num of epochs: 250================
2023-09-02 09:33:53.468059: finished training
epoch: 215, dataset: CVC-300, dice: 0.8681033333333332
CVC-300 :  0.8681033333333332
epoch: 215, dataset: CVC-ClinicDB, dice: 0.8548967741935483
CVC-ClinicDB :  0.8548967741935483
epoch: 215, dataset: Kvasir, dice: 0.9041729999999998
Kvasir :  0.9041729999999998
epoch: 215, dataset: CVC-ColonDB, dice: 0.6984018421052635
CVC-ColonDB :  0.6984018421052635
epoch: 215, dataset: ETIS-LaribPolypDB, dice: 0.7342484693877548
ETIS-LaribPolypDB :  0.7342484693877548
2023-09-02 09:34:44.191287: train_loss -1.4712
2023-09-02 09:34:44.193405: val_loss -1.0182
2023-09-02 09:34:44.195148: Pseudo dice [0.848]
2023-09-02 09:34:44.196499: Epoch time: 108.7 s
2023-09-02 09:34:45.852261: 
2023-09-02 09:34:45.854040: Epoch 216
2023-09-02 09:34:45.855232: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-02 09:34:45.856804: start training, 250
================num of epochs: 250================
2023-09-02 09:35:44.504837: finished training
epoch: 216, dataset: CVC-300, dice: 0.8691416666666669
CVC-300 :  0.8691416666666669
epoch: 216, dataset: CVC-ClinicDB, dice: 0.8566580645161291
CVC-ClinicDB :  0.8566580645161291
epoch: 216, dataset: Kvasir, dice: 0.9057309999999998
Kvasir :  0.9057309999999998
epoch: 216, dataset: CVC-ColonDB, dice: 0.6997068421052635
CVC-ColonDB :  0.6997068421052635
epoch: 216, dataset: ETIS-LaribPolypDB, dice: 0.7354852040816332
ETIS-LaribPolypDB :  0.7354852040816332
2023-09-02 09:36:39.507250: train_loss -1.4711
2023-09-02 09:36:39.509215: val_loss -0.9894
2023-09-02 09:36:39.510986: Pseudo dice [0.8427]
2023-09-02 09:36:39.512523: Epoch time: 113.66 s
2023-09-02 09:36:40.813586: 
2023-09-02 09:36:40.815229: Epoch 217
2023-09-02 09:36:40.816630: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-02 09:36:40.818893: start training, 250
================num of epochs: 250================
2023-09-02 09:37:39.547664: finished training
epoch: 217, dataset: CVC-300, dice: 0.8658916666666667
CVC-300 :  0.8658916666666667
epoch: 217, dataset: CVC-ClinicDB, dice: 0.8558758064516125
CVC-ClinicDB :  0.8558758064516125
epoch: 217, dataset: Kvasir, dice: 0.8996270000000003
Kvasir :  0.8996270000000003
epoch: 217, dataset: CVC-ColonDB, dice: 0.6960131578947371
CVC-ColonDB :  0.6960131578947371
epoch: 217, dataset: ETIS-LaribPolypDB, dice: 0.7262408163265307
ETIS-LaribPolypDB :  0.7262408163265307
2023-09-02 09:38:34.226954: train_loss -1.4712
2023-09-02 09:38:34.228921: val_loss -1.0267
2023-09-02 09:38:34.230400: Pseudo dice [0.8461]
2023-09-02 09:38:34.231612: Epoch time: 113.42 s
2023-09-02 09:38:35.455741: 
2023-09-02 09:38:35.457474: Epoch 218
2023-09-02 09:38:35.458646: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-02 09:38:35.460355: start training, 250
================num of epochs: 250================
2023-09-02 09:39:33.658619: finished training
epoch: 218, dataset: CVC-300, dice: 0.8611016666666669
CVC-300 :  0.8611016666666669
epoch: 218, dataset: CVC-ClinicDB, dice: 0.8579193548387095
CVC-ClinicDB :  0.8579193548387095
epoch: 218, dataset: Kvasir, dice: 0.8952489999999997
Kvasir :  0.8952489999999997
epoch: 218, dataset: CVC-ColonDB, dice: 0.6954578947368433
CVC-ColonDB :  0.6954578947368433
epoch: 218, dataset: ETIS-LaribPolypDB, dice: 0.7290673469387755
ETIS-LaribPolypDB :  0.7290673469387755
2023-09-02 09:40:27.758814: train_loss -1.471
2023-09-02 09:40:27.760767: val_loss -1.018
2023-09-02 09:40:27.762192: Pseudo dice [0.8446]
2023-09-02 09:40:27.763361: Epoch time: 112.3 s
2023-09-02 09:40:28.996186: 
2023-09-02 09:40:28.997976: Epoch 219
2023-09-02 09:40:28.999180: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-02 09:40:29.000796: start training, 250
================num of epochs: 250================
2023-09-02 09:41:27.315958: finished training
epoch: 219, dataset: CVC-300, dice: 0.8667949999999998
CVC-300 :  0.8667949999999998
epoch: 219, dataset: CVC-ClinicDB, dice: 0.8562370967741934
CVC-ClinicDB :  0.8562370967741934
epoch: 219, dataset: Kvasir, dice: 0.9030529999999999
Kvasir :  0.9030529999999999
epoch: 219, dataset: CVC-ColonDB, dice: 0.6974105263157897
CVC-ColonDB :  0.6974105263157897
epoch: 219, dataset: ETIS-LaribPolypDB, dice: 0.7385132653061226
ETIS-LaribPolypDB :  0.7385132653061226
2023-09-02 09:42:21.170177: train_loss -1.4718
2023-09-02 09:42:21.172036: val_loss -0.9552
2023-09-02 09:42:21.173492: Pseudo dice [0.8213]
2023-09-02 09:42:21.174731: Epoch time: 112.18 s
2023-09-02 09:42:23.976038: 
2023-09-02 09:42:23.977834: Epoch 220
2023-09-02 09:42:23.979034: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-02 09:42:23.980643: start training, 250
================num of epochs: 250================
2023-09-02 09:43:22.209634: finished training
epoch: 220, dataset: CVC-300, dice: 0.8670150000000001
CVC-300 :  0.8670150000000001
epoch: 220, dataset: CVC-ClinicDB, dice: 0.855775806451613
CVC-ClinicDB :  0.855775806451613
epoch: 220, dataset: Kvasir, dice: 0.9023759999999998
Kvasir :  0.9023759999999998
epoch: 220, dataset: CVC-ColonDB, dice: 0.6961218421052637
CVC-ColonDB :  0.6961218421052637
epoch: 220, dataset: ETIS-LaribPolypDB, dice: 0.7331168367346934
ETIS-LaribPolypDB :  0.7331168367346934
2023-09-02 09:44:15.170996: train_loss -1.4715
2023-09-02 09:44:15.172883: val_loss -0.9897
2023-09-02 09:44:15.174270: Pseudo dice [0.8437]
2023-09-02 09:44:15.175472: Epoch time: 111.2 s
2023-09-02 09:44:16.370905: 
2023-09-02 09:44:16.372604: Epoch 221
2023-09-02 09:44:16.373802: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-02 09:44:16.375350: start training, 250
================num of epochs: 250================
2023-09-02 09:45:14.366822: finished training
epoch: 221, dataset: CVC-300, dice: 0.8662283333333337
CVC-300 :  0.8662283333333337
epoch: 221, dataset: CVC-ClinicDB, dice: 0.857193548387097
CVC-ClinicDB :  0.857193548387097
epoch: 221, dataset: Kvasir, dice: 0.9048840000000002
Kvasir :  0.9048840000000002
epoch: 221, dataset: CVC-ColonDB, dice: 0.7068173684210521
CVC-ColonDB :  0.7068173684210521
epoch: 221, dataset: ETIS-LaribPolypDB, dice: 0.7409734693877554
ETIS-LaribPolypDB :  0.7409734693877554
2023-09-02 09:46:06.876416: train_loss -1.4712
2023-09-02 09:46:06.878273: val_loss -1.0436
2023-09-02 09:46:06.880064: Pseudo dice [0.8569]
2023-09-02 09:46:06.881224: Epoch time: 110.51 s
2023-09-02 09:46:08.084031: 
2023-09-02 09:46:08.086039: Epoch 222
2023-09-02 09:46:08.087219: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-02 09:46:08.088757: start training, 250
================num of epochs: 250================
2023-09-02 09:47:06.379609: finished training
epoch: 222, dataset: CVC-300, dice: 0.8668500000000002
CVC-300 :  0.8668500000000002
epoch: 222, dataset: CVC-ClinicDB, dice: 0.8551774193548385
CVC-ClinicDB :  0.8551774193548385
epoch: 222, dataset: Kvasir, dice: 0.9020290000000002
Kvasir :  0.9020290000000002
epoch: 222, dataset: CVC-ColonDB, dice: 0.7000310526315794
CVC-ColonDB :  0.7000310526315794
epoch: 222, dataset: ETIS-LaribPolypDB, dice: 0.7348316326530608
ETIS-LaribPolypDB :  0.7348316326530608
2023-09-02 09:47:59.655951: train_loss -1.4712
2023-09-02 09:47:59.657665: val_loss -1.048
2023-09-02 09:47:59.659185: Pseudo dice [0.8568]
2023-09-02 09:47:59.660447: Epoch time: 111.57 s
2023-09-02 09:48:00.860334: 
2023-09-02 09:48:00.862234: Epoch 223
2023-09-02 09:48:00.863596: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-02 09:48:00.865327: start training, 250
================num of epochs: 250================
2023-09-02 09:48:59.165143: finished training
epoch: 223, dataset: CVC-300, dice: 0.8694433333333332
CVC-300 :  0.8694433333333332
epoch: 223, dataset: CVC-ClinicDB, dice: 0.8537080645161289
CVC-ClinicDB :  0.8537080645161289
epoch: 223, dataset: Kvasir, dice: 0.9031549999999996
Kvasir :  0.9031549999999996
epoch: 223, dataset: CVC-ColonDB, dice: 0.6993863157894735
CVC-ColonDB :  0.6993863157894735
epoch: 223, dataset: ETIS-LaribPolypDB, dice: 0.740362755102041
ETIS-LaribPolypDB :  0.740362755102041
2023-09-02 09:49:56.127036: train_loss -1.4717
2023-09-02 09:49:56.128877: val_loss -0.9744
2023-09-02 09:49:56.130343: Pseudo dice [0.8364]
2023-09-02 09:49:56.131416: Epoch time: 115.27 s
2023-09-02 09:49:57.381986: 
2023-09-02 09:49:57.383757: Epoch 224
2023-09-02 09:49:57.385016: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-02 09:49:57.386871: start training, 250
================num of epochs: 250================
2023-09-02 09:50:55.687008: finished training
epoch: 224, dataset: CVC-300, dice: 0.8692616666666668
CVC-300 :  0.8692616666666668
epoch: 224, dataset: CVC-ClinicDB, dice: 0.8564209677419353
CVC-ClinicDB :  0.8564209677419353
epoch: 224, dataset: Kvasir, dice: 0.9037300000000004
Kvasir :  0.9037300000000004
epoch: 224, dataset: CVC-ColonDB, dice: 0.7010931578947373
CVC-ColonDB :  0.7010931578947373
epoch: 224, dataset: ETIS-LaribPolypDB, dice: 0.7490306122448981
ETIS-LaribPolypDB :  0.7490306122448981
2023-09-02 09:51:48.864415: train_loss -1.4711
2023-09-02 09:51:48.866351: val_loss -1.0183
2023-09-02 09:51:48.867872: Pseudo dice [0.8478]
2023-09-02 09:51:48.869187: Epoch time: 111.48 s
2023-09-02 09:51:50.092626: 
2023-09-02 09:51:50.094482: Epoch 225
2023-09-02 09:51:50.096263: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-02 09:51:50.098844: start training, 250
================num of epochs: 250================
2023-09-02 09:52:48.500653: finished training
epoch: 225, dataset: CVC-300, dice: 0.865101666666667
CVC-300 :  0.865101666666667
epoch: 225, dataset: CVC-ClinicDB, dice: 0.8550612903225804
CVC-ClinicDB :  0.8550612903225804
epoch: 225, dataset: Kvasir, dice: 0.903287
Kvasir :  0.903287
epoch: 225, dataset: CVC-ColonDB, dice: 0.6977555263157899
CVC-ColonDB :  0.6977555263157899
epoch: 225, dataset: ETIS-LaribPolypDB, dice: 0.7368270408163271
ETIS-LaribPolypDB :  0.7368270408163271
2023-09-02 09:53:48.186670: train_loss -1.4715
2023-09-02 09:53:48.188469: val_loss -1.0555
2023-09-02 09:53:48.189905: Pseudo dice [0.8595]
2023-09-02 09:53:48.191095: Epoch time: 118.1 s
2023-09-02 09:53:49.411601: 
2023-09-02 09:53:49.413335: Epoch 226
2023-09-02 09:53:49.414630: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-02 09:53:49.416299: start training, 250
================num of epochs: 250================
2023-09-02 09:54:47.809563: finished training
epoch: 226, dataset: CVC-300, dice: 0.8669800000000001
CVC-300 :  0.8669800000000001
epoch: 226, dataset: CVC-ClinicDB, dice: 0.8568354838709674
CVC-ClinicDB :  0.8568354838709674
epoch: 226, dataset: Kvasir, dice: 0.9030330000000001
Kvasir :  0.9030330000000001
epoch: 226, dataset: CVC-ColonDB, dice: 0.6979581578947374
CVC-ColonDB :  0.6979581578947374
epoch: 226, dataset: ETIS-LaribPolypDB, dice: 0.7362668367346942
ETIS-LaribPolypDB :  0.7362668367346942
2023-09-02 09:55:43.767636: train_loss -1.4715
2023-09-02 09:55:43.769425: val_loss -1.0529
2023-09-02 09:55:43.770867: Pseudo dice [0.8605]
2023-09-02 09:55:43.772076: Epoch time: 114.36 s
2023-09-02 09:55:43.773188: Yayy! New best EMA pseudo Dice: 0.8456
2023-09-02 09:55:46.681339: 
2023-09-02 09:55:46.683399: Epoch 227
2023-09-02 09:55:46.684774: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-02 09:55:46.686623: start training, 250
================num of epochs: 250================
2023-09-02 09:56:44.618929: finished training
epoch: 227, dataset: CVC-300, dice: 0.8671583333333331
CVC-300 :  0.8671583333333331
epoch: 227, dataset: CVC-ClinicDB, dice: 0.8585612903225804
CVC-ClinicDB :  0.8585612903225804
epoch: 227, dataset: Kvasir, dice: 0.9006449999999998
Kvasir :  0.9006449999999998
epoch: 227, dataset: CVC-ColonDB, dice: 0.6994571052631591
CVC-ColonDB :  0.6994571052631591
epoch: 227, dataset: ETIS-LaribPolypDB, dice: 0.7409275510204082
ETIS-LaribPolypDB :  0.7409275510204082
2023-09-02 09:57:37.375549: train_loss -1.4715
2023-09-02 09:57:37.377387: val_loss -1.0255
2023-09-02 09:57:37.378867: Pseudo dice [0.8445]
2023-09-02 09:57:37.380071: Epoch time: 110.7 s
2023-09-02 09:57:38.602769: 
2023-09-02 09:57:38.604554: Epoch 228
2023-09-02 09:57:38.605790: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-02 09:57:38.607368: start training, 250
================num of epochs: 250================
2023-09-02 09:58:36.752599: finished training
epoch: 228, dataset: CVC-300, dice: 0.8672333333333332
CVC-300 :  0.8672333333333332
epoch: 228, dataset: CVC-ClinicDB, dice: 0.856991935483871
CVC-ClinicDB :  0.856991935483871
epoch: 228, dataset: Kvasir, dice: 0.9029049999999998
Kvasir :  0.9029049999999998
epoch: 228, dataset: CVC-ColonDB, dice: 0.7005528947368422
CVC-ColonDB :  0.7005528947368422
epoch: 228, dataset: ETIS-LaribPolypDB, dice: 0.7438806122448981
ETIS-LaribPolypDB :  0.7438806122448981
2023-09-02 09:59:30.063430: train_loss -1.4717
2023-09-02 09:59:30.065275: val_loss -0.9354
2023-09-02 09:59:30.067338: Pseudo dice [0.826]
2023-09-02 09:59:30.068650: Epoch time: 111.46 s
2023-09-02 09:59:31.290635: 
2023-09-02 09:59:31.292648: Epoch 229
2023-09-02 09:59:31.294016: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-02 09:59:31.295967: start training, 250
================num of epochs: 250================
2023-09-02 10:00:29.325678: finished training
epoch: 229, dataset: CVC-300, dice: 0.8680433333333331
CVC-300 :  0.8680433333333331
epoch: 229, dataset: CVC-ClinicDB, dice: 0.8559419354838709
CVC-ClinicDB :  0.8559419354838709
epoch: 229, dataset: Kvasir, dice: 0.9041640000000002
Kvasir :  0.9041640000000002
epoch: 229, dataset: CVC-ColonDB, dice: 0.6970978947368426
CVC-ColonDB :  0.6970978947368426
epoch: 229, dataset: ETIS-LaribPolypDB, dice: 0.7418632653061225
ETIS-LaribPolypDB :  0.7418632653061225
2023-09-02 10:01:22.627596: train_loss -1.4718
2023-09-02 10:01:22.629535: val_loss -1.0202
2023-09-02 10:01:22.631207: Pseudo dice [0.8481]
2023-09-02 10:01:22.632535: Epoch time: 111.34 s
2023-09-02 10:01:25.440615: 
2023-09-02 10:01:25.442426: Epoch 230
2023-09-02 10:01:25.443669: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-02 10:01:25.445276: start training, 250
================num of epochs: 250================
2023-09-02 10:02:23.624354: finished training
epoch: 230, dataset: CVC-300, dice: 0.8681016666666667
CVC-300 :  0.8681016666666667
epoch: 230, dataset: CVC-ClinicDB, dice: 0.8565387096774189
CVC-ClinicDB :  0.8565387096774189
epoch: 230, dataset: Kvasir, dice: 0.9028179999999999
Kvasir :  0.9028179999999999
epoch: 230, dataset: CVC-ColonDB, dice: 0.6985728947368424
CVC-ColonDB :  0.6985728947368424
epoch: 230, dataset: ETIS-LaribPolypDB, dice: 0.7467163265306123
ETIS-LaribPolypDB :  0.7467163265306123
2023-09-02 10:03:18.477380: train_loss -1.4717
2023-09-02 10:03:18.479268: val_loss -1.0538
2023-09-02 10:03:18.480848: Pseudo dice [0.8526]
2023-09-02 10:03:18.482198: Epoch time: 113.04 s
2023-09-02 10:03:19.681417: 
2023-09-02 10:03:19.683321: Epoch 231
2023-09-02 10:03:19.684699: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-02 10:03:19.686475: start training, 250
================num of epochs: 250================
2023-09-02 10:04:17.952027: finished training
epoch: 231, dataset: CVC-300, dice: 0.8648116666666668
CVC-300 :  0.8648116666666668
epoch: 231, dataset: CVC-ClinicDB, dice: 0.8593693548387096
CVC-ClinicDB :  0.8593693548387096
epoch: 231, dataset: Kvasir, dice: 0.8986259999999997
Kvasir :  0.8986259999999997
epoch: 231, dataset: CVC-ColonDB, dice: 0.697685526315789
CVC-ColonDB :  0.697685526315789
epoch: 231, dataset: ETIS-LaribPolypDB, dice: 0.7372397959183677
ETIS-LaribPolypDB :  0.7372397959183677
2023-09-02 10:05:10.855657: train_loss -1.4718
2023-09-02 10:05:10.857859: val_loss -1.057
2023-09-02 10:05:10.859602: Pseudo dice [0.8571]
2023-09-02 10:05:10.861017: Epoch time: 111.18 s
2023-09-02 10:05:10.862268: Yayy! New best EMA pseudo Dice: 0.8461
2023-09-02 10:05:13.689324: 
2023-09-02 10:05:13.691340: Epoch 232
2023-09-02 10:05:13.692636: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-02 10:05:13.694395: start training, 250
================num of epochs: 250================
2023-09-02 10:06:11.776058: finished training
epoch: 232, dataset: CVC-300, dice: 0.8663083333333332
CVC-300 :  0.8663083333333332
epoch: 232, dataset: CVC-ClinicDB, dice: 0.8574838709677417
CVC-ClinicDB :  0.8574838709677417
epoch: 232, dataset: Kvasir, dice: 0.8997510000000001
Kvasir :  0.8997510000000001
epoch: 232, dataset: CVC-ColonDB, dice: 0.6954689473684208
CVC-ColonDB :  0.6954689473684208
epoch: 232, dataset: ETIS-LaribPolypDB, dice: 0.7324168367346943
ETIS-LaribPolypDB :  0.7324168367346943
2023-09-02 10:07:05.078568: train_loss -1.4721
2023-09-02 10:07:05.080246: val_loss -0.9858
2023-09-02 10:07:05.081731: Pseudo dice [0.8408]
2023-09-02 10:07:05.082941: Epoch time: 111.39 s
2023-09-02 10:07:06.285994: 
2023-09-02 10:07:06.287861: Epoch 233
2023-09-02 10:07:06.289067: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-02 10:07:06.290667: start training, 250
================num of epochs: 250================
2023-09-02 10:08:04.328434: finished training
epoch: 233, dataset: CVC-300, dice: 0.8707233333333336
CVC-300 :  0.8707233333333336
epoch: 233, dataset: CVC-ClinicDB, dice: 0.8565290322580645
CVC-ClinicDB :  0.8565290322580645
epoch: 233, dataset: Kvasir, dice: 0.9005249999999999
Kvasir :  0.9005249999999999
epoch: 233, dataset: CVC-ColonDB, dice: 0.6961826315789473
CVC-ColonDB :  0.6961826315789473
epoch: 233, dataset: ETIS-LaribPolypDB, dice: 0.7390714285714283
ETIS-LaribPolypDB :  0.7390714285714283
2023-09-02 10:08:57.904574: train_loss -1.4722
2023-09-02 10:08:57.906330: val_loss -1.0451
2023-09-02 10:08:57.907762: Pseudo dice [0.8556]
2023-09-02 10:08:57.908968: Epoch time: 111.62 s
2023-09-02 10:08:57.910131: Yayy! New best EMA pseudo Dice: 0.8466
2023-09-02 10:09:00.732546: 
2023-09-02 10:09:00.734415: Epoch 234
2023-09-02 10:09:00.735645: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-02 10:09:00.737198: start training, 250
================num of epochs: 250================
2023-09-02 10:09:58.948307: finished training
epoch: 234, dataset: CVC-300, dice: 0.8704033333333333
CVC-300 :  0.8704033333333333
epoch: 234, dataset: CVC-ClinicDB, dice: 0.8566822580645158
CVC-ClinicDB :  0.8566822580645158
epoch: 234, dataset: Kvasir, dice: 0.9012809999999996
Kvasir :  0.9012809999999996
epoch: 234, dataset: CVC-ColonDB, dice: 0.6941734210526324
CVC-ColonDB :  0.6941734210526324
epoch: 234, dataset: ETIS-LaribPolypDB, dice: 0.7432668367346936
ETIS-LaribPolypDB :  0.7432668367346936
2023-09-02 10:10:51.863494: train_loss -1.4718
2023-09-02 10:10:51.865388: val_loss -1.0074
2023-09-02 10:10:51.867021: Pseudo dice [0.8461]
2023-09-02 10:10:51.868217: Epoch time: 111.13 s
2023-09-02 10:10:53.055855: 
2023-09-02 10:10:53.057748: Epoch 235
2023-09-02 10:10:53.058960: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-02 10:10:53.060534: start training, 250
================num of epochs: 250================
2023-09-02 10:11:51.019359: finished training
epoch: 235, dataset: CVC-300, dice: 0.8705733333333331
CVC-300 :  0.8705733333333331
epoch: 235, dataset: CVC-ClinicDB, dice: 0.8555193548387096
CVC-ClinicDB :  0.8555193548387096
epoch: 235, dataset: Kvasir, dice: 0.90373
Kvasir :  0.90373
epoch: 235, dataset: CVC-ColonDB, dice: 0.7007921052631586
CVC-ColonDB :  0.7007921052631586
epoch: 235, dataset: ETIS-LaribPolypDB, dice: 0.7474556122448976
ETIS-LaribPolypDB :  0.7474556122448976
2023-09-02 10:12:43.630282: train_loss -1.4721
2023-09-02 10:12:43.632033: val_loss -1.0613
2023-09-02 10:12:43.633567: Pseudo dice [0.862]
2023-09-02 10:12:43.634748: Epoch time: 110.58 s
2023-09-02 10:12:43.635868: Yayy! New best EMA pseudo Dice: 0.8481
2023-09-02 10:12:46.445690: 
2023-09-02 10:12:46.447552: Epoch 236
2023-09-02 10:12:46.448941: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-02 10:12:46.450595: start training, 250
================num of epochs: 250================
2023-09-02 10:13:44.513255: finished training
epoch: 236, dataset: CVC-300, dice: 0.8711883333333332
CVC-300 :  0.8711883333333332
epoch: 236, dataset: CVC-ClinicDB, dice: 0.8461016129032258
CVC-ClinicDB :  0.8461016129032258
epoch: 236, dataset: Kvasir, dice: 0.900572
Kvasir :  0.900572
epoch: 236, dataset: CVC-ColonDB, dice: 0.694280263157895
CVC-ColonDB :  0.694280263157895
epoch: 236, dataset: ETIS-LaribPolypDB, dice: 0.7299096938775512
ETIS-LaribPolypDB :  0.7299096938775512
2023-09-02 10:14:37.244062: train_loss -1.4726
2023-09-02 10:14:37.245864: val_loss -0.9644
2023-09-02 10:14:37.247455: Pseudo dice [0.832]
2023-09-02 10:14:37.248817: Epoch time: 110.8 s
2023-09-02 10:14:38.453022: 
2023-09-02 10:14:38.454912: Epoch 237
2023-09-02 10:14:38.456278: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-02 10:14:38.457975: start training, 250
================num of epochs: 250================
2023-09-02 10:15:36.679881: finished training
epoch: 237, dataset: CVC-300, dice: 0.8709683333333328
CVC-300 :  0.8709683333333328
epoch: 237, dataset: CVC-ClinicDB, dice: 0.8522693548387097
CVC-ClinicDB :  0.8522693548387097
epoch: 237, dataset: Kvasir, dice: 0.9021710000000001
Kvasir :  0.9021710000000001
epoch: 237, dataset: CVC-ColonDB, dice: 0.6964352631578953
CVC-ColonDB :  0.6964352631578953
epoch: 237, dataset: ETIS-LaribPolypDB, dice: 0.7285811224489795
ETIS-LaribPolypDB :  0.7285811224489795
2023-09-02 10:16:29.604217: train_loss -1.4723
2023-09-02 10:16:29.606277: val_loss -0.9541
2023-09-02 10:16:29.607934: Pseudo dice [0.8337]
2023-09-02 10:16:29.609197: Epoch time: 111.15 s
2023-09-02 10:16:30.811964: 
2023-09-02 10:16:30.813886: Epoch 238
2023-09-02 10:16:30.815084: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-02 10:16:30.816771: start training, 250
================num of epochs: 250================
2023-09-02 10:17:28.837429: finished training
epoch: 238, dataset: CVC-300, dice: 0.8674000000000002
CVC-300 :  0.8674000000000002
epoch: 238, dataset: CVC-ClinicDB, dice: 0.8537080645161289
CVC-ClinicDB :  0.8537080645161289
epoch: 238, dataset: Kvasir, dice: 0.9002999999999998
Kvasir :  0.9002999999999998
epoch: 238, dataset: CVC-ColonDB, dice: 0.6947026315789485
CVC-ColonDB :  0.6947026315789485
epoch: 238, dataset: ETIS-LaribPolypDB, dice: 0.7303678571428565
ETIS-LaribPolypDB :  0.7303678571428565
2023-09-02 10:18:21.524080: train_loss -1.4721
2023-09-02 10:18:21.526136: val_loss -0.9233
2023-09-02 10:18:21.527554: Pseudo dice [0.8215]
2023-09-02 10:18:21.528726: Epoch time: 110.71 s
2023-09-02 10:18:22.728328: 
2023-09-02 10:18:22.730319: Epoch 239
2023-09-02 10:18:22.731801: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-02 10:18:22.733478: start training, 250
================num of epochs: 250================
2023-09-02 10:19:20.737218: finished training
epoch: 239, dataset: CVC-300, dice: 0.8717366666666668
CVC-300 :  0.8717366666666668
epoch: 239, dataset: CVC-ClinicDB, dice: 0.8551806451612902
CVC-ClinicDB :  0.8551806451612902
epoch: 239, dataset: Kvasir, dice: 0.9029729999999999
Kvasir :  0.9029729999999999
epoch: 239, dataset: CVC-ColonDB, dice: 0.6983605263157894
CVC-ColonDB :  0.6983605263157894
epoch: 239, dataset: ETIS-LaribPolypDB, dice: 0.7368714285714285
ETIS-LaribPolypDB :  0.7368714285714285
2023-09-02 10:20:13.406281: train_loss -1.4721
2023-09-02 10:20:13.408169: val_loss -0.9153
2023-09-02 10:20:13.409814: Pseudo dice [0.8285]
2023-09-02 10:20:13.411229: Epoch time: 110.68 s
2023-09-02 10:20:16.234707: 
2023-09-02 10:20:16.236425: Epoch 240
2023-09-02 10:20:16.237667: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-02 10:20:16.239291: start training, 250
================num of epochs: 250================
2023-09-02 10:21:14.715119: finished training
epoch: 240, dataset: CVC-300, dice: 0.8690966666666667
CVC-300 :  0.8690966666666667
epoch: 240, dataset: CVC-ClinicDB, dice: 0.8557483870967743
CVC-ClinicDB :  0.8557483870967743
epoch: 240, dataset: Kvasir, dice: 0.9020320000000005
Kvasir :  0.9020320000000005
epoch: 240, dataset: CVC-ColonDB, dice: 0.6959363157894741
CVC-ColonDB :  0.6959363157894741
epoch: 240, dataset: ETIS-LaribPolypDB, dice: 0.7278632653061224
ETIS-LaribPolypDB :  0.7278632653061224
2023-09-02 10:22:07.578502: train_loss -1.4727
2023-09-02 10:22:07.580479: val_loss -0.9255
2023-09-02 10:22:07.581985: Pseudo dice [0.823]
2023-09-02 10:22:07.583206: Epoch time: 111.35 s
2023-09-02 10:22:08.823769: 
2023-09-02 10:22:08.825418: Epoch 241
2023-09-02 10:22:08.826663: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-02 10:22:08.828383: start training, 250
================num of epochs: 250================
2023-09-02 10:23:06.844567: finished training
epoch: 241, dataset: CVC-300, dice: 0.8701683333333334
CVC-300 :  0.8701683333333334
epoch: 241, dataset: CVC-ClinicDB, dice: 0.8560838709677417
CVC-ClinicDB :  0.8560838709677417
epoch: 241, dataset: Kvasir, dice: 0.9018269999999998
Kvasir :  0.9018269999999998
epoch: 241, dataset: CVC-ColonDB, dice: 0.6978060526315795
CVC-ColonDB :  0.6978060526315795
epoch: 241, dataset: ETIS-LaribPolypDB, dice: 0.7377306122448981
ETIS-LaribPolypDB :  0.7377306122448981
2023-09-02 10:23:59.574333: train_loss -1.4723
2023-09-02 10:23:59.576230: val_loss -1.003
2023-09-02 10:23:59.578096: Pseudo dice [0.8416]
2023-09-02 10:23:59.579525: Epoch time: 110.75 s
2023-09-02 10:24:00.811923: 
2023-09-02 10:24:00.813955: Epoch 242
2023-09-02 10:24:00.815294: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-02 10:24:00.817037: start training, 250
================num of epochs: 250================
2023-09-02 10:24:58.855483: finished training
epoch: 242, dataset: CVC-300, dice: 0.8679816666666669
CVC-300 :  0.8679816666666669
epoch: 242, dataset: CVC-ClinicDB, dice: 0.8576483870967738
CVC-ClinicDB :  0.8576483870967738
epoch: 242, dataset: Kvasir, dice: 0.9028129999999999
Kvasir :  0.9028129999999999
epoch: 242, dataset: CVC-ColonDB, dice: 0.6967681578947373
CVC-ColonDB :  0.6967681578947373
epoch: 242, dataset: ETIS-LaribPolypDB, dice: 0.7398025510204085
ETIS-LaribPolypDB :  0.7398025510204085
2023-09-02 10:25:51.185004: train_loss -1.4719
2023-09-02 10:25:51.186617: val_loss -0.9743
2023-09-02 10:25:51.188207: Pseudo dice [0.8377]
2023-09-02 10:25:51.189542: Epoch time: 110.37 s
2023-09-02 10:25:52.409375: 
2023-09-02 10:25:52.411354: Epoch 243
2023-09-02 10:25:52.412659: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-02 10:25:52.414289: start training, 250
================num of epochs: 250================
2023-09-02 10:26:50.674401: finished training
epoch: 243, dataset: CVC-300, dice: 0.869068333333333
CVC-300 :  0.869068333333333
epoch: 243, dataset: CVC-ClinicDB, dice: 0.8583032258064515
CVC-ClinicDB :  0.8583032258064515
epoch: 243, dataset: Kvasir, dice: 0.9025840000000004
Kvasir :  0.9025840000000004
epoch: 243, dataset: CVC-ColonDB, dice: 0.6987210526315801
CVC-ColonDB :  0.6987210526315801
epoch: 243, dataset: ETIS-LaribPolypDB, dice: 0.7351602040816327
ETIS-LaribPolypDB :  0.7351602040816327
2023-09-02 10:27:43.406922: train_loss -1.4724
2023-09-02 10:27:43.408759: val_loss -1.0267
2023-09-02 10:27:43.410180: Pseudo dice [0.8486]
2023-09-02 10:27:43.411404: Epoch time: 111.0 s
2023-09-02 10:27:44.634302: 
2023-09-02 10:27:44.635957: Epoch 244
2023-09-02 10:27:44.637108: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-02 10:27:44.638653: start training, 250
================num of epochs: 250================
2023-09-02 10:28:42.777027: finished training
epoch: 244, dataset: CVC-300, dice: 0.8711383333333333
CVC-300 :  0.8711383333333333
epoch: 244, dataset: CVC-ClinicDB, dice: 0.8585258064516129
CVC-ClinicDB :  0.8585258064516129
epoch: 244, dataset: Kvasir, dice: 0.903013
Kvasir :  0.903013
epoch: 244, dataset: CVC-ColonDB, dice: 0.7000418421052631
CVC-ColonDB :  0.7000418421052631
epoch: 244, dataset: ETIS-LaribPolypDB, dice: 0.7389724489795926
ETIS-LaribPolypDB :  0.7389724489795926
2023-09-02 10:29:38.040241: train_loss -1.4725
2023-09-02 10:29:38.042069: val_loss -0.9818
2023-09-02 10:29:38.043642: Pseudo dice [0.8389]
2023-09-02 10:29:38.045003: Epoch time: 113.41 s
2023-09-02 10:29:39.260081: 
2023-09-02 10:29:39.262214: Epoch 245
2023-09-02 10:29:39.263565: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-02 10:29:39.265257: start training, 250
================num of epochs: 250================
2023-09-02 10:30:37.238815: finished training
epoch: 245, dataset: CVC-300, dice: 0.8715383333333334
CVC-300 :  0.8715383333333334
epoch: 245, dataset: CVC-ClinicDB, dice: 0.8565870967741938
CVC-ClinicDB :  0.8565870967741938
epoch: 245, dataset: Kvasir, dice: 0.9034149999999999
Kvasir :  0.9034149999999999
epoch: 245, dataset: CVC-ColonDB, dice: 0.7011286842105259
CVC-ColonDB :  0.7011286842105259
epoch: 245, dataset: ETIS-LaribPolypDB, dice: 0.7357505102040817
ETIS-LaribPolypDB :  0.7357505102040817
2023-09-02 10:31:29.738114: train_loss -1.4722
2023-09-02 10:31:29.740180: val_loss -1.0118
2023-09-02 10:31:29.741836: Pseudo dice [0.8547]
2023-09-02 10:31:29.743325: Epoch time: 110.48 s
2023-09-02 10:31:30.963656: 
2023-09-02 10:31:30.965524: Epoch 246
2023-09-02 10:31:30.966979: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-02 10:31:30.968821: start training, 250
================num of epochs: 250================
2023-09-02 10:32:29.193336: finished training
epoch: 246, dataset: CVC-300, dice: 0.8673083333333332
CVC-300 :  0.8673083333333332
epoch: 246, dataset: CVC-ClinicDB, dice: 0.8574387096774195
CVC-ClinicDB :  0.8574387096774195
epoch: 246, dataset: Kvasir, dice: 0.9025900000000001
Kvasir :  0.9025900000000001
epoch: 246, dataset: CVC-ColonDB, dice: 0.7017815789473693
CVC-ColonDB :  0.7017815789473693
epoch: 246, dataset: ETIS-LaribPolypDB, dice: 0.7337127551020406
ETIS-LaribPolypDB :  0.7337127551020406
2023-09-02 10:33:21.773362: train_loss -1.4721
2023-09-02 10:33:21.775283: val_loss -1.029
2023-09-02 10:33:21.776879: Pseudo dice [0.8472]
2023-09-02 10:33:21.778273: Epoch time: 110.81 s
2023-09-02 10:33:23.003365: 
2023-09-02 10:33:23.005358: Epoch 247
2023-09-02 10:33:23.006738: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-02 10:33:23.008569: start training, 250
================num of epochs: 250================
2023-09-02 10:34:20.970091: finished training
epoch: 247, dataset: CVC-300, dice: 0.8702583333333334
CVC-300 :  0.8702583333333334
epoch: 247, dataset: CVC-ClinicDB, dice: 0.8592209677419356
CVC-ClinicDB :  0.8592209677419356
epoch: 247, dataset: Kvasir, dice: 0.9043759999999998
Kvasir :  0.9043759999999998
epoch: 247, dataset: CVC-ColonDB, dice: 0.7040197368421056
CVC-ColonDB :  0.7040197368421056
epoch: 247, dataset: ETIS-LaribPolypDB, dice: 0.7323076530612249
ETIS-LaribPolypDB :  0.7323076530612249
2023-09-02 10:35:12.957175: train_loss -1.4723
2023-09-02 10:35:12.958926: val_loss -1.0167
2023-09-02 10:35:12.960372: Pseudo dice [0.8498]
2023-09-02 10:35:12.961692: Epoch time: 109.96 s
2023-09-02 10:35:14.224171: 
2023-09-02 10:35:14.225978: Epoch 248
2023-09-02 10:35:14.227182: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-02 10:35:14.228694: start training, 250
================num of epochs: 250================
2023-09-02 10:36:12.236452: finished training
epoch: 248, dataset: CVC-300, dice: 0.8713650000000001
CVC-300 :  0.8713650000000001
epoch: 248, dataset: CVC-ClinicDB, dice: 0.8572483870967743
CVC-ClinicDB :  0.8572483870967743
epoch: 248, dataset: Kvasir, dice: 0.9026830000000001
Kvasir :  0.9026830000000001
epoch: 248, dataset: CVC-ColonDB, dice: 0.698279210526316
CVC-ColonDB :  0.698279210526316
epoch: 248, dataset: ETIS-LaribPolypDB, dice: 0.7330852040816329
ETIS-LaribPolypDB :  0.7330852040816329
2023-09-02 10:37:04.389617: train_loss -1.4723
2023-09-02 10:37:04.391388: val_loss -0.9269
2023-09-02 10:37:04.392853: Pseudo dice [0.8255]
2023-09-02 10:37:04.394076: Epoch time: 110.17 s
2023-09-02 10:37:05.604088: 
2023-09-02 10:37:05.605979: Epoch 249
2023-09-02 10:37:05.607237: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-02 10:37:05.608892: start training, 250
================num of epochs: 250================
2023-09-02 10:38:03.802573: finished training
epoch: 249, dataset: CVC-300, dice: 0.8726333333333333
CVC-300 :  0.8726333333333333
epoch: 249, dataset: CVC-ClinicDB, dice: 0.8579629032258065
CVC-ClinicDB :  0.8579629032258065
epoch: 249, dataset: Kvasir, dice: 0.9040150000000001
Kvasir :  0.9040150000000001
epoch: 249, dataset: CVC-ColonDB, dice: 0.6957576315789471
CVC-ColonDB :  0.6957576315789471
epoch: 249, dataset: ETIS-LaribPolypDB, dice: 0.7403637755102039
ETIS-LaribPolypDB :  0.7403637755102039
2023-09-02 10:38:56.675736: train_loss -1.4725
2023-09-02 10:38:56.677620: val_loss -1.0679
2023-09-02 10:38:56.679050: Pseudo dice [0.8576]
2023-09-02 10:38:56.680292: Epoch time: 111.07 s
2023-09-02 10:38:59.495056: 
2023-09-02 10:38:59.496713: Epoch 250
2023-09-02 10:38:59.497935: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-02 10:38:59.499529: start training, 250
================num of epochs: 250================
2023-09-02 10:39:57.434060: finished training
epoch: 250, dataset: CVC-300, dice: 0.8693166666666667
CVC-300 :  0.8693166666666667
epoch: 250, dataset: CVC-ClinicDB, dice: 0.8582983870967741
CVC-ClinicDB :  0.8582983870967741
epoch: 250, dataset: Kvasir, dice: 0.9041860000000002
Kvasir :  0.9041860000000002
epoch: 250, dataset: CVC-ColonDB, dice: 0.6996102631578952
CVC-ColonDB :  0.6996102631578952
epoch: 250, dataset: ETIS-LaribPolypDB, dice: 0.7387285714285715
ETIS-LaribPolypDB :  0.7387285714285715
2023-09-02 10:40:50.000726: train_loss -1.4728
2023-09-02 10:40:50.002581: val_loss -1.0162
2023-09-02 10:40:50.004240: Pseudo dice [0.8498]
2023-09-02 10:40:50.005620: Epoch time: 110.51 s
2023-09-02 10:40:51.196381: 
2023-09-02 10:40:51.198237: Epoch 251
2023-09-02 10:40:51.199497: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-02 10:40:51.201098: start training, 250
================num of epochs: 250================
2023-09-02 10:41:49.201554: finished training
epoch: 251, dataset: CVC-300, dice: 0.869015
CVC-300 :  0.869015
epoch: 251, dataset: CVC-ClinicDB, dice: 0.8565967741935481
CVC-ClinicDB :  0.8565967741935481
epoch: 251, dataset: Kvasir, dice: 0.9038250000000001
Kvasir :  0.9038250000000001
epoch: 251, dataset: CVC-ColonDB, dice: 0.6973255263157896
CVC-ColonDB :  0.6973255263157896
epoch: 251, dataset: ETIS-LaribPolypDB, dice: 0.7368372448979594
ETIS-LaribPolypDB :  0.7368372448979594
2023-09-02 10:42:41.875424: train_loss -1.4726
2023-09-02 10:42:41.877220: val_loss -0.9804
2023-09-02 10:42:41.878685: Pseudo dice [0.8399]
2023-09-02 10:42:41.879933: Epoch time: 110.68 s
2023-09-02 10:42:43.092062: 
2023-09-02 10:42:43.093708: Epoch 252
2023-09-02 10:42:43.095097: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-02 10:42:43.096831: start training, 250
================num of epochs: 250================
2023-09-02 10:43:41.331094: finished training
epoch: 252, dataset: CVC-300, dice: 0.8700033333333335
CVC-300 :  0.8700033333333335
epoch: 252, dataset: CVC-ClinicDB, dice: 0.858616129032258
CVC-ClinicDB :  0.858616129032258
epoch: 252, dataset: Kvasir, dice: 0.9041439999999997
Kvasir :  0.9041439999999997
epoch: 252, dataset: CVC-ColonDB, dice: 0.6994050000000004
CVC-ColonDB :  0.6994050000000004
epoch: 252, dataset: ETIS-LaribPolypDB, dice: 0.7481163265306122
ETIS-LaribPolypDB :  0.7481163265306122
2023-09-02 10:44:35.243862: train_loss -1.4723
2023-09-02 10:44:35.245642: val_loss -0.9606
2023-09-02 10:44:35.247138: Pseudo dice [0.8384]
2023-09-02 10:44:35.248679: Epoch time: 112.15 s
2023-09-02 10:44:36.446427: 
2023-09-02 10:44:36.448144: Epoch 253
2023-09-02 10:44:36.449533: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-02 10:44:36.451307: start training, 250
================num of epochs: 250================
2023-09-02 10:45:34.446459: finished training
epoch: 253, dataset: CVC-300, dice: 0.8687716666666669
CVC-300 :  0.8687716666666669
epoch: 253, dataset: CVC-ClinicDB, dice: 0.8578258064516128
CVC-ClinicDB :  0.8578258064516128
epoch: 253, dataset: Kvasir, dice: 0.9037349999999997
Kvasir :  0.9037349999999997
epoch: 253, dataset: CVC-ColonDB, dice: 0.6983226315789478
CVC-ColonDB :  0.6983226315789478
epoch: 253, dataset: ETIS-LaribPolypDB, dice: 0.7448051020408162
ETIS-LaribPolypDB :  0.7448051020408162
2023-09-02 10:46:27.084023: train_loss -1.4729
2023-09-02 10:46:27.085845: val_loss -1.0375
2023-09-02 10:46:27.087351: Pseudo dice [0.8507]
2023-09-02 10:46:27.088652: Epoch time: 110.64 s
2023-09-02 10:46:28.287245: 
2023-09-02 10:46:28.289004: Epoch 254
2023-09-02 10:46:28.290383: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-02 10:46:28.292130: start training, 250
================num of epochs: 250================
2023-09-02 10:47:26.284402: finished training
epoch: 254, dataset: CVC-300, dice: 0.8695316666666669
CVC-300 :  0.8695316666666669
epoch: 254, dataset: CVC-ClinicDB, dice: 0.8580903225806452
CVC-ClinicDB :  0.8580903225806452
epoch: 254, dataset: Kvasir, dice: 0.9049189999999999
Kvasir :  0.9049189999999999
epoch: 254, dataset: CVC-ColonDB, dice: 0.6962921052631578
CVC-ColonDB :  0.6962921052631578
epoch: 254, dataset: ETIS-LaribPolypDB, dice: 0.7402663265306125
ETIS-LaribPolypDB :  0.7402663265306125
2023-09-02 10:48:19.003040: train_loss -1.4724
2023-09-02 10:48:19.004875: val_loss -0.9992
2023-09-02 10:48:19.006483: Pseudo dice [0.8448]
2023-09-02 10:48:19.007920: Epoch time: 110.72 s
2023-09-02 10:48:20.206537: 
2023-09-02 10:48:20.208256: Epoch 255
2023-09-02 10:48:20.209477: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-02 10:48:20.211063: start training, 250
================num of epochs: 250================
2023-09-02 10:49:18.362276: finished training
epoch: 255, dataset: CVC-300, dice: 0.8699650000000002
CVC-300 :  0.8699650000000002
epoch: 255, dataset: CVC-ClinicDB, dice: 0.8571241935483871
CVC-ClinicDB :  0.8571241935483871
epoch: 255, dataset: Kvasir, dice: 0.9047829999999998
Kvasir :  0.9047829999999998
epoch: 255, dataset: CVC-ColonDB, dice: 0.6989526315789472
CVC-ColonDB :  0.6989526315789472
epoch: 255, dataset: ETIS-LaribPolypDB, dice: 0.7392591836734692
ETIS-LaribPolypDB :  0.7392591836734692
2023-09-02 10:50:11.731491: train_loss -1.4728
2023-09-02 10:50:11.733203: val_loss -0.9494
2023-09-02 10:50:11.734810: Pseudo dice [0.8407]
2023-09-02 10:50:11.736053: Epoch time: 111.53 s
2023-09-02 10:50:12.922290: 
2023-09-02 10:50:12.924333: Epoch 256
2023-09-02 10:50:12.925727: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-02 10:50:12.927455: start training, 250
================num of epochs: 250================
2023-09-02 10:51:10.911238: finished training
epoch: 256, dataset: CVC-300, dice: 0.8707499999999996
CVC-300 :  0.8707499999999996
epoch: 256, dataset: CVC-ClinicDB, dice: 0.857759677419355
CVC-ClinicDB :  0.857759677419355
epoch: 256, dataset: Kvasir, dice: 0.9031939999999998
Kvasir :  0.9031939999999998
epoch: 256, dataset: CVC-ColonDB, dice: 0.6988523684210525
CVC-ColonDB :  0.6988523684210525
epoch: 256, dataset: ETIS-LaribPolypDB, dice: 0.7438321428571427
ETIS-LaribPolypDB :  0.7438321428571427
2023-09-02 10:52:03.692123: train_loss -1.4723
2023-09-02 10:52:03.693832: val_loss -0.9119
2023-09-02 10:52:03.695253: Pseudo dice [0.8221]
2023-09-02 10:52:03.696462: Epoch time: 110.77 s
2023-09-02 10:52:04.922040: 
2023-09-02 10:52:04.923729: Epoch 257
2023-09-02 10:52:04.924963: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-02 10:52:04.926664: start training, 250
================num of epochs: 250================
2023-09-02 10:53:02.950067: finished training
epoch: 257, dataset: CVC-300, dice: 0.8693783333333331
CVC-300 :  0.8693783333333331
epoch: 257, dataset: CVC-ClinicDB, dice: 0.856924193548387
CVC-ClinicDB :  0.856924193548387
epoch: 257, dataset: Kvasir, dice: 0.9047640000000001
Kvasir :  0.9047640000000001
epoch: 257, dataset: CVC-ColonDB, dice: 0.6990302631578947
CVC-ColonDB :  0.6990302631578947
epoch: 257, dataset: ETIS-LaribPolypDB, dice: 0.7372234693877546
ETIS-LaribPolypDB :  0.7372234693877546
2023-09-02 10:53:56.101858: train_loss -1.4718
2023-09-02 10:53:56.103884: val_loss -0.9554
2023-09-02 10:53:56.105532: Pseudo dice [0.8337]
2023-09-02 10:53:56.106940: Epoch time: 111.18 s
2023-09-02 10:53:57.317412: 
2023-09-02 10:53:57.318985: Epoch 258
2023-09-02 10:53:57.320166: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-02 10:53:57.321777: start training, 250
================num of epochs: 250================
2023-09-02 10:54:55.475425: finished training
epoch: 258, dataset: CVC-300, dice: 0.8705933333333337
CVC-300 :  0.8705933333333337
epoch: 258, dataset: CVC-ClinicDB, dice: 0.8562354838709679
CVC-ClinicDB :  0.8562354838709679
epoch: 258, dataset: Kvasir, dice: 0.904372
Kvasir :  0.904372
epoch: 258, dataset: CVC-ColonDB, dice: 0.7050831578947373
CVC-ColonDB :  0.7050831578947373
epoch: 258, dataset: ETIS-LaribPolypDB, dice: 0.7451234693877551
ETIS-LaribPolypDB :  0.7451234693877551
2023-09-02 10:55:49.033882: train_loss -1.4727
2023-09-02 10:55:49.035660: val_loss -0.9631
2023-09-02 10:55:49.037223: Pseudo dice [0.8362]
2023-09-02 10:55:49.038511: Epoch time: 111.72 s
2023-09-02 10:55:50.240965: 
2023-09-02 10:55:50.242876: Epoch 259
2023-09-02 10:55:50.244277: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-02 10:55:50.246145: start training, 250
================num of epochs: 250================
2023-09-02 10:56:48.223628: finished training
epoch: 259, dataset: CVC-300, dice: 0.870608333333333
CVC-300 :  0.870608333333333
epoch: 259, dataset: CVC-ClinicDB, dice: 0.8539354838709677
CVC-ClinicDB :  0.8539354838709677
epoch: 259, dataset: Kvasir, dice: 0.9029459999999997
Kvasir :  0.9029459999999997
epoch: 259, dataset: CVC-ColonDB, dice: 0.696793684210527
CVC-ColonDB :  0.696793684210527
epoch: 259, dataset: ETIS-LaribPolypDB, dice: 0.7366275510204084
ETIS-LaribPolypDB :  0.7366275510204084
2023-09-02 10:57:41.620698: train_loss -1.4727
2023-09-02 10:57:41.622660: val_loss -1.0577
2023-09-02 10:57:41.624273: Pseudo dice [0.8532]
2023-09-02 10:57:41.625499: Epoch time: 111.38 s
2023-09-02 10:57:44.415536: 
2023-09-02 10:57:44.417199: Epoch 260
2023-09-02 10:57:44.418515: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-02 10:57:44.420092: start training, 250
================num of epochs: 250================
2023-09-02 10:58:42.566662: finished training
epoch: 260, dataset: CVC-300, dice: 0.8719149999999999
CVC-300 :  0.8719149999999999
epoch: 260, dataset: CVC-ClinicDB, dice: 0.8544387096774195
CVC-ClinicDB :  0.8544387096774195
epoch: 260, dataset: Kvasir, dice: 0.9025959999999995
Kvasir :  0.9025959999999995
epoch: 260, dataset: CVC-ColonDB, dice: 0.6970176315789475
CVC-ColonDB :  0.6970176315789475
epoch: 260, dataset: ETIS-LaribPolypDB, dice: 0.7382285714285713
ETIS-LaribPolypDB :  0.7382285714285713
2023-09-02 10:59:37.096957: train_loss -1.4723
2023-09-02 10:59:37.098660: val_loss -1.0057
2023-09-02 10:59:37.100078: Pseudo dice [0.8415]
2023-09-02 10:59:37.101315: Epoch time: 112.68 s
2023-09-02 10:59:38.288952: 
2023-09-02 10:59:38.290610: Epoch 261
2023-09-02 10:59:38.291882: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-02 10:59:38.293552: start training, 250
================num of epochs: 250================
2023-09-02 11:00:37.024399: finished training
epoch: 261, dataset: CVC-300, dice: 0.8694700000000001
CVC-300 :  0.8694700000000001
epoch: 261, dataset: CVC-ClinicDB, dice: 0.8527209677419353
CVC-ClinicDB :  0.8527209677419353
epoch: 261, dataset: Kvasir, dice: 0.9018649999999999
Kvasir :  0.9018649999999999
epoch: 261, dataset: CVC-ColonDB, dice: 0.696597368421053
CVC-ColonDB :  0.696597368421053
epoch: 261, dataset: ETIS-LaribPolypDB, dice: 0.7357785714285713
ETIS-LaribPolypDB :  0.7357785714285713
2023-09-02 11:01:34.628767: train_loss -1.4728
2023-09-02 11:01:34.630574: val_loss -0.9828
2023-09-02 11:01:34.632019: Pseudo dice [0.8356]
2023-09-02 11:01:34.633246: Epoch time: 116.34 s
2023-09-02 11:01:35.867805: 
2023-09-02 11:01:35.869891: Epoch 262
2023-09-02 11:01:35.871267: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-02 11:01:35.873222: start training, 250
================num of epochs: 250================
2023-09-02 11:02:34.696863: finished training
epoch: 262, dataset: CVC-300, dice: 0.8688283333333333
CVC-300 :  0.8688283333333333
epoch: 262, dataset: CVC-ClinicDB, dice: 0.8555419354838709
CVC-ClinicDB :  0.8555419354838709
epoch: 262, dataset: Kvasir, dice: 0.9016660000000002
Kvasir :  0.9016660000000002
epoch: 262, dataset: CVC-ColonDB, dice: 0.696939210526316
CVC-ColonDB :  0.696939210526316
epoch: 262, dataset: ETIS-LaribPolypDB, dice: 0.7331928571428573
ETIS-LaribPolypDB :  0.7331928571428573
2023-09-02 11:03:27.397516: train_loss -1.4733
2023-09-02 11:03:27.400826: val_loss -0.9874
2023-09-02 11:03:27.404055: Pseudo dice [0.8384]
2023-09-02 11:03:27.405468: Epoch time: 111.53 s
2023-09-02 11:03:28.674186: 
2023-09-02 11:03:28.677431: Epoch 263
2023-09-02 11:03:28.678915: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-02 11:03:28.680891: start training, 250
================num of epochs: 250================
2023-09-02 11:04:27.374799: finished training
epoch: 263, dataset: CVC-300, dice: 0.8691566666666666
CVC-300 :  0.8691566666666666
epoch: 263, dataset: CVC-ClinicDB, dice: 0.8566032258064515
CVC-ClinicDB :  0.8566032258064515
epoch: 263, dataset: Kvasir, dice: 0.9027409999999999
Kvasir :  0.9027409999999999
epoch: 263, dataset: CVC-ColonDB, dice: 0.6992678947368417
CVC-ColonDB :  0.6992678947368417
epoch: 263, dataset: ETIS-LaribPolypDB, dice: 0.7325755102040816
ETIS-LaribPolypDB :  0.7325755102040816
2023-09-02 11:05:20.166413: train_loss -1.4727
2023-09-02 11:05:20.168623: val_loss -0.9453
2023-09-02 11:05:20.170283: Pseudo dice [0.8321]
2023-09-02 11:05:20.171510: Epoch time: 111.5 s
2023-09-02 11:05:21.419199: 
2023-09-02 11:05:21.421249: Epoch 264
2023-09-02 11:05:21.422590: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-02 11:05:21.424595: start training, 250
================num of epochs: 250================
2023-09-02 11:06:19.722589: finished training
epoch: 264, dataset: CVC-300, dice: 0.8683516666666665
CVC-300 :  0.8683516666666665
epoch: 264, dataset: CVC-ClinicDB, dice: 0.8551596774193546
CVC-ClinicDB :  0.8551596774193546
epoch: 264, dataset: Kvasir, dice: 0.9015529999999998
Kvasir :  0.9015529999999998
epoch: 264, dataset: CVC-ColonDB, dice: 0.6961865789473684
CVC-ColonDB :  0.6961865789473684
epoch: 264, dataset: ETIS-LaribPolypDB, dice: 0.7337821428571432
ETIS-LaribPolypDB :  0.7337821428571432
2023-09-02 11:07:09.584186: train_loss -1.4729
2023-09-02 11:07:09.585947: val_loss -0.9249
2023-09-02 11:07:09.587509: Pseudo dice [0.8336]
2023-09-02 11:07:09.588787: Epoch time: 108.17 s
2023-09-02 11:07:11.194610: 
2023-09-02 11:07:11.196537: Epoch 265
2023-09-02 11:07:11.198023: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-02 11:07:11.199913: start training, 250
================num of epochs: 250================
2023-09-02 11:08:09.789935: finished training
epoch: 265, dataset: CVC-300, dice: 0.867905
CVC-300 :  0.867905
epoch: 265, dataset: CVC-ClinicDB, dice: 0.855917741935484
CVC-ClinicDB :  0.855917741935484
epoch: 265, dataset: Kvasir, dice: 0.9034500000000003
Kvasir :  0.9034500000000003
epoch: 265, dataset: CVC-ColonDB, dice: 0.6979984210526317
CVC-ColonDB :  0.6979984210526317
epoch: 265, dataset: ETIS-LaribPolypDB, dice: 0.732532142857143
ETIS-LaribPolypDB :  0.732532142857143
2023-09-02 11:09:00.132676: train_loss -1.4731
2023-09-02 11:09:00.134665: val_loss -0.963
2023-09-02 11:09:00.136294: Pseudo dice [0.8332]
2023-09-02 11:09:00.137568: Epoch time: 108.94 s
2023-09-02 11:09:01.356171: 
2023-09-02 11:09:01.358109: Epoch 266
2023-09-02 11:09:01.359343: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-02 11:09:01.361106: start training, 250
================num of epochs: 250================
2023-09-02 11:10:00.203930: finished training
epoch: 266, dataset: CVC-300, dice: 0.8681883333333336
CVC-300 :  0.8681883333333336
epoch: 266, dataset: CVC-ClinicDB, dice: 0.8559790322580646
CVC-ClinicDB :  0.8559790322580646
epoch: 266, dataset: Kvasir, dice: 0.9044410000000002
Kvasir :  0.9044410000000002
epoch: 266, dataset: CVC-ColonDB, dice: 0.6983036842105258
CVC-ColonDB :  0.6983036842105258
epoch: 266, dataset: ETIS-LaribPolypDB, dice: 0.7361627551020414
ETIS-LaribPolypDB :  0.7361627551020414
2023-09-02 11:10:57.883161: train_loss -1.4732
2023-09-02 11:10:57.887010: val_loss -1.0106
2023-09-02 11:10:57.890037: Pseudo dice [0.8456]
2023-09-02 11:10:57.891346: Epoch time: 116.53 s
2023-09-02 11:10:59.103030: 
2023-09-02 11:10:59.104919: Epoch 267
2023-09-02 11:10:59.106193: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-02 11:10:59.108089: start training, 250
================num of epochs: 250================
2023-09-02 11:11:57.905538: finished training
epoch: 267, dataset: CVC-300, dice: 0.8691150000000001
CVC-300 :  0.8691150000000001
epoch: 267, dataset: CVC-ClinicDB, dice: 0.856132258064516
CVC-ClinicDB :  0.856132258064516
epoch: 267, dataset: Kvasir, dice: 0.9044279999999999
Kvasir :  0.9044279999999999
epoch: 267, dataset: CVC-ColonDB, dice: 0.6963336842105267
CVC-ColonDB :  0.6963336842105267
epoch: 267, dataset: ETIS-LaribPolypDB, dice: 0.7371846938775509
ETIS-LaribPolypDB :  0.7371846938775509
2023-09-02 11:12:52.613778: train_loss -1.473
2023-09-02 11:12:52.615706: val_loss -0.9332
2023-09-02 11:12:52.617367: Pseudo dice [0.8312]
2023-09-02 11:12:52.618625: Epoch time: 113.51 s
2023-09-02 11:12:54.316283: 
2023-09-02 11:12:54.318281: Epoch 268
2023-09-02 11:12:54.319665: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-02 11:12:54.321425: start training, 250
================num of epochs: 250================
2023-09-02 11:13:53.118738: finished training
epoch: 268, dataset: CVC-300, dice: 0.8695916666666667
CVC-300 :  0.8695916666666667
epoch: 268, dataset: CVC-ClinicDB, dice: 0.8576354838709677
CVC-ClinicDB :  0.8576354838709677
epoch: 268, dataset: Kvasir, dice: 0.904839
Kvasir :  0.904839
epoch: 268, dataset: CVC-ColonDB, dice: 0.7002497368421056
CVC-ColonDB :  0.7002497368421056
epoch: 268, dataset: ETIS-LaribPolypDB, dice: 0.7408096938775509
ETIS-LaribPolypDB :  0.7408096938775509
2023-09-02 11:14:53.810892: train_loss -1.4733
2023-09-02 11:14:53.813199: val_loss -0.898
2023-09-02 11:14:53.814725: Pseudo dice [0.821]
2023-09-02 11:14:53.815941: Epoch time: 119.5 s
2023-09-02 11:14:55.047498: 
2023-09-02 11:14:55.049428: Epoch 269
2023-09-02 11:14:55.050719: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-02 11:14:55.052409: start training, 250
================num of epochs: 250================
2023-09-02 11:15:53.052782: finished training
epoch: 269, dataset: CVC-300, dice: 0.8689949999999999
CVC-300 :  0.8689949999999999
epoch: 269, dataset: CVC-ClinicDB, dice: 0.855940322580645
CVC-ClinicDB :  0.855940322580645
epoch: 269, dataset: Kvasir, dice: 0.9027419999999998
Kvasir :  0.9027419999999998
epoch: 269, dataset: CVC-ColonDB, dice: 0.6978957894736851
CVC-ColonDB :  0.6978957894736851
epoch: 269, dataset: ETIS-LaribPolypDB, dice: 0.7405525510204085
ETIS-LaribPolypDB :  0.7405525510204085
2023-09-02 11:16:45.590970: train_loss -1.473
2023-09-02 11:16:45.592957: val_loss -1.0071
2023-09-02 11:16:45.594749: Pseudo dice [0.8502]
2023-09-02 11:16:45.596078: Epoch time: 110.54 s
2023-09-02 11:16:48.480982: 
2023-09-02 11:16:48.483035: Epoch 270
2023-09-02 11:16:48.484921: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-02 11:16:48.487462: start training, 250
================num of epochs: 250================
2023-09-02 11:17:46.519350: finished training
epoch: 270, dataset: CVC-300, dice: 0.8678900000000002
CVC-300 :  0.8678900000000002
epoch: 270, dataset: CVC-ClinicDB, dice: 0.8566080645161293
CVC-ClinicDB :  0.8566080645161293
epoch: 270, dataset: Kvasir, dice: 0.9033169999999998
Kvasir :  0.9033169999999998
epoch: 270, dataset: CVC-ColonDB, dice: 0.7007807894736842
CVC-ColonDB :  0.7007807894736842
epoch: 270, dataset: ETIS-LaribPolypDB, dice: 0.7398423469387756
ETIS-LaribPolypDB :  0.7398423469387756
2023-09-02 11:18:36.686718: train_loss -1.4726
2023-09-02 11:18:36.688451: val_loss -0.8941
2023-09-02 11:18:36.689917: Pseudo dice [0.8235]
2023-09-02 11:18:36.691158: Epoch time: 108.21 s
2023-09-02 11:18:37.954506: 
2023-09-02 11:18:37.956384: Epoch 271
2023-09-02 11:18:37.957741: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-02 11:18:37.959522: start training, 250
================num of epochs: 250================
2023-09-02 11:19:36.259064: finished training
epoch: 271, dataset: CVC-300, dice: 0.8672166666666666
CVC-300 :  0.8672166666666666
epoch: 271, dataset: CVC-ClinicDB, dice: 0.8567112903225808
CVC-ClinicDB :  0.8567112903225808
epoch: 271, dataset: Kvasir, dice: 0.9024920000000001
Kvasir :  0.9024920000000001
epoch: 271, dataset: CVC-ColonDB, dice: 0.6995010526315786
CVC-ColonDB :  0.6995010526315786
epoch: 271, dataset: ETIS-LaribPolypDB, dice: 0.7382469387755101
ETIS-LaribPolypDB :  0.7382469387755101
2023-09-02 11:20:27.903985: train_loss -1.4724
2023-09-02 11:20:27.906038: val_loss -1.094
2023-09-02 11:20:27.907724: Pseudo dice [0.8701]
2023-09-02 11:20:27.909162: Epoch time: 109.95 s
2023-09-02 11:20:29.111466: 
2023-09-02 11:20:29.113294: Epoch 272
2023-09-02 11:20:29.114534: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-02 11:20:29.116203: start training, 250
================num of epochs: 250================
2023-09-02 11:21:27.114453: finished training
epoch: 272, dataset: CVC-300, dice: 0.8707733333333335
CVC-300 :  0.8707733333333335
epoch: 272, dataset: CVC-ClinicDB, dice: 0.8550709677419354
CVC-ClinicDB :  0.8550709677419354
epoch: 272, dataset: Kvasir, dice: 0.9021600000000002
Kvasir :  0.9021600000000002
epoch: 272, dataset: CVC-ColonDB, dice: 0.6983597368421048
CVC-ColonDB :  0.6983597368421048
epoch: 272, dataset: ETIS-LaribPolypDB, dice: 0.7381321428571425
ETIS-LaribPolypDB :  0.7381321428571425
2023-09-02 11:22:17.947221: train_loss -1.4727
2023-09-02 11:22:17.949109: val_loss -1.0253
2023-09-02 11:22:17.950640: Pseudo dice [0.8454]
2023-09-02 11:22:17.952139: Epoch time: 108.84 s
2023-09-02 11:22:19.132016: 
2023-09-02 11:22:19.133926: Epoch 273
2023-09-02 11:22:19.135272: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-02 11:22:19.136990: start training, 250
================num of epochs: 250================
2023-09-02 11:23:17.098460: finished training
epoch: 273, dataset: CVC-300, dice: 0.8674033333333334
CVC-300 :  0.8674033333333334
epoch: 273, dataset: CVC-ClinicDB, dice: 0.8561451612903226
CVC-ClinicDB :  0.8561451612903226
epoch: 273, dataset: Kvasir, dice: 0.9022240000000002
Kvasir :  0.9022240000000002
epoch: 273, dataset: CVC-ColonDB, dice: 0.7014507894736844
CVC-ColonDB :  0.7014507894736844
epoch: 273, dataset: ETIS-LaribPolypDB, dice: 0.7388000000000006
ETIS-LaribPolypDB :  0.7388000000000006
2023-09-02 11:24:06.915101: train_loss -1.4731
2023-09-02 11:24:06.916985: val_loss -1.0265
2023-09-02 11:24:06.918525: Pseudo dice [0.8471]
2023-09-02 11:24:06.919819: Epoch time: 107.78 s
2023-09-02 11:24:08.125494: 
2023-09-02 11:24:08.127297: Epoch 274
2023-09-02 11:24:08.128768: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-02 11:24:08.130527: start training, 250
================num of epochs: 250================
2023-09-02 11:25:06.453918: finished training
epoch: 274, dataset: CVC-300, dice: 0.8659433333333333
CVC-300 :  0.8659433333333333
epoch: 274, dataset: CVC-ClinicDB, dice: 0.8560774193548386
CVC-ClinicDB :  0.8560774193548386
epoch: 274, dataset: Kvasir, dice: 0.9019670000000001
Kvasir :  0.9019670000000001
epoch: 274, dataset: CVC-ColonDB, dice: 0.6985486842105268
CVC-ColonDB :  0.6985486842105268
epoch: 274, dataset: ETIS-LaribPolypDB, dice: 0.7349862244897962
ETIS-LaribPolypDB :  0.7349862244897962
2023-09-02 11:25:56.499758: train_loss -1.4729
2023-09-02 11:25:56.501684: val_loss -0.8867
2023-09-02 11:25:56.503272: Pseudo dice [0.813]
2023-09-02 11:25:56.504571: Epoch time: 108.38 s
2023-09-02 11:25:57.677679: 
2023-09-02 11:25:57.679379: Epoch 275
2023-09-02 11:25:57.681104: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-02 11:25:57.682943: start training, 250
================num of epochs: 250================
2023-09-02 11:26:55.616088: finished training
epoch: 275, dataset: CVC-300, dice: 0.8708133333333336
CVC-300 :  0.8708133333333336
epoch: 275, dataset: CVC-ClinicDB, dice: 0.8552274193548385
CVC-ClinicDB :  0.8552274193548385
epoch: 275, dataset: Kvasir, dice: 0.904469
Kvasir :  0.904469
epoch: 275, dataset: CVC-ColonDB, dice: 0.6989302631578952
CVC-ColonDB :  0.6989302631578952
epoch: 275, dataset: ETIS-LaribPolypDB, dice: 0.7401877551020408
ETIS-LaribPolypDB :  0.7401877551020408
2023-09-02 11:27:46.860763: train_loss -1.4728
2023-09-02 11:27:46.862720: val_loss -0.9783
2023-09-02 11:27:46.864327: Pseudo dice [0.8393]
2023-09-02 11:27:46.865650: Epoch time: 109.18 s
2023-09-02 11:27:48.065396: 
2023-09-02 11:27:48.067155: Epoch 276
2023-09-02 11:27:48.068444: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-02 11:27:48.070138: start training, 250
================num of epochs: 250================
2023-09-02 11:28:46.042100: finished training
epoch: 276, dataset: CVC-300, dice: 0.8710850000000003
CVC-300 :  0.8710850000000003
epoch: 276, dataset: CVC-ClinicDB, dice: 0.8580806451612902
CVC-ClinicDB :  0.8580806451612902
epoch: 276, dataset: Kvasir, dice: 0.9041360000000003
Kvasir :  0.9041360000000003
epoch: 276, dataset: CVC-ColonDB, dice: 0.7025052631578955
CVC-ColonDB :  0.7025052631578955
epoch: 276, dataset: ETIS-LaribPolypDB, dice: 0.7367336734693876
ETIS-LaribPolypDB :  0.7367336734693876
2023-09-02 11:29:37.184482: train_loss -1.4731
2023-09-02 11:29:37.186413: val_loss -1.0752
2023-09-02 11:29:37.188055: Pseudo dice [0.8648]
2023-09-02 11:29:37.189513: Epoch time: 109.12 s
2023-09-02 11:29:38.361644: 
2023-09-02 11:29:38.363734: Epoch 277
2023-09-02 11:29:38.365291: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-02 11:29:38.367227: start training, 250
================num of epochs: 250================
2023-09-02 11:30:36.550653: finished training
epoch: 277, dataset: CVC-300, dice: 0.8688200000000001
CVC-300 :  0.8688200000000001
epoch: 277, dataset: CVC-ClinicDB, dice: 0.8551661290322579
CVC-ClinicDB :  0.8551661290322579
epoch: 277, dataset: Kvasir, dice: 0.9034700000000003
Kvasir :  0.9034700000000003
epoch: 277, dataset: CVC-ColonDB, dice: 0.6980397368421055
CVC-ColonDB :  0.6980397368421055
epoch: 277, dataset: ETIS-LaribPolypDB, dice: 0.7367051020408163
ETIS-LaribPolypDB :  0.7367051020408163
2023-09-02 11:31:28.243211: train_loss -1.4729
2023-09-02 11:31:28.245202: val_loss -0.9852
2023-09-02 11:31:28.246816: Pseudo dice [0.8411]
2023-09-02 11:31:28.248407: Epoch time: 109.88 s
2023-09-02 11:31:29.412503: 
2023-09-02 11:31:29.414448: Epoch 278
2023-09-02 11:31:29.415843: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-02 11:31:29.417565: start training, 250
================num of epochs: 250================
2023-09-02 11:32:27.373255: finished training
epoch: 278, dataset: CVC-300, dice: 0.8685533333333331
CVC-300 :  0.8685533333333331
epoch: 278, dataset: CVC-ClinicDB, dice: 0.8547258064516126
CVC-ClinicDB :  0.8547258064516126
epoch: 278, dataset: Kvasir, dice: 0.9047930000000001
Kvasir :  0.9047930000000001
epoch: 278, dataset: CVC-ColonDB, dice: 0.6956350000000004
CVC-ColonDB :  0.6956350000000004
epoch: 278, dataset: ETIS-LaribPolypDB, dice: 0.7281663265306123
ETIS-LaribPolypDB :  0.7281663265306123
2023-09-02 11:33:18.713471: train_loss -1.4727
2023-09-02 11:33:18.715304: val_loss -0.98
2023-09-02 11:33:18.716985: Pseudo dice [0.8391]
2023-09-02 11:33:18.718410: Epoch time: 109.3 s
2023-09-02 11:33:19.898096: 
2023-09-02 11:33:19.899944: Epoch 279
2023-09-02 11:33:19.901442: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-02 11:33:19.903584: start training, 250
================num of epochs: 250================
2023-09-02 11:34:17.848145: finished training
epoch: 279, dataset: CVC-300, dice: 0.8692116666666668
CVC-300 :  0.8692116666666668
epoch: 279, dataset: CVC-ClinicDB, dice: 0.8485096774193548
CVC-ClinicDB :  0.8485096774193548
epoch: 279, dataset: Kvasir, dice: 0.9019229999999997
Kvasir :  0.9019229999999997
epoch: 279, dataset: CVC-ColonDB, dice: 0.6952313157894742
CVC-ColonDB :  0.6952313157894742
epoch: 279, dataset: ETIS-LaribPolypDB, dice: 0.7309357142857142
ETIS-LaribPolypDB :  0.7309357142857142
2023-09-02 11:35:09.737968: train_loss -1.4731
2023-09-02 11:35:09.739789: val_loss -1.0425
2023-09-02 11:35:09.741324: Pseudo dice [0.8491]
2023-09-02 11:35:09.742650: Epoch time: 109.84 s
2023-09-02 11:35:12.487367: 
2023-09-02 11:35:12.489216: Epoch 280
2023-09-02 11:35:12.490628: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-02 11:35:12.492428: start training, 250
================num of epochs: 250================
2023-09-02 11:36:10.632862: finished training
epoch: 280, dataset: CVC-300, dice: 0.8703200000000001
CVC-300 :  0.8703200000000001
epoch: 280, dataset: CVC-ClinicDB, dice: 0.8523838709677419
CVC-ClinicDB :  0.8523838709677419
epoch: 280, dataset: Kvasir, dice: 0.9035150000000001
Kvasir :  0.9035150000000001
epoch: 280, dataset: CVC-ColonDB, dice: 0.6974644736842102
CVC-ColonDB :  0.6974644736842102
epoch: 280, dataset: ETIS-LaribPolypDB, dice: 0.7329938775510205
ETIS-LaribPolypDB :  0.7329938775510205
2023-09-02 11:37:02.878764: train_loss -1.4732
2023-09-02 11:37:02.880687: val_loss -0.9636
2023-09-02 11:37:02.882241: Pseudo dice [0.8369]
2023-09-02 11:37:02.883513: Epoch time: 110.39 s
2023-09-02 11:37:04.071477: 
2023-09-02 11:37:04.073427: Epoch 281
2023-09-02 11:37:04.074677: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-02 11:37:04.076346: start training, 250
================num of epochs: 250================
2023-09-02 11:38:01.957829: finished training
epoch: 281, dataset: CVC-300, dice: 0.871216666666667
CVC-300 :  0.871216666666667
epoch: 281, dataset: CVC-ClinicDB, dice: 0.8440677419354837
CVC-ClinicDB :  0.8440677419354837
epoch: 281, dataset: Kvasir, dice: 0.9024010000000002
Kvasir :  0.9024010000000002
epoch: 281, dataset: CVC-ColonDB, dice: 0.6977452631578953
CVC-ColonDB :  0.6977452631578953
epoch: 281, dataset: ETIS-LaribPolypDB, dice: 0.7313255102040814
ETIS-LaribPolypDB :  0.7313255102040814
2023-09-02 11:38:54.868986: train_loss -1.4732
2023-09-02 11:38:54.870736: val_loss -0.9547
2023-09-02 11:38:54.872435: Pseudo dice [0.8325]
2023-09-02 11:38:54.873769: Epoch time: 110.8 s
2023-09-02 11:38:56.037514: 
2023-09-02 11:38:56.039326: Epoch 282
2023-09-02 11:38:56.040585: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-02 11:38:56.042671: start training, 250
================num of epochs: 250================
2023-09-02 11:39:54.060821: finished training
epoch: 282, dataset: CVC-300, dice: 0.86989
CVC-300 :  0.86989
epoch: 282, dataset: CVC-ClinicDB, dice: 0.8551822580645161
CVC-ClinicDB :  0.8551822580645161
epoch: 282, dataset: Kvasir, dice: 0.9048609999999994
Kvasir :  0.9048609999999994
epoch: 282, dataset: CVC-ColonDB, dice: 0.6981494736842112
CVC-ColonDB :  0.6981494736842112
epoch: 282, dataset: ETIS-LaribPolypDB, dice: 0.7369627551020403
ETIS-LaribPolypDB :  0.7369627551020403
2023-09-02 11:40:46.032261: train_loss -1.4733
2023-09-02 11:40:46.144073: val_loss -0.9569
2023-09-02 11:40:46.146621: Pseudo dice [0.84]
2023-09-02 11:40:46.148528: Epoch time: 110.0 s
2023-09-02 11:40:47.322424: 
2023-09-02 11:40:47.324350: Epoch 283
2023-09-02 11:40:47.325953: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-02 11:40:47.327854: start training, 250
================num of epochs: 250================
2023-09-02 11:41:45.489709: finished training
epoch: 283, dataset: CVC-300, dice: 0.8710366666666667
CVC-300 :  0.8710366666666667
epoch: 283, dataset: CVC-ClinicDB, dice: 0.8526725806451614
CVC-ClinicDB :  0.8526725806451614
epoch: 283, dataset: Kvasir, dice: 0.9038700000000003
Kvasir :  0.9038700000000003
epoch: 283, dataset: CVC-ColonDB, dice: 0.6986800000000003
CVC-ColonDB :  0.6986800000000003
epoch: 283, dataset: ETIS-LaribPolypDB, dice: 0.7385739795918367
ETIS-LaribPolypDB :  0.7385739795918367
2023-09-02 11:42:38.417259: train_loss -1.473
2023-09-02 11:42:38.419306: val_loss -0.9911
2023-09-02 11:42:38.420947: Pseudo dice [0.8457]
2023-09-02 11:42:38.422289: Epoch time: 111.1 s
2023-09-02 11:42:39.593419: 
2023-09-02 11:42:39.595173: Epoch 284
2023-09-02 11:42:39.596507: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-02 11:42:39.601654: start training, 250
================num of epochs: 250================
2023-09-02 11:43:37.506772: finished training
epoch: 284, dataset: CVC-300, dice: 0.8717249999999999
CVC-300 :  0.8717249999999999
epoch: 284, dataset: CVC-ClinicDB, dice: 0.8536774193548384
CVC-ClinicDB :  0.8536774193548384
epoch: 284, dataset: Kvasir, dice: 0.9035250000000002
Kvasir :  0.9035250000000002
epoch: 284, dataset: CVC-ColonDB, dice: 0.6993023684210532
CVC-ColonDB :  0.6993023684210532
epoch: 284, dataset: ETIS-LaribPolypDB, dice: 0.7365785714285713
ETIS-LaribPolypDB :  0.7365785714285713
2023-09-02 11:44:31.164427: train_loss -1.4732
2023-09-02 11:44:31.166331: val_loss -1.0187
2023-09-02 11:44:31.167881: Pseudo dice [0.8482]
2023-09-02 11:44:31.169201: Epoch time: 111.57 s
2023-09-02 11:44:32.354541: 
2023-09-02 11:44:32.356507: Epoch 285
2023-09-02 11:44:32.358042: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-02 11:44:32.359866: start training, 250
================num of epochs: 250================
2023-09-02 11:45:30.229081: finished training
epoch: 285, dataset: CVC-300, dice: 0.873735
CVC-300 :  0.873735
epoch: 285, dataset: CVC-ClinicDB, dice: 0.8546306451612903
CVC-ClinicDB :  0.8546306451612903
epoch: 285, dataset: Kvasir, dice: 0.9038259999999997
Kvasir :  0.9038259999999997
epoch: 285, dataset: CVC-ColonDB, dice: 0.7019939473684215
CVC-ColonDB :  0.7019939473684215
epoch: 285, dataset: ETIS-LaribPolypDB, dice: 0.7394112244897956
ETIS-LaribPolypDB :  0.7394112244897956
2023-09-02 11:46:24.069120: train_loss -1.4735
2023-09-02 11:46:24.071324: val_loss -0.9377
2023-09-02 11:46:24.072978: Pseudo dice [0.8223]
2023-09-02 11:46:24.074437: Epoch time: 111.72 s
2023-09-02 11:46:25.263849: 
2023-09-02 11:46:25.265616: Epoch 286
2023-09-02 11:46:25.266948: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-02 11:46:25.268599: start training, 250
================num of epochs: 250================
2023-09-02 11:47:23.461448: finished training
epoch: 286, dataset: CVC-300, dice: 0.8691083333333335
CVC-300 :  0.8691083333333335
epoch: 286, dataset: CVC-ClinicDB, dice: 0.8439612903225806
CVC-ClinicDB :  0.8439612903225806
epoch: 286, dataset: Kvasir, dice: 0.9014580000000002
Kvasir :  0.9014580000000002
epoch: 286, dataset: CVC-ColonDB, dice: 0.6947465789473682
CVC-ColonDB :  0.6947465789473682
epoch: 286, dataset: ETIS-LaribPolypDB, dice: 0.7281561224489793
ETIS-LaribPolypDB :  0.7281561224489793
2023-09-02 11:48:16.862906: train_loss -1.4731
2023-09-02 11:48:16.864901: val_loss -0.9328
2023-09-02 11:48:16.866438: Pseudo dice [0.8297]
2023-09-02 11:48:16.867722: Epoch time: 111.6 s
2023-09-02 11:48:18.042885: 
2023-09-02 11:48:18.044995: Epoch 287
2023-09-02 11:48:18.046452: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-02 11:48:18.048662: start training, 250
================num of epochs: 250================
2023-09-02 11:49:15.883092: finished training
epoch: 287, dataset: CVC-300, dice: 0.8698
CVC-300 :  0.8698
epoch: 287, dataset: CVC-ClinicDB, dice: 0.8518887096774193
CVC-ClinicDB :  0.8518887096774193
epoch: 287, dataset: Kvasir, dice: 0.9032139999999999
Kvasir :  0.9032139999999999
epoch: 287, dataset: CVC-ColonDB, dice: 0.6992997368421056
CVC-ColonDB :  0.6992997368421056
epoch: 287, dataset: ETIS-LaribPolypDB, dice: 0.7326642857142854
ETIS-LaribPolypDB :  0.7326642857142854
2023-09-02 11:50:09.274730: train_loss -1.473
2023-09-02 11:50:09.276533: val_loss -1.0562
2023-09-02 11:50:09.278048: Pseudo dice [0.8598]
2023-09-02 11:50:09.279323: Epoch time: 111.23 s
2023-09-02 11:50:10.478329: 
2023-09-02 11:50:10.480159: Epoch 288
2023-09-02 11:50:10.481454: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-02 11:50:10.483187: start training, 250
================num of epochs: 250================
2023-09-02 11:51:08.321878: finished training
epoch: 288, dataset: CVC-300, dice: 0.867913333333333
CVC-300 :  0.867913333333333
epoch: 288, dataset: CVC-ClinicDB, dice: 0.8546129032258064
CVC-ClinicDB :  0.8546129032258064
epoch: 288, dataset: Kvasir, dice: 0.9030369999999999
Kvasir :  0.9030369999999999
epoch: 288, dataset: CVC-ColonDB, dice: 0.6996786842105259
CVC-ColonDB :  0.6996786842105259
epoch: 288, dataset: ETIS-LaribPolypDB, dice: 0.7339795918367349
ETIS-LaribPolypDB :  0.7339795918367349
2023-09-02 11:52:02.222081: train_loss -1.4733
2023-09-02 11:52:02.224053: val_loss -0.9242
2023-09-02 11:52:02.225722: Pseudo dice [0.8253]
2023-09-02 11:52:02.227049: Epoch time: 111.75 s
2023-09-02 11:52:03.408835: 
2023-09-02 11:52:03.410684: Epoch 289
2023-09-02 11:52:03.412371: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-02 11:52:03.414567: start training, 250
================num of epochs: 250================
2023-09-02 11:53:01.536999: finished training
epoch: 289, dataset: CVC-300, dice: 0.8702916666666666
CVC-300 :  0.8702916666666666
epoch: 289, dataset: CVC-ClinicDB, dice: 0.8552548387096771
CVC-ClinicDB :  0.8552548387096771
epoch: 289, dataset: Kvasir, dice: 0.9040310000000001
Kvasir :  0.9040310000000001
epoch: 289, dataset: CVC-ColonDB, dice: 0.7002484210526309
CVC-ColonDB :  0.7002484210526309
epoch: 289, dataset: ETIS-LaribPolypDB, dice: 0.735532653061225
ETIS-LaribPolypDB :  0.735532653061225
2023-09-02 11:53:58.149598: train_loss -1.4736
2023-09-02 11:53:58.151447: val_loss -1.0205
2023-09-02 11:53:58.152966: Pseudo dice [0.8466]
2023-09-02 11:53:58.154268: Epoch time: 114.74 s
2023-09-02 11:54:01.003862: 
2023-09-02 11:54:01.005777: Epoch 290
2023-09-02 11:54:01.007567: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-02 11:54:01.009922: start training, 250
================num of epochs: 250================
2023-09-02 11:54:59.490027: finished training
epoch: 290, dataset: CVC-300, dice: 0.8691416666666666
CVC-300 :  0.8691416666666666
epoch: 290, dataset: CVC-ClinicDB, dice: 0.8541435483870969
CVC-ClinicDB :  0.8541435483870969
epoch: 290, dataset: Kvasir, dice: 0.9049759999999999
Kvasir :  0.9049759999999999
epoch: 290, dataset: CVC-ColonDB, dice: 0.6986184210526323
CVC-ColonDB :  0.6986184210526323
epoch: 290, dataset: ETIS-LaribPolypDB, dice: 0.7342551020408161
ETIS-LaribPolypDB :  0.7342551020408161
2023-09-02 11:55:55.612017: train_loss -1.4733
2023-09-02 11:56:26.366566: val_loss -0.9746
2023-09-02 11:56:26.369070: Pseudo dice [0.8368]
2023-09-02 11:56:26.370956: Epoch time: 114.61 s
2023-09-02 11:56:27.591347: 
2023-09-02 11:56:27.593152: Epoch 291
2023-09-02 11:56:27.594661: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-02 11:56:27.596863: start training, 250
================num of epochs: 250================
2023-09-02 11:57:25.906085: finished training
epoch: 291, dataset: CVC-300, dice: 0.8717333333333331
CVC-300 :  0.8717333333333331
epoch: 291, dataset: CVC-ClinicDB, dice: 0.8545967741935485
CVC-ClinicDB :  0.8545967741935485
epoch: 291, dataset: Kvasir, dice: 0.9044889999999997
Kvasir :  0.9044889999999997
epoch: 291, dataset: CVC-ColonDB, dice: 0.7036031578947373
CVC-ColonDB :  0.7036031578947373
epoch: 291, dataset: ETIS-LaribPolypDB, dice: 0.7408316326530613
ETIS-LaribPolypDB :  0.7408316326530613
2023-09-02 11:58:17.292830: train_loss -1.4732
2023-09-02 11:58:17.294654: val_loss -0.8929
2023-09-02 11:58:17.296202: Pseudo dice [0.8221]
2023-09-02 11:58:17.297526: Epoch time: 109.7 s
2023-09-02 11:58:18.487676: 
2023-09-02 11:58:18.489356: Epoch 292
2023-09-02 11:58:18.490674: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-02 11:58:18.492448: start training, 250
================num of epochs: 250================
2023-09-02 11:59:16.738150: finished training
epoch: 292, dataset: CVC-300, dice: 0.8690916666666667
CVC-300 :  0.8690916666666667
epoch: 292, dataset: CVC-ClinicDB, dice: 0.850958064516129
CVC-ClinicDB :  0.850958064516129
epoch: 292, dataset: Kvasir, dice: 0.9047710000000001
Kvasir :  0.9047710000000001
epoch: 292, dataset: CVC-ColonDB, dice: 0.6972197368421061
CVC-ColonDB :  0.6972197368421061
epoch: 292, dataset: ETIS-LaribPolypDB, dice: 0.7367862244897962
ETIS-LaribPolypDB :  0.7367862244897962
2023-09-02 12:00:08.020965: train_loss -1.4735
2023-09-02 12:00:08.022847: val_loss -1.0321
2023-09-02 12:00:08.024505: Pseudo dice [0.8484]
2023-09-02 12:00:08.026421: Epoch time: 109.53 s
2023-09-02 12:00:09.213377: 
2023-09-02 12:00:09.215169: Epoch 293
2023-09-02 12:00:09.216618: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-02 12:00:09.218877: start training, 250
================num of epochs: 250================
2023-09-02 12:01:07.214150: finished training
epoch: 293, dataset: CVC-300, dice: 0.8682449999999999
CVC-300 :  0.8682449999999999
epoch: 293, dataset: CVC-ClinicDB, dice: 0.8528080645161289
CVC-ClinicDB :  0.8528080645161289
epoch: 293, dataset: Kvasir, dice: 0.9020719999999995
Kvasir :  0.9020719999999995
epoch: 293, dataset: CVC-ColonDB, dice: 0.6982442105263162
CVC-ColonDB :  0.6982442105263162
epoch: 293, dataset: ETIS-LaribPolypDB, dice: 0.7337903061224491
ETIS-LaribPolypDB :  0.7337903061224491
2023-09-02 12:01:58.473677: train_loss -1.4735
2023-09-02 12:01:58.475622: val_loss -1.0478
2023-09-02 12:01:58.477234: Pseudo dice [0.8514]
2023-09-02 12:01:58.478530: Epoch time: 109.26 s
2023-09-02 12:01:59.665356: 
2023-09-02 12:01:59.667200: Epoch 294
2023-09-02 12:01:59.668540: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-02 12:01:59.670395: start training, 250
================num of epochs: 250================
2023-09-02 12:02:57.664210: finished training
epoch: 294, dataset: CVC-300, dice: 0.8685183333333336
CVC-300 :  0.8685183333333336
epoch: 294, dataset: CVC-ClinicDB, dice: 0.852038709677419
CVC-ClinicDB :  0.852038709677419
epoch: 294, dataset: Kvasir, dice: 0.9038010000000001
Kvasir :  0.9038010000000001
epoch: 294, dataset: CVC-ColonDB, dice: 0.6982
CVC-ColonDB :  0.6982
epoch: 294, dataset: ETIS-LaribPolypDB, dice: 0.7362127551020411
ETIS-LaribPolypDB :  0.7362127551020411
2023-09-02 12:03:49.129263: train_loss -1.4732
2023-09-02 12:03:49.131174: val_loss -0.9493
2023-09-02 12:03:49.132769: Pseudo dice [0.8339]
2023-09-02 12:03:49.134103: Epoch time: 109.47 s
2023-09-02 12:03:50.321782: 
2023-09-02 12:03:50.323657: Epoch 295
2023-09-02 12:03:50.325129: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-02 12:03:50.327232: start training, 250
================num of epochs: 250================
2023-09-02 12:04:48.342147: finished training
epoch: 295, dataset: CVC-300, dice: 0.871605
CVC-300 :  0.871605
epoch: 295, dataset: CVC-ClinicDB, dice: 0.85355
CVC-ClinicDB :  0.85355
epoch: 295, dataset: Kvasir, dice: 0.9041090000000002
Kvasir :  0.9041090000000002
epoch: 295, dataset: CVC-ColonDB, dice: 0.7014215789473691
CVC-ColonDB :  0.7014215789473691
epoch: 295, dataset: ETIS-LaribPolypDB, dice: 0.74065
ETIS-LaribPolypDB :  0.74065
2023-09-02 12:05:39.428881: train_loss -1.4735
2023-09-02 12:05:39.430950: val_loss -0.9623
2023-09-02 12:05:39.432517: Pseudo dice [0.8413]
2023-09-02 12:05:39.433854: Epoch time: 109.11 s
2023-09-02 12:05:40.865416: 
2023-09-02 12:05:40.867274: Epoch 296
2023-09-02 12:05:40.868594: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-02 12:05:40.870494: start training, 250
================num of epochs: 250================
2023-09-02 12:06:38.863333: finished training
epoch: 296, dataset: CVC-300, dice: 0.8692816666666664
CVC-300 :  0.8692816666666664
epoch: 296, dataset: CVC-ClinicDB, dice: 0.8536693548387094
CVC-ClinicDB :  0.8536693548387094
epoch: 296, dataset: Kvasir, dice: 0.9037360000000004
Kvasir :  0.9037360000000004
epoch: 296, dataset: CVC-ColonDB, dice: 0.6996321052631581
CVC-ColonDB :  0.6996321052631581
epoch: 296, dataset: ETIS-LaribPolypDB, dice: 0.7366076530612249
ETIS-LaribPolypDB :  0.7366076530612249
2023-09-02 12:07:33.533018: train_loss -1.4736
2023-09-02 12:07:33.534900: val_loss -0.9517
2023-09-02 12:07:33.536463: Pseudo dice [0.8267]
2023-09-02 12:07:33.537781: Epoch time: 112.67 s
2023-09-02 12:07:34.731298: 
2023-09-02 12:07:34.733161: Epoch 297
2023-09-02 12:07:34.734785: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-02 12:07:34.736794: start training, 250
================num of epochs: 250================
2023-09-02 12:08:32.715058: finished training
epoch: 297, dataset: CVC-300, dice: 0.8702800000000004
CVC-300 :  0.8702800000000004
epoch: 297, dataset: CVC-ClinicDB, dice: 0.8561661290322579
CVC-ClinicDB :  0.8561661290322579
epoch: 297, dataset: Kvasir, dice: 0.9043330000000003
Kvasir :  0.9043330000000003
epoch: 297, dataset: CVC-ColonDB, dice: 0.7043334210526316
CVC-ColonDB :  0.7043334210526316
epoch: 297, dataset: ETIS-LaribPolypDB, dice: 0.7382020408163267
ETIS-LaribPolypDB :  0.7382020408163267
2023-09-02 12:09:23.848914: train_loss -1.4734
2023-09-02 12:09:23.850914: val_loss -0.9783
2023-09-02 12:09:23.852576: Pseudo dice [0.8374]
2023-09-02 12:09:23.854062: Epoch time: 109.12 s
2023-09-02 12:09:25.040509: 
2023-09-02 12:09:25.042637: Epoch 298
2023-09-02 12:09:25.044095: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-02 12:09:25.046171: start training, 250
================num of epochs: 250================
2023-09-02 12:10:23.012179: finished training
epoch: 298, dataset: CVC-300, dice: 0.8708150000000001
CVC-300 :  0.8708150000000001
epoch: 298, dataset: CVC-ClinicDB, dice: 0.8539112903225804
CVC-ClinicDB :  0.8539112903225804
epoch: 298, dataset: Kvasir, dice: 0.904237
Kvasir :  0.904237
epoch: 298, dataset: CVC-ColonDB, dice: 0.7003057894736848
CVC-ColonDB :  0.7003057894736848
epoch: 298, dataset: ETIS-LaribPolypDB, dice: 0.7398331632653063
ETIS-LaribPolypDB :  0.7398331632653063
2023-09-02 12:11:15.176556: train_loss -1.4734
2023-09-02 12:11:15.178481: val_loss -1.0339
2023-09-02 12:11:15.180048: Pseudo dice [0.8518]
2023-09-02 12:11:15.181400: Epoch time: 110.14 s
2023-09-02 12:11:16.651623: 
2023-09-02 12:11:16.653496: Epoch 299
2023-09-02 12:11:16.654867: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-02 12:11:16.656506: start training, 250
================num of epochs: 250================
2023-09-02 12:15:31.656673: finished training
epoch: 299, dataset: CVC-300, dice: 0.8694549999999999
CVC-300 :  0.8694549999999999
epoch: 299, dataset: CVC-ClinicDB, dice: 0.8542177419354836
CVC-ClinicDB :  0.8542177419354836
epoch: 299, dataset: Kvasir, dice: 0.9033209999999999
Kvasir :  0.9033209999999999
epoch: 299, dataset: CVC-ColonDB, dice: 0.7013484210526315
CVC-ColonDB :  0.7013484210526315
epoch: 299, dataset: ETIS-LaribPolypDB, dice: 0.7381448979591841
ETIS-LaribPolypDB :  0.7381448979591841
2023-09-02 12:16:23.743625: train_loss -1.4732
2023-09-02 12:16:23.745477: val_loss -0.9544
2023-09-02 12:16:23.747060: Pseudo dice [0.8409]
2023-09-02 12:16:23.750525: Epoch time: 307.09 s
2023-09-02 12:16:26.722419: Training done.
2023-09-02 12:16:26.816159: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset123_Polyp/splits_final.json
2023-09-02 12:16:26.818345: The split file contains 1 splits.
2023-09-02 12:16:26.819589: Desired fold for training: 0
2023-09-02 12:16:26.820784: This split has 1450 training and 798 validation cases.
2023-09-02 12:16:26.834621: predicting CVC-300_149
2023-09-02 12:16:27.651006: predicting CVC-300_150
2023-09-02 12:16:27.732773: predicting CVC-300_151
2023-09-02 12:16:27.811259: predicting CVC-300_152
2023-09-02 12:16:27.885354: predicting CVC-300_153
2023-09-02 12:16:27.960091: predicting CVC-300_154
2023-09-02 12:16:28.049176: predicting CVC-300_155
2023-09-02 12:16:28.136995: predicting CVC-300_156
2023-09-02 12:16:28.225158: predicting CVC-300_157
2023-09-02 12:16:28.313807: predicting CVC-300_158
2023-09-02 12:16:28.420338: predicting CVC-300_159
2023-09-02 12:16:28.506682: predicting CVC-300_160
2023-09-02 12:16:28.591743: predicting CVC-300_161
2023-09-02 12:16:28.677273: predicting CVC-300_162
2023-09-02 12:16:28.763985: predicting CVC-300_163
2023-09-02 12:16:28.847735: predicting CVC-300_164
2023-09-02 12:16:28.933530: predicting CVC-300_165
2023-09-02 12:16:29.037431: predicting CVC-300_166
2023-09-02 12:16:29.124591: predicting CVC-300_167
2023-09-02 12:16:29.209790: predicting CVC-300_168
2023-09-02 12:16:29.294119: predicting CVC-300_169
2023-09-02 12:16:29.381874: predicting CVC-300_170
2023-09-02 12:16:29.508145: predicting CVC-300_171
2023-09-02 12:16:29.605594: predicting CVC-300_172
2023-09-02 12:17:06.018488: predicting CVC-300_173
2023-09-02 12:17:06.094715: predicting CVC-300_174
2023-09-02 12:17:06.164455: predicting CVC-300_175
2023-09-02 12:17:06.233061: predicting CVC-300_176
2023-09-02 12:17:06.300130: predicting CVC-300_177
2023-09-02 12:17:06.366447: predicting CVC-300_178
2023-09-02 12:17:06.433449: predicting CVC-300_179
2023-09-02 12:17:06.501524: predicting CVC-300_180
2023-09-02 12:17:06.568358: predicting CVC-300_181
2023-09-02 12:17:06.648010: predicting CVC-300_182
2023-09-02 12:17:06.740190: predicting CVC-300_183
2023-09-02 12:17:06.807535: predicting CVC-300_184
2023-09-02 12:17:06.873202: predicting CVC-300_185
2023-09-02 12:17:06.940459: predicting CVC-300_186
2023-09-02 12:17:07.007294: predicting CVC-300_187
2023-09-02 12:17:07.072779: predicting CVC-300_188
2023-09-02 12:17:07.138859: predicting CVC-300_189
2023-09-02 12:17:07.206102: predicting CVC-300_190
2023-09-02 12:17:07.272475: predicting CVC-300_191
2023-09-02 12:17:07.339595: predicting CVC-300_192
2023-09-02 12:17:07.405502: predicting CVC-300_193
2023-09-02 12:17:07.471566: predicting CVC-300_194
2023-09-02 12:17:07.538059: predicting CVC-300_195
2023-09-02 12:17:07.604183: predicting CVC-300_196
2023-09-02 12:17:07.681379: predicting CVC-300_197
2023-09-02 12:17:07.748989: predicting CVC-300_198
2023-09-02 12:17:07.820096: predicting CVC-300_199
2023-09-02 12:17:07.887446: predicting CVC-300_200
2023-09-02 12:17:07.954507: predicting CVC-300_201
2023-09-02 12:17:08.021685: predicting CVC-300_202
2023-09-02 12:17:08.090725: predicting CVC-300_203
2023-09-02 12:17:08.157150: predicting CVC-300_204
2023-09-02 12:17:08.223302: predicting CVC-300_205
2023-09-02 12:17:08.288841: predicting CVC-300_206
2023-09-02 12:17:08.355346: predicting CVC-300_207
2023-09-02 12:17:08.421682: predicting CVC-300_208
2023-09-02 12:17:08.511879: predicting CVC-ClinicDB_100
2023-09-02 12:17:08.589433: predicting CVC-ClinicDB_106
2023-09-02 12:17:08.666618: predicting CVC-ClinicDB_119
2023-09-02 12:17:08.744203: predicting CVC-ClinicDB_134
2023-09-02 12:17:08.821390: predicting CVC-ClinicDB_14
2023-09-02 12:17:08.902249: predicting CVC-ClinicDB_148
2023-09-02 12:17:08.983529: predicting CVC-ClinicDB_154
2023-09-02 12:17:09.062892: predicting CVC-ClinicDB_163
2023-09-02 12:17:09.141198: predicting CVC-ClinicDB_166
2023-09-02 12:17:09.218483: predicting CVC-ClinicDB_171
2023-09-02 12:17:09.295911: predicting CVC-ClinicDB_179
2023-09-02 12:17:09.367955: predicting CVC-ClinicDB_181
2023-09-02 12:17:09.435245: predicting CVC-ClinicDB_185
2023-09-02 12:17:09.500780: predicting CVC-ClinicDB_191
2023-09-02 12:17:09.565879: predicting CVC-ClinicDB_205
2023-09-02 12:17:09.632575: predicting CVC-ClinicDB_21
2023-09-02 12:17:09.698955: predicting CVC-ClinicDB_240
2023-09-02 12:17:09.768272: predicting CVC-ClinicDB_25
2023-09-02 12:17:09.850601: predicting CVC-ClinicDB_251
2023-09-02 12:17:09.929164: predicting CVC-ClinicDB_266
2023-09-02 12:17:10.007316: predicting CVC-ClinicDB_279
2023-09-02 12:17:10.084447: predicting CVC-ClinicDB_287
2023-09-02 12:17:10.161673: predicting CVC-ClinicDB_300
2023-09-02 12:17:10.238714: predicting CVC-ClinicDB_307
2023-09-02 12:17:10.317152: predicting CVC-ClinicDB_31
2023-09-02 12:17:10.394385: predicting CVC-ClinicDB_349
2023-09-02 12:17:10.470777: predicting CVC-ClinicDB_353
2023-09-02 12:17:10.549697: predicting CVC-ClinicDB_374
2023-09-02 12:17:10.626799: predicting CVC-ClinicDB_381
2023-09-02 12:17:10.706347: predicting CVC-ClinicDB_388
2023-09-02 12:17:10.782954: predicting CVC-ClinicDB_397
2023-09-02 12:17:10.859829: predicting CVC-ClinicDB_400
2023-09-02 12:17:10.938385: predicting CVC-ClinicDB_404
2023-09-02 12:17:11.015504: predicting CVC-ClinicDB_42
2023-09-02 12:17:11.093411: predicting CVC-ClinicDB_425
2023-09-02 12:17:11.170749: predicting CVC-ClinicDB_429
2023-09-02 12:17:11.248610: predicting CVC-ClinicDB_431
2023-09-02 12:17:11.331018: predicting CVC-ClinicDB_442
2023-09-02 12:17:11.403526: predicting CVC-ClinicDB_453
2023-09-02 12:17:11.471563: predicting CVC-ClinicDB_459
2023-09-02 12:17:11.536936: predicting CVC-ClinicDB_464
2023-09-02 12:17:11.604251: predicting CVC-ClinicDB_474
2023-09-02 12:17:11.671231: predicting CVC-ClinicDB_481
2023-09-02 12:17:11.737963: predicting CVC-ClinicDB_483
2023-09-02 12:17:11.802726: predicting CVC-ClinicDB_492
2023-09-02 12:17:11.877916: predicting CVC-ClinicDB_50
2023-09-02 12:17:11.945331: predicting CVC-ClinicDB_52
2023-09-02 12:17:12.010421: predicting CVC-ClinicDB_526
2023-09-02 12:17:12.098638: predicting CVC-ClinicDB_529
2023-09-02 12:17:12.178743: predicting CVC-ClinicDB_545
2023-09-02 12:17:12.258811: predicting CVC-ClinicDB_555
2023-09-02 12:17:12.337548: predicting CVC-ClinicDB_559
2023-09-02 12:17:12.419391: predicting CVC-ClinicDB_561
2023-09-02 12:17:12.501260: predicting CVC-ClinicDB_569
2023-09-02 12:17:12.583688: predicting CVC-ClinicDB_571
2023-09-02 12:17:12.662788: predicting CVC-ClinicDB_575
2023-09-02 12:17:12.742353: predicting CVC-ClinicDB_61
2023-09-02 12:17:12.822517: predicting CVC-ClinicDB_65
2023-09-02 12:17:12.902019: predicting CVC-ClinicDB_66
2023-09-02 12:17:12.981591: predicting CVC-ClinicDB_73
2023-09-02 12:17:13.061301: predicting CVC-ClinicDB_80
2023-09-02 12:17:13.130164: predicting CVC-ClinicDB_89
2023-09-02 12:17:13.198638: predicting CVC-ColonDB_1
2023-09-02 12:17:13.267430: predicting CVC-ColonDB_10
2023-09-02 12:17:13.335276: predicting CVC-ColonDB_100
2023-09-02 12:17:13.403942: predicting CVC-ColonDB_101
2023-09-02 12:17:13.472821: predicting CVC-ColonDB_102
2023-09-02 12:17:13.545346: predicting CVC-ColonDB_103
2023-09-02 12:17:13.617362: predicting CVC-ColonDB_104
2023-09-02 12:17:13.689162: predicting CVC-ColonDB_105
2023-09-02 12:17:13.764622: predicting CVC-ColonDB_106
2023-09-02 12:17:13.835748: predicting CVC-ColonDB_107
2023-09-02 12:17:13.907912: predicting CVC-ColonDB_108
2023-09-02 12:17:13.979252: predicting CVC-ColonDB_109
2023-09-02 12:17:14.049438: predicting CVC-ColonDB_11
2023-09-02 12:17:14.118696: predicting CVC-ColonDB_110
2023-09-02 12:17:14.187455: predicting CVC-ColonDB_111
2023-09-02 12:17:14.256535: predicting CVC-ColonDB_112
2023-09-02 12:17:14.324970: predicting CVC-ColonDB_113
2023-09-02 12:17:14.392506: predicting CVC-ColonDB_114
2023-09-02 12:17:14.459994: predicting CVC-ColonDB_115
2023-09-02 12:17:14.527206: predicting CVC-ColonDB_116
2023-09-02 12:17:14.594138: predicting CVC-ColonDB_117
2023-09-02 12:17:14.662260: predicting CVC-ColonDB_118
2023-09-02 12:17:14.729000: predicting CVC-ColonDB_119
2023-09-02 12:17:14.795559: predicting CVC-ColonDB_12
2023-09-02 12:17:14.861957: predicting CVC-ColonDB_120
2023-09-02 12:17:14.930703: predicting CVC-ColonDB_121
2023-09-02 12:17:14.998095: predicting CVC-ColonDB_122
2023-09-02 12:17:15.087789: predicting CVC-ColonDB_123
2023-09-02 12:17:15.167484: predicting CVC-ColonDB_124
2023-09-02 12:17:15.247360: predicting CVC-ColonDB_125
2023-09-02 12:17:15.327979: predicting CVC-ColonDB_126
2023-09-02 12:17:15.408695: predicting CVC-ColonDB_127
2023-09-02 12:17:15.489983: predicting CVC-ColonDB_128
2023-09-02 12:17:15.572061: predicting CVC-ColonDB_129
2023-09-02 12:17:15.728902: predicting CVC-ColonDB_13
2023-09-02 12:17:15.813098: predicting CVC-ColonDB_130
2023-09-02 12:17:15.893688: predicting CVC-ColonDB_131
2023-09-02 12:17:15.975095: predicting CVC-ColonDB_132
2023-09-02 12:17:16.065344: predicting CVC-ColonDB_133
2023-09-02 12:17:16.144181: predicting CVC-ColonDB_134
2023-09-02 12:17:16.225735: predicting CVC-ColonDB_135
2023-09-02 12:17:16.304885: predicting CVC-ColonDB_136
2023-09-02 12:17:16.385794: predicting CVC-ColonDB_137
2023-09-02 12:17:16.464463: predicting CVC-ColonDB_138
2023-09-02 12:17:16.549896: predicting CVC-ColonDB_139
2023-09-02 12:17:16.633224: predicting CVC-ColonDB_14
2023-09-02 12:17:16.713449: predicting CVC-ColonDB_140
2023-09-02 12:17:16.794627: predicting CVC-ColonDB_141
2023-09-02 12:17:16.866950: predicting CVC-ColonDB_142
2023-09-02 12:17:16.934547: predicting CVC-ColonDB_143
2023-09-02 12:17:17.008992: predicting CVC-ColonDB_144
2023-09-02 12:17:17.082279: predicting CVC-ColonDB_145
2023-09-02 12:17:17.156006: predicting CVC-ColonDB_146
2023-09-02 12:17:17.229451: predicting CVC-ColonDB_147
2023-09-02 12:17:17.296352: predicting CVC-ColonDB_148
2023-09-02 12:17:17.362544: predicting CVC-ColonDB_149
2023-09-02 12:17:17.429838: predicting CVC-ColonDB_15
2023-09-02 12:17:17.496434: predicting CVC-ColonDB_150
2023-09-02 12:17:17.562519: predicting CVC-ColonDB_151
2023-09-02 12:17:17.628856: predicting CVC-ColonDB_152
2023-09-02 12:17:17.695703: predicting CVC-ColonDB_153
2023-09-02 12:17:17.762236: predicting CVC-ColonDB_154
2023-09-02 12:17:17.828449: predicting CVC-ColonDB_155
2023-09-02 12:17:17.893970: predicting CVC-ColonDB_156
2023-09-02 12:17:17.959212: predicting CVC-ColonDB_157
2023-09-02 12:17:18.037661: predicting CVC-ColonDB_158
2023-09-02 12:17:18.103662: predicting CVC-ColonDB_159
2023-09-02 12:17:18.169374: predicting CVC-ColonDB_16
2023-09-02 12:17:18.236287: predicting CVC-ColonDB_160
2023-09-02 12:17:18.302508: predicting CVC-ColonDB_161
2023-09-02 12:17:18.369593: predicting CVC-ColonDB_162
2023-09-02 12:17:18.435719: predicting CVC-ColonDB_163
2023-09-02 12:17:18.501558: predicting CVC-ColonDB_164
2023-09-02 12:17:18.568110: predicting CVC-ColonDB_165
2023-09-02 12:17:18.633538: predicting CVC-ColonDB_166
2023-09-02 12:17:18.699243: predicting CVC-ColonDB_167
2023-09-02 12:17:18.764388: predicting CVC-ColonDB_168
2023-09-02 12:17:18.830049: predicting CVC-ColonDB_169
2023-09-02 12:17:18.896484: predicting CVC-ColonDB_17
2023-09-02 12:17:18.974462: predicting CVC-ColonDB_170
2023-09-02 12:17:19.040253: predicting CVC-ColonDB_171
2023-09-02 12:17:19.106328: predicting CVC-ColonDB_172
2023-09-02 12:17:19.172511: predicting CVC-ColonDB_173
2023-09-02 12:17:19.238967: predicting CVC-ColonDB_174
2023-09-02 12:17:19.304921: predicting CVC-ColonDB_175
2023-09-02 12:17:19.370254: predicting CVC-ColonDB_176
2023-09-02 12:17:19.435782: predicting CVC-ColonDB_177
2023-09-02 12:17:19.501858: predicting CVC-ColonDB_178
2023-09-02 12:17:19.567726: predicting CVC-ColonDB_179
2023-09-02 12:17:19.633295: predicting CVC-ColonDB_18
2023-09-02 12:17:19.698862: predicting CVC-ColonDB_180
2023-09-02 12:17:19.763719: predicting CVC-ColonDB_181
2023-09-02 12:17:19.829571: predicting CVC-ColonDB_182
2023-09-02 12:17:19.913594: predicting CVC-ColonDB_183
2023-09-02 12:17:19.991971: predicting CVC-ColonDB_184
2023-09-02 12:17:20.069082: predicting CVC-ColonDB_185
2023-09-02 12:17:20.142815: predicting CVC-ColonDB_186
2023-09-02 12:17:20.208875: predicting CVC-ColonDB_187
2023-09-02 12:17:20.289570: predicting CVC-ColonDB_188
2023-09-02 12:17:20.355782: predicting CVC-ColonDB_189
2023-09-02 12:17:20.422375: predicting CVC-ColonDB_19
2023-09-02 12:17:20.488895: predicting CVC-ColonDB_190
2023-09-02 12:17:20.563798: predicting CVC-ColonDB_191
2023-09-02 12:17:20.635134: predicting CVC-ColonDB_192
2023-09-02 12:17:20.701688: predicting CVC-ColonDB_193
2023-09-02 12:17:20.769812: predicting CVC-ColonDB_194
2023-09-02 12:17:20.837736: predicting CVC-ColonDB_195
2023-09-02 12:17:20.904381: predicting CVC-ColonDB_196
2023-09-02 12:17:20.970531: predicting CVC-ColonDB_197
2023-09-02 12:17:21.036537: predicting CVC-ColonDB_198
2023-09-02 12:17:21.102877: predicting CVC-ColonDB_199
2023-09-02 12:17:21.169419: predicting CVC-ColonDB_2
2023-09-02 12:17:21.235408: predicting CVC-ColonDB_20
2023-09-02 12:17:21.301476: predicting CVC-ColonDB_200
2023-09-02 12:17:21.367127: predicting CVC-ColonDB_201
2023-09-02 12:17:21.432843: predicting CVC-ColonDB_202
2023-09-02 12:17:21.498008: predicting CVC-ColonDB_203
2023-09-02 12:17:21.564194: predicting CVC-ColonDB_204
2023-09-02 12:17:21.630479: predicting CVC-ColonDB_205
2023-09-02 12:17:21.698599: predicting CVC-ColonDB_206
2023-09-02 12:17:21.765059: predicting CVC-ColonDB_207
2023-09-02 12:17:21.830578: predicting CVC-ColonDB_208
2023-09-02 12:17:21.896703: predicting CVC-ColonDB_209
2023-09-02 12:17:21.963167: predicting CVC-ColonDB_21
2023-09-02 12:17:22.028862: predicting CVC-ColonDB_210
2023-09-02 12:17:22.102393: predicting CVC-ColonDB_211
2023-09-02 12:17:22.167678: predicting CVC-ColonDB_212
2023-09-02 12:17:22.233691: predicting CVC-ColonDB_213
2023-09-02 12:17:22.299719: predicting CVC-ColonDB_214
2023-09-02 12:17:22.365634: predicting CVC-ColonDB_215
2023-09-02 12:17:22.431641: predicting CVC-ColonDB_216
2023-09-02 12:17:22.497576: predicting CVC-ColonDB_217
2023-09-02 12:17:22.563214: predicting CVC-ColonDB_218
2023-09-02 12:17:22.629184: predicting CVC-ColonDB_219
2023-09-02 12:17:22.695436: predicting CVC-ColonDB_22
2023-09-02 12:17:22.762478: predicting CVC-ColonDB_220
2023-09-02 12:17:22.828951: predicting CVC-ColonDB_221
2023-09-02 12:17:22.895677: predicting CVC-ColonDB_222
2023-09-02 12:17:22.962379: predicting CVC-ColonDB_223
2023-09-02 12:17:23.028414: predicting CVC-ColonDB_224
2023-09-02 12:17:23.094487: predicting CVC-ColonDB_225
2023-09-02 12:17:23.160120: predicting CVC-ColonDB_226
2023-09-02 12:17:23.225914: predicting CVC-ColonDB_227
2023-09-02 12:17:23.292268: predicting CVC-ColonDB_228
2023-09-02 12:17:23.358371: predicting CVC-ColonDB_229
2023-09-02 12:17:23.424895: predicting CVC-ColonDB_23
2023-09-02 12:17:23.490726: predicting CVC-ColonDB_230
2023-09-02 12:17:23.556514: predicting CVC-ColonDB_231
2023-09-02 12:17:23.622820: predicting CVC-ColonDB_232
2023-09-02 12:17:23.687793: predicting CVC-ColonDB_233
2023-09-02 12:17:23.753635: predicting CVC-ColonDB_234
2023-09-02 12:17:23.819534: predicting CVC-ColonDB_235
2023-09-02 12:17:23.885400: predicting CVC-ColonDB_236
2023-09-02 12:17:23.950522: predicting CVC-ColonDB_237
2023-09-02 12:17:24.016324: predicting CVC-ColonDB_238
2023-09-02 12:17:24.084320: predicting CVC-ColonDB_239
2023-09-02 12:17:24.175841: predicting CVC-ColonDB_24
2023-09-02 12:17:24.241701: predicting CVC-ColonDB_240
2023-09-02 12:17:24.308500: predicting CVC-ColonDB_241
2023-09-02 12:17:24.381684: predicting CVC-ColonDB_242
2023-09-02 12:17:24.447966: predicting CVC-ColonDB_243
2023-09-02 12:17:24.514036: predicting CVC-ColonDB_244
2023-09-02 12:17:24.580852: predicting CVC-ColonDB_245
2023-09-02 12:17:24.646236: predicting CVC-ColonDB_246
2023-09-02 12:17:24.720961: predicting CVC-ColonDB_247
2023-09-02 12:17:24.787589: predicting CVC-ColonDB_248
2023-09-02 12:17:24.854063: predicting CVC-ColonDB_249
2023-09-02 12:17:24.919688: predicting CVC-ColonDB_25
2023-09-02 12:17:24.986225: predicting CVC-ColonDB_250
2023-09-02 12:17:25.051827: predicting CVC-ColonDB_251
2023-09-02 12:17:25.117641: predicting CVC-ColonDB_252
2023-09-02 12:17:25.183523: predicting CVC-ColonDB_253
2023-09-02 12:17:25.249958: predicting CVC-ColonDB_254
2023-09-02 12:17:25.316364: predicting CVC-ColonDB_255
2023-09-02 12:17:25.382662: predicting CVC-ColonDB_256
2023-09-02 12:17:25.454511: predicting CVC-ColonDB_257
2023-09-02 12:17:25.520528: predicting CVC-ColonDB_258
2023-09-02 12:17:25.586365: predicting CVC-ColonDB_259
2023-09-02 12:17:25.652525: predicting CVC-ColonDB_26
2023-09-02 12:17:25.717928: predicting CVC-ColonDB_260
2023-09-02 12:17:25.782932: predicting CVC-ColonDB_261
2023-09-02 12:17:25.848182: predicting CVC-ColonDB_262
2023-09-02 12:17:25.913660: predicting CVC-ColonDB_263
2023-09-02 12:17:25.978256: predicting CVC-ColonDB_264
2023-09-02 12:17:26.043626: predicting CVC-ColonDB_265
2023-09-02 12:17:26.108997: predicting CVC-ColonDB_266
2023-09-02 12:17:26.176435: predicting CVC-ColonDB_267
2023-09-02 12:17:26.241784: predicting CVC-ColonDB_268
2023-09-02 12:17:26.307858: predicting CVC-ColonDB_269
2023-09-02 12:17:26.379172: predicting CVC-ColonDB_27
2023-09-02 12:17:26.453937: predicting CVC-ColonDB_270
2023-09-02 12:17:26.519242: predicting CVC-ColonDB_271
2023-09-02 12:17:26.598614: predicting CVC-ColonDB_272
2023-09-02 12:17:26.679340: predicting CVC-ColonDB_273
2023-09-02 12:17:26.746845: predicting CVC-ColonDB_274
2023-09-02 12:17:26.812896: predicting CVC-ColonDB_275
2023-09-02 12:17:26.879119: predicting CVC-ColonDB_276
2023-09-02 12:17:26.945790: predicting CVC-ColonDB_277
2023-09-02 12:17:27.011907: predicting CVC-ColonDB_278
2023-09-02 12:17:27.078096: predicting CVC-ColonDB_279
2023-09-02 12:17:27.145244: predicting CVC-ColonDB_28
2023-09-02 12:17:27.223846: predicting CVC-ColonDB_280
2023-09-02 12:17:27.291132: predicting CVC-ColonDB_281
2023-09-02 12:17:27.359372: predicting CVC-ColonDB_282
2023-09-02 12:17:27.427583: predicting CVC-ColonDB_283
2023-09-02 12:17:27.512385: predicting CVC-ColonDB_284
2023-09-02 12:17:27.579378: predicting CVC-ColonDB_285
2023-09-02 12:17:27.646047: predicting CVC-ColonDB_286
2023-09-02 12:17:27.712092: predicting CVC-ColonDB_287
2023-09-02 12:17:27.777799: predicting CVC-ColonDB_288
2023-09-02 12:17:27.844052: predicting CVC-ColonDB_289
2023-09-02 12:17:27.909339: predicting CVC-ColonDB_29
2023-09-02 12:17:27.994015: predicting CVC-ColonDB_290
2023-09-02 12:17:28.072374: predicting CVC-ColonDB_291
2023-09-02 12:17:28.149728: predicting CVC-ColonDB_292
2023-09-02 12:17:28.252544: predicting CVC-ColonDB_293
2023-09-02 12:17:28.330175: predicting CVC-ColonDB_294
2023-09-02 12:17:28.408087: predicting CVC-ColonDB_295
2023-09-02 12:17:28.484346: predicting CVC-ColonDB_296
2023-09-02 12:17:28.561623: predicting CVC-ColonDB_297
2023-09-02 12:17:28.638727: predicting CVC-ColonDB_298
2023-09-02 12:17:28.715995: predicting CVC-ColonDB_299
2023-09-02 12:17:28.794038: predicting CVC-ColonDB_3
2023-09-02 12:17:28.870858: predicting CVC-ColonDB_30
2023-09-02 12:17:28.949297: predicting CVC-ColonDB_300
2023-09-02 12:17:29.028145: predicting CVC-ColonDB_301
2023-09-02 12:17:29.108517: predicting CVC-ColonDB_302
2023-09-02 12:17:29.180185: predicting CVC-ColonDB_303
2023-09-02 12:17:29.246423: predicting CVC-ColonDB_304
2023-09-02 12:17:29.312324: predicting CVC-ColonDB_305
2023-09-02 12:17:29.376449: predicting CVC-ColonDB_306
2023-09-02 12:17:29.443002: predicting CVC-ColonDB_307
2023-09-02 12:17:29.509068: predicting CVC-ColonDB_308
2023-09-02 12:17:29.574929: predicting CVC-ColonDB_309
2023-09-02 12:17:29.644634: predicting CVC-ColonDB_31
2023-09-02 12:17:29.710324: predicting CVC-ColonDB_310
2023-09-02 12:17:29.774244: predicting CVC-ColonDB_311
2023-09-02 12:17:29.839143: predicting CVC-ColonDB_312
2023-09-02 12:17:29.903748: predicting CVC-ColonDB_313
2023-09-02 12:17:29.968355: predicting CVC-ColonDB_314
2023-09-02 12:17:30.036077: predicting CVC-ColonDB_315
2023-09-02 12:17:30.104212: predicting CVC-ColonDB_316
2023-09-02 12:17:30.169922: predicting CVC-ColonDB_317
2023-09-02 12:17:30.236112: predicting CVC-ColonDB_318
2023-09-02 12:17:30.302399: predicting CVC-ColonDB_319
2023-09-02 12:17:30.381082: predicting CVC-ColonDB_32
2023-09-02 12:17:30.459971: predicting CVC-ColonDB_320
2023-09-02 12:17:30.526115: predicting CVC-ColonDB_321
2023-09-02 12:17:30.592045: predicting CVC-ColonDB_322
2023-09-02 12:17:30.672224: predicting CVC-ColonDB_323
2023-09-02 12:17:30.745128: predicting CVC-ColonDB_324
2023-09-02 12:17:30.811557: predicting CVC-ColonDB_325
2023-09-02 12:17:30.877742: predicting CVC-ColonDB_326
2023-09-02 12:17:30.969250: predicting CVC-ColonDB_327
2023-09-02 12:17:31.047549: predicting CVC-ColonDB_328
2023-09-02 12:17:31.125570: predicting CVC-ColonDB_329
2023-09-02 12:17:31.204130: predicting CVC-ColonDB_33
2023-09-02 12:17:31.281894: predicting CVC-ColonDB_330
2023-09-02 12:17:31.362053: predicting CVC-ColonDB_331
2023-09-02 12:17:31.435792: predicting CVC-ColonDB_332
2023-09-02 12:17:31.503269: predicting CVC-ColonDB_333
2023-09-02 12:17:31.577631: predicting CVC-ColonDB_334
2023-09-02 12:17:31.644289: predicting CVC-ColonDB_335
2023-09-02 12:17:31.710973: predicting CVC-ColonDB_336
2023-09-02 12:17:31.785922: predicting CVC-ColonDB_337
2023-09-02 12:17:31.853579: predicting CVC-ColonDB_338
2023-09-02 12:17:31.919064: predicting CVC-ColonDB_339
2023-09-02 12:17:31.984842: predicting CVC-ColonDB_34
2023-09-02 12:17:32.050765: predicting CVC-ColonDB_340
2023-09-02 12:17:32.124711: predicting CVC-ColonDB_341
2023-09-02 12:17:32.190886: predicting CVC-ColonDB_342
2023-09-02 12:17:32.281932: predicting CVC-ColonDB_343
2023-09-02 12:17:32.349347: predicting CVC-ColonDB_344
2023-09-02 12:17:32.415502: predicting CVC-ColonDB_345
2023-09-02 12:17:32.481745: predicting CVC-ColonDB_346
2023-09-02 12:17:32.548617: predicting CVC-ColonDB_347
2023-09-02 12:17:32.613994: predicting CVC-ColonDB_348
2023-09-02 12:17:32.680370: predicting CVC-ColonDB_349
2023-09-02 12:17:32.746118: predicting CVC-ColonDB_35
2023-09-02 12:17:32.812154: predicting CVC-ColonDB_350
2023-09-02 12:17:32.878369: predicting CVC-ColonDB_351
2023-09-02 12:17:32.944801: predicting CVC-ColonDB_352
2023-09-02 12:17:33.010525: predicting CVC-ColonDB_353
2023-09-02 12:17:33.078975: predicting CVC-ColonDB_354
2023-09-02 12:17:33.145994: predicting CVC-ColonDB_355
2023-09-02 12:17:33.213221: predicting CVC-ColonDB_356
2023-09-02 12:17:33.279991: predicting CVC-ColonDB_357
2023-09-02 12:17:33.348166: predicting CVC-ColonDB_358
2023-09-02 12:17:33.415206: predicting CVC-ColonDB_359
2023-09-02 12:17:33.480832: predicting CVC-ColonDB_36
2023-09-02 12:17:33.547078: predicting CVC-ColonDB_360
2023-09-02 12:17:33.614281: predicting CVC-ColonDB_361
2023-09-02 12:17:33.679897: predicting CVC-ColonDB_362
2023-09-02 12:17:33.744714: predicting CVC-ColonDB_363
2023-09-02 12:17:33.810385: predicting CVC-ColonDB_364
2023-09-02 12:17:33.876188: predicting CVC-ColonDB_365
2023-09-02 12:17:33.941573: predicting CVC-ColonDB_366
2023-09-02 12:17:34.007489: predicting CVC-ColonDB_367
2023-09-02 12:17:34.083204: predicting CVC-ColonDB_368
2023-09-02 12:17:34.149674: predicting CVC-ColonDB_369
2023-09-02 12:17:34.215411: predicting CVC-ColonDB_37
2023-09-02 12:17:34.281260: predicting CVC-ColonDB_370
2023-09-02 12:17:34.348887: predicting CVC-ColonDB_371
2023-09-02 12:17:34.416349: predicting CVC-ColonDB_372
2023-09-02 12:17:34.485380: predicting CVC-ColonDB_373
2023-09-02 12:17:34.550944: predicting CVC-ColonDB_374
2023-09-02 12:17:34.615738: predicting CVC-ColonDB_375
2023-09-02 12:17:34.680734: predicting CVC-ColonDB_376
2023-09-02 12:17:34.745755: predicting CVC-ColonDB_377
2023-09-02 12:17:34.811348: predicting CVC-ColonDB_378
2023-09-02 12:17:34.876408: predicting CVC-ColonDB_379
2023-09-02 12:17:34.941698: predicting CVC-ColonDB_38
2023-09-02 12:17:35.007587: predicting CVC-ColonDB_380
2023-09-02 12:17:35.075954: predicting CVC-ColonDB_39
2023-09-02 12:17:35.141127: predicting CVC-ColonDB_4
2023-09-02 12:17:35.207872: predicting CVC-ColonDB_40
2023-09-02 12:17:35.273745: predicting CVC-ColonDB_41
2023-09-02 12:17:35.339591: predicting CVC-ColonDB_42
2023-09-02 12:17:35.406832: predicting CVC-ColonDB_43
2023-09-02 12:17:35.473640: predicting CVC-ColonDB_44
2023-09-02 12:17:35.539365: predicting CVC-ColonDB_45
2023-09-02 12:17:35.606084: predicting CVC-ColonDB_46
2023-09-02 12:17:35.671885: predicting CVC-ColonDB_47
2023-09-02 12:17:35.738292: predicting CVC-ColonDB_48
2023-09-02 12:17:35.803883: predicting CVC-ColonDB_49
2023-09-02 12:17:35.868954: predicting CVC-ColonDB_5
2023-09-02 12:17:35.935742: predicting CVC-ColonDB_50
2023-09-02 12:17:36.004135: predicting CVC-ColonDB_51
2023-09-02 12:17:36.070497: predicting CVC-ColonDB_52
2023-09-02 12:17:36.138082: predicting CVC-ColonDB_53
2023-09-02 12:17:36.205498: predicting CVC-ColonDB_54
2023-09-02 12:17:36.272396: predicting CVC-ColonDB_55
2023-09-02 12:17:36.338383: predicting CVC-ColonDB_56
2023-09-02 12:17:36.406458: predicting CVC-ColonDB_57
2023-09-02 12:17:36.504690: predicting CVC-ColonDB_58
2023-09-02 12:17:36.571043: predicting CVC-ColonDB_59
2023-09-02 12:17:36.639131: predicting CVC-ColonDB_6
2023-09-02 12:17:36.705531: predicting CVC-ColonDB_60
2023-09-02 12:17:36.771592: predicting CVC-ColonDB_61
2023-09-02 12:17:36.837703: predicting CVC-ColonDB_62
2023-09-02 12:17:36.903942: predicting CVC-ColonDB_63
2023-09-02 12:17:36.980725: predicting CVC-ColonDB_64
2023-09-02 12:17:37.048537: predicting CVC-ColonDB_65
2023-09-02 12:17:37.113815: predicting CVC-ColonDB_66
2023-09-02 12:17:37.187577: predicting CVC-ColonDB_67
2023-09-02 12:17:37.252992: predicting CVC-ColonDB_68
2023-09-02 12:17:37.317987: predicting CVC-ColonDB_69
2023-09-02 12:17:37.381906: predicting CVC-ColonDB_7
2023-09-02 12:17:37.448600: predicting CVC-ColonDB_70
2023-09-02 12:17:37.513978: predicting CVC-ColonDB_71
2023-09-02 12:17:37.580954: predicting CVC-ColonDB_72
2023-09-02 12:17:37.646545: predicting CVC-ColonDB_73
2023-09-02 12:17:37.711299: predicting CVC-ColonDB_74
2023-09-02 12:17:37.776567: predicting CVC-ColonDB_75
2023-09-02 12:17:37.841546: predicting CVC-ColonDB_76
2023-09-02 12:17:37.907529: predicting CVC-ColonDB_77
2023-09-02 12:17:37.972446: predicting CVC-ColonDB_78
2023-09-02 12:17:38.037960: predicting CVC-ColonDB_79
2023-09-02 12:17:38.103054: predicting CVC-ColonDB_8
2023-09-02 12:17:38.168007: predicting CVC-ColonDB_80
2023-09-02 12:17:38.242657: predicting CVC-ColonDB_81
2023-09-02 12:17:38.308289: predicting CVC-ColonDB_82
2023-09-02 12:17:38.375018: predicting CVC-ColonDB_83
2023-09-02 12:17:38.441089: predicting CVC-ColonDB_84
2023-09-02 12:17:38.536057: predicting CVC-ColonDB_85
2023-09-02 12:17:38.601440: predicting CVC-ColonDB_86
2023-09-02 12:17:38.666411: predicting CVC-ColonDB_87
2023-09-02 12:17:38.731151: predicting CVC-ColonDB_88
2023-09-02 12:17:38.796081: predicting CVC-ColonDB_89
2023-09-02 12:17:38.860147: predicting CVC-ColonDB_9
2023-09-02 12:17:38.924192: predicting CVC-ColonDB_90
2023-09-02 12:17:38.989746: predicting CVC-ColonDB_91
2023-09-02 12:17:39.054549: predicting CVC-ColonDB_92
2023-09-02 12:17:39.119502: predicting CVC-ColonDB_93
2023-09-02 12:17:39.184906: predicting CVC-ColonDB_94
2023-09-02 12:17:39.249678: predicting CVC-ColonDB_95
2023-09-02 12:17:39.314205: predicting CVC-ColonDB_96
2023-09-02 12:17:39.378782: predicting CVC-ColonDB_97
2023-09-02 12:17:39.444857: predicting CVC-ColonDB_98
2023-09-02 12:17:39.510172: predicting CVC-ColonDB_99
2023-09-02 12:17:39.574571: predicting ETIS-LaribPolypDB_1
2023-09-02 12:17:39.658751: predicting ETIS-LaribPolypDB_10
2023-09-02 12:17:39.737360: predicting ETIS-LaribPolypDB_100
2023-09-02 12:17:39.814684: predicting ETIS-LaribPolypDB_101
2023-09-02 12:17:39.891612: predicting ETIS-LaribPolypDB_102
2023-09-02 12:17:39.969204: predicting ETIS-LaribPolypDB_103
2023-09-02 12:17:40.047817: predicting ETIS-LaribPolypDB_104
2023-09-02 12:17:40.125490: predicting ETIS-LaribPolypDB_105
2023-09-02 12:17:40.202854: predicting ETIS-LaribPolypDB_106
2023-09-02 12:17:40.276081: predicting ETIS-LaribPolypDB_107
2023-09-02 12:17:40.342374: predicting ETIS-LaribPolypDB_108
2023-09-02 12:17:40.408936: predicting ETIS-LaribPolypDB_109
2023-09-02 12:17:40.475364: predicting ETIS-LaribPolypDB_11
2023-09-02 12:17:40.567918: predicting ETIS-LaribPolypDB_110
2023-09-02 12:17:40.633687: predicting ETIS-LaribPolypDB_111
2023-09-02 12:17:40.701317: predicting ETIS-LaribPolypDB_112
2023-09-02 12:17:40.767064: predicting ETIS-LaribPolypDB_113
2023-09-02 12:17:40.833162: predicting ETIS-LaribPolypDB_114
2023-09-02 12:17:40.899850: predicting ETIS-LaribPolypDB_115
2023-09-02 12:17:40.965555: predicting ETIS-LaribPolypDB_116
2023-09-02 12:17:41.031402: predicting ETIS-LaribPolypDB_117
2023-09-02 12:17:41.096007: predicting ETIS-LaribPolypDB_118
2023-09-02 12:17:41.162127: predicting ETIS-LaribPolypDB_119
2023-09-02 12:17:41.227775: predicting ETIS-LaribPolypDB_12
2023-09-02 12:17:41.293405: predicting ETIS-LaribPolypDB_120
2023-09-02 12:17:41.358531: predicting ETIS-LaribPolypDB_121
2023-09-02 12:17:41.424176: predicting ETIS-LaribPolypDB_122
2023-09-02 12:17:41.489332: predicting ETIS-LaribPolypDB_123
2023-09-02 12:17:41.554654: predicting ETIS-LaribPolypDB_124
2023-09-02 12:17:41.619115: predicting ETIS-LaribPolypDB_125
2023-09-02 12:17:41.684775: predicting ETIS-LaribPolypDB_126
2023-09-02 12:17:41.751191: predicting ETIS-LaribPolypDB_127
2023-09-02 12:17:41.816895: predicting ETIS-LaribPolypDB_128
2023-09-02 12:17:41.883444: predicting ETIS-LaribPolypDB_129
2023-09-02 12:17:41.955547: predicting ETIS-LaribPolypDB_13
2023-09-02 12:17:42.035577: predicting ETIS-LaribPolypDB_130
2023-09-02 12:17:42.112942: predicting ETIS-LaribPolypDB_131
2023-09-02 12:17:42.190760: predicting ETIS-LaribPolypDB_132
2023-09-02 12:17:42.271293: predicting ETIS-LaribPolypDB_133
2023-09-02 12:17:42.337640: predicting ETIS-LaribPolypDB_134
2023-09-02 12:17:42.404505: predicting ETIS-LaribPolypDB_135
2023-09-02 12:17:42.470659: predicting ETIS-LaribPolypDB_136
2023-09-02 12:17:42.541548: predicting ETIS-LaribPolypDB_137
2023-09-02 12:17:42.608405: predicting ETIS-LaribPolypDB_138
2023-09-02 12:17:42.674361: predicting ETIS-LaribPolypDB_139
2023-09-02 12:17:42.740293: predicting ETIS-LaribPolypDB_14
2023-09-02 12:17:42.805727: predicting ETIS-LaribPolypDB_140
2023-09-02 12:17:42.870792: predicting ETIS-LaribPolypDB_141
2023-09-02 12:17:42.938004: predicting ETIS-LaribPolypDB_142
2023-09-02 12:17:43.004934: predicting ETIS-LaribPolypDB_143
2023-09-02 12:17:43.072140: predicting ETIS-LaribPolypDB_144
2023-09-02 12:17:43.140325: predicting ETIS-LaribPolypDB_145
2023-09-02 12:17:43.206369: predicting ETIS-LaribPolypDB_146
2023-09-02 12:17:43.272921: predicting ETIS-LaribPolypDB_147
2023-09-02 12:17:43.338703: predicting ETIS-LaribPolypDB_148
2023-09-02 12:17:43.405045: predicting ETIS-LaribPolypDB_149
2023-09-02 12:17:43.469707: predicting ETIS-LaribPolypDB_15
2023-09-02 12:17:43.536241: predicting ETIS-LaribPolypDB_150
2023-09-02 12:17:43.602064: predicting ETIS-LaribPolypDB_151
2023-09-02 12:17:43.668623: predicting ETIS-LaribPolypDB_152
2023-09-02 12:17:43.734753: predicting ETIS-LaribPolypDB_153
2023-09-02 12:17:43.800343: predicting ETIS-LaribPolypDB_154
2023-09-02 12:17:43.866487: predicting ETIS-LaribPolypDB_155
2023-09-02 12:17:43.932344: predicting ETIS-LaribPolypDB_156
2023-09-02 12:17:43.998492: predicting ETIS-LaribPolypDB_157
2023-09-02 12:17:44.063843: predicting ETIS-LaribPolypDB_158
2023-09-02 12:17:44.129854: predicting ETIS-LaribPolypDB_159
2023-09-02 12:17:44.196264: predicting ETIS-LaribPolypDB_16
2023-09-02 12:17:44.261809: predicting ETIS-LaribPolypDB_160
2023-09-02 12:17:44.326742: predicting ETIS-LaribPolypDB_161
2023-09-02 12:17:44.392575: predicting ETIS-LaribPolypDB_162
2023-09-02 12:17:44.459885: predicting ETIS-LaribPolypDB_163
2023-09-02 12:17:44.525799: predicting ETIS-LaribPolypDB_164
2023-09-02 12:17:44.592039: predicting ETIS-LaribPolypDB_165
2023-09-02 12:17:44.680922: predicting ETIS-LaribPolypDB_166
2023-09-02 12:17:44.747758: predicting ETIS-LaribPolypDB_167
2023-09-02 12:17:44.813566: predicting ETIS-LaribPolypDB_168
2023-09-02 12:17:44.879505: predicting ETIS-LaribPolypDB_169
2023-09-02 12:17:44.945087: predicting ETIS-LaribPolypDB_17
2023-09-02 12:17:45.013006: predicting ETIS-LaribPolypDB_170
2023-09-02 12:17:45.078197: predicting ETIS-LaribPolypDB_171
2023-09-02 12:17:45.143691: predicting ETIS-LaribPolypDB_172
2023-09-02 12:17:45.210075: predicting ETIS-LaribPolypDB_173
2023-09-02 12:17:45.276840: predicting ETIS-LaribPolypDB_174
2023-09-02 12:17:45.342979: predicting ETIS-LaribPolypDB_175
2023-09-02 12:17:45.409482: predicting ETIS-LaribPolypDB_176
2023-09-02 12:17:45.474779: predicting ETIS-LaribPolypDB_177
2023-09-02 12:17:45.542877: predicting ETIS-LaribPolypDB_178
2023-09-02 12:17:45.607876: predicting ETIS-LaribPolypDB_179
2023-09-02 12:17:45.675151: predicting ETIS-LaribPolypDB_18
2023-09-02 12:17:45.740520: predicting ETIS-LaribPolypDB_180
2023-09-02 12:17:45.808702: predicting ETIS-LaribPolypDB_181
2023-09-02 12:17:45.873616: predicting ETIS-LaribPolypDB_182
2023-09-02 12:17:45.940609: predicting ETIS-LaribPolypDB_183
2023-09-02 12:17:46.006117: predicting ETIS-LaribPolypDB_184
2023-09-02 12:17:46.074482: predicting ETIS-LaribPolypDB_185
2023-09-02 12:17:46.144269: predicting ETIS-LaribPolypDB_186
2023-09-02 12:17:46.210704: predicting ETIS-LaribPolypDB_187
2023-09-02 12:17:46.278829: predicting ETIS-LaribPolypDB_188
2023-09-02 12:17:46.345756: predicting ETIS-LaribPolypDB_189
2023-09-02 12:17:46.413693: predicting ETIS-LaribPolypDB_19
2023-09-02 12:17:46.481356: predicting ETIS-LaribPolypDB_190
2023-09-02 12:17:46.548961: predicting ETIS-LaribPolypDB_191
2023-09-02 12:17:46.615984: predicting ETIS-LaribPolypDB_192
2023-09-02 12:17:46.689795: predicting ETIS-LaribPolypDB_193
2023-09-02 12:17:46.756607: predicting ETIS-LaribPolypDB_194
2023-09-02 12:17:46.821796: predicting ETIS-LaribPolypDB_195
2023-09-02 12:17:46.889430: predicting ETIS-LaribPolypDB_196
2023-09-02 12:17:46.955120: predicting ETIS-LaribPolypDB_2
2023-09-02 12:17:47.021433: predicting ETIS-LaribPolypDB_20
2023-09-02 12:17:47.087366: predicting ETIS-LaribPolypDB_21
2023-09-02 12:17:47.155901: predicting ETIS-LaribPolypDB_22
2023-09-02 12:17:47.230482: predicting ETIS-LaribPolypDB_23
2023-09-02 12:17:47.311065: predicting ETIS-LaribPolypDB_24
2023-09-02 12:17:47.389066: predicting ETIS-LaribPolypDB_25
2023-09-02 12:17:47.467002: predicting ETIS-LaribPolypDB_26
2023-09-02 12:17:47.544349: predicting ETIS-LaribPolypDB_27
2023-09-02 12:17:47.622519: predicting ETIS-LaribPolypDB_28
2023-09-02 12:17:47.701164: predicting ETIS-LaribPolypDB_29
2023-09-02 12:17:47.772795: predicting ETIS-LaribPolypDB_3
2023-09-02 12:17:47.839180: predicting ETIS-LaribPolypDB_30
2023-09-02 12:17:47.906282: predicting ETIS-LaribPolypDB_31
2023-09-02 12:17:47.971680: predicting ETIS-LaribPolypDB_32
2023-09-02 12:17:48.042010: predicting ETIS-LaribPolypDB_33
2023-09-02 12:17:48.116338: predicting ETIS-LaribPolypDB_34
2023-09-02 12:17:48.188572: predicting ETIS-LaribPolypDB_35
2023-09-02 12:17:48.254354: predicting ETIS-LaribPolypDB_36
2023-09-02 12:17:48.320021: predicting ETIS-LaribPolypDB_37
2023-09-02 12:17:48.385629: predicting ETIS-LaribPolypDB_38
2023-09-02 12:17:48.451714: predicting ETIS-LaribPolypDB_39
2023-09-02 12:17:48.520291: predicting ETIS-LaribPolypDB_4
2023-09-02 12:17:48.586472: predicting ETIS-LaribPolypDB_40
2023-09-02 12:17:48.653876: predicting ETIS-LaribPolypDB_41
2023-09-02 12:17:48.741012: predicting ETIS-LaribPolypDB_42
2023-09-02 12:17:48.806622: predicting ETIS-LaribPolypDB_43
2023-09-02 12:17:48.875308: predicting ETIS-LaribPolypDB_44
2023-09-02 12:17:48.941236: predicting ETIS-LaribPolypDB_45
2023-09-02 12:17:49.007631: predicting ETIS-LaribPolypDB_46
2023-09-02 12:17:49.073393: predicting ETIS-LaribPolypDB_47
2023-09-02 12:17:49.138180: predicting ETIS-LaribPolypDB_48
2023-09-02 12:17:49.204180: predicting ETIS-LaribPolypDB_49
2023-09-02 12:17:49.268540: predicting ETIS-LaribPolypDB_5
2023-09-02 12:17:49.335176: predicting ETIS-LaribPolypDB_50
2023-09-02 12:17:49.401144: predicting ETIS-LaribPolypDB_51
2023-09-02 12:17:49.465446: predicting ETIS-LaribPolypDB_52
2023-09-02 12:17:49.531185: predicting ETIS-LaribPolypDB_53
2023-09-02 12:17:49.597729: predicting ETIS-LaribPolypDB_54
2023-09-02 12:17:49.663372: predicting ETIS-LaribPolypDB_55
2023-09-02 12:17:49.728019: predicting ETIS-LaribPolypDB_56
2023-09-02 12:17:49.793265: predicting ETIS-LaribPolypDB_57
2023-09-02 12:17:49.858308: predicting ETIS-LaribPolypDB_58
2023-09-02 12:17:49.923609: predicting ETIS-LaribPolypDB_59
2023-09-02 12:17:49.989827: predicting ETIS-LaribPolypDB_6
2023-09-02 12:17:50.054733: predicting ETIS-LaribPolypDB_60
2023-09-02 12:17:50.119073: predicting ETIS-LaribPolypDB_61
2023-09-02 12:17:50.185563: predicting ETIS-LaribPolypDB_62
2023-09-02 12:17:50.250304: predicting ETIS-LaribPolypDB_63
2023-09-02 12:17:50.316912: predicting ETIS-LaribPolypDB_64
2023-09-02 12:17:50.383030: predicting ETIS-LaribPolypDB_65
2023-09-02 12:17:50.448266: predicting ETIS-LaribPolypDB_66
2023-09-02 12:17:50.513725: predicting ETIS-LaribPolypDB_67
2023-09-02 12:17:50.580384: predicting ETIS-LaribPolypDB_68
2023-09-02 12:17:50.648143: predicting ETIS-LaribPolypDB_69
2023-09-02 12:17:50.739527: predicting ETIS-LaribPolypDB_7
2023-09-02 12:17:50.805276: predicting ETIS-LaribPolypDB_70
2023-09-02 12:17:50.869926: predicting ETIS-LaribPolypDB_71
2023-09-02 12:17:50.934876: predicting ETIS-LaribPolypDB_72
2023-09-02 12:17:51.001271: predicting ETIS-LaribPolypDB_73
2023-09-02 12:17:51.066192: predicting ETIS-LaribPolypDB_74
2023-09-02 12:17:51.139719: predicting ETIS-LaribPolypDB_75
2023-09-02 12:17:51.204828: predicting ETIS-LaribPolypDB_76
2023-09-02 12:17:51.271705: predicting ETIS-LaribPolypDB_77
2023-09-02 12:17:51.337775: predicting ETIS-LaribPolypDB_78
2023-09-02 12:17:51.402922: predicting ETIS-LaribPolypDB_79
2023-09-02 12:17:51.469092: predicting ETIS-LaribPolypDB_8
2023-09-02 12:17:51.533893: predicting ETIS-LaribPolypDB_80
2023-09-02 12:17:51.598284: predicting ETIS-LaribPolypDB_81
2023-09-02 12:17:51.666618: predicting ETIS-LaribPolypDB_82
2023-09-02 12:17:51.732588: predicting ETIS-LaribPolypDB_83
2023-09-02 12:17:51.797268: predicting ETIS-LaribPolypDB_84
2023-09-02 12:17:51.864662: predicting ETIS-LaribPolypDB_85
2023-09-02 12:17:51.932186: predicting ETIS-LaribPolypDB_86
2023-09-02 12:17:51.999979: predicting ETIS-LaribPolypDB_87
2023-09-02 12:17:52.066771: predicting ETIS-LaribPolypDB_88
2023-09-02 12:17:52.132928: predicting ETIS-LaribPolypDB_89
2023-09-02 12:17:52.198120: predicting ETIS-LaribPolypDB_9
2023-09-02 12:17:52.263968: predicting ETIS-LaribPolypDB_90
2023-09-02 12:17:52.331189: predicting ETIS-LaribPolypDB_91
2023-09-02 12:17:52.397854: predicting ETIS-LaribPolypDB_92
2023-09-02 12:17:52.464149: predicting ETIS-LaribPolypDB_93
2023-09-02 12:17:52.529959: predicting ETIS-LaribPolypDB_94
2023-09-02 12:17:52.595648: predicting ETIS-LaribPolypDB_95
2023-09-02 12:17:52.662591: predicting ETIS-LaribPolypDB_96
2023-09-02 12:17:52.727541: predicting ETIS-LaribPolypDB_97
2023-09-02 12:17:52.818441: predicting ETIS-LaribPolypDB_98
2023-09-02 12:17:52.885032: predicting ETIS-LaribPolypDB_99
2023-09-02 12:17:52.951118: predicting Kvasir_cju0u82z3cuma0835wlxrnrjv
2023-09-02 12:17:53.017154: predicting Kvasir_cju15wdt3zla10801odjiw7sy
2023-09-02 12:17:53.082457: predicting Kvasir_cju16ach3m1da0993r1dq3sn2
2023-09-02 12:17:53.148157: predicting Kvasir_cju16whaj0e7n0855q7b6cjkm
2023-09-02 12:17:53.227816: predicting Kvasir_cju17z0qongpa0993de4boim4
2023-09-02 12:17:53.292542: predicting Kvasir_cju1amqw6p8pw0993d9gc5crl
2023-09-02 12:17:53.359169: predicting Kvasir_cju1bm8063nmh07996rsjjemq
2023-09-02 12:17:53.424604: predicting Kvasir_cju1c3218411b08014g9f6gig
2023-09-02 12:17:53.490777: predicting Kvasir_cju1cbokpuiw70988j4lq1fpi
2023-09-02 12:17:53.556573: predicting Kvasir_cju1cj3f0qi5n0993ut8f49rj
2023-09-02 12:17:53.621941: predicting Kvasir_cju1cqc7n4gpy0855jt246k68
2023-09-02 12:17:53.689635: predicting Kvasir_cju1ddr6p4k5z08780uuuzit2
2023-09-02 12:17:53.754688: predicting Kvasir_cju1f8w0t65en0799m9oacq0q
2023-09-02 12:17:53.819811: predicting Kvasir_cju1h89h6xbnx08352k2790o9
2023-09-02 12:17:53.885913: predicting Kvasir_cju1hp9i2xu8e0988u2dazk7m
2023-09-02 12:17:53.950566: predicting Kvasir_cju2hfqnmhisa0993gpleeldd
2023-09-02 12:17:54.019412: predicting Kvasir_cju2hjrqcvi2j0801bx1i6gxg
2023-09-02 12:17:54.084358: predicting Kvasir_cju2hos57llxm08359g92p6jj
2023-09-02 12:17:54.162844: predicting Kvasir_cju2hqt33lmra0988fr5ijv8j
2023-09-02 12:17:54.245241: predicting Kvasir_cju2lberzkdzm09938cl40pog
2023-09-02 12:17:54.323021: predicting Kvasir_cju2mh8t6p07008350e01tx2a
2023-09-02 12:17:54.401802: predicting Kvasir_cju2nnqrqzp580855z8mhzgd6
2023-09-02 12:17:54.479484: predicting Kvasir_cju2np2k9zi3v079992ypxqkn
2023-09-02 12:17:54.551153: predicting Kvasir_cju2omjpeqj5a0988pjdlb8l1
2023-09-02 12:17:54.616334: predicting Kvasir_cju2osuru0ki00855txo0n3uu
2023-09-02 12:17:54.683703: predicting Kvasir_cju2pag1f0s4r0878h52uq83s
2023-09-02 12:17:54.749626: predicting Kvasir_cju2rga4psq9n09881z519xx0
2023-09-02 12:17:54.824263: predicting Kvasir_cju2rmd2rsw9g09888hh1efu0
2023-09-02 12:17:54.890575: predicting Kvasir_cju2rqo702wpx0855fn7d5cxh
2023-09-02 12:17:54.956075: predicting Kvasir_cju2top2ruxxy0988p1svx36g
2023-09-02 12:17:55.032392: predicting Kvasir_cju2wve9v7esz0878mxsdcy04
2023-09-02 12:17:55.099771: predicting Kvasir_cju2y40d8ulqo0993q0adtgtb
2023-09-02 12:17:55.165088: predicting Kvasir_cju2yi9tz8vky0801yqip0xyl
2023-09-02 12:17:55.230698: predicting Kvasir_cju2yo1j1v0qz09934o0e683p
2023-09-02 12:17:55.297498: predicting Kvasir_cju2yv4imv6cz099314jveiib
2023-09-02 12:17:55.363257: predicting Kvasir_cju2zp89k9q1g0855k1x0f1xa
2023-09-02 12:17:55.429132: predicting Kvasir_cju2zwg05a0oy0801yr73ig7g
2023-09-02 12:17:55.494778: predicting Kvasir_cju30ajhw09sx0988qyahx9s8
2023-09-02 12:17:55.560009: predicting Kvasir_cju30gxjq0djk0988jytm49rs
2023-09-02 12:17:55.625081: predicting Kvasir_cju30j1rgadut0801vuyrsnt8
2023-09-02 12:17:55.691265: predicting Kvasir_cju31w6goazci0799n014ly1q
2023-09-02 12:17:55.757781: predicting Kvasir_cju32srle1xfq083575i3fl75
2023-09-02 12:17:55.822957: predicting Kvasir_cju34m7h536wq0988xz7gx79v
2023-09-02 12:17:55.887609: predicting Kvasir_cju34xspwzenf0993cyzajv9n
2023-09-02 12:17:55.954181: predicting Kvasir_cju3tp94kfstl08181awh6z49
2023-09-02 12:17:56.019917: predicting Kvasir_cju3uhb79gcgr0871orbrbi3x
2023-09-02 12:17:56.084639: predicting Kvasir_cju3v11mrgwwb0755u242ygye
2023-09-02 12:17:56.151115: predicting Kvasir_cju3x5u2tiihx0818914gzxy1
2023-09-02 12:17:56.217015: predicting Kvasir_cju3xga12iixg0817dijbvjxw
2023-09-02 12:17:56.282470: predicting Kvasir_cju3ya7goj6at0818v2l5ay7f
2023-09-02 12:17:56.361396: predicting Kvasir_cju3ykamdj9u208503pygyuc8
2023-09-02 12:17:56.451460: predicting Kvasir_cju40m0rjkpw80871z6n6yg1u
2023-09-02 12:17:56.524142: predicting Kvasir_cju42qet0lsq90871e50xbnuv
2023-09-02 12:17:56.591891: predicting Kvasir_cju42wamblrqn098798r2yyok
2023-09-02 12:17:56.664250: predicting Kvasir_cju43jcqim2cp08172dvjvyui
2023-09-02 12:17:56.738789: predicting Kvasir_cju45rj7ln8980850a7821fov
2023-09-02 12:17:56.829736: predicting Kvasir_cju45ty6zn9oz0850qy4qnck1
2023-09-02 12:17:56.911976: predicting Kvasir_cju45v0pungu40871acnwtmu5
2023-09-02 12:17:56.991222: predicting Kvasir_cju5cky5xb0ay0801oxet697t
2023-09-02 12:17:57.069422: predicting Kvasir_cju5clr68b48r0755cmuvponm
2023-09-02 12:17:57.137816: predicting Kvasir_cju5hi52odyf90817prvcwg45
2023-09-02 12:17:57.204566: predicting Kvasir_cju5hyi9yegob0755ho3do8en
2023-09-02 12:17:57.272168: predicting Kvasir_cju5k3j3uf6de0817hszzfr7n
2023-09-02 12:17:57.340518: predicting Kvasir_cju5o4pk9h0720755lgp9jq8m
2023-09-02 12:17:57.412802: predicting Kvasir_cju5wrrs0m2af0818vmnajbtw
2023-09-02 12:17:57.481519: predicting Kvasir_cju5x00l6m5j608503k78ptee
2023-09-02 12:17:57.553005: predicting Kvasir_cju5xjn5mm78b09871spyqhhr
2023-09-02 12:17:57.626772: predicting Kvasir_cju5xkwzxmf0z0818gk4xabdm
2023-09-02 12:17:57.694778: predicting Kvasir_cju5xq3tdm9fn0987pbedxdg5
2023-09-02 12:17:57.770595: predicting Kvasir_cju5y4hgqmk0i08180rjhbwvp
2023-09-02 12:17:57.838701: predicting Kvasir_cju5yeqiwmkgl0801fzv2douc
2023-09-02 12:17:57.905291: predicting Kvasir_cju6us80mv1b50871ebyq2wxa
2023-09-02 12:17:57.972063: predicting Kvasir_cju6uy20suzbl0987rzuhz7z9
2023-09-02 12:17:58.037830: predicting Kvasir_cju6v1m1xv07w09870ah3njy1
2023-09-02 12:17:58.119547: predicting Kvasir_cju6vifjlv55z0987un6y4zdo
2023-09-02 12:17:58.199911: predicting Kvasir_cju6vrs1ov8cr098788h8gs6j
2023-09-02 12:17:58.280032: predicting Kvasir_cju6x0yqbvxqt0755dhxislgb
2023-09-02 12:17:58.359354: predicting Kvasir_cju7ajnbo1gvm098749rdouk0
2023-09-02 12:17:58.437301: predicting Kvasir_cju7awzmu1ncs0871hziy65zx
2023-09-02 12:17:58.516758: predicting Kvasir_cju7bd1qu1mx409877xjxibox
2023-09-02 12:17:58.594466: predicting Kvasir_cju7bgnvb1sf808717qa799ir
2023-09-02 12:17:58.673203: predicting Kvasir_cju7crgxa28550755wbsgqkel
2023-09-02 12:17:58.751324: predicting Kvasir_cju7da88w2eod0755wejzynvt
2023-09-02 12:17:58.829389: predicting Kvasir_cju7ddtz729960801uazp1knc
2023-09-02 12:17:58.934379: predicting Kvasir_cju7do8c72dbo0801vxfzxdc4
2023-09-02 12:17:59.012182: predicting Kvasir_cju7dymur2od30755eg8yv2ht
2023-09-02 12:17:59.091399: predicting Kvasir_cju7ecl9i2i060987xawjp4l0
2023-09-02 12:17:59.169643: predicting Kvasir_cju7fbndk2sl608015ravktum
2023-09-02 12:17:59.247140: predicting Kvasir_cju7fcgbe2z3p07550vaflqdb
2023-09-02 12:17:59.327577: predicting Kvasir_cju7fpfzq2wyf0818xxd1oziv
2023-09-02 12:17:59.407951: predicting Kvasir_cju84hibuktj80871u519o71q
2023-09-02 12:17:59.486380: predicting Kvasir_cju88cddensj00987788yotmg
2023-09-02 12:17:59.564558: predicting Kvasir_cju88t4fvokxf07558ymyh281
2023-09-02 12:17:59.643379: predicting Kvasir_cju88vx2uoocy075531lc63n3
2023-09-02 12:17:59.721425: predicting Kvasir_cju8alhigqn2h0801zksudldd
2023-09-02 12:17:59.795119: predicting Kvasir_cju8aqq8uqmoq0987hphto9gg
2023-09-02 12:17:59.861125: predicting Kvasir_cju8bk8oirjhw0817hgkua2w8
2023-09-02 12:17:59.930051: predicting Kvasir_cju8c2rqzs5t80850d0zky5dy
2023-09-02 12:17:59.998401: predicting Kvasir_cju8d4jgatgpj0871q2ophhkm
2023-09-02 12:18:00.064531: predicting Kvasir_cju8dqkrqu83i0818ev74qpxq
2023-09-02 12:18:20.024630: Validation complete
2023-09-02 12:18:20.026432: Mean Validation Dice:  0.8242196748964974
