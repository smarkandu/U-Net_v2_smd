OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-03 10:08:35.341585: I am training on qa-rtx6k-009.crc.nd.edu
2023-09-03 10:08:35.343077: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/458817_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
loading /afs/crc.nd.edu/user/y/ypeng4/Polyp-PVT_2/pvt_pth/pvt_v2_b2.pth
loading /afs/crc.nd.edu/user/y/ypeng4/Polyp-PVT_2/pvt_pth/pvt_v2_b2.pth
model: PVTUNetPlus(
  (backbone): Identity()
  (model): UnetPlusPlus(
    (encoder): PVTEncoder(
      (backbone): pvt_v2_b2(
        (patch_embed1): OverlapPatchEmbed(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed2): OverlapPatchEmbed(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed3): OverlapPatchEmbed(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed4): OverlapPatchEmbed(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (block1): ModuleList(
          (0): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.007)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.013)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (block2): ModuleList(
          (0): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.020)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.033)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.040)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (block3): ModuleList(
          (0): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.060)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.067)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.073)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.080)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (block4): ModuleList(
          (0): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.087)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.093)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
    )
    (decoder): UnetPlusPlusDecoder(
      (center): Identity()
      (blocks): ModuleDict(
        (x_0_0): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(832, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_0_1): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_1_1): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(448, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_0_2): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_1_2): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_2_2): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_0_3): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_1_3): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_2_3): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_3_3): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (x_0_4): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
      )
    )
    (segmentation_head): SegmentationHead(
      (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): Identity()
      (2): Activation(
        (activation): Identity()
      )
    )
  )
)
==========<class 'nnunetv2.training.network.model.dim2.pvt.pvt_unetplusplus.PVTUNetPlus'>===========
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'pvt_unetplus', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset124_ISIC2018', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.57754516601562, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 29.0, 'percentile_99_5': 253.0, 'std': 42.08180618286133}, '1': {'max': 255.0, 'mean': 111.1130142211914, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 8.0, 'percentile_99_5': 222.0, 'std': 43.864933013916016}, '2': {'max': 255.0, 'mean': 91.45153045654297, 'median': 91.0, 'min': 0.0, 'percentile_00_5': 4.0, 'percentile_99_5': 209.0, 'std': 43.73163604736328}}} 

2023-09-03 10:11:55.131890: unpacking dataset...
2023-09-03 10:12:14.273888: unpacking done...
2023-09-03 10:12:14.275919: do_dummy_2d_data_aug: False
2023-09-03 10:12:14.294934: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:12:14.295868: The split file contains 1 splits.
2023-09-03 10:12:14.296276: Desired fold for training: 0
2023-09-03 10:12:14.296569: This split has 1886 training and 808 validation cases.
==================batch size: 49==================
2023-09-03 10:12:14.331412: Unable to plot network architecture:
2023-09-03 10:12:14.331823: No module named 'hiddenlayer'
PVTUNetPlus
===================debug: False===================
2023-09-03 10:12:15.971784: 
2023-09-03 10:12:15.972489: Epoch 0
2023-09-03 10:12:15.972988: Current learning rate: backbone 0.001, others 0.001
2023-09-03 10:12:15.973662: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-03 10:14:30.136043: finished training epoch 0
2023-09-03 10:14:30.164428: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:14:30.165749: The split file contains 1 splits.
2023-09-03 10:14:30.166410: Desired fold for training: 0
2023-09-03 10:14:30.166913: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:19:35.648774: dsc: 89.74%
2023-09-03 10:19:35.649998: miou: 81.39%
2023-09-03 10:19:35.650901: acc: 94.81%, sen: 90.22%, spe: 96.36%
2023-09-03 10:19:35.652369: current best miou: 0.8138793485874743 at epoch: 0, (0, 0.8138793485874743, 0.8973908316683445)
2023-09-03 10:19:35.653114: current best dsc: 0.8973908316683445 at epoch: 0, (0, 0.8138793485874743, 0.8973908316683445)
2023-09-03 10:19:37.604969: finished real validation
using pin_memory on device 0
2023-09-03 10:19:46.834851: train_loss -0.9858
2023-09-03 10:19:46.836290: val_loss -1.1602
2023-09-03 10:19:46.839022: Pseudo dice [0.8975]
2023-09-03 10:19:46.840406: Epoch time: 450.86 s
2023-09-03 10:19:46.841348: Yayy! New best EMA pseudo Dice: 0.8975
2023-09-03 10:19:49.671329: 
2023-09-03 10:19:49.673032: Epoch 1
2023-09-03 10:19:49.674290: Current learning rate: backbone 0.000997, others 0.000997
2023-09-03 10:19:49.676642: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:21:48.613940: finished training epoch 1
2023-09-03 10:21:48.649293: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:21:48.650942: The split file contains 1 splits.
2023-09-03 10:21:48.651625: Desired fold for training: 0
2023-09-03 10:21:48.652097: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:26:57.081419: dsc: 90.88%
2023-09-03 10:26:57.082599: miou: 83.28%
2023-09-03 10:26:57.083231: acc: 95.35%, sen: 92.10%, spe: 96.44%
2023-09-03 10:26:57.084101: current best miou: 0.8328131813245557 at epoch: 1, (1, 0.8328131813245557, 0.9087813093123762)
2023-09-03 10:26:57.084707: current best dsc: 0.9087813093123762 at epoch: 1, (1, 0.8328131813245557, 0.9087813093123762)
2023-09-03 10:26:59.020023: finished real validation
2023-09-03 10:27:07.475204: train_loss -1.264
2023-09-03 10:27:07.476951: val_loss -1.2143
2023-09-03 10:27:07.477796: Pseudo dice [0.9104]
2023-09-03 10:27:07.478445: Epoch time: 437.81 s
2023-09-03 10:27:07.479095: Yayy! New best EMA pseudo Dice: 0.8988
2023-09-03 10:27:10.510215: 
2023-09-03 10:27:10.511254: Epoch 2
2023-09-03 10:27:10.512012: Current learning rate: backbone 0.000994, others 0.000994
2023-09-03 10:27:10.513048: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:29:09.460196: finished training epoch 2
2023-09-03 10:29:09.488546: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:29:09.490405: The split file contains 1 splits.
2023-09-03 10:29:09.491145: Desired fold for training: 0
2023-09-03 10:29:09.491789: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:34:22.796996: dsc: 90.66%
2023-09-03 10:34:22.798189: miou: 82.91%
2023-09-03 10:34:22.798846: acc: 95.21%, sen: 92.36%, spe: 96.17%
2023-09-03 10:34:22.799741: current best miou: 0.8328131813245557 at epoch: 1, (1, 0.8328131813245557, 0.9087813093123762)
2023-09-03 10:34:22.800349: current best dsc: 0.9087813093123762 at epoch: 1, (1, 0.8328131813245557, 0.9087813093123762)
2023-09-03 10:34:22.800848: finished real validation
2023-09-03 10:34:31.246541: train_loss -1.2941
2023-09-03 10:34:31.247646: val_loss -1.1996
2023-09-03 10:34:31.248598: Pseudo dice [0.9077]
2023-09-03 10:34:31.249316: Epoch time: 440.74 s
2023-09-03 10:34:31.249911: Yayy! New best EMA pseudo Dice: 0.8997
2023-09-03 10:34:34.187598: 
2023-09-03 10:34:34.188644: Epoch 3
2023-09-03 10:34:34.189318: Current learning rate: backbone 0.000991, others 0.000991
2023-09-03 10:34:34.190426: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:36:33.069838: finished training epoch 3
2023-09-03 10:36:33.098055: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:36:33.099700: The split file contains 1 splits.
2023-09-03 10:36:33.100527: Desired fold for training: 0
2023-09-03 10:36:33.101167: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:41:49.932023: dsc: 91.02%
2023-09-03 10:41:49.933220: miou: 83.52%
2023-09-03 10:41:49.933857: acc: 95.46%, sen: 91.47%, spe: 96.80%
2023-09-03 10:41:49.934786: current best miou: 0.8351884610841372 at epoch: 3, (3, 0.8351884610841372, 0.910193670889528)
2023-09-03 10:41:49.935500: current best dsc: 0.910193670889528 at epoch: 3, (3, 0.8351884610841372, 0.910193670889528)
2023-09-03 10:41:51.962696: finished real validation
2023-09-03 10:42:00.412323: train_loss -1.311
2023-09-03 10:42:00.413597: val_loss -1.208
2023-09-03 10:42:00.414479: Pseudo dice [0.9103]
2023-09-03 10:42:00.415269: Epoch time: 446.23 s
2023-09-03 10:42:00.415889: Yayy! New best EMA pseudo Dice: 0.9007
2023-09-03 10:42:03.392964: 
2023-09-03 10:42:03.394200: Epoch 4
2023-09-03 10:42:03.394952: Current learning rate: backbone 0.00098799, others 0.00098799
2023-09-03 10:42:03.395951: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:44:02.339307: finished training epoch 4
2023-09-03 10:44:02.378522: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:44:02.380402: The split file contains 1 splits.
2023-09-03 10:44:02.381130: Desired fold for training: 0
2023-09-03 10:44:02.381771: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:49:19.135581: dsc: 91.09%
2023-09-03 10:49:19.136593: miou: 83.64%
2023-09-03 10:49:19.137172: acc: 95.52%, sen: 91.10%, spe: 97.00%
2023-09-03 10:49:19.138656: current best miou: 0.8363743171133515 at epoch: 4, (4, 0.8363743171133515, 0.910897423601602)
2023-09-03 10:49:19.139547: current best dsc: 0.910897423601602 at epoch: 4, (4, 0.8363743171133515, 0.910897423601602)
2023-09-03 10:49:21.021869: finished real validation
2023-09-03 10:49:29.476457: train_loss -1.3308
2023-09-03 10:49:29.477620: val_loss -1.2097
2023-09-03 10:49:29.478528: Pseudo dice [0.913]
2023-09-03 10:49:29.479356: Epoch time: 446.09 s
2023-09-03 10:49:29.480340: Yayy! New best EMA pseudo Dice: 0.902
2023-09-03 10:49:32.436116: 
2023-09-03 10:49:32.437240: Epoch 5
2023-09-03 10:49:32.438054: Current learning rate: backbone 0.00098499, others 0.00098499
2023-09-03 10:49:32.439119: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:51:31.407223: finished training epoch 5
2023-09-03 10:51:31.456984: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:51:31.458557: The split file contains 1 splits.
2023-09-03 10:51:31.459246: Desired fold for training: 0
2023-09-03 10:51:31.459855: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:56:44.884302: dsc: 91.29%
2023-09-03 10:56:44.885677: miou: 83.98%
2023-09-03 10:56:44.886387: acc: 95.63%, sen: 90.98%, spe: 97.20%
2023-09-03 10:56:44.887542: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 10:56:44.888274: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 10:56:46.825107: finished real validation
2023-09-03 10:56:55.293999: train_loss -1.3396
2023-09-03 10:56:55.295202: val_loss -1.2059
2023-09-03 10:56:55.296192: Pseudo dice [0.9124]
2023-09-03 10:56:55.296945: Epoch time: 442.86 s
2023-09-03 10:56:55.297567: Yayy! New best EMA pseudo Dice: 0.903
2023-09-03 10:56:58.317207: 
2023-09-03 10:56:58.318437: Epoch 6
2023-09-03 10:56:58.319293: Current learning rate: backbone 0.00098198, others 0.00098198
2023-09-03 10:56:58.320473: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:58:57.367722: finished training epoch 6
2023-09-03 10:58:57.410109: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:58:57.411718: The split file contains 1 splits.
2023-09-03 10:58:57.412446: Desired fold for training: 0
2023-09-03 10:58:57.413061: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:04:09.580712: dsc: 90.56%
2023-09-03 11:04:09.581862: miou: 82.76%
2023-09-03 11:04:09.582546: acc: 95.13%, sen: 92.85%, spe: 95.90%
2023-09-03 11:04:09.583513: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:04:09.584229: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:04:09.585026: finished real validation
2023-09-03 11:04:18.039209: train_loss -1.3471
2023-09-03 11:04:18.040492: val_loss -1.164
2023-09-03 11:04:18.041461: Pseudo dice [0.9017]
2023-09-03 11:04:18.042229: Epoch time: 439.72 s
2023-09-03 11:04:19.120760: 
2023-09-03 11:04:19.121936: Epoch 7
2023-09-03 11:04:19.122699: Current learning rate: backbone 0.00097898, others 0.00097898
2023-09-03 11:04:19.123735: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:06:18.194613: finished training epoch 7
2023-09-03 11:06:18.233793: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:06:18.235746: The split file contains 1 splits.
2023-09-03 11:06:18.236577: Desired fold for training: 0
2023-09-03 11:06:18.237260: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:11:30.673991: dsc: 90.92%
2023-09-03 11:11:30.675169: miou: 83.35%
2023-09-03 11:11:30.676120: acc: 95.43%, sen: 90.85%, spe: 96.97%
2023-09-03 11:11:30.677443: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:11:30.678298: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:11:30.679151: finished real validation
2023-09-03 11:11:39.135795: train_loss -1.3514
2023-09-03 11:11:39.137170: val_loss -1.1925
2023-09-03 11:11:39.138281: Pseudo dice [0.9085]
2023-09-03 11:11:39.139054: Epoch time: 440.02 s
2023-09-03 11:11:39.139724: Yayy! New best EMA pseudo Dice: 0.9034
2023-09-03 11:11:42.178496: 
2023-09-03 11:11:42.179780: Epoch 8
2023-09-03 11:11:42.180515: Current learning rate: backbone 0.00097597, others 0.00097597
2023-09-03 11:11:42.181705: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:13:41.180998: finished training epoch 8
2023-09-03 11:13:41.210435: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:13:41.212003: The split file contains 1 splits.
2023-09-03 11:13:41.212731: Desired fold for training: 0
2023-09-03 11:13:41.213305: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:19:00.660615: dsc: 91.15%
2023-09-03 11:19:00.662164: miou: 83.73%
2023-09-03 11:19:00.662946: acc: 95.50%, sen: 92.12%, spe: 96.64%
2023-09-03 11:19:00.663928: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:19:00.664660: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:19:00.665231: finished real validation
2023-09-03 11:19:09.108963: train_loss -1.3575
2023-09-03 11:19:09.110396: val_loss -1.1954
2023-09-03 11:19:09.111456: Pseudo dice [0.911]
2023-09-03 11:19:09.112297: Epoch time: 446.93 s
2023-09-03 11:19:09.112926: Yayy! New best EMA pseudo Dice: 0.9042
2023-09-03 11:19:12.029232: 
2023-09-03 11:19:12.030422: Epoch 9
2023-09-03 11:19:12.031193: Current learning rate: backbone 0.00097296, others 0.00097296
2023-09-03 11:19:12.032333: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:21:11.122924: finished training epoch 9
2023-09-03 11:21:11.167145: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:21:11.169240: The split file contains 1 splits.
2023-09-03 11:21:11.170101: Desired fold for training: 0
2023-09-03 11:21:11.170867: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:26:38.125636: dsc: 90.66%
2023-09-03 11:26:38.126863: miou: 82.92%
2023-09-03 11:26:38.127582: acc: 95.25%, sen: 91.74%, spe: 96.43%
2023-09-03 11:26:38.128548: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:26:38.129216: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:26:38.129770: finished real validation
2023-09-03 11:26:46.561871: train_loss -1.3632
2023-09-03 11:26:46.563202: val_loss -1.1633
2023-09-03 11:26:46.564204: Pseudo dice [0.9044]
2023-09-03 11:26:46.565164: Epoch time: 454.53 s
2023-09-03 11:26:48.479518: Yayy! New best EMA pseudo Dice: 0.9042
2023-09-03 11:26:51.376529: 
2023-09-03 11:26:51.377971: Epoch 10
2023-09-03 11:26:51.379062: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-03 11:26:51.380155: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:28:50.548338: finished training epoch 10
2023-09-03 11:28:50.577365: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:28:50.579048: The split file contains 1 splits.
2023-09-03 11:28:50.579770: Desired fold for training: 0
2023-09-03 11:28:50.580413: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:34:04.661145: dsc: 90.95%
2023-09-03 11:34:04.662692: miou: 83.40%
2023-09-03 11:34:04.663508: acc: 95.44%, sen: 91.14%, spe: 96.88%
2023-09-03 11:34:04.664591: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:34:04.665266: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:34:04.666034: finished real validation
2023-09-03 11:34:13.127506: train_loss -1.3691
2023-09-03 11:34:13.128836: val_loss -1.1849
2023-09-03 11:34:13.129768: Pseudo dice [0.9106]
2023-09-03 11:34:13.130538: Epoch time: 441.75 s
2023-09-03 11:34:13.131409: Yayy! New best EMA pseudo Dice: 0.9049
2023-09-03 11:34:16.104740: 
2023-09-03 11:34:16.105929: Epoch 11
2023-09-03 11:34:16.106740: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-03 11:34:16.108081: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:36:15.120070: finished training epoch 11
2023-09-03 11:36:15.165529: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:36:15.166986: The split file contains 1 splits.
2023-09-03 11:36:15.167750: Desired fold for training: 0
2023-09-03 11:36:15.168480: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:41:41.059600: dsc: 91.09%
2023-09-03 11:41:41.060854: miou: 83.63%
2023-09-03 11:41:41.061598: acc: 95.49%, sen: 91.65%, spe: 96.78%
2023-09-03 11:41:41.063003: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:41:41.063712: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:41:41.064488: finished real validation
2023-09-03 11:41:49.528989: train_loss -1.3719
2023-09-03 11:41:49.530220: val_loss -1.1923
2023-09-03 11:41:49.531297: Pseudo dice [0.9144]
2023-09-03 11:41:49.532029: Epoch time: 453.43 s
2023-09-03 11:41:49.532708: Yayy! New best EMA pseudo Dice: 0.9058
2023-09-03 11:41:52.696029: 
2023-09-03 11:41:52.697265: Epoch 12
2023-09-03 11:41:52.698117: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-03 11:41:52.699600: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:43:51.888261: finished training epoch 12
2023-09-03 11:43:51.917195: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:43:51.919070: The split file contains 1 splits.
2023-09-03 11:43:51.920033: Desired fold for training: 0
2023-09-03 11:43:51.921101: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:50:33.913073: dsc: 91.04%
2023-09-03 11:50:33.924341: miou: 83.56%
2023-09-03 11:50:33.932910: acc: 95.41%, sen: 92.74%, spe: 96.31%
2023-09-03 11:50:33.943269: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:50:33.970070: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:50:34.001691: finished real validation
2023-09-03 11:50:42.464314: train_loss -1.3755
2023-09-03 11:50:42.475431: val_loss -1.1758
2023-09-03 11:50:42.495890: Pseudo dice [0.9098]
2023-09-03 11:50:42.510911: Epoch time: 529.77 s
2023-09-03 11:50:42.524991: Yayy! New best EMA pseudo Dice: 0.9062
2023-09-03 11:50:45.737360: 
2023-09-03 11:50:45.743002: Epoch 13
2023-09-03 11:50:45.753984: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-03 11:50:45.765721: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:52:44.871489: finished training epoch 13
2023-09-03 11:52:44.899516: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:52:44.901159: The split file contains 1 splits.
2023-09-03 11:52:44.902008: Desired fold for training: 0
2023-09-03 11:52:44.902929: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:58:14.458574: dsc: 90.98%
2023-09-03 11:58:14.459715: miou: 83.46%
2023-09-03 11:58:14.460585: acc: 95.47%, sen: 90.81%, spe: 97.04%
2023-09-03 11:58:14.461552: current best miou: 0.8397872967613014 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:58:14.462313: current best dsc: 0.9129178120097189 at epoch: 5, (5, 0.8397872967613014, 0.9129178120097189)
2023-09-03 11:58:14.463184: finished real validation
2023-09-03 11:58:22.896718: train_loss -1.3798
2023-09-03 11:58:22.898105: val_loss -1.1646
2023-09-03 11:58:22.899539: Pseudo dice [0.9091]
2023-09-03 11:58:22.900853: Epoch time: 457.16 s
2023-09-03 11:58:22.901872: Yayy! New best EMA pseudo Dice: 0.9065
2023-09-03 11:58:26.102293: 
2023-09-03 11:58:26.103909: Epoch 14
2023-09-03 11:58:26.105064: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-03 11:58:26.106682: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:00:25.096033: finished training epoch 14
2023-09-03 12:00:25.125377: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:00:25.127241: The split file contains 1 splits.
2023-09-03 12:00:25.128055: Desired fold for training: 0
2023-09-03 12:00:25.129353: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:05:52.819175: dsc: 91.43%
2023-09-03 12:05:52.820925: miou: 84.21%
2023-09-03 12:05:52.822053: acc: 95.67%, sen: 91.70%, spe: 97.01%
2023-09-03 12:05:52.823368: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:05:52.824515: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:05:54.896925: finished real validation
2023-09-03 12:06:03.356671: train_loss -1.3846
2023-09-03 12:06:03.372351: val_loss -1.1818
2023-09-03 12:06:03.408069: Pseudo dice [0.913]
2023-09-03 12:06:03.437299: Epoch time: 457.26 s
2023-09-03 12:06:03.454458: Yayy! New best EMA pseudo Dice: 0.9072
2023-09-03 12:06:06.570262: 
2023-09-03 12:06:06.577774: Epoch 15
2023-09-03 12:06:06.578626: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-03 12:06:06.579958: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:08:05.608694: finished training epoch 15
2023-09-03 12:08:05.638737: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:08:05.640527: The split file contains 1 splits.
2023-09-03 12:08:05.641568: Desired fold for training: 0
2023-09-03 12:08:05.642238: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:13:49.432657: dsc: 91.09%
2023-09-03 12:13:49.434490: miou: 83.64%
2023-09-03 12:13:49.436879: acc: 95.46%, sen: 92.32%, spe: 96.51%
2023-09-03 12:13:49.438332: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:13:49.440192: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:13:49.441721: finished real validation
2023-09-03 12:13:57.901582: train_loss -1.3865
2023-09-03 12:13:57.903366: val_loss -1.1647
2023-09-03 12:13:57.904536: Pseudo dice [0.9106]
2023-09-03 12:13:57.905401: Epoch time: 471.33 s
2023-09-03 12:13:57.906643: Yayy! New best EMA pseudo Dice: 0.9075
2023-09-03 12:14:01.024165: 
2023-09-03 12:14:01.026225: Epoch 16
2023-09-03 12:14:01.027544: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-03 12:14:01.028839: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:16:00.085195: finished training epoch 16
2023-09-03 12:16:00.125552: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:16:00.127882: The split file contains 1 splits.
2023-09-03 12:16:00.129387: Desired fold for training: 0
2023-09-03 12:16:00.130630: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:21:17.578771: dsc: 91.05%
2023-09-03 12:21:17.580109: miou: 83.57%
2023-09-03 12:21:17.580834: acc: 95.47%, sen: 91.62%, spe: 96.76%
2023-09-03 12:21:17.581838: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:21:17.582542: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:21:17.583385: finished real validation
2023-09-03 12:21:26.042494: train_loss -1.3913
2023-09-03 12:21:26.043858: val_loss -1.1566
2023-09-03 12:21:26.044890: Pseudo dice [0.9091]
2023-09-03 12:21:26.045752: Epoch time: 445.02 s
2023-09-03 12:21:26.046495: Yayy! New best EMA pseudo Dice: 0.9077
2023-09-03 12:21:29.061466: 
2023-09-03 12:21:29.062636: Epoch 17
2023-09-03 12:21:29.063437: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-03 12:21:29.064570: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:23:28.108259: finished training epoch 17
2023-09-03 12:23:28.137272: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:23:28.138865: The split file contains 1 splits.
2023-09-03 12:23:28.139646: Desired fold for training: 0
2023-09-03 12:23:28.140334: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:28:44.258020: dsc: 91.00%
2023-09-03 12:28:44.259609: miou: 83.49%
2023-09-03 12:28:44.260468: acc: 95.44%, sen: 91.63%, spe: 96.73%
2023-09-03 12:28:44.261488: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:28:44.262483: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:28:44.263274: finished real validation
2023-09-03 12:28:52.722246: train_loss -1.3925
2023-09-03 12:28:52.723663: val_loss -1.1501
2023-09-03 12:28:52.724888: Pseudo dice [0.907]
2023-09-03 12:28:52.725915: Epoch time: 443.66 s
2023-09-03 12:28:53.889196: 
2023-09-03 12:28:53.890406: Epoch 18
2023-09-03 12:28:53.891242: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-03 12:28:53.892405: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:30:52.976160: finished training epoch 18
2023-09-03 12:30:53.003825: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:30:53.005366: The split file contains 1 splits.
2023-09-03 12:30:53.006200: Desired fold for training: 0
2023-09-03 12:30:53.007009: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:36:16.019650: dsc: 91.34%
2023-09-03 12:36:16.021008: miou: 84.07%
2023-09-03 12:36:16.022004: acc: 95.60%, sen: 92.31%, spe: 96.71%
2023-09-03 12:36:16.023318: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:36:16.024145: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:36:16.024816: finished real validation
2023-09-03 12:36:24.469856: train_loss -1.3947
2023-09-03 12:36:24.471154: val_loss -1.1813
2023-09-03 12:36:24.472228: Pseudo dice [0.9157]
2023-09-03 12:36:24.473071: Epoch time: 450.58 s
2023-09-03 12:36:24.473789: Yayy! New best EMA pseudo Dice: 0.9084
2023-09-03 12:36:27.537039: 
2023-09-03 12:36:27.538637: Epoch 19
2023-09-03 12:36:27.539601: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-03 12:36:27.540770: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:38:26.641213: finished training epoch 19
2023-09-03 12:38:26.674931: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:38:26.677152: The split file contains 1 splits.
2023-09-03 12:38:26.677959: Desired fold for training: 0
2023-09-03 12:38:26.678699: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:43:48.701970: dsc: 90.91%
2023-09-03 12:43:48.703320: miou: 83.34%
2023-09-03 12:43:48.704146: acc: 95.39%, sen: 91.68%, spe: 96.64%
2023-09-03 12:43:48.705416: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:43:48.706191: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:43:48.707162: finished real validation
2023-09-03 12:43:57.158036: train_loss -1.3965
2023-09-03 12:43:57.159289: val_loss -1.137
2023-09-03 12:43:57.160491: Pseudo dice [0.9036]
2023-09-03 12:43:57.161285: Epoch time: 449.62 s
2023-09-03 12:44:00.148051: 
2023-09-03 12:44:00.149357: Epoch 20
2023-09-03 12:44:00.150332: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-03 12:44:00.151653: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:45:59.507115: finished training epoch 20
2023-09-03 12:45:59.549086: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:45:59.550754: The split file contains 1 splits.
2023-09-03 12:45:59.551640: Desired fold for training: 0
2023-09-03 12:45:59.552653: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:51:35.585717: dsc: 91.25%
2023-09-03 12:51:35.586997: miou: 83.90%
2023-09-03 12:51:35.587996: acc: 95.57%, sen: 91.87%, spe: 96.81%
2023-09-03 12:51:35.589123: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:51:35.589893: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 12:51:35.590605: finished real validation
2023-09-03 12:51:44.039474: train_loss -1.3984
2023-09-03 12:51:44.040899: val_loss -1.1558
2023-09-03 12:51:44.042098: Pseudo dice [0.9108]
2023-09-03 12:51:44.042968: Epoch time: 463.89 s
2023-09-03 12:51:45.160651: 
2023-09-03 12:51:45.161940: Epoch 21
2023-09-03 12:51:45.163057: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-03 12:51:45.164692: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:53:44.411319: finished training epoch 21
2023-09-03 12:53:44.444195: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:53:44.445771: The split file contains 1 splits.
2023-09-03 12:53:44.446589: Desired fold for training: 0
2023-09-03 12:53:44.447401: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:00:23.630624: dsc: 90.96%
2023-09-03 13:00:23.631835: miou: 83.42%
2023-09-03 13:00:23.632749: acc: 95.39%, sen: 92.17%, spe: 96.48%
2023-09-03 13:00:23.633780: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:00:23.634542: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:00:23.635196: finished real validation
2023-09-03 13:00:32.069763: train_loss -1.4021
2023-09-03 13:00:32.070920: val_loss -1.1603
2023-09-03 13:00:32.071909: Pseudo dice [0.9096]
2023-09-03 13:00:32.072733: Epoch time: 526.91 s
2023-09-03 13:00:33.152907: 
2023-09-03 13:00:33.154021: Epoch 22
2023-09-03 13:00:33.154988: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-03 13:00:33.156180: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:02:32.122935: finished training epoch 22
2023-09-03 13:02:32.151961: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:02:32.153729: The split file contains 1 splits.
2023-09-03 13:02:32.154567: Desired fold for training: 0
2023-09-03 13:02:32.155309: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:08:10.183008: dsc: 91.22%
2023-09-03 13:08:10.184269: miou: 83.86%
2023-09-03 13:08:10.185148: acc: 95.55%, sen: 91.87%, spe: 96.79%
2023-09-03 13:08:10.186287: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:08:10.227678: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:08:10.243622: finished real validation
2023-09-03 13:08:18.695479: train_loss -1.4043
2023-09-03 13:08:18.710104: val_loss -1.1747
2023-09-03 13:08:18.735420: Pseudo dice [0.9131]
2023-09-03 13:08:18.751342: Epoch time: 465.54 s
2023-09-03 13:08:18.752717: Yayy! New best EMA pseudo Dice: 0.9088
2023-09-03 13:08:21.777751: 
2023-09-03 13:08:21.778872: Epoch 23
2023-09-03 13:08:21.779714: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-03 13:08:21.780885: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:10:20.820764: finished training epoch 23
2023-09-03 13:10:20.850240: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:10:20.852206: The split file contains 1 splits.
2023-09-03 13:10:20.853393: Desired fold for training: 0
2023-09-03 13:10:20.854559: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:15:52.761419: dsc: 91.02%
2023-09-03 13:15:52.762702: miou: 83.53%
2023-09-03 13:15:52.763743: acc: 95.45%, sen: 91.77%, spe: 96.68%
2023-09-03 13:15:52.764998: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:15:52.765953: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:15:52.766891: finished real validation
2023-09-03 13:16:01.197328: train_loss -1.4043
2023-09-03 13:16:01.198622: val_loss -1.1486
2023-09-03 13:16:01.199701: Pseudo dice [0.9092]
2023-09-03 13:16:01.200573: Epoch time: 459.42 s
2023-09-03 13:16:01.201529: Yayy! New best EMA pseudo Dice: 0.9089
2023-09-03 13:16:04.280648: 
2023-09-03 13:16:04.281920: Epoch 24
2023-09-03 13:16:04.283062: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-03 13:16:04.284741: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:18:03.245015: finished training epoch 24
2023-09-03 13:18:03.274364: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:18:03.276102: The split file contains 1 splits.
2023-09-03 13:18:03.276941: Desired fold for training: 0
2023-09-03 13:18:03.277748: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:23:43.814136: dsc: 91.30%
2023-09-03 13:23:43.822155: miou: 83.99%
2023-09-03 13:23:43.833313: acc: 95.58%, sen: 92.15%, spe: 96.74%
2023-09-03 13:23:43.845227: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:23:43.850051: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:23:43.855742: finished real validation
2023-09-03 13:23:52.321594: train_loss -1.4066
2023-09-03 13:23:52.328567: val_loss -1.1654
2023-09-03 13:23:52.334515: Pseudo dice [0.9106]
2023-09-03 13:23:52.339905: Epoch time: 468.04 s
2023-09-03 13:23:52.345499: Yayy! New best EMA pseudo Dice: 0.909
2023-09-03 13:23:55.342976: 
2023-09-03 13:23:55.354730: Epoch 25
2023-09-03 13:23:55.361092: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-03 13:23:55.367601: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:25:54.390525: finished training epoch 25
2023-09-03 13:25:54.429062: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:25:54.431023: The split file contains 1 splits.
2023-09-03 13:25:54.431901: Desired fold for training: 0
2023-09-03 13:25:54.432715: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:31:33.679195: dsc: 91.12%
2023-09-03 13:31:33.680465: miou: 83.68%
2023-09-03 13:31:33.681227: acc: 95.49%, sen: 91.94%, spe: 96.69%
2023-09-03 13:31:33.682292: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:31:33.683157: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:31:33.684065: finished real validation
2023-09-03 13:31:42.140146: train_loss -1.4083
2023-09-03 13:31:42.141533: val_loss -1.1524
2023-09-03 13:31:42.142608: Pseudo dice [0.911]
2023-09-03 13:31:42.143497: Epoch time: 466.8 s
2023-09-03 13:31:42.144403: Yayy! New best EMA pseudo Dice: 0.9092
2023-09-03 13:31:45.115475: 
2023-09-03 13:31:45.117077: Epoch 26
2023-09-03 13:31:45.117956: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-03 13:31:45.119220: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:33:44.440486: finished training epoch 26
2023-09-03 13:33:44.475039: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:33:44.476979: The split file contains 1 splits.
2023-09-03 13:33:44.478143: Desired fold for training: 0
2023-09-03 13:33:44.479074: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:40:50.950652: dsc: 90.93%
2023-09-03 13:40:50.952170: miou: 83.36%
2023-09-03 13:40:50.953145: acc: 95.44%, sen: 90.95%, spe: 96.94%
2023-09-03 13:40:50.954506: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:40:50.955299: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:40:50.956047: finished real validation
2023-09-03 13:40:59.412600: train_loss -1.41
2023-09-03 13:40:59.413936: val_loss -1.1427
2023-09-03 13:40:59.415029: Pseudo dice [0.9071]
2023-09-03 13:40:59.415888: Epoch time: 554.3 s
2023-09-03 13:41:00.531004: 
2023-09-03 13:41:00.532448: Epoch 27
2023-09-03 13:41:00.533309: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-03 13:41:00.534618: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:42:59.599468: finished training epoch 27
2023-09-03 13:43:00.024877: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:43:00.026660: The split file contains 1 splits.
2023-09-03 13:43:00.027514: Desired fold for training: 0
2023-09-03 13:43:00.028277: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:48:36.658087: dsc: 91.07%
2023-09-03 13:48:36.659358: miou: 83.60%
2023-09-03 13:48:36.660179: acc: 95.50%, sen: 91.14%, spe: 96.97%
2023-09-03 13:48:36.661236: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:48:36.662067: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:48:36.662813: finished real validation
2023-09-03 13:48:45.095592: train_loss -1.4114
2023-09-03 13:48:45.096949: val_loss -1.1442
2023-09-03 13:48:45.097948: Pseudo dice [0.912]
2023-09-03 13:48:45.098764: Epoch time: 464.57 s
2023-09-03 13:48:45.099522: Yayy! New best EMA pseudo Dice: 0.9093
2023-09-03 13:48:48.189847: 
2023-09-03 13:48:48.191184: Epoch 28
2023-09-03 13:48:48.192414: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-03 13:48:48.194173: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:50:47.222874: finished training epoch 28
2023-09-03 13:50:47.251635: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:50:47.253391: The split file contains 1 splits.
2023-09-03 13:50:47.254282: Desired fold for training: 0
2023-09-03 13:50:47.255237: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:56:26.117444: dsc: 91.01%
2023-09-03 13:56:26.118841: miou: 83.50%
2023-09-03 13:56:26.119735: acc: 95.48%, sen: 91.00%, spe: 96.98%
2023-09-03 13:56:26.122421: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:56:26.123610: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 13:56:26.124755: finished real validation
2023-09-03 13:56:34.549541: train_loss -1.4119
2023-09-03 13:56:34.550877: val_loss -1.1372
2023-09-03 13:56:34.552109: Pseudo dice [0.908]
2023-09-03 13:56:34.552992: Epoch time: 466.36 s
2023-09-03 13:56:35.641341: 
2023-09-03 13:56:35.642661: Epoch 29
2023-09-03 13:56:35.643721: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-03 13:56:35.645295: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:58:34.678398: finished training epoch 29
2023-09-03 13:58:34.717527: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:58:34.719753: The split file contains 1 splits.
2023-09-03 13:58:34.720874: Desired fold for training: 0
2023-09-03 13:58:34.721905: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:04:10.908759: dsc: 91.10%
2023-09-03 14:04:10.910195: miou: 83.65%
2023-09-03 14:04:10.911026: acc: 95.51%, sen: 91.27%, spe: 96.94%
2023-09-03 14:04:10.912144: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:04:10.912986: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:04:10.913835: finished real validation
2023-09-03 14:04:19.362082: train_loss -1.4132
2023-09-03 14:04:19.363502: val_loss -1.1432
2023-09-03 14:04:19.364600: Pseudo dice [0.9104]
2023-09-03 14:04:19.365515: Epoch time: 463.72 s
2023-09-03 14:04:22.401901: 
2023-09-03 14:04:22.403296: Epoch 30
2023-09-03 14:04:22.404239: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-03 14:04:22.405494: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:06:21.543879: finished training epoch 30
2023-09-03 14:06:21.573348: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:06:21.575186: The split file contains 1 splits.
2023-09-03 14:06:21.576085: Desired fold for training: 0
2023-09-03 14:06:21.576960: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:12:00.308967: dsc: 91.17%
2023-09-03 14:12:00.311200: miou: 83.77%
2023-09-03 14:12:00.312014: acc: 95.56%, sen: 91.16%, spe: 97.04%
2023-09-03 14:12:00.313121: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:12:00.313932: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:12:00.314668: finished real validation
2023-09-03 14:12:08.764388: train_loss -1.4146
2023-09-03 14:12:08.765868: val_loss -1.1398
2023-09-03 14:12:08.767271: Pseudo dice [0.9096]
2023-09-03 14:12:08.768705: Epoch time: 466.36 s
2023-09-03 14:12:08.769942: Yayy! New best EMA pseudo Dice: 0.9093
2023-09-03 14:12:11.705611: 
2023-09-03 14:12:11.707107: Epoch 31
2023-09-03 14:12:11.708149: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-03 14:12:11.709447: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:14:10.868762: finished training epoch 31
2023-09-03 14:14:10.917531: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:14:10.919772: The split file contains 1 splits.
2023-09-03 14:14:10.920796: Desired fold for training: 0
2023-09-03 14:14:10.921753: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:19:42.609307: dsc: 91.19%
2023-09-03 14:19:42.610641: miou: 83.80%
2023-09-03 14:19:42.611505: acc: 95.52%, sen: 92.05%, spe: 96.69%
2023-09-03 14:19:42.612703: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:19:42.613710: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:19:42.614688: finished real validation
2023-09-03 14:19:51.053621: train_loss -1.4155
2023-09-03 14:19:51.056276: val_loss -1.1369
2023-09-03 14:19:51.057650: Pseudo dice [0.9076]
2023-09-03 14:19:51.058809: Epoch time: 459.35 s
2023-09-03 14:19:52.150415: 
2023-09-03 14:19:52.151837: Epoch 32
2023-09-03 14:19:52.152764: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-03 14:19:52.154447: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:21:51.298226: finished training epoch 32
2023-09-03 14:21:51.335735: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:21:51.337837: The split file contains 1 splits.
2023-09-03 14:21:51.338965: Desired fold for training: 0
2023-09-03 14:21:51.340055: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:27:29.705228: dsc: 91.08%
2023-09-03 14:27:29.708697: miou: 83.62%
2023-09-03 14:27:29.711059: acc: 95.49%, sen: 91.52%, spe: 96.82%
2023-09-03 14:27:29.713893: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:27:29.714996: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:27:29.715947: finished real validation
2023-09-03 14:27:38.165542: train_loss -1.4175
2023-09-03 14:27:38.168918: val_loss -1.1106
2023-09-03 14:27:38.170560: Pseudo dice [0.9046]
2023-09-03 14:27:38.171979: Epoch time: 466.02 s
2023-09-03 14:27:39.280643: 
2023-09-03 14:27:39.282113: Epoch 33
2023-09-03 14:27:39.283404: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-03 14:27:39.285153: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:29:38.528605: finished training epoch 33
2023-09-03 14:29:38.558995: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:29:38.561632: The split file contains 1 splits.
2023-09-03 14:29:38.562873: Desired fold for training: 0
2023-09-03 14:29:38.563878: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:35:43.837884: dsc: 90.97%
2023-09-03 14:35:43.839481: miou: 83.44%
2023-09-03 14:35:43.840356: acc: 95.43%, sen: 91.53%, spe: 96.74%
2023-09-03 14:35:43.841494: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:35:43.842361: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:35:43.843160: finished real validation
2023-09-03 14:35:52.285603: train_loss -1.4174
2023-09-03 14:35:52.288125: val_loss -1.1245
2023-09-03 14:35:52.289764: Pseudo dice [0.9067]
2023-09-03 14:35:52.290695: Epoch time: 493.01 s
2023-09-03 14:35:53.424179: 
2023-09-03 14:35:53.425755: Epoch 34
2023-09-03 14:35:53.426709: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-03 14:35:53.428112: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:37:52.657758: finished training epoch 34
2023-09-03 14:37:52.684089: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:37:52.685771: The split file contains 1 splits.
2023-09-03 14:37:52.687070: Desired fold for training: 0
2023-09-03 14:37:52.692321: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:43:31.133226: dsc: 90.86%
2023-09-03 14:43:31.134742: miou: 83.25%
2023-09-03 14:43:31.135571: acc: 95.41%, sen: 90.79%, spe: 96.96%
2023-09-03 14:43:31.136734: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:43:31.137603: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:43:31.138332: finished real validation
2023-09-03 14:43:39.571399: train_loss -1.4191
2023-09-03 14:43:39.572726: val_loss -1.1167
2023-09-03 14:43:39.573862: Pseudo dice [0.905]
2023-09-03 14:43:39.574948: Epoch time: 466.15 s
2023-09-03 14:43:40.706834: 
2023-09-03 14:43:40.708147: Epoch 35
2023-09-03 14:43:40.709057: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-03 14:43:40.710308: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:45:39.922840: finished training epoch 35
2023-09-03 14:45:39.952586: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:45:39.954484: The split file contains 1 splits.
2023-09-03 14:45:39.955341: Desired fold for training: 0
2023-09-03 14:45:39.956159: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:51:10.467219: dsc: 91.03%
2023-09-03 14:51:10.468520: miou: 83.53%
2023-09-03 14:51:10.469348: acc: 95.49%, sen: 90.96%, spe: 97.01%
2023-09-03 14:51:10.470443: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:51:10.471525: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:51:10.472556: finished real validation
2023-09-03 14:51:18.898350: train_loss -1.4183
2023-09-03 14:51:18.899756: val_loss -1.1509
2023-09-03 14:51:18.901387: Pseudo dice [0.9129]
2023-09-03 14:51:18.902310: Epoch time: 458.19 s
2023-09-03 14:51:20.033211: 
2023-09-03 14:51:20.034590: Epoch 36
2023-09-03 14:51:20.035442: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-03 14:51:20.036656: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:53:19.122011: finished training epoch 36
2023-09-03 14:53:19.151601: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:53:19.154111: The split file contains 1 splits.
2023-09-03 14:53:19.155911: Desired fold for training: 0
2023-09-03 14:53:19.158417: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:58:55.467925: dsc: 90.93%
2023-09-03 14:58:55.469564: miou: 83.38%
2023-09-03 14:58:55.470662: acc: 95.42%, sen: 91.43%, spe: 96.76%
2023-09-03 14:58:55.472154: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:58:55.473068: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 14:58:55.473998: finished real validation
2023-09-03 14:59:03.941163: train_loss -1.4209
2023-09-03 14:59:03.942980: val_loss -1.1444
2023-09-03 14:59:03.944298: Pseudo dice [0.9118]
2023-09-03 14:59:03.945310: Epoch time: 463.91 s
2023-09-03 14:59:05.077477: 
2023-09-03 14:59:05.078642: Epoch 37
2023-09-03 14:59:05.079593: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-03 14:59:05.080869: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:01:04.207806: finished training epoch 37
2023-09-03 15:01:04.236804: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:01:04.238547: The split file contains 1 splits.
2023-09-03 15:01:04.239407: Desired fold for training: 0
2023-09-03 15:01:04.240203: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:06:34.442739: dsc: 91.14%
2023-09-03 15:06:34.444197: miou: 83.72%
2023-09-03 15:06:34.445107: acc: 95.48%, sen: 92.32%, spe: 96.55%
2023-09-03 15:06:34.446470: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:06:34.447378: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:06:34.448380: finished real validation
2023-09-03 15:06:42.906929: train_loss -1.4195
2023-09-03 15:06:42.908284: val_loss -1.1223
2023-09-03 15:06:42.909492: Pseudo dice [0.9062]
2023-09-03 15:06:42.911151: Epoch time: 457.83 s
2023-09-03 15:06:44.029483: 
2023-09-03 15:06:44.030946: Epoch 38
2023-09-03 15:06:44.031863: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-03 15:06:44.033117: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:08:43.105078: finished training epoch 38
2023-09-03 15:08:43.134236: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:08:43.136148: The split file contains 1 splits.
2023-09-03 15:08:43.137212: Desired fold for training: 0
2023-09-03 15:08:43.138188: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:14:14.136064: dsc: 91.21%
2023-09-03 15:14:14.138506: miou: 83.83%
2023-09-03 15:14:14.139647: acc: 95.56%, sen: 91.46%, spe: 96.94%
2023-09-03 15:14:14.141671: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:14:14.142779: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:14:14.143784: finished real validation
2023-09-03 15:14:22.591837: train_loss -1.4215
2023-09-03 15:14:22.593369: val_loss -1.1211
2023-09-03 15:14:22.594625: Pseudo dice [0.9082]
2023-09-03 15:14:22.595562: Epoch time: 458.56 s
2023-09-03 15:14:23.723091: 
2023-09-03 15:14:23.724412: Epoch 39
2023-09-03 15:14:23.725787: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-03 15:14:23.727712: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:16:22.747740: finished training epoch 39
2023-09-03 15:16:22.779245: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:16:22.781218: The split file contains 1 splits.
2023-09-03 15:16:22.782426: Desired fold for training: 0
2023-09-03 15:16:22.783287: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:21:58.016462: dsc: 91.20%
2023-09-03 15:21:58.017953: miou: 83.83%
2023-09-03 15:21:58.018960: acc: 95.58%, sen: 91.07%, spe: 97.10%
2023-09-03 15:21:58.020214: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:21:58.021124: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:21:58.022092: finished real validation
2023-09-03 15:22:06.461879: train_loss -1.4223
2023-09-03 15:22:06.463274: val_loss -1.1397
2023-09-03 15:22:06.464417: Pseudo dice [0.9105]
2023-09-03 15:22:06.465343: Epoch time: 462.74 s
2023-09-03 15:22:09.473835: 
2023-09-03 15:22:09.475361: Epoch 40
2023-09-03 15:22:09.476326: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-03 15:22:09.477592: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:24:08.569630: finished training epoch 40
2023-09-03 15:24:08.598672: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:24:08.600600: The split file contains 1 splits.
2023-09-03 15:24:08.601683: Desired fold for training: 0
2023-09-03 15:24:08.602576: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:29:37.157459: dsc: 91.23%
2023-09-03 15:29:37.159022: miou: 83.87%
2023-09-03 15:29:37.160200: acc: 95.60%, sen: 90.91%, spe: 97.18%
2023-09-03 15:29:37.161929: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:29:37.163039: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:29:37.164072: finished real validation
2023-09-03 15:29:45.611079: train_loss -1.4228
2023-09-03 15:29:45.612540: val_loss -1.1231
2023-09-03 15:29:45.613785: Pseudo dice [0.9094]
2023-09-03 15:29:45.614927: Epoch time: 456.14 s
2023-09-03 15:29:46.791612: 
2023-09-03 15:29:46.793134: Epoch 41
2023-09-03 15:29:46.794102: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-03 15:29:46.795834: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:31:45.858985: finished training epoch 41
2023-09-03 15:31:45.887534: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:31:45.889524: The split file contains 1 splits.
2023-09-03 15:31:45.890489: Desired fold for training: 0
2023-09-03 15:31:45.891456: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:37:21.218256: dsc: 91.21%
2023-09-03 15:37:21.219665: miou: 83.83%
2023-09-03 15:37:21.220558: acc: 95.58%, sen: 91.19%, spe: 97.05%
2023-09-03 15:37:21.221786: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:37:21.222817: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:37:21.223835: finished real validation
2023-09-03 15:37:29.672808: train_loss -1.4246
2023-09-03 15:37:29.674174: val_loss -1.1526
2023-09-03 15:37:29.675350: Pseudo dice [0.9138]
2023-09-03 15:37:29.676296: Epoch time: 462.88 s
2023-09-03 15:37:29.677158: Yayy! New best EMA pseudo Dice: 0.9094
2023-09-03 15:37:33.192389: 
2023-09-03 15:37:33.194013: Epoch 42
2023-09-03 15:37:33.195235: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-03 15:37:33.196567: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:39:32.361037: finished training epoch 42
2023-09-03 15:39:32.394540: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:39:32.396333: The split file contains 1 splits.
2023-09-03 15:39:32.397234: Desired fold for training: 0
2023-09-03 15:39:32.398084: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:45:49.486447: dsc: 91.24%
2023-09-03 15:45:49.487959: miou: 83.89%
2023-09-03 15:45:49.488881: acc: 95.58%, sen: 91.61%, spe: 96.91%
2023-09-03 15:45:49.490206: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:45:49.491086: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:45:49.491982: finished real validation
2023-09-03 15:45:57.957530: train_loss -1.4263
2023-09-03 15:45:57.958950: val_loss -1.1409
2023-09-03 15:45:57.960140: Pseudo dice [0.9136]
2023-09-03 15:45:57.961031: Epoch time: 504.77 s
2023-09-03 15:45:57.961851: Yayy! New best EMA pseudo Dice: 0.9098
2023-09-03 15:46:00.956605: 
2023-09-03 15:46:00.958029: Epoch 43
2023-09-03 15:46:00.958974: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-03 15:46:00.960271: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:48:00.081310: finished training epoch 43
2023-09-03 15:48:00.108876: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:48:00.110583: The split file contains 1 splits.
2023-09-03 15:48:00.111740: Desired fold for training: 0
2023-09-03 15:48:00.112742: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:53:39.299384: dsc: 91.18%
2023-09-03 15:53:39.300731: miou: 83.78%
2023-09-03 15:53:39.301630: acc: 95.50%, sen: 92.36%, spe: 96.56%
2023-09-03 15:53:39.302932: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:53:39.303777: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 15:53:39.304554: finished real validation
2023-09-03 15:53:47.766398: train_loss -1.4264
2023-09-03 15:53:47.767997: val_loss -1.1219
2023-09-03 15:53:47.769255: Pseudo dice [0.9085]
2023-09-03 15:53:47.770144: Epoch time: 466.81 s
2023-09-03 15:53:48.884078: 
2023-09-03 15:53:48.885443: Epoch 44
2023-09-03 15:53:48.886469: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-03 15:53:48.887794: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:55:47.985449: finished training epoch 44
2023-09-03 15:55:48.015719: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:55:48.017642: The split file contains 1 splits.
2023-09-03 15:55:48.018577: Desired fold for training: 0
2023-09-03 15:55:48.019793: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:01:24.438368: dsc: 91.26%
2023-09-03 16:01:25.372154: miou: 83.93%
2023-09-03 16:01:25.373935: acc: 95.58%, sen: 91.76%, spe: 96.86%
2023-09-03 16:01:25.376263: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:01:25.381827: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:01:25.383483: finished real validation
2023-09-03 16:01:33.832724: train_loss -1.4264
2023-09-03 16:01:33.834128: val_loss -1.1127
2023-09-03 16:01:33.835287: Pseudo dice [0.9087]
2023-09-03 16:01:33.836202: Epoch time: 464.95 s
2023-09-03 16:01:34.922233: 
2023-09-03 16:01:34.923599: Epoch 45
2023-09-03 16:01:34.924598: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-03 16:01:34.925910: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:03:33.933030: finished training epoch 45
2023-09-03 16:03:33.962432: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:03:33.965017: The split file contains 1 splits.
2023-09-03 16:03:33.966193: Desired fold for training: 0
2023-09-03 16:03:33.967319: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:09:00.210589: dsc: 91.27%
2023-09-03 16:09:00.211909: miou: 83.94%
2023-09-03 16:09:00.212863: acc: 95.62%, sen: 91.10%, spe: 97.14%
2023-09-03 16:09:00.214104: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:09:00.215054: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:09:00.215928: finished real validation
2023-09-03 16:09:08.655968: train_loss -1.4284
2023-09-03 16:09:08.657634: val_loss -1.151
2023-09-03 16:09:08.658964: Pseudo dice [0.9156]
2023-09-03 16:09:08.660022: Epoch time: 453.74 s
2023-09-03 16:09:08.660896: Yayy! New best EMA pseudo Dice: 0.9102
2023-09-03 16:09:11.668256: 
2023-09-03 16:09:11.669568: Epoch 46
2023-09-03 16:09:11.670519: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-03 16:09:11.671830: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:11:10.727617: finished training epoch 46
2023-09-03 16:11:10.756215: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:11:10.757931: The split file contains 1 splits.
2023-09-03 16:11:10.759122: Desired fold for training: 0
2023-09-03 16:11:10.760003: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:17:13.212927: dsc: 91.28%
2023-09-03 16:17:13.214527: miou: 83.95%
2023-09-03 16:17:13.215491: acc: 95.63%, sen: 91.01%, spe: 97.18%
2023-09-03 16:17:13.216863: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:17:13.217997: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:17:13.219052: finished real validation
2023-09-03 16:17:21.667974: train_loss -1.429
2023-09-03 16:17:21.669506: val_loss -1.0904
2023-09-03 16:17:21.670753: Pseudo dice [0.9069]
2023-09-03 16:17:21.671800: Epoch time: 490.0 s
2023-09-03 16:17:22.754753: 
2023-09-03 16:17:22.756420: Epoch 47
2023-09-03 16:17:22.757768: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-03 16:17:22.759151: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:19:21.663187: finished training epoch 47
2023-09-03 16:19:21.692225: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:19:21.694121: The split file contains 1 splits.
2023-09-03 16:19:21.695096: Desired fold for training: 0
2023-09-03 16:19:21.695998: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:24:54.146590: dsc: 91.28%
2023-09-03 16:24:54.148000: miou: 83.96%
2023-09-03 16:24:54.149204: acc: 95.59%, sen: 91.68%, spe: 96.91%
2023-09-03 16:24:54.150874: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:24:54.151995: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:24:54.153097: finished real validation
2023-09-03 16:25:02.610312: train_loss -1.4286
2023-09-03 16:25:02.612502: val_loss -1.1128
2023-09-03 16:25:02.614056: Pseudo dice [0.9085]
2023-09-03 16:25:02.615256: Epoch time: 459.86 s
2023-09-03 16:25:03.700150: 
2023-09-03 16:25:03.702162: Epoch 48
2023-09-03 16:25:03.704265: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-03 16:25:03.707657: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:27:02.559822: finished training epoch 48
2023-09-03 16:27:02.590314: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:27:02.592270: The split file contains 1 splits.
2023-09-03 16:27:02.593154: Desired fold for training: 0
2023-09-03 16:27:02.594034: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:32:24.667915: dsc: 91.19%
2023-09-03 16:32:24.669306: miou: 83.81%
2023-09-03 16:32:24.670843: acc: 95.57%, sen: 91.15%, spe: 97.06%
2023-09-03 16:32:24.672032: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:32:24.673125: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:32:24.674336: finished real validation
2023-09-03 16:32:33.125899: train_loss -1.4297
2023-09-03 16:32:33.127253: val_loss -1.0931
2023-09-03 16:32:33.128559: Pseudo dice [0.9067]
2023-09-03 16:32:33.129970: Epoch time: 449.43 s
2023-09-03 16:32:34.228679: 
2023-09-03 16:32:34.230266: Epoch 49
2023-09-03 16:32:34.231364: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-03 16:32:34.232887: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:34:33.217477: finished training epoch 49
2023-09-03 16:34:33.246498: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:34:33.248392: The split file contains 1 splits.
2023-09-03 16:34:33.249434: Desired fold for training: 0
2023-09-03 16:34:33.250378: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:40:04.214095: dsc: 91.42%
2023-09-03 16:40:04.215546: miou: 84.19%
2023-09-03 16:40:04.216532: acc: 95.68%, sen: 91.47%, spe: 97.10%
2023-09-03 16:40:04.217816: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:40:04.218776: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:40:04.219809: finished real validation
2023-09-03 16:40:12.687728: train_loss -1.4296
2023-09-03 16:40:12.689105: val_loss -1.1266
2023-09-03 16:40:12.690440: Pseudo dice [0.9124]
2023-09-03 16:40:12.691424: Epoch time: 458.46 s
2023-09-03 16:40:15.648612: 
2023-09-03 16:40:15.649900: Epoch 50
2023-09-03 16:40:15.651138: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-03 16:40:15.652432: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:42:14.643906: finished training epoch 50
2023-09-03 16:42:14.677884: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:42:14.679753: The split file contains 1 splits.
2023-09-03 16:42:14.680682: Desired fold for training: 0
2023-09-03 16:42:14.681535: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:47:32.920700: dsc: 91.15%
2023-09-03 16:47:32.922350: miou: 83.74%
2023-09-03 16:47:32.923463: acc: 95.54%, sen: 91.35%, spe: 96.95%
2023-09-03 16:47:32.925133: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:47:32.926154: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:47:32.927201: finished real validation
2023-09-03 16:47:41.374482: train_loss -1.4305
2023-09-03 16:47:41.375884: val_loss -1.0879
2023-09-03 16:47:41.377041: Pseudo dice [0.9072]
2023-09-03 16:47:41.378016: Epoch time: 445.73 s
2023-09-03 16:47:42.457140: 
2023-09-03 16:47:42.459630: Epoch 51
2023-09-03 16:47:42.461024: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-03 16:47:42.462949: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:49:41.542094: finished training epoch 51
2023-09-03 16:49:41.573758: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:49:41.576922: The split file contains 1 splits.
2023-09-03 16:49:41.579222: Desired fold for training: 0
2023-09-03 16:49:41.581107: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:55:15.292519: dsc: 91.18%
2023-09-03 16:55:15.809219: miou: 83.80%
2023-09-03 16:55:15.810414: acc: 95.54%, sen: 91.78%, spe: 96.80%
2023-09-03 16:55:15.812158: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:55:15.813137: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 16:55:15.814133: finished real validation
2023-09-03 16:55:24.260242: train_loss -1.431
2023-09-03 16:55:24.261967: val_loss -1.1098
2023-09-03 16:55:24.264028: Pseudo dice [0.9092]
2023-09-03 16:55:24.265193: Epoch time: 461.8 s
2023-09-03 16:55:25.373863: 
2023-09-03 16:55:25.375412: Epoch 52
2023-09-03 16:55:25.376535: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-03 16:55:25.378340: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:57:24.380211: finished training epoch 52
2023-09-03 16:57:24.425573: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:57:24.427441: The split file contains 1 splits.
2023-09-03 16:57:24.428428: Desired fold for training: 0
2023-09-03 16:57:24.429350: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:03:55.168784: dsc: 91.31%
2023-09-03 17:03:55.170010: miou: 84.02%
2023-09-03 17:03:55.170918: acc: 95.60%, sen: 91.88%, spe: 96.86%
2023-09-03 17:03:55.172266: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:03:55.173123: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:03:55.173936: finished real validation
2023-09-03 17:04:03.624989: train_loss -1.4319
2023-09-03 17:04:03.626297: val_loss -1.1355
2023-09-03 17:04:03.627473: Pseudo dice [0.9139]
2023-09-03 17:04:03.628458: Epoch time: 518.25 s
2023-09-03 17:04:04.743161: 
2023-09-03 17:04:04.744540: Epoch 53
2023-09-03 17:04:04.745593: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-03 17:04:04.746878: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:06:03.803639: finished training epoch 53
2023-09-03 17:06:03.843344: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:06:03.845325: The split file contains 1 splits.
2023-09-03 17:06:03.846363: Desired fold for training: 0
2023-09-03 17:06:03.847327: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:11:30.117475: dsc: 91.26%
2023-09-03 17:11:30.118849: miou: 83.92%
2023-09-03 17:11:30.119833: acc: 95.58%, sen: 91.67%, spe: 96.90%
2023-09-03 17:11:30.121151: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:11:30.122113: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:11:30.123006: finished real validation
2023-09-03 17:11:38.558704: train_loss -1.432
2023-09-03 17:11:38.560490: val_loss -1.1173
2023-09-03 17:11:38.561650: Pseudo dice [0.9122]
2023-09-03 17:11:38.563130: Epoch time: 453.82 s
2023-09-03 17:11:39.691665: 
2023-09-03 17:11:39.692922: Epoch 54
2023-09-03 17:11:39.693892: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-03 17:11:39.695166: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:13:38.608785: finished training epoch 54
2023-09-03 17:13:38.637690: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:13:38.639459: The split file contains 1 splits.
2023-09-03 17:13:38.640839: Desired fold for training: 0
2023-09-03 17:13:38.641909: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:19:20.899813: dsc: 91.08%
2023-09-03 17:19:20.901127: miou: 83.62%
2023-09-03 17:19:20.902040: acc: 95.52%, sen: 90.98%, spe: 97.04%
2023-09-03 17:19:20.903330: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:19:20.904291: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:19:20.905603: finished real validation
2023-09-03 17:19:29.336954: train_loss -1.4317
2023-09-03 17:19:29.338364: val_loss -1.1033
2023-09-03 17:19:29.339551: Pseudo dice [0.9078]
2023-09-03 17:19:29.340515: Epoch time: 469.65 s
2023-09-03 17:19:30.444990: 
2023-09-03 17:19:30.446321: Epoch 55
2023-09-03 17:19:30.447252: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-03 17:19:30.448558: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:21:29.397602: finished training epoch 55
2023-09-03 17:21:29.427074: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:21:29.429131: The split file contains 1 splits.
2023-09-03 17:21:29.430153: Desired fold for training: 0
2023-09-03 17:21:29.431133: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:27:02.490109: dsc: 91.27%
2023-09-03 17:27:02.491435: miou: 83.94%
2023-09-03 17:27:02.492359: acc: 95.59%, sen: 91.71%, spe: 96.89%
2023-09-03 17:27:02.493804: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:27:02.494857: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:27:02.495707: finished real validation
2023-09-03 17:27:10.927519: train_loss -1.4331
2023-09-03 17:27:10.928917: val_loss -1.1202
2023-09-03 17:27:10.930179: Pseudo dice [0.9108]
2023-09-03 17:27:10.931178: Epoch time: 460.48 s
2023-09-03 17:27:12.038896: 
2023-09-03 17:27:12.040794: Epoch 56
2023-09-03 17:27:12.042046: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-03 17:27:12.043676: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:29:11.095494: finished training epoch 56
2023-09-03 17:29:11.124789: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:29:11.126539: The split file contains 1 splits.
2023-09-03 17:29:11.127727: Desired fold for training: 0
2023-09-03 17:29:11.128673: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:34:37.051886: dsc: 91.23%
2023-09-03 17:34:37.053733: miou: 83.88%
2023-09-03 17:34:37.055061: acc: 95.57%, sen: 91.69%, spe: 96.87%
2023-09-03 17:34:37.056447: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:34:37.057661: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:34:37.058784: finished real validation
2023-09-03 17:34:45.515625: train_loss -1.4329
2023-09-03 17:34:45.517102: val_loss -1.1289
2023-09-03 17:34:45.518336: Pseudo dice [0.9121]
2023-09-03 17:34:45.519294: Epoch time: 453.48 s
2023-09-03 17:34:45.520202: Yayy! New best EMA pseudo Dice: 0.9102
2023-09-03 17:34:48.482008: 
2023-09-03 17:34:48.483563: Epoch 57
2023-09-03 17:34:48.484626: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-03 17:34:48.485988: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:36:47.373257: finished training epoch 57
2023-09-03 17:36:47.402493: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:36:47.404334: The split file contains 1 splits.
2023-09-03 17:36:47.405480: Desired fold for training: 0
2023-09-03 17:36:47.406331: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:42:16.234847: dsc: 91.16%
2023-09-03 17:42:16.236260: miou: 83.76%
2023-09-03 17:42:16.237276: acc: 95.55%, sen: 91.35%, spe: 96.96%
2023-09-03 17:42:16.238680: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:42:16.239890: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:42:16.241044: finished real validation
2023-09-03 17:42:24.698232: train_loss -1.4348
2023-09-03 17:42:24.700049: val_loss -1.1118
2023-09-03 17:42:24.701342: Pseudo dice [0.91]
2023-09-03 17:42:24.702483: Epoch time: 456.22 s
2023-09-03 17:42:25.803751: 
2023-09-03 17:42:25.805173: Epoch 58
2023-09-03 17:42:25.806561: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-03 17:42:25.807986: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:44:24.771289: finished training epoch 58
2023-09-03 17:44:24.803290: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:44:24.805419: The split file contains 1 splits.
2023-09-03 17:44:24.806360: Desired fold for training: 0
2023-09-03 17:44:24.807262: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:50:25.186504: dsc: 91.14%
2023-09-03 17:50:25.188036: miou: 83.72%
2023-09-03 17:50:25.189227: acc: 95.54%, sen: 91.24%, spe: 96.98%
2023-09-03 17:50:25.190974: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:50:25.192104: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:50:25.193267: finished real validation
2023-09-03 17:50:33.645388: train_loss -1.434
2023-09-03 17:50:33.646925: val_loss -1.1145
2023-09-03 17:50:33.648084: Pseudo dice [0.9111]
2023-09-03 17:50:33.649183: Epoch time: 487.84 s
2023-09-03 17:50:33.650170: Yayy! New best EMA pseudo Dice: 0.9103
2023-09-03 17:50:36.616076: 
2023-09-03 17:50:36.617692: Epoch 59
2023-09-03 17:50:36.618767: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-03 17:50:36.620074: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:52:35.614454: finished training epoch 59
2023-09-03 17:52:35.644021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:52:35.645970: The split file contains 1 splits.
2023-09-03 17:52:35.646986: Desired fold for training: 0
2023-09-03 17:52:35.647949: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:58:01.142114: dsc: 91.11%
2023-09-03 17:58:01.143661: miou: 83.67%
2023-09-03 17:58:01.144657: acc: 95.53%, sen: 91.13%, spe: 97.00%
2023-09-03 17:58:01.146396: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:58:01.147661: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 17:58:01.148792: finished real validation
2023-09-03 17:58:09.592269: train_loss -1.4342
2023-09-03 17:58:09.594647: val_loss -1.0905
2023-09-03 17:58:09.595955: Pseudo dice [0.9088]
2023-09-03 17:58:09.597360: Epoch time: 452.98 s
2023-09-03 17:58:12.561127: 
2023-09-03 17:58:12.562596: Epoch 60
2023-09-03 17:58:12.563664: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-03 17:58:12.565092: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:00:11.543480: finished training epoch 60
2023-09-03 18:00:11.581155: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:00:11.583498: The split file contains 1 splits.
2023-09-03 18:00:11.584520: Desired fold for training: 0
2023-09-03 18:00:11.585465: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:05:35.200038: dsc: 91.23%
2023-09-03 18:05:35.201585: miou: 83.88%
2023-09-03 18:05:35.202605: acc: 95.61%, sen: 90.90%, spe: 97.19%
2023-09-03 18:05:35.203867: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 18:05:35.205031: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 18:05:35.206129: finished real validation
2023-09-03 18:05:43.650679: train_loss -1.4358
2023-09-03 18:05:43.652366: val_loss -1.0941
2023-09-03 18:05:43.653637: Pseudo dice [0.9109]
2023-09-03 18:05:43.654737: Epoch time: 451.09 s
2023-09-03 18:05:44.812550: 
2023-09-03 18:05:44.814063: Epoch 61
2023-09-03 18:05:44.815203: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-03 18:05:44.816739: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:07:43.824515: finished training epoch 61
2023-09-03 18:07:43.853865: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:07:43.856002: The split file contains 1 splits.
2023-09-03 18:07:43.857118: Desired fold for training: 0
2023-09-03 18:07:43.858084: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:13:06.992498: dsc: 91.16%
2023-09-03 18:13:06.994148: miou: 83.76%
2023-09-03 18:13:06.995183: acc: 95.53%, sen: 91.62%, spe: 96.85%
2023-09-03 18:13:06.996452: current best miou: 0.8420790408050584 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 18:13:06.997713: current best dsc: 0.9142702589320357 at epoch: 14, (14, 0.8420790408050584, 0.9142702589320357)
2023-09-03 18:13:06.998950: finished real validation
2023-09-03 18:13:15.442125: train_loss -1.4353
2023-09-03 18:13:15.444136: val_loss -1.1284
2023-09-03 18:13:15.445587: Pseudo dice [0.9148]
2023-09-03 18:13:15.446722: Epoch time: 450.63 s
2023-09-03 18:13:15.447955: Yayy! New best EMA pseudo Dice: 0.9107
2023-09-03 18:13:18.429606: 
2023-09-03 18:13:18.431329: Epoch 62
2023-09-03 18:13:18.432495: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-03 18:13:18.433914: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:15:17.417522: finished training epoch 62
2023-09-03 18:15:17.448251: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:15:17.450317: The split file contains 1 splits.
2023-09-03 18:15:17.451357: Desired fold for training: 0
2023-09-03 18:15:17.452380: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:20:49.638219: dsc: 91.45%
2023-09-03 18:20:49.639655: miou: 84.25%
2023-09-03 18:20:49.640740: acc: 95.67%, sen: 92.02%, spe: 96.90%
2023-09-03 18:20:49.642203: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:20:49.643410: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:20:51.588979: finished real validation
2023-09-03 18:21:00.043283: train_loss -1.4355
2023-09-03 18:21:00.044729: val_loss -1.143
2023-09-03 18:21:00.046031: Pseudo dice [0.917]
2023-09-03 18:21:00.047096: Epoch time: 461.62 s
2023-09-03 18:21:00.048060: Yayy! New best EMA pseudo Dice: 0.9113
2023-09-03 18:21:02.995401: 
2023-09-03 18:21:02.996870: Epoch 63
2023-09-03 18:21:02.998159: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-03 18:21:02.999654: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:23:01.939418: finished training epoch 63
2023-09-03 18:23:01.967769: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:23:01.969507: The split file contains 1 splits.
2023-09-03 18:23:01.970525: Desired fold for training: 0
2023-09-03 18:23:01.971485: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:29:48.302024: dsc: 91.26%
2023-09-03 18:29:48.303382: miou: 83.92%
2023-09-03 18:29:48.304363: acc: 95.59%, sen: 91.43%, spe: 96.99%
2023-09-03 18:29:48.305591: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:29:48.306545: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:29:48.307386: finished real validation
2023-09-03 18:29:56.733877: train_loss -1.4361
2023-09-03 18:29:56.735590: val_loss -1.116
2023-09-03 18:29:56.736969: Pseudo dice [0.9111]
2023-09-03 18:29:56.738029: Epoch time: 533.74 s
2023-09-03 18:29:57.865432: 
2023-09-03 18:29:57.866608: Epoch 64
2023-09-03 18:29:57.867618: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-03 18:29:57.868967: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:31:56.796926: finished training epoch 64
2023-09-03 18:31:56.836574: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:31:56.839061: The split file contains 1 splits.
2023-09-03 18:31:56.840048: Desired fold for training: 0
2023-09-03 18:31:56.841039: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:37:31.434819: dsc: 91.33%
2023-09-03 18:37:31.436257: miou: 84.04%
2023-09-03 18:37:31.437272: acc: 95.62%, sen: 91.71%, spe: 96.93%
2023-09-03 18:37:31.438645: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:37:31.439643: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:37:31.440601: finished real validation
2023-09-03 18:37:39.889006: train_loss -1.4369
2023-09-03 18:37:39.890599: val_loss -1.1114
2023-09-03 18:37:39.891833: Pseudo dice [0.9098]
2023-09-03 18:37:39.892879: Epoch time: 462.03 s
2023-09-03 18:37:41.020924: 
2023-09-03 18:37:41.022459: Epoch 65
2023-09-03 18:37:41.023594: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-03 18:37:41.025061: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:39:39.965854: finished training epoch 65
2023-09-03 18:39:39.994625: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:39:39.996616: The split file contains 1 splits.
2023-09-03 18:39:39.997706: Desired fold for training: 0
2023-09-03 18:39:39.998689: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:45:14.035138: dsc: 91.18%
2023-09-03 18:45:14.036878: miou: 83.79%
2023-09-03 18:45:14.038165: acc: 95.55%, sen: 91.38%, spe: 96.96%
2023-09-03 18:45:14.040400: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:45:14.041623: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:45:14.042916: finished real validation
2023-09-03 18:45:22.494318: train_loss -1.4368
2023-09-03 18:45:22.495838: val_loss -1.1342
2023-09-03 18:45:22.497535: Pseudo dice [0.9159]
2023-09-03 18:45:22.498780: Epoch time: 461.47 s
2023-09-03 18:45:22.500118: Yayy! New best EMA pseudo Dice: 0.9116
2023-09-03 18:45:25.587408: 
2023-09-03 18:45:25.589020: Epoch 66
2023-09-03 18:45:25.590331: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-03 18:45:25.591889: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:47:24.517599: finished training epoch 66
2023-09-03 18:47:24.546072: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:47:24.548004: The split file contains 1 splits.
2023-09-03 18:47:24.549140: Desired fold for training: 0
2023-09-03 18:47:24.550225: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:52:48.233212: dsc: 91.22%
2023-09-03 18:52:48.234798: miou: 83.87%
2023-09-03 18:52:48.235840: acc: 95.57%, sen: 91.48%, spe: 96.95%
2023-09-03 18:52:48.237152: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:52:48.238406: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 18:52:48.239786: finished real validation
2023-09-03 18:52:56.700167: train_loss -1.4368
2023-09-03 18:52:56.701863: val_loss -1.1342
2023-09-03 18:52:56.703261: Pseudo dice [0.9147]
2023-09-03 18:52:56.704370: Epoch time: 451.11 s
2023-09-03 18:52:56.705458: Yayy! New best EMA pseudo Dice: 0.9119
2023-09-03 18:52:59.688315: 
2023-09-03 18:52:59.689940: Epoch 67
2023-09-03 18:52:59.691040: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-03 18:52:59.692796: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:54:58.611524: finished training epoch 67
2023-09-03 18:54:58.640064: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:54:58.641987: The split file contains 1 splits.
2023-09-03 18:54:58.643223: Desired fold for training: 0
2023-09-03 18:54:58.644247: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:00:32.218894: dsc: 91.27%
2023-09-03 19:00:32.220500: miou: 83.95%
2023-09-03 19:00:32.221535: acc: 95.58%, sen: 91.82%, spe: 96.85%
2023-09-03 19:00:32.223481: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:00:32.224652: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:00:32.225853: finished real validation
2023-09-03 19:00:40.675674: train_loss -1.4378
2023-09-03 19:00:40.677282: val_loss -1.1308
2023-09-03 19:00:40.678591: Pseudo dice [0.9152]
2023-09-03 19:00:40.679691: Epoch time: 460.99 s
2023-09-03 19:00:40.680726: Yayy! New best EMA pseudo Dice: 0.9122
2023-09-03 19:00:43.799472: 
2023-09-03 19:00:43.801092: Epoch 68
2023-09-03 19:00:43.802674: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-03 19:00:43.804196: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:02:42.885539: finished training epoch 68
2023-09-03 19:02:42.913491: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:02:42.915337: The split file contains 1 splits.
2023-09-03 19:02:42.916349: Desired fold for training: 0
2023-09-03 19:02:42.917326: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:08:16.060584: dsc: 91.17%
2023-09-03 19:08:16.062165: miou: 83.77%
2023-09-03 19:08:16.063467: acc: 95.55%, sen: 91.42%, spe: 96.93%
2023-09-03 19:08:16.065460: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:08:16.066910: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:08:16.068238: finished real validation
2023-09-03 19:08:24.511873: train_loss -1.4385
2023-09-03 19:08:24.513562: val_loss -1.0932
2023-09-03 19:08:24.515099: Pseudo dice [0.9101]
2023-09-03 19:08:24.516390: Epoch time: 460.71 s
2023-09-03 19:08:25.619854: 
2023-09-03 19:08:25.621286: Epoch 69
2023-09-03 19:08:25.622677: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-03 19:08:25.624313: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:10:24.648070: finished training epoch 69
2023-09-03 19:10:24.696318: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:10:24.698710: The split file contains 1 splits.
2023-09-03 19:10:24.699834: Desired fold for training: 0
2023-09-03 19:10:24.700826: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:15:54.606773: dsc: 91.24%
2023-09-03 19:15:54.608358: miou: 83.89%
2023-09-03 19:15:54.609411: acc: 95.58%, sen: 91.44%, spe: 96.98%
2023-09-03 19:15:54.611288: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:15:54.612400: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:15:54.613551: finished real validation
2023-09-03 19:16:03.071961: train_loss -1.4382
2023-09-03 19:16:03.073499: val_loss -1.0906
2023-09-03 19:16:03.075215: Pseudo dice [0.9086]
2023-09-03 19:16:03.076312: Epoch time: 457.45 s
2023-09-03 19:16:06.036349: 
2023-09-03 19:16:06.037881: Epoch 70
2023-09-03 19:16:06.038962: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-03 19:16:06.040617: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:18:05.012148: finished training epoch 70
2023-09-03 19:18:05.054499: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:18:05.057555: The split file contains 1 splits.
2023-09-03 19:18:05.059116: Desired fold for training: 0
2023-09-03 19:18:05.060678: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:23:34.055314: dsc: 91.30%
2023-09-03 19:23:34.056737: miou: 84.00%
2023-09-03 19:23:34.058078: acc: 95.59%, sen: 91.99%, spe: 96.80%
2023-09-03 19:23:34.059597: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:23:34.060862: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:23:34.061917: finished real validation
2023-09-03 19:23:42.512500: train_loss -1.4385
2023-09-03 19:23:42.514387: val_loss -1.1074
2023-09-03 19:23:42.516807: Pseudo dice [0.9119]
2023-09-03 19:23:42.517950: Epoch time: 456.48 s
2023-09-03 19:23:43.634260: 
2023-09-03 19:23:43.635794: Epoch 71
2023-09-03 19:23:43.636876: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-03 19:23:43.638732: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:25:42.654378: finished training epoch 71
2023-09-03 19:25:42.687112: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:25:42.689362: The split file contains 1 splits.
2023-09-03 19:25:42.690488: Desired fold for training: 0
2023-09-03 19:25:42.691919: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:31:14.086174: dsc: 91.20%
2023-09-03 19:31:14.087765: miou: 83.83%
2023-09-03 19:31:14.088969: acc: 95.56%, sen: 91.55%, spe: 96.90%
2023-09-03 19:31:14.090649: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:31:14.091741: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:31:14.092893: finished real validation
2023-09-03 19:31:22.537763: train_loss -1.4394
2023-09-03 19:31:22.539419: val_loss -1.0875
2023-09-03 19:31:22.540774: Pseudo dice [0.9078]
2023-09-03 19:31:22.542097: Epoch time: 458.91 s
2023-09-03 19:31:23.662209: 
2023-09-03 19:31:23.663927: Epoch 72
2023-09-03 19:31:23.665185: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-03 19:31:23.667125: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:33:22.702009: finished training epoch 72
2023-09-03 19:33:22.731854: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:33:22.735727: The split file contains 1 splits.
2023-09-03 19:33:22.737151: Desired fold for training: 0
2023-09-03 19:33:22.738467: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:40:06.927919: dsc: 91.28%
2023-09-03 19:40:06.952423: miou: 83.96%
2023-09-03 19:40:06.953859: acc: 95.56%, sen: 92.53%, spe: 96.57%
2023-09-03 19:40:06.956221: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:40:06.957593: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:40:06.958876: finished real validation
2023-09-03 19:40:15.415702: train_loss -1.4389
2023-09-03 19:40:15.417217: val_loss -1.0855
2023-09-03 19:40:15.418555: Pseudo dice [0.9094]
2023-09-03 19:40:15.419754: Epoch time: 531.76 s
2023-09-03 19:40:16.534384: 
2023-09-03 19:40:16.535942: Epoch 73
2023-09-03 19:40:16.537086: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-03 19:40:16.538483: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:42:15.350691: finished training epoch 73
2023-09-03 19:42:15.379993: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:42:15.382019: The split file contains 1 splits.
2023-09-03 19:42:15.383120: Desired fold for training: 0
2023-09-03 19:42:15.384173: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:47:47.617481: dsc: 91.30%
2023-09-03 19:47:47.619083: miou: 83.99%
2023-09-03 19:47:47.620152: acc: 95.62%, sen: 91.40%, spe: 97.03%
2023-09-03 19:47:47.621545: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:47:47.622542: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:47:47.623485: finished real validation
2023-09-03 19:47:56.069853: train_loss -1.439
2023-09-03 19:47:56.071182: val_loss -1.1332
2023-09-03 19:47:56.072348: Pseudo dice [0.9167]
2023-09-03 19:47:56.073500: Epoch time: 459.54 s
2023-09-03 19:47:57.196510: 
2023-09-03 19:47:57.198173: Epoch 74
2023-09-03 19:47:57.199431: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-03 19:47:57.201057: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:49:56.076175: finished training epoch 74
2023-09-03 19:49:56.105530: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:49:56.107589: The split file contains 1 splits.
2023-09-03 19:49:56.108830: Desired fold for training: 0
2023-09-03 19:49:56.110030: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:55:25.360914: dsc: 91.18%
2023-09-03 19:55:25.363114: miou: 83.79%
2023-09-03 19:55:25.365271: acc: 95.57%, sen: 91.08%, spe: 97.08%
2023-09-03 19:55:25.367937: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:55:25.369271: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 19:55:25.370589: finished real validation
2023-09-03 19:55:34.810740: train_loss -1.4402
2023-09-03 19:55:34.812601: val_loss -1.1044
2023-09-03 19:55:34.814174: Pseudo dice [0.9122]
2023-09-03 19:55:34.815396: Epoch time: 457.62 s
2023-09-03 19:55:35.933515: 
2023-09-03 19:55:35.935289: Epoch 75
2023-09-03 19:55:35.936866: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-03 19:55:35.938464: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:57:35.028115: finished training epoch 75
2023-09-03 19:57:35.073756: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:57:35.075693: The split file contains 1 splits.
2023-09-03 19:57:35.076888: Desired fold for training: 0
2023-09-03 19:57:35.078182: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:04:23.077471: dsc: 91.34%
2023-09-03 20:04:23.079241: miou: 84.07%
2023-09-03 20:04:23.080743: acc: 95.64%, sen: 91.56%, spe: 97.01%
2023-09-03 20:04:23.083246: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:04:23.084714: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:04:23.086166: finished real validation
2023-09-03 20:04:31.536622: train_loss -1.4402
2023-09-03 20:04:31.538318: val_loss -1.1205
2023-09-03 20:04:31.539818: Pseudo dice [0.9138]
2023-09-03 20:04:31.540962: Epoch time: 535.6 s
2023-09-03 20:04:32.662771: 
2023-09-03 20:04:32.664529: Epoch 76
2023-09-03 20:04:32.665952: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-03 20:04:32.667924: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:06:31.535394: finished training epoch 76
2023-09-03 20:06:31.577773: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:06:31.580495: The split file contains 1 splits.
2023-09-03 20:06:31.581677: Desired fold for training: 0
2023-09-03 20:06:31.582752: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:12:03.459147: dsc: 91.34%
2023-09-03 20:12:03.460796: miou: 84.07%
2023-09-03 20:12:03.462031: acc: 95.65%, sen: 91.20%, spe: 97.15%
2023-09-03 20:12:03.463606: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:12:03.464773: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:12:03.465812: finished real validation
2023-09-03 20:12:11.926600: train_loss -1.441
2023-09-03 20:12:11.928133: val_loss -1.1158
2023-09-03 20:12:11.929472: Pseudo dice [0.914]
2023-09-03 20:12:11.930898: Epoch time: 459.27 s
2023-09-03 20:12:13.033612: 
2023-09-03 20:12:13.035415: Epoch 77
2023-09-03 20:12:13.036855: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-03 20:12:13.038480: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:14:12.103339: finished training epoch 77
2023-09-03 20:14:12.134466: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:14:12.136687: The split file contains 1 splits.
2023-09-03 20:14:12.137768: Desired fold for training: 0
2023-09-03 20:14:12.138746: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:21:07.060329: dsc: 91.26%
2023-09-03 20:21:07.061908: miou: 83.93%
2023-09-03 20:21:07.063168: acc: 95.60%, sen: 91.31%, spe: 97.04%
2023-09-03 20:21:07.064669: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:21:07.066052: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:21:07.067395: finished real validation
2023-09-03 20:21:15.493588: train_loss -1.4415
2023-09-03 20:21:15.495175: val_loss -1.1102
2023-09-03 20:21:15.496604: Pseudo dice [0.9127]
2023-09-03 20:21:15.497794: Epoch time: 542.46 s
2023-09-03 20:21:16.645208: 
2023-09-03 20:21:16.646731: Epoch 78
2023-09-03 20:21:16.647842: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-03 20:21:16.649313: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:23:15.600352: finished training epoch 78
2023-09-03 20:23:15.630027: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:23:15.632321: The split file contains 1 splits.
2023-09-03 20:23:15.633417: Desired fold for training: 0
2023-09-03 20:23:15.634452: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:28:47.726908: dsc: 91.40%
2023-09-03 20:28:47.728265: miou: 84.17%
2023-09-03 20:28:47.729352: acc: 95.68%, sen: 91.41%, spe: 97.11%
2023-09-03 20:28:47.730798: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:28:47.731872: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:28:47.732863: finished real validation
2023-09-03 20:28:56.179264: train_loss -1.4413
2023-09-03 20:28:56.180823: val_loss -1.0823
2023-09-03 20:28:56.182087: Pseudo dice [0.9083]
2023-09-03 20:28:56.183212: Epoch time: 459.54 s
2023-09-03 20:28:57.332269: 
2023-09-03 20:28:57.333859: Epoch 79
2023-09-03 20:28:57.335331: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-03 20:28:57.337894: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:30:56.275124: finished training epoch 79
2023-09-03 20:30:56.303689: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:30:56.305599: The split file contains 1 splits.
2023-09-03 20:30:56.306637: Desired fold for training: 0
2023-09-03 20:30:56.307644: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:36:29.853124: dsc: 91.14%
2023-09-03 20:36:29.855072: miou: 83.72%
2023-09-03 20:36:29.856534: acc: 95.55%, sen: 91.06%, spe: 97.05%
2023-09-03 20:36:29.858611: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:36:29.859864: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:36:29.861234: finished real validation
2023-09-03 20:36:38.303891: train_loss -1.4409
2023-09-03 20:36:38.305613: val_loss -1.0807
2023-09-03 20:36:38.307080: Pseudo dice [0.9097]
2023-09-03 20:36:38.308425: Epoch time: 460.97 s
2023-09-03 20:36:41.307565: 
2023-09-03 20:36:41.309578: Epoch 80
2023-09-03 20:36:41.311169: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-03 20:36:41.313216: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:38:40.113953: finished training epoch 80
2023-09-03 20:38:40.154181: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:38:40.157154: The split file contains 1 splits.
2023-09-03 20:38:40.158604: Desired fold for training: 0
2023-09-03 20:38:40.160055: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:44:20.703247: dsc: 91.40%
2023-09-03 20:44:20.704896: miou: 84.17%
2023-09-03 20:44:20.706190: acc: 95.68%, sen: 91.26%, spe: 97.17%
2023-09-03 20:44:20.707994: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:44:20.709231: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:44:20.710521: finished real validation
2023-09-03 20:44:29.153671: train_loss -1.4422
2023-09-03 20:44:29.155399: val_loss -1.1034
2023-09-03 20:44:29.156811: Pseudo dice [0.9124]
2023-09-03 20:44:29.158045: Epoch time: 467.85 s
2023-09-03 20:44:30.286654: 
2023-09-03 20:44:30.288586: Epoch 81
2023-09-03 20:44:30.290020: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-03 20:44:30.291898: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:46:29.178679: finished training epoch 81
2023-09-03 20:46:29.208554: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:46:29.211770: The split file contains 1 splits.
2023-09-03 20:46:29.213457: Desired fold for training: 0
2023-09-03 20:46:29.214864: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:51:55.816576: dsc: 91.30%
2023-09-03 20:51:55.820577: miou: 84.00%
2023-09-03 20:51:55.823436: acc: 95.64%, sen: 91.03%, spe: 97.19%
2023-09-03 20:51:55.826157: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:51:55.828723: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:51:55.831212: finished real validation
2023-09-03 20:52:04.268102: train_loss -1.4415
2023-09-03 20:52:04.269781: val_loss -1.098
2023-09-03 20:52:04.271184: Pseudo dice [0.9106]
2023-09-03 20:52:04.272355: Epoch time: 453.98 s
2023-09-03 20:52:05.397992: 
2023-09-03 20:52:05.399860: Epoch 82
2023-09-03 20:52:05.401306: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-03 20:52:05.402959: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:54:04.316320: finished training epoch 82
2023-09-03 20:54:04.350201: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:54:04.352576: The split file contains 1 splits.
2023-09-03 20:54:04.353748: Desired fold for training: 0
2023-09-03 20:54:04.355197: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:59:41.944356: dsc: 91.31%
2023-09-03 20:59:41.945954: miou: 84.00%
2023-09-03 20:59:41.947202: acc: 95.61%, sen: 91.61%, spe: 96.96%
2023-09-03 20:59:41.948759: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:59:41.949861: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 20:59:41.950914: finished real validation
2023-09-03 20:59:50.385366: train_loss -1.4422
2023-09-03 20:59:50.386980: val_loss -1.0993
2023-09-03 20:59:50.388479: Pseudo dice [0.9137]
2023-09-03 20:59:50.389639: Epoch time: 464.99 s
2023-09-03 20:59:51.464811: 
2023-09-03 20:59:51.466592: Epoch 83
2023-09-03 20:59:51.468103: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-03 20:59:51.469810: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:01:50.473838: finished training epoch 83
2023-09-03 21:01:50.530021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:01:50.533202: The split file contains 1 splits.
2023-09-03 21:01:50.534778: Desired fold for training: 0
2023-09-03 21:01:50.536190: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:07:39.176605: dsc: 91.20%
2023-09-03 21:07:39.178359: miou: 83.82%
2023-09-03 21:07:39.179845: acc: 95.55%, sen: 91.79%, spe: 96.81%
2023-09-03 21:07:39.181553: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:07:39.183018: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:07:39.184102: finished real validation
2023-09-03 21:07:47.615429: train_loss -1.4424
2023-09-03 21:07:47.617142: val_loss -1.1232
2023-09-03 21:07:47.618771: Pseudo dice [0.9135]
2023-09-03 21:07:47.621018: Epoch time: 476.15 s
2023-09-03 21:07:48.699395: 
2023-09-03 21:07:48.701253: Epoch 84
2023-09-03 21:07:48.702584: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-03 21:07:48.704180: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:09:47.743542: finished training epoch 84
2023-09-03 21:09:47.786185: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:09:47.790890: The split file contains 1 splits.
2023-09-03 21:09:47.792077: Desired fold for training: 0
2023-09-03 21:09:47.793158: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:16:02.491728: dsc: 91.23%
2023-09-03 21:16:02.493630: miou: 83.87%
2023-09-03 21:16:02.494916: acc: 95.58%, sen: 91.42%, spe: 96.97%
2023-09-03 21:16:02.496702: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:16:02.497952: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:16:02.499109: finished real validation
2023-09-03 21:16:10.929759: train_loss -1.4425
2023-09-03 21:16:10.931154: val_loss -1.1023
2023-09-03 21:16:10.932490: Pseudo dice [0.9109]
2023-09-03 21:16:10.933617: Epoch time: 502.23 s
2023-09-03 21:16:12.073767: 
2023-09-03 21:16:12.075368: Epoch 85
2023-09-03 21:16:12.076913: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-03 21:16:12.078688: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:18:11.031378: finished training epoch 85
2023-09-03 21:18:11.062475: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:18:11.064806: The split file contains 1 splits.
2023-09-03 21:18:11.066157: Desired fold for training: 0
2023-09-03 21:18:11.067394: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:23:47.159303: dsc: 91.23%
2023-09-03 21:23:47.160910: miou: 83.88%
2023-09-03 21:23:47.162276: acc: 95.57%, sen: 91.66%, spe: 96.88%
2023-09-03 21:23:47.163895: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:23:47.165223: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:23:47.166389: finished real validation
2023-09-03 21:23:55.600281: train_loss -1.4427
2023-09-03 21:23:55.602108: val_loss -1.1036
2023-09-03 21:23:55.603795: Pseudo dice [0.9135]
2023-09-03 21:23:55.605073: Epoch time: 463.53 s
2023-09-03 21:23:56.721130: 
2023-09-03 21:23:56.722864: Epoch 86
2023-09-03 21:23:56.724020: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-03 21:23:56.726040: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:25:55.653649: finished training epoch 86
2023-09-03 21:25:55.682720: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:25:55.685135: The split file contains 1 splits.
2023-09-03 21:25:55.686344: Desired fold for training: 0
2023-09-03 21:25:55.687876: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:31:23.076485: dsc: 91.15%
2023-09-03 21:31:23.077935: miou: 83.74%
2023-09-03 21:31:23.078972: acc: 95.55%, sen: 91.04%, spe: 97.07%
2023-09-03 21:31:23.080330: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:31:23.081445: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:31:23.082426: finished real validation
2023-09-03 21:31:31.525708: train_loss -1.4425
2023-09-03 21:31:31.527385: val_loss -1.0836
2023-09-03 21:31:31.528779: Pseudo dice [0.9088]
2023-09-03 21:31:31.530195: Epoch time: 454.81 s
2023-09-03 21:31:32.620890: 
2023-09-03 21:31:32.622477: Epoch 87
2023-09-03 21:31:32.623619: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-03 21:31:32.625032: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:33:31.751860: finished training epoch 87
2023-09-03 21:33:31.781809: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:33:31.784269: The split file contains 1 splits.
2023-09-03 21:33:31.785626: Desired fold for training: 0
2023-09-03 21:33:31.786939: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:38:56.080479: dsc: 91.29%
2023-09-03 21:38:56.082543: miou: 83.97%
2023-09-03 21:38:56.083769: acc: 95.61%, sen: 91.40%, spe: 97.03%
2023-09-03 21:38:56.085795: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:38:56.086948: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:38:56.088245: finished real validation
2023-09-03 21:39:04.528802: train_loss -1.4431
2023-09-03 21:39:04.530559: val_loss -1.0809
2023-09-03 21:39:04.532005: Pseudo dice [0.9092]
2023-09-03 21:39:04.533245: Epoch time: 451.91 s
2023-09-03 21:39:05.622730: 
2023-09-03 21:39:05.624505: Epoch 88
2023-09-03 21:39:05.625870: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-03 21:39:05.627754: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:41:04.550420: finished training epoch 88
2023-09-03 21:41:04.580868: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:41:04.583282: The split file contains 1 splits.
2023-09-03 21:41:04.584504: Desired fold for training: 0
2023-09-03 21:41:04.585624: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:46:28.678207: dsc: 91.32%
2023-09-03 21:46:28.679998: miou: 84.02%
2023-09-03 21:46:28.681288: acc: 95.64%, sen: 91.08%, spe: 97.18%
2023-09-03 21:46:28.683008: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:46:28.684120: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:46:28.685423: finished real validation
2023-09-03 21:46:37.121846: train_loss -1.444
2023-09-03 21:46:37.123626: val_loss -1.0773
2023-09-03 21:46:37.124971: Pseudo dice [0.9101]
2023-09-03 21:46:37.126122: Epoch time: 451.5 s
2023-09-03 21:46:38.208811: 
2023-09-03 21:46:38.210399: Epoch 89
2023-09-03 21:46:38.211633: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-03 21:46:38.213618: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:48:37.161922: finished training epoch 89
2023-09-03 21:48:37.192037: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:48:37.194178: The split file contains 1 splits.
2023-09-03 21:48:37.195513: Desired fold for training: 0
2023-09-03 21:48:37.196615: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:54:19.224511: dsc: 91.34%
2023-09-03 21:54:19.302881: miou: 84.06%
2023-09-03 21:54:19.304544: acc: 95.63%, sen: 91.63%, spe: 96.97%
2023-09-03 21:54:19.306988: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:54:19.308520: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 21:54:19.309973: finished real validation
2023-09-03 21:54:27.773081: train_loss -1.4439
2023-09-03 21:54:27.774963: val_loss -1.106
2023-09-03 21:54:27.776331: Pseudo dice [0.9117]
2023-09-03 21:54:27.777578: Epoch time: 469.57 s
2023-09-03 21:54:30.779693: 
2023-09-03 21:54:30.781479: Epoch 90
2023-09-03 21:54:30.782709: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-03 21:54:30.784261: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:56:29.864289: finished training epoch 90
2023-09-03 21:56:29.908065: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:56:29.910759: The split file contains 1 splits.
2023-09-03 21:56:29.912043: Desired fold for training: 0
2023-09-03 21:56:29.913219: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:02:26.045566: dsc: 91.37%
2023-09-03 22:02:26.047506: miou: 84.12%
2023-09-03 22:02:26.049054: acc: 95.65%, sen: 91.58%, spe: 97.02%
2023-09-03 22:02:26.051222: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:02:26.053463: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:02:26.054782: finished real validation
2023-09-03 22:02:34.516690: train_loss -1.4443
2023-09-03 22:02:34.518317: val_loss -1.1071
2023-09-03 22:02:34.520185: Pseudo dice [0.9144]
2023-09-03 22:02:34.521787: Epoch time: 483.74 s
2023-09-03 22:02:35.596049: 
2023-09-03 22:02:35.597672: Epoch 91
2023-09-03 22:02:35.598909: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-03 22:02:35.600724: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:04:34.641363: finished training epoch 91
2023-09-03 22:04:34.670945: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:04:34.673134: The split file contains 1 splits.
2023-09-03 22:04:34.674423: Desired fold for training: 0
2023-09-03 22:04:34.675627: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:11:06.079948: dsc: 91.37%
2023-09-03 22:11:06.081664: miou: 84.11%
2023-09-03 22:11:06.083007: acc: 95.67%, sen: 91.17%, spe: 97.18%
2023-09-03 22:11:06.084414: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:11:06.085539: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:11:06.086572: finished real validation
2023-09-03 22:11:14.546532: train_loss -1.4445
2023-09-03 22:11:14.548186: val_loss -1.0988
2023-09-03 22:11:14.549591: Pseudo dice [0.9142]
2023-09-03 22:11:14.550766: Epoch time: 518.95 s
2023-09-03 22:11:15.662932: 
2023-09-03 22:11:15.664791: Epoch 92
2023-09-03 22:11:15.666183: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-03 22:11:15.667883: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:13:14.704202: finished training epoch 92
2023-09-03 22:13:14.731769: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:13:14.734085: The split file contains 1 splits.
2023-09-03 22:13:14.735662: Desired fold for training: 0
2023-09-03 22:13:14.737350: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:18:53.860479: dsc: 91.17%
2023-09-03 22:18:53.862820: miou: 83.78%
2023-09-03 22:18:53.863860: acc: 95.57%, sen: 90.90%, spe: 97.14%
2023-09-03 22:18:53.865507: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:18:53.866576: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:18:53.867604: finished real validation
2023-09-03 22:19:02.314129: train_loss -1.4446
2023-09-03 22:19:02.315703: val_loss -1.0772
2023-09-03 22:19:02.317335: Pseudo dice [0.9102]
2023-09-03 22:19:02.318670: Epoch time: 466.65 s
2023-09-03 22:19:03.443182: 
2023-09-03 22:19:03.445469: Epoch 93
2023-09-03 22:19:03.446681: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-03 22:19:03.448386: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:21:02.556164: finished training epoch 93
2023-09-03 22:21:02.585686: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:21:02.587865: The split file contains 1 splits.
2023-09-03 22:21:02.589043: Desired fold for training: 0
2023-09-03 22:21:02.590124: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:26:30.623575: dsc: 91.14%
2023-09-03 22:26:30.625255: miou: 83.72%
2023-09-03 22:26:30.626543: acc: 95.55%, sen: 90.97%, spe: 97.09%
2023-09-03 22:26:30.628152: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:26:30.629511: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:26:30.630697: finished real validation
2023-09-03 22:26:39.070013: train_loss -1.4451
2023-09-03 22:26:39.071656: val_loss -1.112
2023-09-03 22:26:39.073193: Pseudo dice [0.9139]
2023-09-03 22:26:39.074480: Epoch time: 455.63 s
2023-09-03 22:26:40.182426: 
2023-09-03 22:26:40.184015: Epoch 94
2023-09-03 22:26:40.185518: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-03 22:26:40.187827: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:28:39.310674: finished training epoch 94
2023-09-03 22:28:39.344438: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:28:39.346529: The split file contains 1 splits.
2023-09-03 22:28:39.347751: Desired fold for training: 0
2023-09-03 22:28:39.348891: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:34:19.948344: dsc: 91.28%
2023-09-03 22:34:19.950037: miou: 83.96%
2023-09-03 22:34:19.951276: acc: 95.60%, sen: 91.49%, spe: 96.99%
2023-09-03 22:34:19.952808: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:34:19.954097: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:34:19.958524: finished real validation
2023-09-03 22:34:28.398521: train_loss -1.4459
2023-09-03 22:34:28.400500: val_loss -1.0984
2023-09-03 22:34:28.402203: Pseudo dice [0.9134]
2023-09-03 22:34:28.403499: Epoch time: 468.22 s
2023-09-03 22:34:29.517901: 
2023-09-03 22:34:29.519802: Epoch 95
2023-09-03 22:34:29.521175: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-03 22:34:29.522988: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:36:28.466449: finished training epoch 95
2023-09-03 22:36:28.496036: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:36:28.498122: The split file contains 1 splits.
2023-09-03 22:36:28.499370: Desired fold for training: 0
2023-09-03 22:36:28.500507: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:42:08.524033: dsc: 91.39%
2023-09-03 22:42:09.398114: miou: 84.14%
2023-09-03 22:42:09.399510: acc: 95.67%, sen: 91.33%, spe: 97.13%
2023-09-03 22:42:09.401605: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:42:09.403132: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:42:09.404559: finished real validation
2023-09-03 22:42:17.862856: train_loss -1.4446
2023-09-03 22:42:17.864629: val_loss -1.1149
2023-09-03 22:42:17.866272: Pseudo dice [0.9158]
2023-09-03 22:42:17.867680: Epoch time: 468.35 s
2023-09-03 22:42:17.868897: Yayy! New best EMA pseudo Dice: 0.9125
2023-09-03 22:42:20.907730: 
2023-09-03 22:42:20.909759: Epoch 96
2023-09-03 22:42:20.911432: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-03 22:42:20.913139: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:44:19.888948: finished training epoch 96
2023-09-03 22:44:19.918204: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:44:19.920417: The split file contains 1 splits.
2023-09-03 22:44:19.921597: Desired fold for training: 0
2023-09-03 22:44:19.922724: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:49:55.501426: dsc: 91.29%
2023-09-03 22:49:55.503010: miou: 83.98%
2023-09-03 22:49:55.504351: acc: 95.60%, sen: 91.77%, spe: 96.89%
2023-09-03 22:49:55.505888: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:49:55.507089: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:49:55.508217: finished real validation
2023-09-03 22:50:03.952450: train_loss -1.4459
2023-09-03 22:50:03.954112: val_loss -1.0919
2023-09-03 22:50:03.955562: Pseudo dice [0.911]
2023-09-03 22:50:03.956844: Epoch time: 463.05 s
2023-09-03 22:50:05.057200: 
2023-09-03 22:50:05.058913: Epoch 97
2023-09-03 22:50:05.060102: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-03 22:50:05.061618: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:52:04.072907: finished training epoch 97
2023-09-03 22:52:04.102724: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:52:04.105206: The split file contains 1 splits.
2023-09-03 22:52:04.106451: Desired fold for training: 0
2023-09-03 22:52:04.107767: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:57:30.864088: dsc: 91.33%
2023-09-03 22:57:30.865831: miou: 84.04%
2023-09-03 22:57:30.867191: acc: 95.62%, sen: 91.69%, spe: 96.94%
2023-09-03 22:57:30.868819: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:57:30.870256: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 22:57:30.871657: finished real validation
2023-09-03 22:57:39.305005: train_loss -1.4459
2023-09-03 22:57:39.306664: val_loss -1.0947
2023-09-03 22:57:39.308295: Pseudo dice [0.9138]
2023-09-03 22:57:39.309640: Epoch time: 454.25 s
2023-09-03 22:57:39.310853: Yayy! New best EMA pseudo Dice: 0.9125
2023-09-03 22:57:42.295673: 
2023-09-03 22:57:42.298132: Epoch 98
2023-09-03 22:57:42.299937: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-03 22:57:42.301988: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:59:41.321037: finished training epoch 98
2023-09-03 22:59:41.362883: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:59:41.365208: The split file contains 1 splits.
2023-09-03 22:59:41.366489: Desired fold for training: 0
2023-09-03 22:59:41.367630: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:05:17.410068: dsc: 91.33%
2023-09-03 23:05:17.412578: miou: 84.05%
2023-09-03 23:05:17.413992: acc: 95.62%, sen: 91.70%, spe: 96.94%
2023-09-03 23:05:17.415717: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:05:17.417221: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:05:17.418630: finished real validation
2023-09-03 23:05:25.863420: train_loss -1.4457
2023-09-03 23:05:25.865141: val_loss -1.1007
2023-09-03 23:05:25.866576: Pseudo dice [0.9134]
2023-09-03 23:05:25.867866: Epoch time: 463.57 s
2023-09-03 23:05:25.869173: Yayy! New best EMA pseudo Dice: 0.9126
2023-09-03 23:05:28.839834: 
2023-09-03 23:05:28.841642: Epoch 99
2023-09-03 23:05:28.843153: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-03 23:05:28.845237: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:07:27.944901: finished training epoch 99
2023-09-03 23:07:27.987095: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:07:27.989557: The split file contains 1 splits.
2023-09-03 23:07:27.990816: Desired fold for training: 0
2023-09-03 23:07:27.992074: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:13:05.914908: dsc: 91.33%
2023-09-03 23:13:05.916918: miou: 84.04%
2023-09-03 23:13:05.918671: acc: 95.62%, sen: 91.74%, spe: 96.92%
2023-09-03 23:13:05.920835: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:13:05.922383: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:13:05.923678: finished real validation
2023-09-03 23:13:14.378583: train_loss -1.4457
2023-09-03 23:13:14.380519: val_loss -1.1202
2023-09-03 23:13:14.382041: Pseudo dice [0.9177]
2023-09-03 23:13:14.383958: Epoch time: 465.54 s
2023-09-03 23:13:16.341169: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-03 23:13:19.486772: 
2023-09-03 23:13:19.488682: Epoch 100
2023-09-03 23:13:19.490145: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-03 23:13:19.491884: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:15:18.607966: finished training epoch 100
2023-09-03 23:15:18.640457: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:15:18.642892: The split file contains 1 splits.
2023-09-03 23:15:18.644264: Desired fold for training: 0
2023-09-03 23:15:18.645548: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:20:51.326287: dsc: 91.33%
2023-09-03 23:20:51.328011: miou: 84.05%
2023-09-03 23:20:51.329236: acc: 95.63%, sen: 91.61%, spe: 96.98%
2023-09-03 23:20:51.330793: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:20:51.332093: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:20:51.333418: finished real validation
2023-09-03 23:20:59.795524: train_loss -1.4467
2023-09-03 23:20:59.797359: val_loss -1.0827
2023-09-03 23:20:59.798931: Pseudo dice [0.9128]
2023-09-03 23:20:59.800355: Epoch time: 460.31 s
2023-09-03 23:21:00.915440: 
2023-09-03 23:21:00.917393: Epoch 101
2023-09-03 23:21:00.918885: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-03 23:21:00.920554: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:23:00.173311: finished training epoch 101
2023-09-03 23:23:00.201527: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:23:00.203570: The split file contains 1 splits.
2023-09-03 23:23:00.204864: Desired fold for training: 0
2023-09-03 23:23:00.205977: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:28:43.806421: dsc: 91.29%
2023-09-03 23:28:43.808199: miou: 83.98%
2023-09-03 23:28:43.809560: acc: 95.63%, sen: 90.97%, spe: 97.20%
2023-09-03 23:28:43.811176: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:28:43.812543: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:28:43.813811: finished real validation
2023-09-03 23:28:52.284596: train_loss -1.4466
2023-09-03 23:28:52.286567: val_loss -1.0742
2023-09-03 23:28:52.288316: Pseudo dice [0.911]
2023-09-03 23:28:52.289756: Epoch time: 471.37 s
2023-09-03 23:28:53.429477: 
2023-09-03 23:28:53.431339: Epoch 102
2023-09-03 23:28:53.432815: Current learning rate: backbone 0.000688, others 0.000688
2023-09-03 23:28:53.434670: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:30:52.608728: finished training epoch 102
2023-09-03 23:30:52.661617: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:30:52.665403: The split file contains 1 splits.
2023-09-03 23:30:52.666694: Desired fold for training: 0
2023-09-03 23:30:52.667871: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:36:36.411897: dsc: 91.30%
2023-09-03 23:36:36.413446: miou: 83.99%
2023-09-03 23:36:36.414691: acc: 95.62%, sen: 91.24%, spe: 97.10%
2023-09-03 23:36:36.416248: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:36:36.417633: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:36:36.418810: finished real validation
2023-09-03 23:36:44.839639: train_loss -1.4468
2023-09-03 23:36:44.841345: val_loss -1.1038
2023-09-03 23:36:44.842683: Pseudo dice [0.9147]
2023-09-03 23:36:44.843878: Epoch time: 471.41 s
2023-09-03 23:36:45.964521: 
2023-09-03 23:36:45.966486: Epoch 103
2023-09-03 23:36:45.967935: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-03 23:36:45.969595: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:38:44.958422: finished training epoch 103
2023-09-03 23:38:44.987730: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:38:44.989816: The split file contains 1 splits.
2023-09-03 23:38:44.991029: Desired fold for training: 0
2023-09-03 23:38:44.992176: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:44:35.755728: dsc: 91.35%
2023-09-03 23:44:35.757546: miou: 84.08%
2023-09-03 23:44:35.758871: acc: 95.62%, sen: 92.02%, spe: 96.83%
2023-09-03 23:44:35.760516: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:44:35.761690: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:44:35.762722: finished real validation
2023-09-03 23:44:44.325327: train_loss -1.4465
2023-09-03 23:44:44.328072: val_loss -1.0607
2023-09-03 23:44:44.330410: Pseudo dice [0.9113]
2023-09-03 23:44:44.331936: Epoch time: 478.36 s
2023-09-03 23:44:45.477143: 
2023-09-03 23:44:45.479128: Epoch 104
2023-09-03 23:44:45.480575: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-03 23:44:45.482487: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:46:44.902828: finished training epoch 104
2023-09-03 23:46:44.937509: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:46:44.939811: The split file contains 1 splits.
2023-09-03 23:46:44.941068: Desired fold for training: 0
2023-09-03 23:46:44.942298: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:52:17.988652: dsc: 91.42%
2023-09-03 23:52:18.545574: miou: 84.20%
2023-09-03 23:52:18.547209: acc: 95.67%, sen: 91.83%, spe: 96.96%
2023-09-03 23:52:18.549497: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:52:18.550959: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:52:18.552817: finished real validation
2023-09-03 23:52:27.003249: train_loss -1.4469
2023-09-03 23:52:27.005130: val_loss -1.1203
2023-09-03 23:52:27.006758: Pseudo dice [0.9168]
2023-09-03 23:52:27.008151: Epoch time: 461.53 s
2023-09-03 23:52:27.009464: Yayy! New best EMA pseudo Dice: 0.9133
2023-09-03 23:52:30.003017: 
2023-09-03 23:52:30.004894: Epoch 105
2023-09-03 23:52:30.006211: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-03 23:52:30.007873: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:54:28.997656: finished training epoch 105
2023-09-03 23:54:29.030360: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:54:29.032646: The split file contains 1 splits.
2023-09-03 23:54:29.033844: Desired fold for training: 0
2023-09-03 23:54:29.035007: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:59:53.243648: dsc: 91.35%
2023-09-03 23:59:53.245500: miou: 84.08%
2023-09-03 23:59:53.246805: acc: 95.62%, sen: 91.86%, spe: 96.89%
2023-09-03 23:59:53.248602: current best miou: 0.842456328689616 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:59:53.250146: current best dsc: 0.9144925885855696 at epoch: 62, (62, 0.842456328689616, 0.9144925885855696)
2023-09-03 23:59:53.251665: finished real validation
2023-09-04 00:00:01.698568: train_loss -1.4474
2023-09-04 00:00:01.700399: val_loss -1.0925
2023-09-04 00:00:01.702083: Pseudo dice [0.9163]
2023-09-04 00:00:01.703536: Epoch time: 451.7 s
2023-09-04 00:00:01.704910: Yayy! New best EMA pseudo Dice: 0.9136
2023-09-04 00:00:04.707633: 
2023-09-04 00:00:04.709424: Epoch 106
2023-09-04 00:00:04.711170: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-04 00:00:04.713013: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:02:03.707913: finished training epoch 106
2023-09-04 00:02:03.918831: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:02:03.920900: The split file contains 1 splits.
2023-09-04 00:02:03.922192: Desired fold for training: 0
2023-09-04 00:02:03.923401: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:07:31.381637: dsc: 91.46%
2023-09-04 00:07:31.383450: miou: 84.26%
2023-09-04 00:07:31.385103: acc: 95.67%, sen: 92.13%, spe: 96.86%
2023-09-04 00:07:31.387309: current best miou: 0.8426101788288453 at epoch: 106, (106, 0.8426101788288453, 0.9145832238530284)
2023-09-04 00:07:31.388803: current best dsc: 0.9145832238530284 at epoch: 106, (106, 0.8426101788288453, 0.9145832238530284)
2023-09-04 00:07:33.243851: finished real validation
2023-09-04 00:07:41.671722: train_loss -1.4475
2023-09-04 00:07:41.673915: val_loss -1.0734
2023-09-04 00:07:41.675745: Pseudo dice [0.9101]
2023-09-04 00:07:41.677140: Epoch time: 456.97 s
2023-09-04 00:07:42.791990: 
2023-09-04 00:07:42.793656: Epoch 107
2023-09-04 00:07:42.795002: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-04 00:07:42.796639: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:09:41.860162: finished training epoch 107
2023-09-04 00:09:41.890629: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:09:41.893367: The split file contains 1 splits.
2023-09-04 00:09:41.895118: Desired fold for training: 0
2023-09-04 00:09:41.896909: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:15:24.732767: dsc: 91.49%
2023-09-04 00:15:24.734596: miou: 84.31%
2023-09-04 00:15:24.735918: acc: 95.68%, sen: 92.30%, spe: 96.82%
2023-09-04 00:15:24.737769: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:15:24.739311: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:15:26.597191: finished real validation
2023-09-04 00:15:35.033443: train_loss -1.4474
2023-09-04 00:15:35.035312: val_loss -1.0933
2023-09-04 00:15:35.036868: Pseudo dice [0.912]
2023-09-04 00:15:35.038196: Epoch time: 472.24 s
2023-09-04 00:15:36.145292: 
2023-09-04 00:15:36.147259: Epoch 108
2023-09-04 00:15:36.148989: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-04 00:15:36.151256: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:17:35.255154: finished training epoch 108
2023-09-04 00:17:35.285963: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:17:35.288398: The split file contains 1 splits.
2023-09-04 00:17:35.289785: Desired fold for training: 0
2023-09-04 00:17:35.291042: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:24:20.768847: dsc: 91.28%
2023-09-04 00:24:20.770573: miou: 83.96%
2023-09-04 00:24:20.771785: acc: 95.61%, sen: 91.26%, spe: 97.08%
2023-09-04 00:24:20.773256: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:24:20.774460: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:24:20.775607: finished real validation
2023-09-04 00:24:29.200221: train_loss -1.4478
2023-09-04 00:24:29.202514: val_loss -1.0892
2023-09-04 00:24:29.204818: Pseudo dice [0.9134]
2023-09-04 00:24:29.206702: Epoch time: 533.06 s
2023-09-04 00:24:30.348922: 
2023-09-04 00:24:30.350677: Epoch 109
2023-09-04 00:24:30.352313: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-04 00:24:30.354441: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:26:29.398728: finished training epoch 109
2023-09-04 00:26:29.432057: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:26:29.434672: The split file contains 1 splits.
2023-09-04 00:26:29.436144: Desired fold for training: 0
2023-09-04 00:26:29.437529: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:32:01.087180: dsc: 91.36%
2023-09-04 00:32:01.089180: miou: 84.10%
2023-09-04 00:32:01.090534: acc: 95.62%, sen: 92.11%, spe: 96.80%
2023-09-04 00:32:01.092552: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:32:01.093936: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:32:01.095381: finished real validation
2023-09-04 00:32:09.551253: train_loss -1.448
2023-09-04 00:32:09.553004: val_loss -1.103
2023-09-04 00:32:09.554600: Pseudo dice [0.9139]
2023-09-04 00:32:09.555907: Epoch time: 459.2 s
2023-09-04 00:32:12.608886: 
2023-09-04 00:32:12.610667: Epoch 110
2023-09-04 00:32:12.612006: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-04 00:32:12.613965: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:34:11.680235: finished training epoch 110
2023-09-04 00:34:11.709860: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:34:11.712183: The split file contains 1 splits.
2023-09-04 00:34:11.713501: Desired fold for training: 0
2023-09-04 00:34:11.714710: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:39:45.445701: dsc: 91.27%
2023-09-04 00:39:45.447536: miou: 83.94%
2023-09-04 00:39:45.448949: acc: 95.60%, sen: 91.44%, spe: 97.00%
2023-09-04 00:39:45.451205: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:39:45.452496: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:39:45.453923: finished real validation
2023-09-04 00:39:53.914228: train_loss -1.4478
2023-09-04 00:39:53.916010: val_loss -1.0706
2023-09-04 00:39:53.917502: Pseudo dice [0.911]
2023-09-04 00:39:53.918778: Epoch time: 461.31 s
2023-09-04 00:39:55.046201: 
2023-09-04 00:39:55.048119: Epoch 111
2023-09-04 00:39:55.049540: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-04 00:39:55.051303: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:41:54.052220: finished training epoch 111
2023-09-04 00:41:54.081638: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:41:54.084098: The split file contains 1 splits.
2023-09-04 00:41:54.085484: Desired fold for training: 0
2023-09-04 00:41:54.086724: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:47:32.956423: dsc: 91.41%
2023-09-04 00:47:32.960875: miou: 84.18%
2023-09-04 00:47:32.963981: acc: 95.66%, sen: 91.75%, spe: 96.98%
2023-09-04 00:47:32.965659: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:47:32.967333: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:47:32.968695: finished real validation
2023-09-04 00:47:41.412285: train_loss -1.4479
2023-09-04 00:47:41.414071: val_loss -1.0998
2023-09-04 00:47:41.415653: Pseudo dice [0.9148]
2023-09-04 00:47:41.417047: Epoch time: 466.37 s
2023-09-04 00:47:42.529939: 
2023-09-04 00:47:42.531805: Epoch 112
2023-09-04 00:47:42.533172: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-04 00:47:42.534809: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:49:41.584777: finished training epoch 112
2023-09-04 00:49:41.614139: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:49:41.616299: The split file contains 1 splits.
2023-09-04 00:49:41.617581: Desired fold for training: 0
2023-09-04 00:49:41.618769: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:55:12.427518: dsc: 91.28%
2023-09-04 00:55:12.429539: miou: 83.97%
2023-09-04 00:55:12.430948: acc: 95.62%, sen: 91.17%, spe: 97.12%
2023-09-04 00:55:12.433036: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:55:12.434468: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 00:55:12.435939: finished real validation
2023-09-04 00:55:20.875906: train_loss -1.4489
2023-09-04 00:55:20.878314: val_loss -1.0898
2023-09-04 00:55:20.880234: Pseudo dice [0.9135]
2023-09-04 00:55:20.881699: Epoch time: 458.35 s
2023-09-04 00:55:21.987134: 
2023-09-04 00:55:21.988920: Epoch 113
2023-09-04 00:55:21.990220: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-04 00:55:21.991843: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:57:20.996991: finished training epoch 113
2023-09-04 00:57:21.027131: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:57:21.029438: The split file contains 1 splits.
2023-09-04 00:57:21.030780: Desired fold for training: 0
2023-09-04 00:57:21.032089: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:02:52.070584: dsc: 91.38%
2023-09-04 01:02:52.072603: miou: 84.13%
2023-09-04 01:02:52.074084: acc: 95.66%, sen: 91.56%, spe: 97.03%
2023-09-04 01:02:52.075921: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:02:52.077419: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:02:52.078805: finished real validation
2023-09-04 01:03:00.533921: train_loss -1.4486
2023-09-04 01:03:00.536079: val_loss -1.0981
2023-09-04 01:03:00.537920: Pseudo dice [0.9139]
2023-09-04 01:03:00.539383: Epoch time: 458.55 s
2023-09-04 01:03:01.644077: 
2023-09-04 01:03:01.646163: Epoch 114
2023-09-04 01:03:01.647557: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-04 01:03:01.649237: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:05:00.678036: finished training epoch 114
2023-09-04 01:05:00.722494: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:05:00.725058: The split file contains 1 splits.
2023-09-04 01:05:00.726445: Desired fold for training: 0
2023-09-04 01:05:00.727787: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:10:37.647994: dsc: 91.40%
2023-09-04 01:10:37.649822: miou: 84.17%
2023-09-04 01:10:37.651211: acc: 95.68%, sen: 91.35%, spe: 97.13%
2023-09-04 01:10:37.652845: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:10:37.654341: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:10:37.655766: finished real validation
2023-09-04 01:10:46.101728: train_loss -1.4491
2023-09-04 01:10:46.103847: val_loss -1.0848
2023-09-04 01:10:46.105514: Pseudo dice [0.9138]
2023-09-04 01:10:46.107001: Epoch time: 464.46 s
2023-09-04 01:10:47.212614: 
2023-09-04 01:10:47.214349: Epoch 115
2023-09-04 01:10:47.216134: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-04 01:10:47.218239: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:12:46.480604: finished training epoch 115
2023-09-04 01:12:46.520262: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:12:46.522281: The split file contains 1 splits.
2023-09-04 01:12:46.523554: Desired fold for training: 0
2023-09-04 01:12:46.524745: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:18:40.508791: dsc: 91.34%
2023-09-04 01:18:40.510650: miou: 84.07%
2023-09-04 01:18:40.511950: acc: 95.63%, sen: 91.65%, spe: 96.97%
2023-09-04 01:18:40.513495: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:18:40.514771: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:18:40.515953: finished real validation
2023-09-04 01:18:48.952556: train_loss -1.4494
2023-09-04 01:18:48.954634: val_loss -1.0905
2023-09-04 01:18:48.956194: Pseudo dice [0.9143]
2023-09-04 01:18:48.957585: Epoch time: 481.74 s
2023-09-04 01:18:50.107410: 
2023-09-04 01:18:50.109398: Epoch 116
2023-09-04 01:18:50.110743: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-04 01:18:50.112409: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:20:49.178651: finished training epoch 116
2023-09-04 01:20:49.215657: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:20:49.217824: The split file contains 1 splits.
2023-09-04 01:20:49.219181: Desired fold for training: 0
2023-09-04 01:20:49.220811: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:26:29.981848: dsc: 91.37%
2023-09-04 01:26:29.983943: miou: 84.10%
2023-09-04 01:26:29.985377: acc: 95.67%, sen: 91.12%, spe: 97.20%
2023-09-04 01:26:29.987054: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:26:29.988499: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:26:29.989853: finished real validation
2023-09-04 01:26:38.456221: train_loss -1.4491
2023-09-04 01:26:38.458063: val_loss -1.0954
2023-09-04 01:26:38.459580: Pseudo dice [0.9143]
2023-09-04 01:26:38.460883: Epoch time: 468.35 s
2023-09-04 01:26:39.605250: 
2023-09-04 01:26:39.607356: Epoch 117
2023-09-04 01:26:39.609070: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-04 01:26:39.611097: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:28:38.713446: finished training epoch 117
2023-09-04 01:28:38.748568: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:28:38.750841: The split file contains 1 splits.
2023-09-04 01:28:38.752221: Desired fold for training: 0
2023-09-04 01:28:38.753582: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:34:09.144310: dsc: 91.26%
2023-09-04 01:34:09.146107: miou: 83.92%
2023-09-04 01:34:09.147471: acc: 95.59%, sen: 91.59%, spe: 96.93%
2023-09-04 01:34:09.149043: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:34:09.150346: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:34:09.151545: finished real validation
2023-09-04 01:34:17.590874: train_loss -1.4495
2023-09-04 01:34:17.592641: val_loss -1.0565
2023-09-04 01:34:17.594180: Pseudo dice [0.9082]
2023-09-04 01:34:17.595628: Epoch time: 457.99 s
2023-09-04 01:34:18.742767: 
2023-09-04 01:34:18.744826: Epoch 118
2023-09-04 01:34:18.746387: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-04 01:34:18.748221: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:36:17.817623: finished training epoch 118
2023-09-04 01:36:17.846546: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:36:17.848804: The split file contains 1 splits.
2023-09-04 01:36:17.850301: Desired fold for training: 0
2023-09-04 01:36:17.851672: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:41:54.085940: dsc: 91.37%
2023-09-04 01:41:54.087821: miou: 84.12%
2023-09-04 01:41:54.089275: acc: 95.64%, sen: 91.72%, spe: 96.96%
2023-09-04 01:41:54.091117: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:41:54.092665: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:41:54.094107: finished real validation
2023-09-04 01:42:02.532507: train_loss -1.4496
2023-09-04 01:42:02.534479: val_loss -1.0598
2023-09-04 01:42:02.536837: Pseudo dice [0.9096]
2023-09-04 01:42:02.538764: Epoch time: 463.79 s
2023-09-04 01:42:03.694867: 
2023-09-04 01:42:03.696759: Epoch 119
2023-09-04 01:42:03.698191: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-04 01:42:03.700427: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:44:02.756502: finished training epoch 119
2023-09-04 01:44:02.785721: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:44:02.788088: The split file contains 1 splits.
2023-09-04 01:44:02.789549: Desired fold for training: 0
2023-09-04 01:44:02.790920: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:49:35.120726: dsc: 91.26%
2023-09-04 01:49:35.122655: miou: 83.93%
2023-09-04 01:49:35.124241: acc: 95.60%, sen: 91.48%, spe: 96.98%
2023-09-04 01:49:35.125981: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:49:35.127461: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:49:35.128701: finished real validation
2023-09-04 01:49:43.571666: train_loss -1.4496
2023-09-04 01:49:43.573540: val_loss -1.0665
2023-09-04 01:49:43.575057: Pseudo dice [0.9092]
2023-09-04 01:49:43.576444: Epoch time: 459.88 s
2023-09-04 01:49:46.552743: 
2023-09-04 01:49:46.554778: Epoch 120
2023-09-04 01:49:46.556197: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-04 01:49:46.557915: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:51:45.503003: finished training epoch 120
2023-09-04 01:51:45.532346: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:51:45.534460: The split file contains 1 splits.
2023-09-04 01:51:45.535736: Desired fold for training: 0
2023-09-04 01:51:45.536972: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:57:20.339741: dsc: 91.21%
2023-09-04 01:57:20.341954: miou: 83.83%
2023-09-04 01:57:20.343555: acc: 95.57%, sen: 91.31%, spe: 97.00%
2023-09-04 01:57:20.345333: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:57:20.346952: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 01:57:20.348559: finished real validation
2023-09-04 01:57:28.796938: train_loss -1.4494
2023-09-04 01:57:28.799064: val_loss -1.0719
2023-09-04 01:57:28.800797: Pseudo dice [0.911]
2023-09-04 01:57:28.802392: Epoch time: 462.25 s
2023-09-04 01:57:29.917926: 
2023-09-04 01:57:29.919782: Epoch 121
2023-09-04 01:57:29.921538: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-04 01:57:29.923616: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:59:28.821032: finished training epoch 121
2023-09-04 01:59:28.850351: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:59:28.852620: The split file contains 1 splits.
2023-09-04 01:59:28.854039: Desired fold for training: 0
2023-09-04 01:59:28.855344: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:05:06.331400: dsc: 91.33%
2023-09-04 02:05:06.333322: miou: 84.04%
2023-09-04 02:05:06.335378: acc: 95.63%, sen: 91.36%, spe: 97.07%
2023-09-04 02:05:06.336981: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:05:06.338890: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:05:06.340584: finished real validation
2023-09-04 02:05:14.776390: train_loss -1.45
2023-09-04 02:05:14.778356: val_loss -1.0906
2023-09-04 02:05:14.780095: Pseudo dice [0.9142]
2023-09-04 02:05:14.781540: Epoch time: 464.86 s
2023-09-04 02:05:15.899127: 
2023-09-04 02:05:15.901045: Epoch 122
2023-09-04 02:05:15.902692: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-04 02:05:15.904898: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:07:14.945753: finished training epoch 122
2023-09-04 02:07:14.988461: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:07:14.991664: The split file contains 1 splits.
2023-09-04 02:07:14.993356: Desired fold for training: 0
2023-09-04 02:07:14.994975: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:12:55.681174: dsc: 91.31%
2023-09-04 02:12:55.683252: miou: 84.01%
2023-09-04 02:12:55.684911: acc: 95.61%, sen: 91.70%, spe: 96.92%
2023-09-04 02:12:55.686713: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:12:55.688167: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:12:55.689718: finished real validation
2023-09-04 02:13:04.137470: train_loss -1.4498
2023-09-04 02:13:04.139343: val_loss -1.0714
2023-09-04 02:13:04.140969: Pseudo dice [0.9127]
2023-09-04 02:13:04.142470: Epoch time: 468.24 s
2023-09-04 02:13:05.258228: 
2023-09-04 02:13:05.260062: Epoch 123
2023-09-04 02:13:05.261516: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-04 02:13:05.263669: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:15:04.401752: finished training epoch 123
2023-09-04 02:15:04.447399: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:15:04.449643: The split file contains 1 splits.
2023-09-04 02:15:04.450987: Desired fold for training: 0
2023-09-04 02:15:04.452347: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:21:35.702973: dsc: 91.31%
2023-09-04 02:21:35.706156: miou: 84.01%
2023-09-04 02:21:35.707819: acc: 95.63%, sen: 91.25%, spe: 97.10%
2023-09-04 02:21:35.710065: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:21:35.711437: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:21:35.712795: finished real validation
2023-09-04 02:21:44.170366: train_loss -1.4495
2023-09-04 02:21:44.172926: val_loss -1.0943
2023-09-04 02:21:44.174957: Pseudo dice [0.9151]
2023-09-04 02:21:44.176674: Epoch time: 518.91 s
2023-09-04 02:21:45.314069: 
2023-09-04 02:21:45.315794: Epoch 124
2023-09-04 02:21:45.317167: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-04 02:21:45.318905: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:23:44.463285: finished training epoch 124
2023-09-04 02:23:44.494972: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:23:44.497435: The split file contains 1 splits.
2023-09-04 02:23:44.498926: Desired fold for training: 0
2023-09-04 02:23:44.500305: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:29:21.421276: dsc: 91.37%
2023-09-04 02:29:21.423383: miou: 84.11%
2023-09-04 02:29:21.425466: acc: 95.63%, sen: 92.03%, spe: 96.84%
2023-09-04 02:29:21.427804: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:29:21.429759: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:29:21.431658: finished real validation
2023-09-04 02:29:29.873341: train_loss -1.4499
2023-09-04 02:29:29.875249: val_loss -1.1002
2023-09-04 02:29:29.876945: Pseudo dice [0.9152]
2023-09-04 02:29:29.878480: Epoch time: 464.56 s
2023-09-04 02:29:31.021464: 
2023-09-04 02:29:31.023517: Epoch 125
2023-09-04 02:29:31.025652: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-04 02:29:31.028180: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:31:30.141325: finished training epoch 125
2023-09-04 02:31:30.173245: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:31:30.176391: The split file contains 1 splits.
2023-09-04 02:31:30.177958: Desired fold for training: 0
2023-09-04 02:31:30.179446: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:37:01.129701: dsc: 91.38%
2023-09-04 02:37:01.131399: miou: 84.13%
2023-09-04 02:37:01.132768: acc: 95.65%, sen: 91.67%, spe: 96.99%
2023-09-04 02:37:01.134416: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:37:01.135823: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:37:01.137061: finished real validation
2023-09-04 02:37:09.562145: train_loss -1.4505
2023-09-04 02:37:09.564184: val_loss -1.1079
2023-09-04 02:37:09.565948: Pseudo dice [0.9164]
2023-09-04 02:37:09.567573: Epoch time: 458.54 s
2023-09-04 02:37:10.685777: 
2023-09-04 02:37:10.687690: Epoch 126
2023-09-04 02:37:10.690268: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-04 02:37:10.692416: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:39:09.645535: finished training epoch 126
2023-09-04 02:39:09.674930: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:39:09.677363: The split file contains 1 splits.
2023-09-04 02:39:09.678924: Desired fold for training: 0
2023-09-04 02:39:09.680311: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:44:47.798138: dsc: 91.28%
2023-09-04 02:44:47.800144: miou: 83.96%
2023-09-04 02:44:47.801700: acc: 95.62%, sen: 91.12%, spe: 97.14%
2023-09-04 02:44:47.803946: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:44:47.805428: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:44:47.806844: finished real validation
2023-09-04 02:44:56.252269: train_loss -1.45
2023-09-04 02:44:56.254122: val_loss -1.0532
2023-09-04 02:44:56.255751: Pseudo dice [0.9092]
2023-09-04 02:44:56.257186: Epoch time: 465.57 s
2023-09-04 02:44:57.387202: 
2023-09-04 02:44:57.389066: Epoch 127
2023-09-04 02:44:57.390491: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-04 02:44:57.392528: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:46:56.427308: finished training epoch 127
2023-09-04 02:46:56.457397: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:46:56.460024: The split file contains 1 splits.
2023-09-04 02:46:56.461450: Desired fold for training: 0
2023-09-04 02:46:56.462839: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:52:29.846382: dsc: 91.37%
2023-09-04 02:52:29.848670: miou: 84.11%
2023-09-04 02:52:29.850388: acc: 95.63%, sen: 91.86%, spe: 96.90%
2023-09-04 02:52:29.852270: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:52:29.853626: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 02:52:29.855031: finished real validation
2023-09-04 02:52:38.293834: train_loss -1.4507
2023-09-04 02:52:39.401925: val_loss -1.0966
2023-09-04 02:52:39.404152: Pseudo dice [0.915]
2023-09-04 02:52:39.406022: Epoch time: 460.91 s
2023-09-04 02:52:40.522976: 
2023-09-04 02:52:40.525162: Epoch 128
2023-09-04 02:52:40.527187: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-04 02:52:40.529513: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:54:39.518709: finished training epoch 128
2023-09-04 02:54:39.566135: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:54:39.568351: The split file contains 1 splits.
2023-09-04 02:54:39.569798: Desired fold for training: 0
2023-09-04 02:54:39.571142: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:00:35.943383: dsc: 91.31%
2023-09-04 03:00:35.945338: miou: 84.01%
2023-09-04 03:00:35.947086: acc: 95.62%, sen: 91.58%, spe: 96.97%
2023-09-04 03:00:35.949459: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:00:35.950952: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:00:35.952497: finished real validation
2023-09-04 03:00:44.391859: train_loss -1.4505
2023-09-04 03:00:44.394077: val_loss -1.0756
2023-09-04 03:00:44.396338: Pseudo dice [0.9136]
2023-09-04 03:00:44.398243: Epoch time: 483.87 s
2023-09-04 03:00:45.517903: 
2023-09-04 03:00:45.519979: Epoch 129
2023-09-04 03:00:45.521738: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-04 03:00:45.523476: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:02:44.575692: finished training epoch 129
2023-09-04 03:02:44.609559: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:02:44.611914: The split file contains 1 splits.
2023-09-04 03:02:44.613481: Desired fold for training: 0
2023-09-04 03:02:44.615028: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:08:38.629361: dsc: 91.22%
2023-09-04 03:08:38.631360: miou: 83.86%
2023-09-04 03:08:38.632812: acc: 95.60%, sen: 90.90%, spe: 97.18%
2023-09-04 03:08:38.634527: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:08:38.635912: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:08:38.637225: finished real validation
2023-09-04 03:08:47.084010: train_loss -1.4501
2023-09-04 03:08:47.085936: val_loss -1.048
2023-09-04 03:08:47.087552: Pseudo dice [0.9075]
2023-09-04 03:08:47.088956: Epoch time: 481.57 s
2023-09-04 03:08:50.299134: 
2023-09-04 03:08:50.301268: Epoch 130
2023-09-04 03:08:50.302906: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-04 03:08:50.304825: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:10:49.472565: finished training epoch 130
2023-09-04 03:10:49.500021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:10:49.502277: The split file contains 1 splits.
2023-09-04 03:10:49.503839: Desired fold for training: 0
2023-09-04 03:10:49.505120: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:16:39.060381: dsc: 91.29%
2023-09-04 03:16:39.062142: miou: 83.98%
2023-09-04 03:16:39.063425: acc: 95.62%, sen: 91.33%, spe: 97.06%
2023-09-04 03:16:39.065023: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:16:39.066479: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:16:39.067849: finished real validation
2023-09-04 03:16:47.505412: train_loss -1.4503
2023-09-04 03:16:47.507166: val_loss -1.0976
2023-09-04 03:16:47.508771: Pseudo dice [0.9158]
2023-09-04 03:16:47.510164: Epoch time: 477.21 s
2023-09-04 03:16:48.654131: 
2023-09-04 03:16:48.656079: Epoch 131
2023-09-04 03:16:48.657632: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-04 03:16:48.659560: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:18:47.696144: finished training epoch 131
2023-09-04 03:18:47.726778: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:18:47.729593: The split file contains 1 splits.
2023-09-04 03:18:47.731543: Desired fold for training: 0
2023-09-04 03:18:47.733582: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:24:24.958282: dsc: 91.32%
2023-09-04 03:24:24.960103: miou: 84.02%
2023-09-04 03:24:24.961526: acc: 95.62%, sen: 91.53%, spe: 97.00%
2023-09-04 03:24:24.963302: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:24:24.964963: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:24:24.966491: finished real validation
2023-09-04 03:24:33.401956: train_loss -1.4509
2023-09-04 03:24:33.403937: val_loss -1.0847
2023-09-04 03:24:33.405653: Pseudo dice [0.912]
2023-09-04 03:24:33.407129: Epoch time: 464.75 s
2023-09-04 03:24:34.547302: 
2023-09-04 03:24:34.549101: Epoch 132
2023-09-04 03:24:34.550540: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-04 03:24:34.552391: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:26:33.529516: finished training epoch 132
2023-09-04 03:26:33.558913: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:26:33.561026: The split file contains 1 splits.
2023-09-04 03:26:33.562457: Desired fold for training: 0
2023-09-04 03:26:33.563780: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:32:05.378417: dsc: 91.34%
2023-09-04 03:32:05.380555: miou: 84.07%
2023-09-04 03:32:05.382304: acc: 95.63%, sen: 91.61%, spe: 96.98%
2023-09-04 03:32:05.384278: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:32:05.386143: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:32:05.387713: finished real validation
2023-09-04 03:32:13.845334: train_loss -1.451
2023-09-04 03:32:13.847301: val_loss -1.0828
2023-09-04 03:32:13.849384: Pseudo dice [0.9132]
2023-09-04 03:32:13.851224: Epoch time: 459.3 s
2023-09-04 03:32:14.981944: 
2023-09-04 03:32:14.983780: Epoch 133
2023-09-04 03:32:14.985264: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-04 03:32:14.987045: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:34:14.098254: finished training epoch 133
2023-09-04 03:34:14.127908: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:34:14.130245: The split file contains 1 splits.
2023-09-04 03:34:14.131642: Desired fold for training: 0
2023-09-04 03:34:14.132936: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:39:45.029864: dsc: 91.41%
2023-09-04 03:39:45.031937: miou: 84.18%
2023-09-04 03:39:45.033680: acc: 95.67%, sen: 91.74%, spe: 96.99%
2023-09-04 03:39:45.035693: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:39:45.037444: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:39:45.039049: finished real validation
2023-09-04 03:39:53.479708: train_loss -1.4516
2023-09-04 03:39:53.481874: val_loss -1.1068
2023-09-04 03:39:53.483828: Pseudo dice [0.9172]
2023-09-04 03:39:53.485450: Epoch time: 458.5 s
2023-09-04 03:39:54.608664: 
2023-09-04 03:39:54.610770: Epoch 134
2023-09-04 03:39:54.612361: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-04 03:39:54.614330: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:41:53.589036: finished training epoch 134
2023-09-04 03:41:53.640152: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:41:53.642974: The split file contains 1 splits.
2023-09-04 03:41:53.644611: Desired fold for training: 0
2023-09-04 03:41:53.646060: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:48:40.077633: dsc: 91.39%
2023-09-04 03:48:40.079688: miou: 84.15%
2023-09-04 03:48:40.081356: acc: 95.65%, sen: 91.78%, spe: 96.95%
2023-09-04 03:48:40.083302: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:48:40.084903: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:48:40.086703: finished real validation
2023-09-04 03:48:48.541109: train_loss -1.4514
2023-09-04 03:48:48.543228: val_loss -1.0582
2023-09-04 03:48:48.545057: Pseudo dice [0.912]
2023-09-04 03:48:48.547163: Epoch time: 533.93 s
2023-09-04 03:48:49.686894: 
2023-09-04 03:48:49.689054: Epoch 135
2023-09-04 03:48:49.690701: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-04 03:48:49.692628: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:50:48.757387: finished training epoch 135
2023-09-04 03:50:48.785207: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:50:48.787775: The split file contains 1 splits.
2023-09-04 03:50:48.789208: Desired fold for training: 0
2023-09-04 03:50:48.790582: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:56:20.603629: dsc: 91.37%
2023-09-04 03:56:20.605776: miou: 84.11%
2023-09-04 03:56:20.607474: acc: 95.66%, sen: 91.41%, spe: 97.08%
2023-09-04 03:56:20.609530: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:56:20.611113: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 03:56:20.612947: finished real validation
2023-09-04 03:56:29.054335: train_loss -1.4517
2023-09-04 03:56:29.056409: val_loss -1.0792
2023-09-04 03:56:29.058389: Pseudo dice [0.9139]
2023-09-04 03:56:29.060464: Epoch time: 459.37 s
2023-09-04 03:56:30.205255: 
2023-09-04 03:56:30.207332: Epoch 136
2023-09-04 03:56:30.208986: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-04 03:56:30.210908: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:58:29.312517: finished training epoch 136
2023-09-04 03:58:29.386641: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:58:29.389327: The split file contains 1 splits.
2023-09-04 03:58:29.390743: Desired fold for training: 0
2023-09-04 03:58:29.392052: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:03:58.091846: dsc: 91.37%
2023-09-04 04:03:58.093903: miou: 84.11%
2023-09-04 04:03:58.095602: acc: 95.64%, sen: 91.73%, spe: 96.96%
2023-09-04 04:03:58.097741: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:03:58.099466: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:03:58.101179: finished real validation
2023-09-04 04:04:06.537676: train_loss -1.452
2023-09-04 04:04:06.539671: val_loss -1.0705
2023-09-04 04:04:06.541479: Pseudo dice [0.9114]
2023-09-04 04:04:06.542952: Epoch time: 456.33 s
2023-09-04 04:04:07.673148: 
2023-09-04 04:04:07.675274: Epoch 137
2023-09-04 04:04:07.676748: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-04 04:04:07.678522: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:06:06.806819: finished training epoch 137
2023-09-04 04:06:06.866998: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:06:06.869479: The split file contains 1 splits.
2023-09-04 04:06:06.871163: Desired fold for training: 0
2023-09-04 04:06:06.872742: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:12:07.762291: dsc: 91.36%
2023-09-04 04:12:07.764312: miou: 84.09%
2023-09-04 04:12:07.765699: acc: 95.66%, sen: 91.15%, spe: 97.18%
2023-09-04 04:12:07.767477: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:12:07.768845: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:12:07.770138: finished real validation
2023-09-04 04:12:16.207961: train_loss -1.452
2023-09-04 04:12:16.210097: val_loss -1.0381
2023-09-04 04:12:16.211897: Pseudo dice [0.9093]
2023-09-04 04:12:16.213341: Epoch time: 488.54 s
2023-09-04 04:12:17.412047: 
2023-09-04 04:12:17.414054: Epoch 138
2023-09-04 04:12:17.415555: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-04 04:12:17.417547: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:14:16.639384: finished training epoch 138
2023-09-04 04:14:16.680479: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:14:16.682674: The split file contains 1 splits.
2023-09-04 04:14:16.684062: Desired fold for training: 0
2023-09-04 04:14:16.685365: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:20:02.333529: dsc: 91.21%
2023-09-04 04:20:02.335337: miou: 83.85%
2023-09-04 04:20:02.337101: acc: 95.58%, sen: 91.16%, spe: 97.07%
2023-09-04 04:20:02.339168: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:20:02.340992: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:20:02.342568: finished real validation
2023-09-04 04:20:10.779877: train_loss -1.4518
2023-09-04 04:20:10.781862: val_loss -1.0875
2023-09-04 04:20:10.783507: Pseudo dice [0.9149]
2023-09-04 04:20:10.785016: Epoch time: 473.37 s
2023-09-04 04:20:11.930652: 
2023-09-04 04:20:11.932676: Epoch 139
2023-09-04 04:20:11.934194: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-04 04:20:11.935985: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:22:10.933520: finished training epoch 139
2023-09-04 04:22:10.971391: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:22:10.974144: The split file contains 1 splits.
2023-09-04 04:22:10.975742: Desired fold for training: 0
2023-09-04 04:22:10.977719: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:27:50.312251: dsc: 91.24%
2023-09-04 04:27:50.314193: miou: 83.89%
2023-09-04 04:27:50.315803: acc: 95.58%, sen: 91.57%, spe: 96.92%
2023-09-04 04:27:50.317727: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:27:50.319919: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:27:50.321651: finished real validation
2023-09-04 04:27:58.759655: train_loss -1.4517
2023-09-04 04:27:58.761711: val_loss -1.0643
2023-09-04 04:27:58.763841: Pseudo dice [0.9142]
2023-09-04 04:27:58.765501: Epoch time: 466.83 s
2023-09-04 04:28:01.847418: 
2023-09-04 04:28:01.849577: Epoch 140
2023-09-04 04:28:01.851325: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-04 04:28:01.853448: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:30:00.764670: finished training epoch 140
2023-09-04 04:30:00.794199: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:30:00.796529: The split file contains 1 splits.
2023-09-04 04:30:00.797923: Desired fold for training: 0
2023-09-04 04:30:00.799247: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:35:31.743798: dsc: 91.16%
2023-09-04 04:35:31.746097: miou: 83.76%
2023-09-04 04:35:31.747560: acc: 95.56%, sen: 91.05%, spe: 97.07%
2023-09-04 04:35:31.749496: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:35:31.751184: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:35:31.752764: finished real validation
2023-09-04 04:35:40.187132: train_loss -1.4516
2023-09-04 04:35:40.189216: val_loss -1.0577
2023-09-04 04:35:40.191000: Pseudo dice [0.9096]
2023-09-04 04:35:40.192536: Epoch time: 458.34 s
2023-09-04 04:35:41.322177: 
2023-09-04 04:35:41.324333: Epoch 141
2023-09-04 04:35:41.326349: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-04 04:35:41.328496: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:37:40.337787: finished training epoch 141
2023-09-04 04:37:40.371063: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:37:40.373585: The split file contains 1 splits.
2023-09-04 04:37:40.375108: Desired fold for training: 0
2023-09-04 04:37:40.376552: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:43:05.644055: dsc: 91.24%
2023-09-04 04:43:05.645971: miou: 83.89%
2023-09-04 04:43:05.647785: acc: 95.57%, sen: 91.61%, spe: 96.91%
2023-09-04 04:43:05.649770: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:43:05.651800: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:43:05.653312: finished real validation
2023-09-04 04:43:14.107224: train_loss -1.4524
2023-09-04 04:43:14.109748: val_loss -1.0633
2023-09-04 04:43:14.111806: Pseudo dice [0.9128]
2023-09-04 04:43:14.113740: Epoch time: 452.79 s
2023-09-04 04:43:15.249685: 
2023-09-04 04:43:15.251724: Epoch 142
2023-09-04 04:43:15.253620: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-04 04:43:15.255603: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:45:14.295991: finished training epoch 142
2023-09-04 04:45:14.325577: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:45:14.327942: The split file contains 1 splits.
2023-09-04 04:45:14.329444: Desired fold for training: 0
2023-09-04 04:45:14.330888: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:50:39.164892: dsc: 91.28%
2023-09-04 04:50:39.167270: miou: 83.95%
2023-09-04 04:50:39.169084: acc: 95.60%, sen: 91.46%, spe: 96.99%
2023-09-04 04:50:39.171247: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:50:39.172801: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:50:39.174537: finished real validation
2023-09-04 04:50:47.601801: train_loss -1.4524
2023-09-04 04:50:47.603842: val_loss -1.0848
2023-09-04 04:50:47.605696: Pseudo dice [0.9148]
2023-09-04 04:50:47.607756: Epoch time: 452.35 s
2023-09-04 04:50:48.729013: 
2023-09-04 04:50:48.731296: Epoch 143
2023-09-04 04:50:48.733018: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-04 04:50:48.734873: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:52:47.690544: finished training epoch 143
2023-09-04 04:52:47.733127: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:52:47.735830: The split file contains 1 splits.
2023-09-04 04:52:47.737255: Desired fold for training: 0
2023-09-04 04:52:47.738559: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:58:19.783088: dsc: 91.27%
2023-09-04 04:58:19.785028: miou: 83.93%
2023-09-04 04:58:19.786738: acc: 95.62%, sen: 90.99%, spe: 97.18%
2023-09-04 04:58:19.789145: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:58:19.791418: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 04:58:19.793263: finished real validation
2023-09-04 04:58:28.235258: train_loss -1.4522
2023-09-04 04:58:28.237848: val_loss -1.0533
2023-09-04 04:58:28.239858: Pseudo dice [0.9088]
2023-09-04 04:58:28.241605: Epoch time: 459.51 s
2023-09-04 04:58:29.362152: 
2023-09-04 04:58:29.364392: Epoch 144
2023-09-04 04:58:29.366641: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-04 04:58:29.368627: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:00:28.458246: finished training epoch 144
2023-09-04 05:00:28.491902: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:00:28.494930: The split file contains 1 splits.
2023-09-04 05:00:28.496687: Desired fold for training: 0
2023-09-04 05:00:28.498161: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:05:52.999089: dsc: 91.27%
2023-09-04 05:05:53.003055: miou: 83.93%
2023-09-04 05:05:53.006822: acc: 95.60%, sen: 91.47%, spe: 96.98%
2023-09-04 05:05:53.011540: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:05:53.015969: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:05:53.020645: finished real validation
2023-09-04 05:06:01.469192: train_loss -1.4528
2023-09-04 05:06:01.471299: val_loss -1.07
2023-09-04 05:06:01.473106: Pseudo dice [0.9115]
2023-09-04 05:06:01.474617: Epoch time: 452.11 s
2023-09-04 05:06:02.604818: 
2023-09-04 05:06:02.606922: Epoch 145
2023-09-04 05:06:02.608626: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-04 05:06:02.610680: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:08:01.624207: finished training epoch 145
2023-09-04 05:08:01.665430: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:08:01.668049: The split file contains 1 splits.
2023-09-04 05:08:01.669660: Desired fold for training: 0
2023-09-04 05:08:01.671201: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:13:41.046150: dsc: 91.18%
2023-09-04 05:13:41.048235: miou: 83.78%
2023-09-04 05:13:41.049813: acc: 95.54%, sen: 91.70%, spe: 96.83%
2023-09-04 05:13:41.051698: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:13:41.055520: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:13:41.060776: finished real validation
2023-09-04 05:13:49.503557: train_loss -1.4528
2023-09-04 05:13:49.505721: val_loss -1.0307
2023-09-04 05:13:49.507755: Pseudo dice [0.9092]
2023-09-04 05:13:49.509963: Epoch time: 466.9 s
2023-09-04 05:13:50.625878: 
2023-09-04 05:13:50.627796: Epoch 146
2023-09-04 05:13:50.629504: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-04 05:13:50.631606: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:15:49.838333: finished training epoch 146
2023-09-04 05:15:49.885611: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:15:49.888083: The split file contains 1 splits.
2023-09-04 05:15:49.889447: Desired fold for training: 0
2023-09-04 05:15:49.890731: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:21:51.352024: dsc: 91.22%
2023-09-04 05:21:51.354042: miou: 83.86%
2023-09-04 05:21:51.355738: acc: 95.57%, sen: 91.52%, spe: 96.93%
2023-09-04 05:21:51.357733: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:21:51.359248: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:21:51.360675: finished real validation
2023-09-04 05:21:59.806704: train_loss -1.4527
2023-09-04 05:21:59.808535: val_loss -1.0272
2023-09-04 05:21:59.810172: Pseudo dice [0.9055]
2023-09-04 05:21:59.811627: Epoch time: 489.18 s
2023-09-04 05:22:00.970690: 
2023-09-04 05:22:00.972782: Epoch 147
2023-09-04 05:22:00.974342: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-04 05:22:00.976206: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:24:00.086085: finished training epoch 147
2023-09-04 05:24:00.115965: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:24:00.118405: The split file contains 1 splits.
2023-09-04 05:24:00.120009: Desired fold for training: 0
2023-09-04 05:24:00.121545: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:29:55.009951: dsc: 91.38%
2023-09-04 05:29:55.011736: miou: 84.13%
2023-09-04 05:29:55.013096: acc: 95.65%, sen: 91.71%, spe: 96.97%
2023-09-04 05:29:55.014737: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:29:55.016207: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:29:55.017581: finished real validation
2023-09-04 05:30:03.457267: train_loss -1.4526
2023-09-04 05:30:03.459146: val_loss -1.0804
2023-09-04 05:30:03.461093: Pseudo dice [0.9153]
2023-09-04 05:30:03.462834: Epoch time: 482.49 s
2023-09-04 05:30:04.606771: 
2023-09-04 05:30:04.608698: Epoch 148
2023-09-04 05:30:04.610551: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-04 05:30:04.612502: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:32:03.637130: finished training epoch 148
2023-09-04 05:32:03.666310: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:32:03.668730: The split file contains 1 splits.
2023-09-04 05:32:03.670227: Desired fold for training: 0
2023-09-04 05:32:03.671655: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:37:37.154925: dsc: 91.29%
2023-09-04 05:37:37.157033: miou: 83.97%
2023-09-04 05:37:37.158571: acc: 95.62%, sen: 91.33%, spe: 97.06%
2023-09-04 05:37:37.160457: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:37:37.161930: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:37:37.163298: finished real validation
2023-09-04 05:37:45.613424: train_loss -1.4529
2023-09-04 05:37:45.615503: val_loss -1.0741
2023-09-04 05:37:45.617200: Pseudo dice [0.913]
2023-09-04 05:37:45.618747: Epoch time: 461.01 s
2023-09-04 05:37:46.751970: 
2023-09-04 05:37:46.754219: Epoch 149
2023-09-04 05:37:46.756318: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-04 05:37:46.758547: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:39:45.722549: finished training epoch 149
2023-09-04 05:39:45.752421: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:39:45.754964: The split file contains 1 splits.
2023-09-04 05:39:45.756727: Desired fold for training: 0
2023-09-04 05:39:45.758610: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:45:20.989531: dsc: 91.30%
2023-09-04 05:45:20.991706: miou: 83.99%
2023-09-04 05:45:20.993264: acc: 95.62%, sen: 91.35%, spe: 97.06%
2023-09-04 05:45:20.995407: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:45:20.996955: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:45:20.998655: finished real validation
2023-09-04 05:45:29.456609: train_loss -1.4529
2023-09-04 05:45:29.458519: val_loss -1.0687
2023-09-04 05:45:29.460671: Pseudo dice [0.9123]
2023-09-04 05:45:29.462425: Epoch time: 462.71 s
2023-09-04 05:45:32.425486: 
2023-09-04 05:45:32.427711: Epoch 150
2023-09-04 05:45:32.429572: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-04 05:45:32.431621: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:47:32.274865: finished training epoch 150
2023-09-04 05:47:32.304269: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:47:32.306734: The split file contains 1 splits.
2023-09-04 05:47:32.308223: Desired fold for training: 0
2023-09-04 05:47:32.309626: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:53:02.051059: dsc: 91.31%
2023-09-04 05:53:02.053129: miou: 84.01%
2023-09-04 05:53:02.054600: acc: 95.62%, sen: 91.39%, spe: 97.05%
2023-09-04 05:53:02.056320: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:53:02.057742: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 05:53:02.059129: finished real validation
2023-09-04 05:53:10.518204: train_loss -1.4531
2023-09-04 05:53:10.520146: val_loss -1.0681
2023-09-04 05:53:10.521938: Pseudo dice [0.9105]
2023-09-04 05:53:10.524030: Epoch time: 458.09 s
2023-09-04 05:53:11.677462: 
2023-09-04 05:53:11.679781: Epoch 151
2023-09-04 05:53:11.681874: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-04 05:53:11.685216: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:55:10.835970: finished training epoch 151
2023-09-04 05:55:10.876320: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:55:10.879044: The split file contains 1 splits.
2023-09-04 05:55:10.880705: Desired fold for training: 0
2023-09-04 05:55:10.882256: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:00:44.057347: dsc: 91.28%
2023-09-04 06:00:44.059510: miou: 83.96%
2023-09-04 06:00:44.061249: acc: 95.60%, sen: 91.64%, spe: 96.92%
2023-09-04 06:00:44.063408: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:00:44.065180: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:00:44.066926: finished real validation
2023-09-04 06:00:52.545986: train_loss -1.453
2023-09-04 06:00:52.548239: val_loss -1.0641
2023-09-04 06:00:52.550028: Pseudo dice [0.9105]
2023-09-04 06:00:52.551606: Epoch time: 460.87 s
2023-09-04 06:00:53.690683: 
2023-09-04 06:00:53.692960: Epoch 152
2023-09-04 06:00:53.694940: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-04 06:00:53.697155: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:02:52.903887: finished training epoch 152
2023-09-04 06:02:52.948223: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:02:52.951785: The split file contains 1 splits.
2023-09-04 06:02:52.953723: Desired fold for training: 0
2023-09-04 06:02:52.955316: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:08:24.911726: dsc: 91.32%
2023-09-04 06:08:24.913793: miou: 84.03%
2023-09-04 06:08:24.915564: acc: 95.62%, sen: 91.53%, spe: 97.00%
2023-09-04 06:08:24.917659: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:08:24.919472: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:08:24.921261: finished real validation
2023-09-04 06:08:33.378196: train_loss -1.454
2023-09-04 06:08:33.380380: val_loss -1.049
2023-09-04 06:08:33.382564: Pseudo dice [0.9107]
2023-09-04 06:08:33.384337: Epoch time: 459.69 s
2023-09-04 06:08:34.530424: 
2023-09-04 06:08:34.532743: Epoch 153
2023-09-04 06:08:34.534476: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-04 06:08:34.536541: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:10:33.730226: finished training epoch 153
2023-09-04 06:10:33.772031: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:10:33.774975: The split file contains 1 splits.
2023-09-04 06:10:33.776587: Desired fold for training: 0
2023-09-04 06:10:33.778090: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:15:55.157107: dsc: 91.39%
2023-09-04 06:15:55.159307: miou: 84.14%
2023-09-04 06:15:55.160952: acc: 95.65%, sen: 91.67%, spe: 96.99%
2023-09-04 06:15:55.163018: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:15:55.164842: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:15:55.166345: finished real validation
2023-09-04 06:16:03.633116: train_loss -1.4533
2023-09-04 06:16:03.638110: val_loss -1.0706
2023-09-04 06:16:03.641052: Pseudo dice [0.9137]
2023-09-04 06:16:03.643640: Epoch time: 449.1 s
2023-09-04 06:16:04.796968: 
2023-09-04 06:16:04.798916: Epoch 154
2023-09-04 06:16:04.800632: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-04 06:16:04.802722: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:18:03.945117: finished training epoch 154
2023-09-04 06:18:03.975221: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:18:03.978831: The split file contains 1 splits.
2023-09-04 06:18:03.980659: Desired fold for training: 0
2023-09-04 06:18:03.982430: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:23:43.083565: dsc: 91.22%
2023-09-04 06:23:43.086058: miou: 83.86%
2023-09-04 06:23:43.087689: acc: 95.59%, sen: 91.15%, spe: 97.08%
2023-09-04 06:23:43.089571: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:23:43.091116: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:23:43.092564: finished real validation
2023-09-04 06:23:51.540763: train_loss -1.4532
2023-09-04 06:23:51.542977: val_loss -1.0604
2023-09-04 06:23:51.545244: Pseudo dice [0.9127]
2023-09-04 06:23:51.547158: Epoch time: 466.75 s
2023-09-04 06:23:52.698045: 
2023-09-04 06:23:52.700265: Epoch 155
2023-09-04 06:23:52.702060: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-04 06:23:52.704779: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:25:51.897144: finished training epoch 155
2023-09-04 06:25:51.949649: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:25:51.952017: The split file contains 1 splits.
2023-09-04 06:25:51.953530: Desired fold for training: 0
2023-09-04 06:25:51.955037: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:32:08.357163: dsc: 91.41%
2023-09-04 06:32:08.359318: miou: 84.18%
2023-09-04 06:32:08.360810: acc: 95.67%, sen: 91.60%, spe: 97.04%
2023-09-04 06:32:08.362601: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:32:08.364068: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:32:08.365484: finished real validation
2023-09-04 06:32:16.818493: train_loss -1.4536
2023-09-04 06:32:16.820469: val_loss -1.1107
2023-09-04 06:32:16.822221: Pseudo dice [0.9192]
2023-09-04 06:32:16.824314: Epoch time: 504.12 s
2023-09-04 06:32:17.977990: 
2023-09-04 06:32:17.979994: Epoch 156
2023-09-04 06:32:17.981458: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-04 06:32:17.983239: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:34:17.084438: finished training epoch 156
2023-09-04 06:34:17.125407: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:34:17.128196: The split file contains 1 splits.
2023-09-04 06:34:17.129902: Desired fold for training: 0
2023-09-04 06:34:17.131430: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:40:00.048596: dsc: 91.33%
2023-09-04 06:40:00.050783: miou: 84.05%
2023-09-04 06:40:00.052630: acc: 95.63%, sen: 91.48%, spe: 97.03%
2023-09-04 06:40:00.055619: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:40:00.057682: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:40:00.059206: finished real validation
2023-09-04 06:40:08.504541: train_loss -1.4531
2023-09-04 06:40:08.506399: val_loss -1.0826
2023-09-04 06:40:08.508123: Pseudo dice [0.9143]
2023-09-04 06:40:08.510072: Epoch time: 470.53 s
2023-09-04 06:40:09.703175: 
2023-09-04 06:40:09.705095: Epoch 157
2023-09-04 06:40:09.706599: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-04 06:40:09.708404: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:42:08.649327: finished training epoch 157
2023-09-04 06:42:08.678824: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:42:08.681436: The split file contains 1 splits.
2023-09-04 06:42:08.683118: Desired fold for training: 0
2023-09-04 06:42:08.684604: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:47:37.873744: dsc: 91.33%
2023-09-04 06:47:37.875931: miou: 84.04%
2023-09-04 06:47:37.877732: acc: 95.64%, sen: 91.25%, spe: 97.12%
2023-09-04 06:47:37.879792: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:47:37.881505: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:47:37.883300: finished real validation
2023-09-04 06:47:46.333806: train_loss -1.454
2023-09-04 06:47:46.336118: val_loss -1.0683
2023-09-04 06:47:46.338133: Pseudo dice [0.9128]
2023-09-04 06:47:46.339934: Epoch time: 456.63 s
2023-09-04 06:47:47.485550: 
2023-09-04 06:47:47.487922: Epoch 158
2023-09-04 06:47:47.490079: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-04 06:47:47.492694: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:49:46.484701: finished training epoch 158
2023-09-04 06:49:46.518080: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:49:46.520561: The split file contains 1 splits.
2023-09-04 06:49:46.522201: Desired fold for training: 0
2023-09-04 06:49:46.523879: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:55:24.907008: dsc: 91.38%
2023-09-04 06:55:24.909096: miou: 84.13%
2023-09-04 06:55:24.910653: acc: 95.63%, sen: 92.13%, spe: 96.81%
2023-09-04 06:55:24.912484: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:55:24.914047: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 06:55:24.915599: finished real validation
2023-09-04 06:55:33.362906: train_loss -1.4538
2023-09-04 06:55:33.365124: val_loss -1.0658
2023-09-04 06:55:33.367133: Pseudo dice [0.9109]
2023-09-04 06:55:33.369100: Epoch time: 465.88 s
2023-09-04 06:55:34.515171: 
2023-09-04 06:55:34.517385: Epoch 159
2023-09-04 06:55:34.519313: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-04 06:55:34.521579: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:57:33.499573: finished training epoch 159
2023-09-04 06:57:33.529800: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:57:33.532654: The split file contains 1 splits.
2023-09-04 06:57:33.534320: Desired fold for training: 0
2023-09-04 06:57:33.535994: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:03:17.094024: dsc: 91.38%
2023-09-04 07:03:17.096063: miou: 84.12%
2023-09-04 07:03:17.097960: acc: 95.66%, sen: 91.32%, spe: 97.13%
2023-09-04 07:03:17.099824: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:03:17.101342: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:03:17.102813: finished real validation
2023-09-04 07:03:25.556787: train_loss -1.454
2023-09-04 07:03:25.558969: val_loss -1.0829
2023-09-04 07:03:25.560778: Pseudo dice [0.9161]
2023-09-04 07:03:25.562326: Epoch time: 471.04 s
2023-09-04 07:03:28.538441: 
2023-09-04 07:03:28.540507: Epoch 160
2023-09-04 07:03:28.542215: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-04 07:03:28.544825: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:05:27.694680: finished training epoch 160
2023-09-04 07:05:27.730167: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:05:27.734044: The split file contains 1 splits.
2023-09-04 07:05:27.736015: Desired fold for training: 0
2023-09-04 07:05:27.737825: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:10:56.100539: dsc: 91.30%
2023-09-04 07:10:56.102638: miou: 84.00%
2023-09-04 07:10:56.104398: acc: 95.63%, sen: 91.27%, spe: 97.09%
2023-09-04 07:10:56.106325: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:10:56.108064: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:10:56.109882: finished real validation
2023-09-04 07:11:04.550206: train_loss -1.454
2023-09-04 07:11:04.552457: val_loss -1.0632
2023-09-04 07:11:04.554351: Pseudo dice [0.9119]
2023-09-04 07:11:04.556414: Epoch time: 456.01 s
2023-09-04 07:11:05.694485: 
2023-09-04 07:11:05.696597: Epoch 161
2023-09-04 07:11:05.698393: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-04 07:11:05.700844: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:13:04.954100: finished training epoch 161
2023-09-04 07:13:04.987774: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:13:04.990543: The split file contains 1 splits.
2023-09-04 07:13:04.992424: Desired fold for training: 0
2023-09-04 07:13:04.994157: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:18:33.656497: dsc: 91.29%
2023-09-04 07:18:33.658520: miou: 83.98%
2023-09-04 07:18:33.660096: acc: 95.60%, sen: 91.59%, spe: 96.95%
2023-09-04 07:18:33.662095: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:18:33.663980: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:18:33.665704: finished real validation
2023-09-04 07:18:42.101214: train_loss -1.4548
2023-09-04 07:18:42.103388: val_loss -1.0524
2023-09-04 07:18:42.105350: Pseudo dice [0.9119]
2023-09-04 07:18:42.107691: Epoch time: 456.41 s
2023-09-04 07:18:43.241247: 
2023-09-04 07:18:43.243408: Epoch 162
2023-09-04 07:18:43.245051: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-04 07:18:43.247056: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:20:42.451901: finished training epoch 162
2023-09-04 07:20:42.482986: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:20:42.486002: The split file contains 1 splits.
2023-09-04 07:20:42.487790: Desired fold for training: 0
2023-09-04 07:20:42.489551: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:26:14.650064: dsc: 91.40%
2023-09-04 07:26:14.652128: miou: 84.17%
2023-09-04 07:26:14.653826: acc: 95.65%, sen: 91.85%, spe: 96.93%
2023-09-04 07:26:14.655903: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:26:14.657697: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:26:14.659490: finished real validation
2023-09-04 07:26:23.094785: train_loss -1.4539
2023-09-04 07:26:23.096897: val_loss -1.0672
2023-09-04 07:26:23.098618: Pseudo dice [0.9138]
2023-09-04 07:26:23.100174: Epoch time: 459.86 s
2023-09-04 07:26:24.242332: 
2023-09-04 07:26:24.244660: Epoch 163
2023-09-04 07:26:24.246469: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-04 07:26:24.248720: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:28:23.368195: finished training epoch 163
2023-09-04 07:28:23.398932: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:28:23.401743: The split file contains 1 splits.
2023-09-04 07:28:23.403696: Desired fold for training: 0
2023-09-04 07:28:23.405268: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:34:02.558592: dsc: 91.26%
2023-09-04 07:34:02.560611: miou: 83.92%
2023-09-04 07:34:02.562339: acc: 95.61%, sen: 91.15%, spe: 97.11%
2023-09-04 07:34:02.564510: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:34:02.566511: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:34:02.568207: finished real validation
2023-09-04 07:34:11.012243: train_loss -1.4547
2023-09-04 07:34:11.014292: val_loss -1.0663
2023-09-04 07:34:11.016059: Pseudo dice [0.913]
2023-09-04 07:34:11.017632: Epoch time: 466.77 s
2023-09-04 07:34:12.170869: 
2023-09-04 07:34:12.173102: Epoch 164
2023-09-04 07:34:12.174867: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-04 07:34:12.177166: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:36:11.399532: finished training epoch 164
2023-09-04 07:36:11.428712: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:36:11.431093: The split file contains 1 splits.
2023-09-04 07:36:11.432718: Desired fold for training: 0
2023-09-04 07:36:11.434612: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:42:55.659719: dsc: 91.37%
2023-09-04 07:42:55.662169: miou: 84.11%
2023-09-04 07:42:55.664087: acc: 95.66%, sen: 91.27%, spe: 97.14%
2023-09-04 07:42:55.665904: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:42:55.667344: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:42:55.669686: finished real validation
2023-09-04 07:43:04.107491: train_loss -1.4546
2023-09-04 07:43:04.109485: val_loss -1.0742
2023-09-04 07:43:04.111246: Pseudo dice [0.9151]
2023-09-04 07:43:04.112857: Epoch time: 531.94 s
2023-09-04 07:43:05.271619: 
2023-09-04 07:43:05.273949: Epoch 165
2023-09-04 07:43:05.275769: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-04 07:43:05.277907: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:45:04.281629: finished training epoch 165
2023-09-04 07:45:04.318553: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:45:04.321118: The split file contains 1 splits.
2023-09-04 07:45:04.322709: Desired fold for training: 0
2023-09-04 07:45:04.324399: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:50:35.716421: dsc: 91.25%
2023-09-04 07:50:35.718513: miou: 83.91%
2023-09-04 07:50:35.720095: acc: 95.60%, sen: 91.23%, spe: 97.07%
2023-09-04 07:50:35.721934: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:50:35.723430: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:50:35.724878: finished real validation
2023-09-04 07:50:44.173906: train_loss -1.454
2023-09-04 07:50:44.175899: val_loss -1.0441
2023-09-04 07:50:44.177721: Pseudo dice [0.9097]
2023-09-04 07:50:44.179272: Epoch time: 458.9 s
2023-09-04 07:50:45.311613: 
2023-09-04 07:50:45.313766: Epoch 166
2023-09-04 07:50:45.315359: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-04 07:50:45.317338: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:52:44.389576: finished training epoch 166
2023-09-04 07:52:44.419161: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:52:44.421651: The split file contains 1 splits.
2023-09-04 07:52:44.423254: Desired fold for training: 0
2023-09-04 07:52:44.424788: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:58:21.692221: dsc: 91.43%
2023-09-04 07:58:21.694587: miou: 84.21%
2023-09-04 07:58:21.696345: acc: 95.68%, sen: 91.72%, spe: 97.01%
2023-09-04 07:58:21.698606: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:58:21.700486: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 07:58:21.702361: finished real validation
2023-09-04 07:58:30.126619: train_loss -1.4544
2023-09-04 07:58:30.128721: val_loss -1.092
2023-09-04 07:58:30.130613: Pseudo dice [0.9158]
2023-09-04 07:58:30.132254: Epoch time: 464.82 s
2023-09-04 07:58:31.240602: 
2023-09-04 07:58:31.243068: Epoch 167
2023-09-04 07:58:31.245033: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-04 07:58:31.247214: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:00:30.413081: finished training epoch 167
2023-09-04 08:00:30.443498: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:00:30.448024: The split file contains 1 splits.
2023-09-04 08:00:30.450146: Desired fold for training: 0
2023-09-04 08:00:30.452131: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:06:02.354761: dsc: 91.32%
2023-09-04 08:06:02.357023: miou: 84.03%
2023-09-04 08:06:02.359409: acc: 95.65%, sen: 91.08%, spe: 97.18%
2023-09-04 08:06:02.361398: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:06:02.363429: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:06:02.365246: finished real validation
2023-09-04 08:06:10.807028: train_loss -1.4542
2023-09-04 08:06:10.809124: val_loss -1.0677
2023-09-04 08:06:10.810908: Pseudo dice [0.9133]
2023-09-04 08:06:10.812796: Epoch time: 459.57 s
2023-09-04 08:06:11.928548: 
2023-09-04 08:06:11.930907: Epoch 168
2023-09-04 08:06:11.932655: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-04 08:06:11.934672: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:08:10.933620: finished training epoch 168
2023-09-04 08:08:10.973640: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:08:10.976320: The split file contains 1 splits.
2023-09-04 08:08:10.978005: Desired fold for training: 0
2023-09-04 08:08:10.979597: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:13:52.464833: dsc: 91.29%
2023-09-04 08:13:52.467052: miou: 83.97%
2023-09-04 08:13:52.468881: acc: 95.62%, sen: 91.29%, spe: 97.07%
2023-09-04 08:13:52.470872: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:13:52.472561: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:13:52.474481: finished real validation
2023-09-04 08:14:00.909918: train_loss -1.4548
2023-09-04 08:14:00.912225: val_loss -1.0822
2023-09-04 08:14:00.914216: Pseudo dice [0.914]
2023-09-04 08:14:00.916055: Epoch time: 468.98 s
2023-09-04 08:14:02.031376: 
2023-09-04 08:14:02.033794: Epoch 169
2023-09-04 08:14:02.035605: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-04 08:14:02.037699: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:16:01.955613: finished training epoch 169
2023-09-04 08:16:01.985490: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:16:01.988244: The split file contains 1 splits.
2023-09-04 08:16:01.990001: Desired fold for training: 0
2023-09-04 08:16:01.991749: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:22:40.375887: dsc: 91.43%
2023-09-04 08:22:40.377800: miou: 84.21%
2023-09-04 08:22:40.379677: acc: 95.68%, sen: 91.60%, spe: 97.05%
2023-09-04 08:22:40.381992: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:22:40.383610: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:22:40.386011: finished real validation
2023-09-04 08:22:48.816402: train_loss -1.4546
2023-09-04 08:22:48.818475: val_loss -1.0609
2023-09-04 08:22:48.820901: Pseudo dice [0.9141]
2023-09-04 08:22:48.822545: Epoch time: 526.79 s
2023-09-04 08:22:51.849948: 
2023-09-04 08:22:51.851971: Epoch 170
2023-09-04 08:22:51.854087: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-04 08:22:51.856815: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:24:50.866482: finished training epoch 170
2023-09-04 08:24:50.896265: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:24:50.898909: The split file contains 1 splits.
2023-09-04 08:24:50.900741: Desired fold for training: 0
2023-09-04 08:24:50.902477: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:30:22.794410: dsc: 91.48%
2023-09-04 08:30:22.796764: miou: 84.30%
2023-09-04 08:30:22.798128: acc: 95.71%, sen: 91.55%, spe: 97.11%
2023-09-04 08:30:22.799802: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:30:22.801184: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:30:22.802515: finished real validation
2023-09-04 08:30:31.226145: train_loss -1.4546
2023-09-04 08:30:31.228263: val_loss -1.0421
2023-09-04 08:30:31.230492: Pseudo dice [0.9084]
2023-09-04 08:30:31.232305: Epoch time: 459.38 s
2023-09-04 08:30:32.389365: 
2023-09-04 08:30:32.391319: Epoch 171
2023-09-04 08:30:32.392847: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-04 08:30:32.394773: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:32:31.444367: finished training epoch 171
2023-09-04 08:32:31.475188: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:32:31.478094: The split file contains 1 splits.
2023-09-04 08:32:31.479806: Desired fold for training: 0
2023-09-04 08:32:31.481485: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:38:17.609782: dsc: 91.31%
2023-09-04 08:38:17.612499: miou: 84.02%
2023-09-04 08:38:17.614301: acc: 95.63%, sen: 91.33%, spe: 97.08%
2023-09-04 08:38:17.616331: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:38:17.617931: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:38:17.619662: finished real validation
2023-09-04 08:38:26.071505: train_loss -1.4545
2023-09-04 08:38:26.073645: val_loss -1.0769
2023-09-04 08:38:26.075458: Pseudo dice [0.9139]
2023-09-04 08:38:26.077727: Epoch time: 473.68 s
2023-09-04 08:38:27.227919: 
2023-09-04 08:38:27.230239: Epoch 172
2023-09-04 08:38:27.232267: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-04 08:38:27.234626: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:40:26.400622: finished training epoch 172
2023-09-04 08:40:26.430830: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:40:26.433792: The split file contains 1 splits.
2023-09-04 08:40:26.435433: Desired fold for training: 0
2023-09-04 08:40:26.437015: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:46:01.159042: dsc: 91.47%
2023-09-04 08:46:01.161327: miou: 84.27%
2023-09-04 08:46:01.163104: acc: 95.70%, sen: 91.55%, spe: 97.10%
2023-09-04 08:46:01.165369: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:46:01.167325: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:46:01.169140: finished real validation
2023-09-04 08:46:09.614996: train_loss -1.4548
2023-09-04 08:46:09.617141: val_loss -1.05
2023-09-04 08:46:09.619009: Pseudo dice [0.9127]
2023-09-04 08:46:09.620747: Epoch time: 462.39 s
2023-09-04 08:46:10.761622: 
2023-09-04 08:46:10.763726: Epoch 173
2023-09-04 08:46:10.765487: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-04 08:46:10.767656: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:48:09.849982: finished training epoch 173
2023-09-04 08:48:09.893185: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:48:09.896784: The split file contains 1 splits.
2023-09-04 08:48:09.898855: Desired fold for training: 0
2023-09-04 08:48:09.900767: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:53:53.553752: dsc: 91.48%
2023-09-04 08:53:53.556048: miou: 84.30%
2023-09-04 08:53:53.557849: acc: 95.70%, sen: 91.70%, spe: 97.05%
2023-09-04 08:53:53.560046: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:53:53.562157: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 08:53:53.564173: finished real validation
2023-09-04 08:54:02.005032: train_loss -1.4547
2023-09-04 08:54:02.007383: val_loss -1.0834
2023-09-04 08:54:02.009563: Pseudo dice [0.9167]
2023-09-04 08:54:02.011276: Epoch time: 471.24 s
2023-09-04 08:54:03.131794: 
2023-09-04 08:54:03.133951: Epoch 174
2023-09-04 08:54:03.135624: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-04 08:54:03.137666: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:56:02.247217: finished training epoch 174
2023-09-04 08:56:02.284138: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:56:02.286487: The split file contains 1 splits.
2023-09-04 08:56:02.288125: Desired fold for training: 0
2023-09-04 08:56:02.289588: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:01:39.098053: dsc: 91.35%
2023-09-04 09:01:39.100685: miou: 84.07%
2023-09-04 09:01:39.102602: acc: 95.65%, sen: 91.33%, spe: 97.10%
2023-09-04 09:01:39.104726: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:01:39.106420: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:01:39.108006: finished real validation
2023-09-04 09:01:47.547061: train_loss -1.4551
2023-09-04 09:01:47.549241: val_loss -1.0668
2023-09-04 09:01:47.552109: Pseudo dice [0.9114]
2023-09-04 09:01:47.554612: Epoch time: 464.42 s
2023-09-04 09:01:48.726987: 
2023-09-04 09:01:48.729212: Epoch 175
2023-09-04 09:01:48.730897: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-04 09:01:48.732907: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:03:47.830075: finished training epoch 175
2023-09-04 09:03:47.869868: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:03:47.873243: The split file contains 1 splits.
2023-09-04 09:03:47.875413: Desired fold for training: 0
2023-09-04 09:03:47.877497: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:09:30.789952: dsc: 91.35%
2023-09-04 09:09:30.791968: miou: 84.08%
2023-09-04 09:09:30.793487: acc: 95.64%, sen: 91.65%, spe: 96.97%
2023-09-04 09:09:30.795552: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:09:30.797376: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:09:30.799586: finished real validation
2023-09-04 09:09:39.231045: train_loss -1.4551
2023-09-04 09:09:39.233028: val_loss -1.0629
2023-09-04 09:09:39.235144: Pseudo dice [0.9146]
2023-09-04 09:09:39.237194: Epoch time: 470.51 s
2023-09-04 09:09:40.387497: 
2023-09-04 09:09:40.389704: Epoch 176
2023-09-04 09:09:40.391424: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-04 09:09:40.393451: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:11:39.452091: finished training epoch 176
2023-09-04 09:11:39.481655: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:11:39.484244: The split file contains 1 splits.
2023-09-04 09:11:39.486269: Desired fold for training: 0
2023-09-04 09:11:39.487988: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:17:17.328488: dsc: 91.47%
2023-09-04 09:17:17.330816: miou: 84.28%
2023-09-04 09:17:17.332836: acc: 95.68%, sen: 91.99%, spe: 96.93%
2023-09-04 09:17:17.335116: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:17:17.337612: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:17:17.340406: finished real validation
2023-09-04 09:17:25.800982: train_loss -1.4551
2023-09-04 09:17:25.803139: val_loss -1.0322
2023-09-04 09:17:25.804997: Pseudo dice [0.9088]
2023-09-04 09:17:25.806668: Epoch time: 465.42 s
2023-09-04 09:17:26.944173: 
2023-09-04 09:17:26.945981: Epoch 177
2023-09-04 09:17:26.947539: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-04 09:17:26.949370: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:19:26.140099: finished training epoch 177
2023-09-04 09:19:26.170944: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:19:26.173712: The split file contains 1 splits.
2023-09-04 09:19:26.175658: Desired fold for training: 0
2023-09-04 09:19:26.177699: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:24:58.663578: dsc: 91.34%
2023-09-04 09:24:58.665974: miou: 84.05%
2023-09-04 09:24:58.668024: acc: 95.64%, sen: 91.37%, spe: 97.08%
2023-09-04 09:24:58.670403: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:24:58.672321: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:24:58.674285: finished real validation
2023-09-04 09:25:07.469026: train_loss -1.4552
2023-09-04 09:25:07.471176: val_loss -1.0739
2023-09-04 09:25:07.473094: Pseudo dice [0.9143]
2023-09-04 09:25:07.475208: Epoch time: 460.53 s
2023-09-04 09:25:08.661328: 
2023-09-04 09:25:08.663474: Epoch 178
2023-09-04 09:25:08.665414: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-04 09:25:08.667652: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:27:07.858493: finished training epoch 178
2023-09-04 09:27:07.889365: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:27:07.892646: The split file contains 1 splits.
2023-09-04 09:27:07.894646: Desired fold for training: 0
2023-09-04 09:27:07.896539: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:32:52.739903: dsc: 91.33%
2023-09-04 09:32:52.742304: miou: 84.04%
2023-09-04 09:32:52.744112: acc: 95.63%, sen: 91.48%, spe: 97.02%
2023-09-04 09:32:52.746622: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:32:52.748439: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:32:52.750119: finished real validation
2023-09-04 09:33:01.177451: train_loss -1.4555
2023-09-04 09:33:01.179684: val_loss -1.0646
2023-09-04 09:33:01.181678: Pseudo dice [0.9136]
2023-09-04 09:33:01.183834: Epoch time: 472.52 s
2023-09-04 09:33:02.312192: 
2023-09-04 09:33:02.314348: Epoch 179
2023-09-04 09:33:02.316133: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-04 09:33:02.318336: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:35:01.433460: finished training epoch 179
2023-09-04 09:35:01.473508: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:35:01.476225: The split file contains 1 splits.
2023-09-04 09:35:01.477901: Desired fold for training: 0
2023-09-04 09:35:01.479589: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:40:49.242739: dsc: 91.43%
2023-09-04 09:40:49.244840: miou: 84.22%
2023-09-04 09:40:49.246549: acc: 95.66%, sen: 91.99%, spe: 96.90%
2023-09-04 09:40:49.249207: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:40:49.250901: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:40:49.252506: finished real validation
2023-09-04 09:40:57.688531: train_loss -1.4555
2023-09-04 09:40:57.690989: val_loss -1.0821
2023-09-04 09:40:57.693120: Pseudo dice [0.9164]
2023-09-04 09:40:57.694994: Epoch time: 475.38 s
2023-09-04 09:41:00.705922: 
2023-09-04 09:41:00.708199: Epoch 180
2023-09-04 09:41:00.710055: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-04 09:41:00.712241: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:43:00.084491: finished training epoch 180
2023-09-04 09:43:00.121235: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:43:00.124140: The split file contains 1 splits.
2023-09-04 09:43:00.126019: Desired fold for training: 0
2023-09-04 09:43:00.127688: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:48:39.217899: dsc: 91.30%
2023-09-04 09:48:39.220133: miou: 83.99%
2023-09-04 09:48:39.222145: acc: 95.62%, sen: 91.29%, spe: 97.08%
2023-09-04 09:48:39.224406: current best miou: 0.8431270818027369 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:48:39.226228: current best dsc: 0.9148876278005594 at epoch: 107, (107, 0.8431270818027369, 0.9148876278005594)
2023-09-04 09:48:39.227814: finished real validation
2023-09-04 09:48:47.666312: train_loss -1.456
2023-09-04 09:48:47.668478: val_loss -1.0674
2023-09-04 09:48:47.670415: Pseudo dice [0.9133]
2023-09-04 09:48:47.672180: Epoch time: 466.96 s
2023-09-04 09:48:48.787635: 
2023-09-04 09:48:48.789964: Epoch 181
2023-09-04 09:48:48.792020: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-04 09:48:48.794394: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:50:48.004760: finished training epoch 181
2023-09-04 09:50:48.032587: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:50:48.035550: The split file contains 1 splits.
2023-09-04 09:50:48.038115: Desired fold for training: 0
2023-09-04 09:50:48.041543: This split has 1886 training and 808 validation cases.
