OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-02 00:09:07.785057: I am training on qa-rtx6k-009.crc.nd.edu
2023-09-02 00:09:07.786050: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/456329_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

===============use SpatialAtt + ChannelAtt and My attention layer===============
model: PVTNetwork_1(
  (backbone): pvt_v2_b2(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (ca_1): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_1): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_2): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_2): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_3): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(320, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(20, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_3): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (ca_4): ChannelAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (max_pool): AdaptiveMaxPool2d(output_size=1)
    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (relu1): ReLU()
    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (sigmoid): Sigmoid()
  )
  (sa_4): SpatialAttention(
    (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (sigmoid): Sigmoid()
  )
  (Translayer_1): BasicConv2d(
    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_2): BasicConv2d(
    (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_3): BasicConv2d(
    (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (Translayer_4): BasicConv2d(
    (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (attention_1): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_2): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_3): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (attention_4): AttentionLayer(
    (convs): ModuleList(
      (0-3): 4 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (seg_outs): ModuleList(
    (0-3): 4 x Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (deconv2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (deconv5): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
)
===============<class 'nnunetv2.training.network.model.dim2.pvt.pvt_1.PVTNetwork_1'>================
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]
loading from : /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/456329_my_unet_FusedMBConv_16/fold_0/checkpoint_latest.pth

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'pvt1', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset124_ISIC2018', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.57754516601562, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 29.0, 'percentile_99_5': 253.0, 'std': 42.08180618286133}, '1': {'max': 255.0, 'mean': 111.1130142211914, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 8.0, 'percentile_99_5': 222.0, 'std': 43.864933013916016}, '2': {'max': 255.0, 'mean': 91.45153045654297, 'median': 91.0, 'min': 0.0, 'percentile_00_5': 4.0, 'percentile_99_5': 209.0, 'std': 43.73163604736328}}} 

2023-09-02 00:09:11.769805: unpacking dataset...
2023-09-02 00:09:54.524806: unpacking done...
2023-09-02 00:09:54.526345: do_dummy_2d_data_aug: False
2023-09-02 00:09:54.546328: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:09:54.547614: The split file contains 1 splits.
2023-09-02 00:09:54.548109: Desired fold for training: 0
2023-09-02 00:09:54.548526: This split has 1886 training and 808 validation cases.
==================batch size: 49==================
2023-09-02 00:09:54.583156: Unable to plot network architecture:
2023-09-02 00:09:54.583507: No module named 'hiddenlayer'
===================debug: False===================
2023-09-02 00:09:57.111114: 
2023-09-02 00:09:57.111795: Epoch 170
2023-09-02 00:09:57.112527: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-02 00:09:57.113074: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-02 00:11:11.264284: finished training epoch 170
2023-09-02 00:11:11.299542: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:11:11.301005: The split file contains 1 splits.
2023-09-02 00:11:11.301871: Desired fold for training: 0
2023-09-02 00:11:11.302444: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:16:17.827759: dsc: 91.19%
2023-09-02 00:16:17.828927: miou: 83.80%
2023-09-02 00:16:17.829599: acc: 95.58%, sen: 90.82%, spe: 97.18%
2023-09-02 00:16:17.830590: current best miou: 0.8379932158881044 at epoch: 170, (170, 0.8379932158881044, 0.9118567018031047)
2023-09-02 00:16:17.831197: current best dsc: 0.9118567018031047 at epoch: 170, (170, 0.8379932158881044, 0.9118567018031047)
2023-09-02 00:16:19.364852: finished real validation
using pin_memory on device 0
2023-09-02 00:16:24.626007: train_loss -1.4402
2023-09-02 00:16:24.627123: val_loss -1.0063
2023-09-02 00:16:24.628510: Pseudo dice [0.911]
2023-09-02 00:16:24.629294: Epoch time: 387.52 s
2023-09-02 00:16:26.842067: 
2023-09-02 00:16:26.843038: Epoch 171
2023-09-02 00:16:26.843707: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-02 00:16:26.845084: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:17:28.933405: finished training epoch 171
2023-09-02 00:17:28.976144: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:17:28.978016: The split file contains 1 splits.
2023-09-02 00:17:28.978732: Desired fold for training: 0
2023-09-02 00:17:28.979334: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:22:44.218337: dsc: 91.26%
2023-09-02 00:22:44.219368: miou: 83.92%
2023-09-02 00:22:44.220083: acc: 95.61%, sen: 91.16%, spe: 97.10%
2023-09-02 00:22:44.220935: current best miou: 0.8391908786172766 at epoch: 171, (171, 0.8391908786172766, 0.912565289849838)
2023-09-02 00:22:44.221577: current best dsc: 0.912565289849838 at epoch: 171, (171, 0.8391908786172766, 0.912565289849838)
2023-09-02 00:22:45.769644: finished real validation
2023-09-02 00:22:50.151964: train_loss -1.4403
2023-09-02 00:22:50.153156: val_loss -1.0341
2023-09-02 00:22:50.154094: Pseudo dice [0.9134]
2023-09-02 00:22:50.154711: Epoch time: 383.31 s
2023-09-02 00:22:51.302532: 
2023-09-02 00:22:51.303626: Epoch 172
2023-09-02 00:22:51.304324: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-02 00:22:51.305421: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:23:53.509789: finished training epoch 172
2023-09-02 00:23:53.543998: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:23:53.545351: The split file contains 1 splits.
2023-09-02 00:23:53.545907: Desired fold for training: 0
2023-09-02 00:23:53.546377: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:30:09.544950: dsc: 91.30%
2023-09-02 00:30:09.545851: miou: 83.99%
2023-09-02 00:30:09.546461: acc: 95.62%, sen: 91.41%, spe: 97.03%
2023-09-02 00:30:09.547398: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:30:09.548007: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:30:11.168929: finished real validation
2023-09-02 00:30:15.533939: train_loss -1.4409
2023-09-02 00:30:15.535110: val_loss -0.9915
2023-09-02 00:30:15.536236: Pseudo dice [0.9066]
2023-09-02 00:30:15.536943: Epoch time: 444.23 s
2023-09-02 00:30:16.752632: 
2023-09-02 00:30:16.753489: Epoch 173
2023-09-02 00:30:16.754124: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-02 00:30:16.755080: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:31:18.700181: finished training epoch 173
2023-09-02 00:31:18.750569: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:31:18.752269: The split file contains 1 splits.
2023-09-02 00:31:18.753043: Desired fold for training: 0
2023-09-02 00:31:18.753574: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:36:22.470717: dsc: 91.07%
2023-09-02 00:36:22.471797: miou: 83.60%
2023-09-02 00:36:22.472494: acc: 95.50%, sen: 91.21%, spe: 96.94%
2023-09-02 00:36:22.473522: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:36:22.474121: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:36:22.474710: finished real validation
2023-09-02 00:36:26.836111: train_loss -1.4402
2023-09-02 00:36:26.837214: val_loss -1.0015
2023-09-02 00:36:26.838071: Pseudo dice [0.9065]
2023-09-02 00:36:26.838737: Epoch time: 370.08 s
2023-09-02 00:36:29.052150: 
2023-09-02 00:36:29.053182: Epoch 174
2023-09-02 00:36:29.053953: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-02 00:36:29.055089: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:37:31.107351: finished training epoch 174
2023-09-02 00:37:31.143495: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:37:31.145017: The split file contains 1 splits.
2023-09-02 00:37:31.145659: Desired fold for training: 0
2023-09-02 00:37:31.146248: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:42:55.792006: dsc: 91.09%
2023-09-02 00:42:55.793145: miou: 83.63%
2023-09-02 00:42:55.793832: acc: 95.51%, sen: 91.27%, spe: 96.93%
2023-09-02 00:42:55.794696: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:42:55.795258: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:42:55.795752: finished real validation
2023-09-02 00:43:00.146890: train_loss -1.4408
2023-09-02 00:43:00.147983: val_loss -1.0437
2023-09-02 00:43:00.148924: Pseudo dice [0.9153]
2023-09-02 00:43:00.149636: Epoch time: 391.1 s
2023-09-02 00:43:01.310997: 
2023-09-02 00:43:01.312155: Epoch 175
2023-09-02 00:43:01.312908: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-02 00:43:01.314016: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:44:03.361412: finished training epoch 175
2023-09-02 00:44:03.397786: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:44:03.399795: The split file contains 1 splits.
2023-09-02 00:44:03.400553: Desired fold for training: 0
2023-09-02 00:44:03.401184: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:49:10.841846: dsc: 91.17%
2023-09-02 00:49:10.843025: miou: 83.77%
2023-09-02 00:49:10.843738: acc: 95.56%, sen: 91.10%, spe: 97.06%
2023-09-02 00:49:10.844672: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:49:10.845332: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:49:10.845872: finished real validation
2023-09-02 00:49:15.212058: train_loss -1.4414
2023-09-02 00:49:15.213221: val_loss -1.0164
2023-09-02 00:49:15.214105: Pseudo dice [0.9101]
2023-09-02 00:49:15.214817: Epoch time: 373.9 s
2023-09-02 00:49:16.367685: 
2023-09-02 00:49:16.368584: Epoch 176
2023-09-02 00:49:16.369270: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-02 00:49:16.370332: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:50:18.668473: finished training epoch 176
2023-09-02 00:50:18.709012: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:50:18.710555: The split file contains 1 splits.
2023-09-02 00:50:18.711835: Desired fold for training: 0
2023-09-02 00:50:18.713001: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 00:55:24.872068: dsc: 91.13%
2023-09-02 00:55:24.873382: miou: 83.70%
2023-09-02 00:55:24.874002: acc: 95.53%, sen: 91.22%, spe: 96.98%
2023-09-02 00:55:24.874863: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:55:24.875763: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 00:55:24.876487: finished real validation
2023-09-02 00:55:29.255551: train_loss -1.4411
2023-09-02 00:55:29.257017: val_loss -1.0506
2023-09-02 00:55:29.258224: Pseudo dice [0.918]
2023-09-02 00:55:29.259008: Epoch time: 372.89 s
2023-09-02 00:55:30.414311: 
2023-09-02 00:55:30.415251: Epoch 177
2023-09-02 00:55:30.416037: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-02 00:55:30.417349: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 00:56:32.544699: finished training epoch 177
2023-09-02 00:56:32.582967: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 00:56:32.584577: The split file contains 1 splits.
2023-09-02 00:56:32.585315: Desired fold for training: 0
2023-09-02 00:56:32.585926: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:01:35.556840: dsc: 91.20%
2023-09-02 01:01:35.558125: miou: 83.83%
2023-09-02 01:01:35.558825: acc: 95.58%, sen: 91.12%, spe: 97.08%
2023-09-02 01:01:35.559840: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:01:35.560533: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:01:35.561112: finished real validation
2023-09-02 01:01:39.942701: train_loss -1.441
2023-09-02 01:01:39.943953: val_loss -0.9939
2023-09-02 01:01:39.944973: Pseudo dice [0.9097]
2023-09-02 01:01:39.945673: Epoch time: 369.53 s
2023-09-02 01:01:41.141249: 
2023-09-02 01:01:41.142316: Epoch 178
2023-09-02 01:01:41.143098: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-02 01:01:41.144317: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:02:43.222327: finished training epoch 178
2023-09-02 01:02:43.265051: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:02:43.266864: The split file contains 1 splits.
2023-09-02 01:02:43.267656: Desired fold for training: 0
2023-09-02 01:02:43.268282: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:07:51.004478: dsc: 91.26%
2023-09-02 01:07:51.005631: miou: 83.93%
2023-09-02 01:07:51.006458: acc: 95.62%, sen: 90.94%, spe: 97.19%
2023-09-02 01:07:51.007453: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:07:51.008144: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:07:51.008678: finished real validation
2023-09-02 01:07:55.378800: train_loss -1.4415
2023-09-02 01:07:55.379964: val_loss -1.0631
2023-09-02 01:07:55.380917: Pseudo dice [0.9184]
2023-09-02 01:07:55.381679: Epoch time: 374.24 s
2023-09-02 01:07:56.545741: 
2023-09-02 01:07:56.546919: Epoch 179
2023-09-02 01:07:56.547754: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-02 01:07:56.548860: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:08:58.615590: finished training epoch 179
2023-09-02 01:08:58.650961: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:08:58.653345: The split file contains 1 splits.
2023-09-02 01:08:58.654148: Desired fold for training: 0
2023-09-02 01:08:58.654884: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:14:06.031975: dsc: 91.19%
2023-09-02 01:14:06.033156: miou: 83.80%
2023-09-02 01:14:06.033798: acc: 95.60%, sen: 90.45%, spe: 97.33%
2023-09-02 01:14:06.034695: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:14:06.035333: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:14:06.035986: finished real validation
2023-09-02 01:14:10.411021: train_loss -1.4417
2023-09-02 01:14:10.412641: val_loss -1.0188
2023-09-02 01:14:10.414495: Pseudo dice [0.9136]
2023-09-02 01:14:10.415764: Epoch time: 373.87 s
2023-09-02 01:14:13.265790: 
2023-09-02 01:14:13.266953: Epoch 180
2023-09-02 01:14:13.267701: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-02 01:14:13.268881: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:15:15.402812: finished training epoch 180
2023-09-02 01:15:15.435715: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:15:15.437162: The split file contains 1 splits.
2023-09-02 01:15:15.437822: Desired fold for training: 0
2023-09-02 01:15:15.438345: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:21:26.814978: dsc: 91.20%
2023-09-02 01:21:26.816138: miou: 83.82%
2023-09-02 01:21:26.816796: acc: 95.60%, sen: 90.68%, spe: 97.25%
2023-09-02 01:21:26.817768: current best miou: 0.8398566402991586 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:21:26.818493: current best dsc: 0.9129587837480629 at epoch: 172, (172, 0.8398566402991586, 0.9129587837480629)
2023-09-02 01:21:26.819048: finished real validation
2023-09-02 01:21:31.172770: train_loss -1.4414
2023-09-02 01:21:31.173898: val_loss -1.0318
2023-09-02 01:21:31.174804: Pseudo dice [0.9137]
2023-09-02 01:21:31.175484: Epoch time: 437.91 s
2023-09-02 01:21:32.354759: 
2023-09-02 01:21:32.355918: Epoch 181
2023-09-02 01:21:32.356694: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-02 01:21:32.357711: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:22:34.372940: finished training epoch 181
2023-09-02 01:22:34.410024: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:22:34.411703: The split file contains 1 splits.
2023-09-02 01:22:34.412439: Desired fold for training: 0
2023-09-02 01:22:34.413039: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:27:44.403336: dsc: 91.30%
2023-09-02 01:27:44.404454: miou: 83.99%
2023-09-02 01:27:44.405145: acc: 95.65%, sen: 90.81%, spe: 97.27%
2023-09-02 01:27:44.406156: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:27:44.406861: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:27:45.946866: finished real validation
2023-09-02 01:27:50.312490: train_loss -1.4411
2023-09-02 01:27:50.313699: val_loss -1.0204
2023-09-02 01:27:50.314681: Pseudo dice [0.9117]
2023-09-02 01:27:50.315449: Epoch time: 377.96 s
2023-09-02 01:27:51.476422: 
2023-09-02 01:27:51.477602: Epoch 182
2023-09-02 01:27:51.478348: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-02 01:27:51.479423: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:28:53.511164: finished training epoch 182
2023-09-02 01:28:53.555790: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:28:53.557576: The split file contains 1 splits.
2023-09-02 01:28:53.558290: Desired fold for training: 0
2023-09-02 01:28:53.559011: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:33:59.633262: dsc: 91.21%
2023-09-02 01:33:59.634573: miou: 83.84%
2023-09-02 01:33:59.635237: acc: 95.58%, sen: 91.23%, spe: 97.04%
2023-09-02 01:33:59.636791: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:33:59.637473: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:33:59.638052: finished real validation
2023-09-02 01:34:04.008248: train_loss -1.4413
2023-09-02 01:34:04.009493: val_loss -0.9899
2023-09-02 01:34:04.010476: Pseudo dice [0.9101]
2023-09-02 01:34:04.011263: Epoch time: 372.53 s
2023-09-02 01:34:05.176913: 
2023-09-02 01:34:05.178045: Epoch 183
2023-09-02 01:34:05.178920: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-02 01:34:05.180027: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:35:07.353791: finished training epoch 183
2023-09-02 01:35:07.400988: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:35:07.402727: The split file contains 1 splits.
2023-09-02 01:35:07.403511: Desired fold for training: 0
2023-09-02 01:35:07.404941: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:40:18.338136: dsc: 91.28%
2023-09-02 01:40:18.339248: miou: 83.95%
2023-09-02 01:40:18.340321: acc: 95.61%, sen: 91.25%, spe: 97.08%
2023-09-02 01:40:18.342312: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:40:18.343332: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:40:18.344212: finished real validation
2023-09-02 01:40:22.720934: train_loss -1.4419
2023-09-02 01:40:22.722223: val_loss -1.0327
2023-09-02 01:40:22.723242: Pseudo dice [0.9137]
2023-09-02 01:40:22.724026: Epoch time: 377.55 s
2023-09-02 01:40:23.897802: 
2023-09-02 01:40:23.898901: Epoch 184
2023-09-02 01:40:23.899682: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-02 01:40:23.900826: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:41:26.065353: finished training epoch 184
2023-09-02 01:41:26.112103: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:41:26.113685: The split file contains 1 splits.
2023-09-02 01:41:26.114639: Desired fold for training: 0
2023-09-02 01:41:26.115533: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:47:38.706939: dsc: 91.24%
2023-09-02 01:47:38.708108: miou: 83.89%
2023-09-02 01:47:38.708858: acc: 95.61%, sen: 90.92%, spe: 97.18%
2023-09-02 01:47:38.709929: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:47:38.710691: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:47:38.711319: finished real validation
2023-09-02 01:47:43.097732: train_loss -1.4418
2023-09-02 01:47:43.099129: val_loss -1.0324
2023-09-02 01:47:43.103721: Pseudo dice [0.9146]
2023-09-02 01:47:43.105051: Epoch time: 439.2 s
2023-09-02 01:47:44.294138: 
2023-09-02 01:47:44.295328: Epoch 185
2023-09-02 01:47:44.296129: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-02 01:47:44.297364: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:48:46.295914: finished training epoch 185
2023-09-02 01:48:46.335549: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:48:46.337514: The split file contains 1 splits.
2023-09-02 01:48:46.338265: Desired fold for training: 0
2023-09-02 01:48:46.338967: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 01:54:00.050164: dsc: 91.27%
2023-09-02 01:54:00.051563: miou: 83.94%
2023-09-02 01:54:00.052256: acc: 95.62%, sen: 91.02%, spe: 97.17%
2023-09-02 01:54:00.053331: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:54:00.054071: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 01:54:00.054827: finished real validation
2023-09-02 01:54:04.424748: train_loss -1.4414
2023-09-02 01:54:04.425907: val_loss -1.0335
2023-09-02 01:54:04.426824: Pseudo dice [0.9135]
2023-09-02 01:54:04.427568: Epoch time: 380.13 s
2023-09-02 01:54:05.583640: 
2023-09-02 01:54:05.584923: Epoch 186
2023-09-02 01:54:05.585708: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-02 01:54:05.586848: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 01:55:07.505388: finished training epoch 186
2023-09-02 01:55:07.537841: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 01:55:07.540798: The split file contains 1 splits.
2023-09-02 01:55:07.541946: Desired fold for training: 0
2023-09-02 01:55:07.542881: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:00:16.487364: dsc: 91.22%
2023-09-02 02:00:16.488501: miou: 83.85%
2023-09-02 02:00:16.489221: acc: 95.60%, sen: 90.87%, spe: 97.19%
2023-09-02 02:00:16.490192: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 02:00:16.490882: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 02:00:16.491522: finished real validation
2023-09-02 02:00:20.849863: train_loss -1.4422
2023-09-02 02:00:20.851246: val_loss -1.0217
2023-09-02 02:00:20.852385: Pseudo dice [0.9139]
2023-09-02 02:00:20.853246: Epoch time: 375.27 s
2023-09-02 02:00:22.024014: 
2023-09-02 02:00:22.025146: Epoch 187
2023-09-02 02:00:22.025991: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-02 02:00:22.027148: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:01:24.011734: finished training epoch 187
2023-09-02 02:01:24.052908: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:01:24.054535: The split file contains 1 splits.
2023-09-02 02:01:24.055233: Desired fold for training: 0
2023-09-02 02:01:24.055965: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:06:35.927216: dsc: 91.16%
2023-09-02 02:06:35.928662: miou: 83.76%
2023-09-02 02:06:35.929452: acc: 95.57%, sen: 90.87%, spe: 97.15%
2023-09-02 02:06:35.930850: current best miou: 0.8399340235384382 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 02:06:35.931578: current best dsc: 0.9130045021104976 at epoch: 181, (181, 0.8399340235384382, 0.9130045021104976)
2023-09-02 02:06:35.932248: finished real validation
2023-09-02 02:06:40.310045: train_loss -1.4422
2023-09-02 02:06:40.311322: val_loss -0.9973
2023-09-02 02:06:40.312417: Pseudo dice [0.9091]
2023-09-02 02:06:40.313245: Epoch time: 378.29 s
2023-09-02 02:06:41.505187: 
2023-09-02 02:06:41.506386: Epoch 188
2023-09-02 02:06:41.507205: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-02 02:06:41.508529: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:07:43.605671: finished training epoch 188
2023-09-02 02:07:43.668571: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:07:43.670536: The split file contains 1 splits.
2023-09-02 02:07:43.671414: Desired fold for training: 0
2023-09-02 02:07:43.672158: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:13:57.152624: dsc: 91.32%
2023-09-02 02:13:57.153693: miou: 84.03%
2023-09-02 02:13:57.154518: acc: 95.63%, sen: 91.36%, spe: 97.07%
2023-09-02 02:13:57.156651: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:13:57.157792: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:13:58.732759: finished real validation
2023-09-02 02:14:03.111436: train_loss -1.4419
2023-09-02 02:14:03.112820: val_loss -1.0252
2023-09-02 02:14:03.113888: Pseudo dice [0.9144]
2023-09-02 02:14:03.114877: Epoch time: 441.61 s
2023-09-02 02:14:04.323835: 
2023-09-02 02:14:04.325200: Epoch 189
2023-09-02 02:14:04.326547: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-02 02:14:04.329108: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:15:06.816031: finished training epoch 189
2023-09-02 02:15:06.851292: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:15:06.853504: The split file contains 1 splits.
2023-09-02 02:15:06.854399: Desired fold for training: 0
2023-09-02 02:15:06.855223: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:20:22.107571: dsc: 91.18%
2023-09-02 02:20:22.158529: miou: 83.80%
2023-09-02 02:20:22.159744: acc: 95.58%, sen: 90.88%, spe: 97.16%
2023-09-02 02:20:22.161550: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:20:22.162589: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:20:22.163546: finished real validation
2023-09-02 02:20:26.527211: train_loss -1.4423
2023-09-02 02:20:26.528571: val_loss -1.0104
2023-09-02 02:20:26.529542: Pseudo dice [0.9115]
2023-09-02 02:20:26.530354: Epoch time: 382.21 s
2023-09-02 02:20:29.389971: 
2023-09-02 02:20:29.391223: Epoch 190
2023-09-02 02:20:29.392056: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-02 02:20:29.393209: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:21:31.503723: finished training epoch 190
2023-09-02 02:21:31.560244: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:21:31.562078: The split file contains 1 splits.
2023-09-02 02:21:31.562871: Desired fold for training: 0
2023-09-02 02:21:31.563624: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:26:40.620400: dsc: 91.00%
2023-09-02 02:26:40.621590: miou: 83.49%
2023-09-02 02:26:40.622397: acc: 95.47%, sen: 91.09%, spe: 96.94%
2023-09-02 02:26:40.623478: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:26:40.624213: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:26:40.624880: finished real validation
2023-09-02 02:26:44.986174: train_loss -1.4419
2023-09-02 02:26:44.987609: val_loss -1.0056
2023-09-02 02:26:44.988759: Pseudo dice [0.9097]
2023-09-02 02:26:44.989608: Epoch time: 375.6 s
2023-09-02 02:26:46.143064: 
2023-09-02 02:26:46.144220: Epoch 191
2023-09-02 02:26:46.145055: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-02 02:26:46.146316: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:27:48.173321: finished training epoch 191
2023-09-02 02:27:48.214846: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:27:48.216716: The split file contains 1 splits.
2023-09-02 02:27:48.217483: Desired fold for training: 0
2023-09-02 02:27:48.218182: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:33:00.090911: dsc: 91.13%
2023-09-02 02:33:00.092155: miou: 83.71%
2023-09-02 02:33:00.092907: acc: 95.55%, sen: 90.98%, spe: 97.08%
2023-09-02 02:33:00.094294: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:33:00.095041: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:33:00.095695: finished real validation
2023-09-02 02:33:04.466624: train_loss -1.4424
2023-09-02 02:33:04.468094: val_loss -1.0135
2023-09-02 02:33:04.469142: Pseudo dice [0.9133]
2023-09-02 02:33:04.469961: Epoch time: 378.32 s
2023-09-02 02:33:05.628544: 
2023-09-02 02:33:05.629785: Epoch 192
2023-09-02 02:33:05.630673: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-02 02:33:05.631895: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:34:07.844472: finished training epoch 192
2023-09-02 02:34:07.904110: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:34:07.905660: The split file contains 1 splits.
2023-09-02 02:34:07.906482: Desired fold for training: 0
2023-09-02 02:34:07.907204: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:40:26.063606: dsc: 91.16%
2023-09-02 02:40:26.064664: miou: 83.76%
2023-09-02 02:40:26.065356: acc: 95.57%, sen: 90.82%, spe: 97.17%
2023-09-02 02:40:26.066486: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:40:26.067178: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:40:26.067797: finished real validation
2023-09-02 02:40:30.440314: train_loss -1.4424
2023-09-02 02:40:30.441548: val_loss -0.9964
2023-09-02 02:40:30.442554: Pseudo dice [0.9078]
2023-09-02 02:40:30.443310: Epoch time: 444.81 s
2023-09-02 02:40:31.641103: 
2023-09-02 02:40:31.642466: Epoch 193
2023-09-02 02:40:31.643326: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-02 02:40:31.644579: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:41:33.650931: finished training epoch 193
2023-09-02 02:41:33.680142: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:41:33.681686: The split file contains 1 splits.
2023-09-02 02:41:33.682506: Desired fold for training: 0
2023-09-02 02:41:33.683249: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:46:40.298521: dsc: 91.17%
2023-09-02 02:46:40.299641: miou: 83.77%
2023-09-02 02:46:40.300399: acc: 95.56%, sen: 91.15%, spe: 97.04%
2023-09-02 02:46:40.301541: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:46:40.302319: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:46:40.302999: finished real validation
2023-09-02 02:46:44.680288: train_loss -1.4422
2023-09-02 02:46:44.681734: val_loss -1.0115
2023-09-02 02:46:44.682924: Pseudo dice [0.912]
2023-09-02 02:46:44.683754: Epoch time: 373.04 s
2023-09-02 02:46:45.893725: 
2023-09-02 02:46:45.895006: Epoch 194
2023-09-02 02:46:45.895802: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-02 02:46:45.897918: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:47:47.863969: finished training epoch 194
2023-09-02 02:47:47.893287: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:47:47.894833: The split file contains 1 splits.
2023-09-02 02:47:47.895842: Desired fold for training: 0
2023-09-02 02:47:47.896613: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:52:55.221652: dsc: 91.14%
2023-09-02 02:52:55.223155: miou: 83.73%
2023-09-02 02:52:55.224267: acc: 95.57%, sen: 90.62%, spe: 97.23%
2023-09-02 02:52:55.226200: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:52:55.227246: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:52:55.228232: finished real validation
2023-09-02 02:52:59.591500: train_loss -1.4423
2023-09-02 02:52:59.592833: val_loss -1.0052
2023-09-02 02:52:59.593850: Pseudo dice [0.9111]
2023-09-02 02:52:59.594704: Epoch time: 373.7 s
2023-09-02 02:53:00.777253: 
2023-09-02 02:53:00.778577: Epoch 195
2023-09-02 02:53:00.779454: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-02 02:53:00.780720: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 02:54:02.811637: finished training epoch 195
2023-09-02 02:54:02.852504: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 02:54:02.854471: The split file contains 1 splits.
2023-09-02 02:54:02.855238: Desired fold for training: 0
2023-09-02 02:54:02.855916: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 02:59:12.370023: dsc: 91.19%
2023-09-02 02:59:12.371251: miou: 83.81%
2023-09-02 02:59:12.372039: acc: 95.56%, sen: 91.35%, spe: 96.97%
2023-09-02 02:59:12.373082: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:59:12.373882: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 02:59:12.374747: finished real validation
2023-09-02 02:59:16.758614: train_loss -1.4427
2023-09-02 02:59:16.760125: val_loss -0.9925
2023-09-02 02:59:16.761314: Pseudo dice [0.9116]
2023-09-02 02:59:16.762367: Epoch time: 375.98 s
2023-09-02 02:59:17.935990: 
2023-09-02 02:59:17.937218: Epoch 196
2023-09-02 02:59:17.938126: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-02 02:59:17.939463: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:00:19.965627: finished training epoch 196
2023-09-02 03:00:19.999538: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:00:20.001600: The split file contains 1 splits.
2023-09-02 03:00:20.002381: Desired fold for training: 0
2023-09-02 03:00:20.003118: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:05:26.629738: dsc: 91.17%
2023-09-02 03:05:26.630850: miou: 83.78%
2023-09-02 03:05:26.631593: acc: 95.56%, sen: 91.17%, spe: 97.04%
2023-09-02 03:05:26.632592: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:05:26.633489: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:05:26.634187: finished real validation
2023-09-02 03:05:31.032045: train_loss -1.4429
2023-09-02 03:05:31.033348: val_loss -0.9935
2023-09-02 03:05:31.034426: Pseudo dice [0.9123]
2023-09-02 03:05:31.035255: Epoch time: 373.1 s
2023-09-02 03:05:32.198690: 
2023-09-02 03:05:32.199826: Epoch 197
2023-09-02 03:05:32.200688: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-02 03:05:32.201862: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:06:34.381966: finished training epoch 197
2023-09-02 03:06:34.442063: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:06:34.448384: The split file contains 1 splits.
2023-09-02 03:06:34.449807: Desired fold for training: 0
2023-09-02 03:06:34.451185: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:11:45.354267: dsc: 91.18%
2023-09-02 03:11:45.355588: miou: 83.80%
2023-09-02 03:11:45.356336: acc: 95.57%, sen: 91.02%, spe: 97.10%
2023-09-02 03:11:45.357378: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:11:45.358152: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:11:45.358835: finished real validation
2023-09-02 03:11:49.743836: train_loss -1.4428
2023-09-02 03:11:49.745235: val_loss -1.0173
2023-09-02 03:11:49.746367: Pseudo dice [0.9145]
2023-09-02 03:11:49.747416: Epoch time: 377.55 s
2023-09-02 03:11:50.942593: 
2023-09-02 03:11:50.943907: Epoch 198
2023-09-02 03:11:50.944798: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-02 03:11:50.946041: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:12:52.964528: finished training epoch 198
2023-09-02 03:12:53.000943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:12:53.002810: The split file contains 1 splits.
2023-09-02 03:12:53.003639: Desired fold for training: 0
2023-09-02 03:12:53.004359: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:18:12.062494: dsc: 91.24%
2023-09-02 03:18:12.063539: miou: 83.90%
2023-09-02 03:18:12.064282: acc: 95.59%, sen: 91.28%, spe: 97.04%
2023-09-02 03:18:12.065329: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:18:12.066060: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:18:12.066713: finished real validation
2023-09-02 03:18:16.439604: train_loss -1.4426
2023-09-02 03:18:16.440920: val_loss -1.0237
2023-09-02 03:18:16.441985: Pseudo dice [0.9126]
2023-09-02 03:18:16.442779: Epoch time: 385.5 s
2023-09-02 03:18:17.684490: 
2023-09-02 03:18:17.685555: Epoch 199
2023-09-02 03:18:17.686414: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-02 03:18:17.687650: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:19:19.650385: finished training epoch 199
2023-09-02 03:19:19.681385: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:19:19.683081: The split file contains 1 splits.
2023-09-02 03:19:19.683882: Desired fold for training: 0
2023-09-02 03:19:19.684566: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:24:30.873760: dsc: 91.24%
2023-09-02 03:24:30.875055: miou: 83.90%
2023-09-02 03:24:30.875865: acc: 95.59%, sen: 91.38%, spe: 97.00%
2023-09-02 03:24:30.877098: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:24:30.877935: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:24:30.878687: finished real validation
2023-09-02 03:24:35.246761: train_loss -1.4428
2023-09-02 03:24:35.248296: val_loss -1.0397
2023-09-02 03:24:35.249443: Pseudo dice [0.9149]
2023-09-02 03:24:35.250782: Epoch time: 377.56 s
2023-09-02 03:24:38.016157: 
2023-09-02 03:24:38.017338: Epoch 200
2023-09-02 03:24:38.018228: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-02 03:24:38.019572: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:25:40.035930: finished training epoch 200
2023-09-02 03:25:40.078960: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:25:40.081981: The split file contains 1 splits.
2023-09-02 03:25:40.083254: Desired fold for training: 0
2023-09-02 03:25:40.084232: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:30:57.115913: dsc: 91.16%
2023-09-02 03:30:57.117201: miou: 83.76%
2023-09-02 03:30:57.117963: acc: 95.56%, sen: 90.98%, spe: 97.10%
2023-09-02 03:30:57.119015: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:30:57.119809: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:30:57.120536: finished real validation
2023-09-02 03:31:01.509116: train_loss -1.443
2023-09-02 03:31:01.510672: val_loss -1.0048
2023-09-02 03:31:01.511844: Pseudo dice [0.9123]
2023-09-02 03:31:01.512762: Epoch time: 383.49 s
2023-09-02 03:31:02.679275: 
2023-09-02 03:31:02.680498: Epoch 201
2023-09-02 03:31:02.681429: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-02 03:31:02.682784: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:32:05.473743: finished training epoch 201
2023-09-02 03:32:05.512318: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:32:05.514058: The split file contains 1 splits.
2023-09-02 03:32:05.514889: Desired fold for training: 0
2023-09-02 03:32:05.515680: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:37:18.118751: dsc: 91.25%
2023-09-02 03:37:18.120288: miou: 83.90%
2023-09-02 03:37:18.121169: acc: 95.60%, sen: 91.13%, spe: 97.11%
2023-09-02 03:37:18.122470: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:37:18.123280: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:37:18.124029: finished real validation
2023-09-02 03:37:22.537021: train_loss -1.443
2023-09-02 03:37:22.538907: val_loss -0.9958
2023-09-02 03:37:22.540761: Pseudo dice [0.9139]
2023-09-02 03:37:22.542105: Epoch time: 379.86 s
2023-09-02 03:37:23.728312: 
2023-09-02 03:37:23.729648: Epoch 202
2023-09-02 03:37:23.730535: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-02 03:37:23.731917: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:38:25.802121: finished training epoch 202
2023-09-02 03:38:25.850557: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:38:25.852638: The split file contains 1 splits.
2023-09-02 03:38:25.853644: Desired fold for training: 0
2023-09-02 03:38:25.854516: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:43:38.134494: dsc: 91.21%
2023-09-02 03:43:38.135775: miou: 83.84%
2023-09-02 03:43:38.136595: acc: 95.57%, sen: 91.45%, spe: 96.95%
2023-09-02 03:43:38.137723: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:43:38.138507: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:43:38.139172: finished real validation
2023-09-02 03:43:42.560218: train_loss -1.4435
2023-09-02 03:43:42.561747: val_loss -0.9916
2023-09-02 03:43:42.563643: Pseudo dice [0.9116]
2023-09-02 03:43:42.565001: Epoch time: 378.83 s
2023-09-02 03:43:43.794428: 
2023-09-02 03:43:43.796155: Epoch 203
2023-09-02 03:43:43.797171: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-02 03:43:43.798740: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:44:46.166525: finished training epoch 203
2023-09-02 03:44:46.195228: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:44:46.196876: The split file contains 1 splits.
2023-09-02 03:44:46.198259: Desired fold for training: 0
2023-09-02 03:44:46.199247: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:49:56.181631: dsc: 91.26%
2023-09-02 03:49:56.182840: miou: 83.92%
2023-09-02 03:49:56.183626: acc: 95.61%, sen: 91.17%, spe: 97.10%
2023-09-02 03:49:56.184740: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:49:56.185621: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:49:56.186352: finished real validation
2023-09-02 03:50:00.570975: train_loss -1.4429
2023-09-02 03:50:00.572357: val_loss -1.0595
2023-09-02 03:50:00.573469: Pseudo dice [0.9182]
2023-09-02 03:50:00.574368: Epoch time: 376.78 s
2023-09-02 03:50:00.575163: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-02 03:50:03.615740: 
2023-09-02 03:50:03.617005: Epoch 204
2023-09-02 03:50:03.617867: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-02 03:50:03.619052: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:51:05.612964: finished training epoch 204
2023-09-02 03:51:05.659054: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:51:05.660706: The split file contains 1 splits.
2023-09-02 03:51:05.661676: Desired fold for training: 0
2023-09-02 03:51:05.662659: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 03:56:12.413954: dsc: 91.20%
2023-09-02 03:56:12.415516: miou: 83.82%
2023-09-02 03:56:12.416612: acc: 95.58%, sen: 91.02%, spe: 97.11%
2023-09-02 03:56:12.418000: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:56:12.418946: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 03:56:12.419847: finished real validation
2023-09-02 03:56:16.799486: train_loss -1.4429
2023-09-02 03:56:16.800991: val_loss -0.9949
2023-09-02 03:56:16.802139: Pseudo dice [0.9105]
2023-09-02 03:56:16.803070: Epoch time: 373.19 s
2023-09-02 03:56:17.990905: 
2023-09-02 03:56:17.992128: Epoch 205
2023-09-02 03:56:17.993030: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-02 03:56:17.994316: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 03:57:19.971488: finished training epoch 205
2023-09-02 03:57:20.002412: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 03:57:20.005059: The split file contains 1 splits.
2023-09-02 03:57:20.006927: Desired fold for training: 0
2023-09-02 03:57:20.008987: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:02:36.989988: dsc: 91.20%
2023-09-02 04:02:36.991338: miou: 83.82%
2023-09-02 04:02:36.992245: acc: 95.57%, sen: 91.22%, spe: 97.03%
2023-09-02 04:02:36.993510: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:02:36.994871: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:02:36.995915: finished real validation
2023-09-02 04:02:41.383749: train_loss -1.4437
2023-09-02 04:02:41.385964: val_loss -0.9988
2023-09-02 04:02:41.387165: Pseudo dice [0.9132]
2023-09-02 04:02:41.388157: Epoch time: 383.39 s
2023-09-02 04:02:42.499688: 
2023-09-02 04:02:42.500976: Epoch 206
2023-09-02 04:02:42.501909: Current learning rate: backbone 0.00035189, others 0.00035189
2023-09-02 04:02:42.503186: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:03:44.461145: finished training epoch 206
2023-09-02 04:03:44.523604: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:03:44.525258: The split file contains 1 splits.
2023-09-02 04:03:44.526090: Desired fold for training: 0
2023-09-02 04:03:44.526888: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:08:56.815952: dsc: 91.17%
2023-09-02 04:08:56.817353: miou: 83.77%
2023-09-02 04:08:56.818256: acc: 95.56%, sen: 91.04%, spe: 97.09%
2023-09-02 04:08:56.819410: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:08:56.820237: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:08:56.820991: finished real validation
2023-09-02 04:09:01.210839: train_loss -1.4428
2023-09-02 04:09:01.212168: val_loss -0.9758
2023-09-02 04:09:01.213252: Pseudo dice [0.9085]
2023-09-02 04:09:01.214149: Epoch time: 378.71 s
2023-09-02 04:09:02.335180: 
2023-09-02 04:09:02.336546: Epoch 207
2023-09-02 04:09:02.337451: Current learning rate: backbone 0.00034852, others 0.00034852
2023-09-02 04:09:02.338748: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:10:04.258807: finished training epoch 207
2023-09-02 04:10:04.307480: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:10:04.309411: The split file contains 1 splits.
2023-09-02 04:10:04.310332: Desired fold for training: 0
2023-09-02 04:10:04.311139: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:15:14.552526: dsc: 91.23%
2023-09-02 04:15:14.554134: miou: 83.88%
2023-09-02 04:15:14.554955: acc: 95.61%, sen: 90.81%, spe: 97.22%
2023-09-02 04:15:14.556129: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:15:14.556978: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:15:14.557703: finished real validation
2023-09-02 04:15:18.950412: train_loss -1.4435
2023-09-02 04:15:18.951783: val_loss -0.9718
2023-09-02 04:15:18.952982: Pseudo dice [0.9086]
2023-09-02 04:15:18.953959: Epoch time: 376.62 s
2023-09-02 04:15:20.109752: 
2023-09-02 04:15:20.111198: Epoch 208
2023-09-02 04:15:20.112164: Current learning rate: backbone 0.00034514, others 0.00034514
2023-09-02 04:15:20.113461: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:16:22.256726: finished training epoch 208
2023-09-02 04:16:22.293696: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:16:22.295458: The split file contains 1 splits.
2023-09-02 04:16:22.296271: Desired fold for training: 0
2023-09-02 04:16:22.296985: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:22:15.854703: dsc: 91.11%
2023-09-02 04:22:15.856173: miou: 83.67%
2023-09-02 04:22:15.857046: acc: 95.54%, sen: 90.86%, spe: 97.11%
2023-09-02 04:22:15.858319: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:22:15.859227: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:22:15.860022: finished real validation
2023-09-02 04:22:20.243309: train_loss -1.4432
2023-09-02 04:22:20.244592: val_loss -1.0278
2023-09-02 04:22:20.245697: Pseudo dice [0.914]
2023-09-02 04:22:20.246593: Epoch time: 420.13 s
2023-09-02 04:22:21.367911: 
2023-09-02 04:22:21.369210: Epoch 209
2023-09-02 04:22:21.370174: Current learning rate: backbone 0.00034177, others 0.00034177
2023-09-02 04:22:21.371539: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:23:23.399449: finished training epoch 209
2023-09-02 04:23:23.440256: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:23:23.442005: The split file contains 1 splits.
2023-09-02 04:23:23.442881: Desired fold for training: 0
2023-09-02 04:23:23.443767: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:28:33.547930: dsc: 91.22%
2023-09-02 04:28:33.549692: miou: 83.86%
2023-09-02 04:28:33.550646: acc: 95.58%, sen: 91.27%, spe: 97.03%
2023-09-02 04:28:33.551858: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:28:33.552740: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:28:33.553509: finished real validation
2023-09-02 04:28:37.944493: train_loss -1.4439
2023-09-02 04:28:37.945855: val_loss -1.0119
2023-09-02 04:28:37.947023: Pseudo dice [0.9136]
2023-09-02 04:28:37.947953: Epoch time: 376.58 s
2023-09-02 04:28:40.615665: 
2023-09-02 04:28:40.616939: Epoch 210
2023-09-02 04:28:40.617895: Current learning rate: backbone 0.00033838, others 0.00033838
2023-09-02 04:28:40.619277: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:29:42.544918: finished training epoch 210
2023-09-02 04:29:42.573316: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:29:42.575163: The split file contains 1 splits.
2023-09-02 04:29:42.576628: Desired fold for training: 0
2023-09-02 04:29:42.577816: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:34:42.187389: dsc: 91.19%
2023-09-02 04:34:42.188768: miou: 83.81%
2023-09-02 04:34:42.189856: acc: 95.56%, sen: 91.36%, spe: 96.97%
2023-09-02 04:34:42.191679: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:34:42.192814: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:34:42.193785: finished real validation
2023-09-02 04:34:46.583763: train_loss -1.4437
2023-09-02 04:34:46.585504: val_loss -1.0396
2023-09-02 04:34:46.587221: Pseudo dice [0.9171]
2023-09-02 04:34:46.588737: Epoch time: 365.97 s
2023-09-02 04:34:47.686768: 
2023-09-02 04:34:47.688035: Epoch 211
2023-09-02 04:34:47.688982: Current learning rate: backbone 0.000335, others 0.000335
2023-09-02 04:34:47.690398: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:35:50.050275: finished training epoch 211
2023-09-02 04:35:50.085300: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:35:50.087647: The split file contains 1 splits.
2023-09-02 04:35:50.088696: Desired fold for training: 0
2023-09-02 04:35:50.090063: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:40:49.322183: dsc: 91.10%
2023-09-02 04:40:49.323671: miou: 83.66%
2023-09-02 04:40:49.324585: acc: 95.54%, sen: 90.85%, spe: 97.11%
2023-09-02 04:40:49.325801: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:40:49.326701: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:40:49.327544: finished real validation
2023-09-02 04:40:53.739990: train_loss -1.4436
2023-09-02 04:40:53.741875: val_loss -0.9862
2023-09-02 04:40:53.743874: Pseudo dice [0.9121]
2023-09-02 04:40:53.745220: Epoch time: 366.05 s
2023-09-02 04:40:54.869470: 
2023-09-02 04:40:54.870978: Epoch 212
2023-09-02 04:40:54.871946: Current learning rate: backbone 0.00033161, others 0.00033161
2023-09-02 04:40:54.873516: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:41:57.011157: finished training epoch 212
2023-09-02 04:41:57.045285: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:41:57.047398: The split file contains 1 splits.
2023-09-02 04:41:57.048303: Desired fold for training: 0
2023-09-02 04:41:57.049102: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:47:25.585775: dsc: 91.20%
2023-09-02 04:47:25.587192: miou: 83.82%
2023-09-02 04:47:25.588170: acc: 95.59%, sen: 90.80%, spe: 97.20%
2023-09-02 04:47:25.589360: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:47:25.590446: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:47:25.591497: finished real validation
2023-09-02 04:47:29.964865: train_loss -1.4436
2023-09-02 04:47:29.967615: val_loss -0.976
2023-09-02 04:47:29.969996: Pseudo dice [0.9088]
2023-09-02 04:47:29.971002: Epoch time: 395.1 s
2023-09-02 04:47:31.090803: 
2023-09-02 04:47:31.092193: Epoch 213
2023-09-02 04:47:31.093204: Current learning rate: backbone 0.00032821, others 0.00032821
2023-09-02 04:47:31.095618: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:48:32.669731: finished training epoch 213
2023-09-02 04:48:32.712641: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:48:32.715208: The split file contains 1 splits.
2023-09-02 04:48:32.716184: Desired fold for training: 0
2023-09-02 04:48:32.717053: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 04:53:54.158105: dsc: 91.27%
2023-09-02 04:53:54.159794: miou: 83.95%
2023-09-02 04:53:54.160686: acc: 95.61%, sen: 91.25%, spe: 97.08%
2023-09-02 04:53:54.161969: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:53:54.162838: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 04:53:54.163684: finished real validation
2023-09-02 04:53:58.546915: train_loss -1.4436
2023-09-02 04:53:58.548495: val_loss -1.0205
2023-09-02 04:53:58.549780: Pseudo dice [0.9158]
2023-09-02 04:53:58.550755: Epoch time: 387.46 s
2023-09-02 04:53:59.682995: 
2023-09-02 04:53:59.684594: Epoch 214
2023-09-02 04:53:59.685641: Current learning rate: backbone 0.00032482, others 0.00032482
2023-09-02 04:53:59.687626: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 04:55:01.466993: finished training epoch 214
2023-09-02 04:55:01.512205: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 04:55:01.514229: The split file contains 1 splits.
2023-09-02 04:55:01.515192: Desired fold for training: 0
2023-09-02 04:55:01.516111: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:01:01.387814: dsc: 91.16%
2023-09-02 05:01:01.389273: miou: 83.75%
2023-09-02 05:01:01.390163: acc: 95.56%, sen: 90.87%, spe: 97.14%
2023-09-02 05:01:01.391344: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:01:01.392486: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:01:01.393611: finished real validation
2023-09-02 05:01:05.799875: train_loss -1.4439
2023-09-02 05:01:05.801646: val_loss -1.0087
2023-09-02 05:01:05.803027: Pseudo dice [0.9136]
2023-09-02 05:01:05.803946: Epoch time: 426.12 s
2023-09-02 05:01:06.938039: 
2023-09-02 05:01:06.939455: Epoch 215
2023-09-02 05:01:06.940521: Current learning rate: backbone 0.00032142, others 0.00032142
2023-09-02 05:01:06.942240: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:02:09.091623: finished training epoch 215
2023-09-02 05:02:09.124495: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:02:09.126865: The split file contains 1 splits.
2023-09-02 05:02:09.127795: Desired fold for training: 0
2023-09-02 05:02:09.128639: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:08:02.901839: dsc: 91.18%
2023-09-02 05:08:02.903171: miou: 83.79%
2023-09-02 05:08:02.904062: acc: 95.56%, sen: 91.28%, spe: 97.00%
2023-09-02 05:08:02.905228: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:08:02.906104: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:08:02.906904: finished real validation
2023-09-02 05:08:07.283899: train_loss -1.4438
2023-09-02 05:08:07.285392: val_loss -1.0007
2023-09-02 05:08:07.286587: Pseudo dice [0.9132]
2023-09-02 05:08:07.287591: Epoch time: 420.35 s
2023-09-02 05:08:08.414139: 
2023-09-02 05:08:08.415421: Epoch 216
2023-09-02 05:08:08.416459: Current learning rate: backbone 0.00031801, others 0.00031801
2023-09-02 05:08:08.419360: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:09:10.326998: finished training epoch 216
2023-09-02 05:09:10.360080: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:09:10.361880: The split file contains 1 splits.
2023-09-02 05:09:10.362825: Desired fold for training: 0
2023-09-02 05:09:10.363576: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:15:15.945921: dsc: 91.19%
2023-09-02 05:15:15.947370: miou: 83.81%
2023-09-02 05:15:15.948292: acc: 95.56%, sen: 91.27%, spe: 97.01%
2023-09-02 05:15:15.949868: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:15:15.950958: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:15:15.952056: finished real validation
2023-09-02 05:15:20.287264: train_loss -1.4437
2023-09-02 05:15:20.289331: val_loss -0.9965
2023-09-02 05:15:20.291188: Pseudo dice [0.9112]
2023-09-02 05:15:20.292525: Epoch time: 431.87 s
2023-09-02 05:15:21.398061: 
2023-09-02 05:15:21.399668: Epoch 217
2023-09-02 05:15:21.401005: Current learning rate: backbone 0.0003146, others 0.0003146
2023-09-02 05:15:21.402963: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:16:23.133657: finished training epoch 217
2023-09-02 05:16:23.185455: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:16:23.187345: The split file contains 1 splits.
2023-09-02 05:16:23.188364: Desired fold for training: 0
2023-09-02 05:16:23.189279: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:22:00.792450: dsc: 91.27%
2023-09-02 05:22:00.794130: miou: 83.94%
2023-09-02 05:22:00.795249: acc: 95.60%, sen: 91.39%, spe: 97.02%
2023-09-02 05:22:00.796868: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:22:00.798010: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:22:00.799161: finished real validation
2023-09-02 05:22:05.136685: train_loss -1.4441
2023-09-02 05:22:05.138379: val_loss -1.0456
2023-09-02 05:22:05.139652: Pseudo dice [0.9176]
2023-09-02 05:22:05.140634: Epoch time: 403.74 s
2023-09-02 05:22:05.141556: Yayy! New best EMA pseudo Dice: 0.9132
2023-09-02 05:22:07.982072: 
2023-09-02 05:22:07.983648: Epoch 218
2023-09-02 05:22:07.984663: Current learning rate: backbone 0.00031119, others 0.00031119
2023-09-02 05:22:07.986068: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:23:08.619645: finished training epoch 218
2023-09-02 05:23:08.651202: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:23:08.653366: The split file contains 1 splits.
2023-09-02 05:23:08.654314: Desired fold for training: 0
2023-09-02 05:23:08.655189: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:28:36.264155: dsc: 91.26%
2023-09-02 05:28:36.265727: miou: 83.93%
2023-09-02 05:28:36.267015: acc: 95.61%, sen: 91.15%, spe: 97.11%
2023-09-02 05:28:36.268735: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:28:36.269783: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:28:36.270866: finished real validation
2023-09-02 05:28:40.627185: train_loss -1.4439
2023-09-02 05:28:40.628903: val_loss -0.9768
2023-09-02 05:28:40.630324: Pseudo dice [0.9114]
2023-09-02 05:28:40.631776: Epoch time: 392.65 s
2023-09-02 05:28:41.760723: 
2023-09-02 05:28:41.762062: Epoch 219
2023-09-02 05:28:41.763053: Current learning rate: backbone 0.00030777, others 0.00030777
2023-09-02 05:28:41.764864: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:29:44.475361: finished training epoch 219
2023-09-02 05:29:44.516113: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:29:44.518419: The split file contains 1 splits.
2023-09-02 05:29:44.519768: Desired fold for training: 0
2023-09-02 05:29:44.520776: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:35:38.723866: dsc: 91.28%
2023-09-02 05:35:38.725322: miou: 83.96%
2023-09-02 05:35:38.726534: acc: 95.63%, sen: 90.99%, spe: 97.19%
2023-09-02 05:35:38.728414: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:35:38.729502: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:35:38.730573: finished real validation
2023-09-02 05:35:43.070021: train_loss -1.4446
2023-09-02 05:35:43.071430: val_loss -0.9876
2023-09-02 05:35:43.072637: Pseudo dice [0.9124]
2023-09-02 05:35:43.073585: Epoch time: 421.31 s
2023-09-02 05:35:45.860404: 
2023-09-02 05:35:45.862012: Epoch 220
2023-09-02 05:35:45.863024: Current learning rate: backbone 0.00030435, others 0.00030435
2023-09-02 05:35:45.864491: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:36:48.382522: finished training epoch 220
2023-09-02 05:36:48.414857: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:36:48.417041: The split file contains 1 splits.
2023-09-02 05:36:48.418019: Desired fold for training: 0
2023-09-02 05:36:48.418935: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:41:48.694432: dsc: 91.22%
2023-09-02 05:41:48.695853: miou: 83.85%
2023-09-02 05:41:48.696716: acc: 95.59%, sen: 90.99%, spe: 97.14%
2023-09-02 05:41:48.697883: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:41:48.698767: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:41:48.699600: finished real validation
2023-09-02 05:41:53.090440: train_loss -1.4439
2023-09-02 05:41:53.092267: val_loss -0.9765
2023-09-02 05:41:53.093748: Pseudo dice [0.9098]
2023-09-02 05:41:53.094823: Epoch time: 367.23 s
2023-09-02 05:41:54.317784: 
2023-09-02 05:41:54.319454: Epoch 221
2023-09-02 05:41:54.320961: Current learning rate: backbone 0.00030092, others 0.00030092
2023-09-02 05:41:54.323381: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:42:56.111235: finished training epoch 221
2023-09-02 05:42:56.152174: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:42:56.155564: The split file contains 1 splits.
2023-09-02 05:42:56.156996: Desired fold for training: 0
2023-09-02 05:42:56.158297: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:48:12.843246: dsc: 91.22%
2023-09-02 05:48:12.844665: miou: 83.86%
2023-09-02 05:48:12.845559: acc: 95.61%, sen: 90.78%, spe: 97.23%
2023-09-02 05:48:12.846740: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:48:12.847677: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:48:12.848486: finished real validation
2023-09-02 05:48:17.226687: train_loss -1.444
2023-09-02 05:48:17.228931: val_loss -1.0136
2023-09-02 05:48:17.231001: Pseudo dice [0.9147]
2023-09-02 05:48:17.232533: Epoch time: 382.91 s
2023-09-02 05:48:18.331807: 
2023-09-02 05:48:18.333334: Epoch 222
2023-09-02 05:48:18.334393: Current learning rate: backbone 0.00029749, others 0.00029749
2023-09-02 05:48:18.336121: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:49:20.066272: finished training epoch 222
2023-09-02 05:49:20.106594: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:49:20.108573: The split file contains 1 splits.
2023-09-02 05:49:20.109486: Desired fold for training: 0
2023-09-02 05:49:20.110403: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 05:54:22.349817: dsc: 91.21%
2023-09-02 05:54:22.351404: miou: 83.84%
2023-09-02 05:54:22.352376: acc: 95.58%, sen: 91.06%, spe: 97.10%
2023-09-02 05:54:22.353678: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:54:22.354614: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 05:54:22.355552: finished real validation
2023-09-02 05:54:26.754053: train_loss -1.4443
2023-09-02 05:54:26.755561: val_loss -0.9893
2023-09-02 05:54:26.756691: Pseudo dice [0.912]
2023-09-02 05:54:26.757691: Epoch time: 368.42 s
2023-09-02 05:54:27.861787: 
2023-09-02 05:54:27.863269: Epoch 223
2023-09-02 05:54:27.864233: Current learning rate: backbone 0.00029406, others 0.00029406
2023-09-02 05:54:27.865831: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 05:55:29.778407: finished training epoch 223
2023-09-02 05:55:29.808406: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 05:55:29.811460: The split file contains 1 splits.
2023-09-02 05:55:29.812784: Desired fold for training: 0
2023-09-02 05:55:29.814081: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:00:31.657102: dsc: 91.17%
2023-09-02 06:00:31.658636: miou: 83.78%
2023-09-02 06:00:31.659555: acc: 95.55%, sen: 91.33%, spe: 96.97%
2023-09-02 06:00:31.660703: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:00:31.661590: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:00:31.662442: finished real validation
2023-09-02 06:00:36.050490: train_loss -1.4443
2023-09-02 06:00:36.052036: val_loss -0.9991
2023-09-02 06:00:36.053312: Pseudo dice [0.9129]
2023-09-02 06:00:36.054459: Epoch time: 368.19 s
2023-09-02 06:00:37.149659: 
2023-09-02 06:00:37.151048: Epoch 224
2023-09-02 06:00:37.152076: Current learning rate: backbone 0.00029062, others 0.00029062
2023-09-02 06:00:37.153480: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:01:38.921111: finished training epoch 224
2023-09-02 06:01:38.949972: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:01:38.951779: The split file contains 1 splits.
2023-09-02 06:01:38.953160: Desired fold for training: 0
2023-09-02 06:01:38.954353: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:06:39.315987: dsc: 91.15%
2023-09-02 06:06:39.318074: miou: 83.74%
2023-09-02 06:06:39.319656: acc: 95.56%, sen: 91.00%, spe: 97.09%
2023-09-02 06:06:39.322134: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:06:39.323349: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:06:39.324496: finished real validation
2023-09-02 06:06:43.736960: train_loss -1.4444
2023-09-02 06:06:43.738442: val_loss -1.0354
2023-09-02 06:06:43.739949: Pseudo dice [0.9168]
2023-09-02 06:06:43.741049: Epoch time: 366.59 s
2023-09-02 06:06:44.840139: 
2023-09-02 06:06:44.841498: Epoch 225
2023-09-02 06:06:44.842596: Current learning rate: backbone 0.00028717, others 0.00028717
2023-09-02 06:06:44.844088: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:07:46.593200: finished training epoch 225
2023-09-02 06:07:46.623895: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:07:46.625751: The split file contains 1 splits.
2023-09-02 06:07:46.626649: Desired fold for training: 0
2023-09-02 06:07:46.627478: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:12:47.867986: dsc: 91.09%
2023-09-02 06:12:47.869431: miou: 83.64%
2023-09-02 06:12:47.870379: acc: 95.52%, sen: 91.04%, spe: 97.03%
2023-09-02 06:12:47.871641: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:12:47.872658: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:12:47.873587: finished real validation
2023-09-02 06:12:52.256695: train_loss -1.4444
2023-09-02 06:12:52.258832: val_loss -0.9793
2023-09-02 06:12:52.260691: Pseudo dice [0.911]
2023-09-02 06:12:52.262120: Epoch time: 367.42 s
2023-09-02 06:12:53.383533: 
2023-09-02 06:12:53.384954: Epoch 226
2023-09-02 06:12:53.386063: Current learning rate: backbone 0.00028373, others 0.00028373
2023-09-02 06:12:53.387969: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:13:55.374116: finished training epoch 226
2023-09-02 06:13:55.402876: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:13:55.404817: The split file contains 1 splits.
2023-09-02 06:13:55.406116: Desired fold for training: 0
2023-09-02 06:13:55.407227: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:18:59.465621: dsc: 91.21%
2023-09-02 06:18:59.467242: miou: 83.84%
2023-09-02 06:18:59.468248: acc: 95.58%, sen: 91.25%, spe: 97.03%
2023-09-02 06:18:59.469483: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:18:59.470410: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:18:59.471249: finished real validation
2023-09-02 06:19:03.852889: train_loss -1.4447
2023-09-02 06:19:03.854548: val_loss -0.9946
2023-09-02 06:19:03.855934: Pseudo dice [0.9101]
2023-09-02 06:19:03.856977: Epoch time: 370.47 s
2023-09-02 06:19:04.946258: 
2023-09-02 06:19:04.947561: Epoch 227
2023-09-02 06:19:04.948574: Current learning rate: backbone 0.00028027, others 0.00028027
2023-09-02 06:19:04.950039: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:20:06.709123: finished training epoch 227
2023-09-02 06:20:06.738108: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:20:06.739885: The split file contains 1 splits.
2023-09-02 06:20:06.740888: Desired fold for training: 0
2023-09-02 06:20:06.741812: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:25:13.033703: dsc: 91.17%
2023-09-02 06:25:13.035151: miou: 83.77%
2023-09-02 06:25:13.036046: acc: 95.56%, sen: 91.02%, spe: 97.09%
2023-09-02 06:25:13.037234: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:25:13.038190: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:25:13.039146: finished real validation
2023-09-02 06:25:17.431947: train_loss -1.4444
2023-09-02 06:25:17.433346: val_loss -0.9938
2023-09-02 06:25:17.434595: Pseudo dice [0.9126]
2023-09-02 06:25:17.435621: Epoch time: 372.49 s
2023-09-02 06:25:18.535192: 
2023-09-02 06:25:18.536546: Epoch 228
2023-09-02 06:25:18.537562: Current learning rate: backbone 0.00027682, others 0.00027682
2023-09-02 06:25:18.538918: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:26:20.504106: finished training epoch 228
2023-09-02 06:26:20.533082: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:26:20.535743: The split file contains 1 splits.
2023-09-02 06:26:20.537095: Desired fold for training: 0
2023-09-02 06:26:20.538300: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:31:26.001689: dsc: 91.12%
2023-09-02 06:31:26.003203: miou: 83.69%
2023-09-02 06:31:26.004224: acc: 95.52%, sen: 91.38%, spe: 96.91%
2023-09-02 06:31:26.005581: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:31:26.006596: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:31:26.007516: finished real validation
2023-09-02 06:31:30.398796: train_loss -1.4447
2023-09-02 06:31:30.400323: val_loss -0.9495
2023-09-02 06:31:30.401552: Pseudo dice [0.9111]
2023-09-02 06:31:30.402582: Epoch time: 371.86 s
2023-09-02 06:31:31.502858: 
2023-09-02 06:31:31.504298: Epoch 229
2023-09-02 06:31:31.505366: Current learning rate: backbone 0.00027335, others 0.00027335
2023-09-02 06:31:31.506758: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:32:33.355033: finished training epoch 229
2023-09-02 06:32:33.384038: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:32:33.386477: The split file contains 1 splits.
2023-09-02 06:32:33.388008: Desired fold for training: 0
2023-09-02 06:32:33.389549: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:37:40.102130: dsc: 91.14%
2023-09-02 06:37:40.104011: miou: 83.72%
2023-09-02 06:37:40.105306: acc: 95.53%, sen: 91.51%, spe: 96.87%
2023-09-02 06:37:40.107437: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:37:40.108711: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:37:40.109893: finished real validation
2023-09-02 06:37:44.511325: train_loss -1.4444
2023-09-02 06:37:44.513169: val_loss -0.9995
2023-09-02 06:37:44.515055: Pseudo dice [0.9134]
2023-09-02 06:37:44.516564: Epoch time: 373.01 s
2023-09-02 06:37:47.198238: 
2023-09-02 06:37:47.199717: Epoch 230
2023-09-02 06:37:47.200778: Current learning rate: backbone 0.00026989, others 0.00026989
2023-09-02 06:37:47.202133: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:38:49.047578: finished training epoch 230
2023-09-02 06:38:49.076944: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:38:49.079773: The split file contains 1 splits.
2023-09-02 06:38:49.081144: Desired fold for training: 0
2023-09-02 06:38:49.082415: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:43:53.091478: dsc: 91.24%
2023-09-02 06:43:53.092988: miou: 83.88%
2023-09-02 06:43:53.094010: acc: 95.60%, sen: 91.02%, spe: 97.14%
2023-09-02 06:43:53.095299: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:43:53.096238: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:43:53.097128: finished real validation
2023-09-02 06:43:57.490307: train_loss -1.445
2023-09-02 06:43:57.491687: val_loss -0.9918
2023-09-02 06:43:57.492919: Pseudo dice [0.9122]
2023-09-02 06:43:57.493919: Epoch time: 370.29 s
2023-09-02 06:43:58.586743: 
2023-09-02 06:43:58.588112: Epoch 231
2023-09-02 06:43:58.589187: Current learning rate: backbone 0.00026641, others 0.00026641
2023-09-02 06:43:58.590595: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:45:00.345042: finished training epoch 231
2023-09-02 06:45:00.374137: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:45:00.375956: The split file contains 1 splits.
2023-09-02 06:45:00.377227: Desired fold for training: 0
2023-09-02 06:45:00.378210: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:50:13.929241: dsc: 91.18%
2023-09-02 06:50:13.930774: miou: 83.79%
2023-09-02 06:50:13.931780: acc: 95.57%, sen: 91.06%, spe: 97.08%
2023-09-02 06:50:13.932974: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:50:13.933895: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:50:13.934777: finished real validation
2023-09-02 06:50:18.336979: train_loss -1.4447
2023-09-02 06:50:18.338444: val_loss -1.021
2023-09-02 06:50:18.339693: Pseudo dice [0.9144]
2023-09-02 06:50:18.340748: Epoch time: 379.75 s
2023-09-02 06:50:19.436587: 
2023-09-02 06:50:19.437933: Epoch 232
2023-09-02 06:50:19.439100: Current learning rate: backbone 0.00026294, others 0.00026294
2023-09-02 06:50:19.440534: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:51:21.195374: finished training epoch 232
2023-09-02 06:51:21.232068: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:51:21.234087: The split file contains 1 splits.
2023-09-02 06:51:21.235064: Desired fold for training: 0
2023-09-02 06:51:21.236012: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 06:56:26.734661: dsc: 91.14%
2023-09-02 06:56:26.736056: miou: 83.73%
2023-09-02 06:56:26.736977: acc: 95.55%, sen: 91.12%, spe: 97.03%
2023-09-02 06:56:26.738139: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:56:26.739080: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 06:56:26.739950: finished real validation
2023-09-02 06:56:31.153283: train_loss -1.4452
2023-09-02 06:56:31.154768: val_loss -0.9791
2023-09-02 06:56:31.156069: Pseudo dice [0.9121]
2023-09-02 06:56:31.157133: Epoch time: 371.72 s
2023-09-02 06:56:32.254045: 
2023-09-02 06:56:32.255491: Epoch 233
2023-09-02 06:56:32.256623: Current learning rate: backbone 0.00025945, others 0.00025945
2023-09-02 06:56:32.258011: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 06:57:34.061212: finished training epoch 233
2023-09-02 06:57:34.097557: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 06:57:34.100218: The split file contains 1 splits.
2023-09-02 06:57:34.101326: Desired fold for training: 0
2023-09-02 06:57:34.102338: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:02:39.044610: dsc: 91.17%
2023-09-02 07:02:39.046119: miou: 83.78%
2023-09-02 07:02:39.047595: acc: 95.57%, sen: 90.95%, spe: 97.12%
2023-09-02 07:02:39.052512: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:02:39.053779: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:02:39.054971: finished real validation
2023-09-02 07:02:43.474246: train_loss -1.4449
2023-09-02 07:02:43.475828: val_loss -1.0247
2023-09-02 07:02:43.477080: Pseudo dice [0.9169]
2023-09-02 07:02:43.478132: Epoch time: 371.22 s
2023-09-02 07:02:44.557929: 
2023-09-02 07:02:44.559232: Epoch 234
2023-09-02 07:02:44.560335: Current learning rate: backbone 0.00025596, others 0.00025596
2023-09-02 07:02:44.561739: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:03:46.326161: finished training epoch 234
2023-09-02 07:03:46.356829: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:03:46.358810: The split file contains 1 splits.
2023-09-02 07:03:46.359889: Desired fold for training: 0
2023-09-02 07:03:46.360820: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:08:51.777140: dsc: 91.21%
2023-09-02 07:08:51.778551: miou: 83.84%
2023-09-02 07:08:51.779488: acc: 95.59%, sen: 91.03%, spe: 97.12%
2023-09-02 07:08:51.780665: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:08:51.781588: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:08:51.782457: finished real validation
2023-09-02 07:08:56.182438: train_loss -1.4449
2023-09-02 07:08:56.184097: val_loss -0.9904
2023-09-02 07:08:56.185355: Pseudo dice [0.9132]
2023-09-02 07:08:56.186417: Epoch time: 371.63 s
2023-09-02 07:08:57.295158: 
2023-09-02 07:08:57.296497: Epoch 235
2023-09-02 07:08:57.297545: Current learning rate: backbone 0.00025247, others 0.00025247
2023-09-02 07:08:57.298960: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:09:59.073730: finished training epoch 235
2023-09-02 07:09:59.113347: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:09:59.115309: The split file contains 1 splits.
2023-09-02 07:09:59.116395: Desired fold for training: 0
2023-09-02 07:09:59.117392: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:15:04.695317: dsc: 91.21%
2023-09-02 07:15:04.696811: miou: 83.83%
2023-09-02 07:15:04.697812: acc: 95.57%, sen: 91.31%, spe: 97.01%
2023-09-02 07:15:04.699088: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:15:04.700059: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:15:04.700954: finished real validation
2023-09-02 07:15:09.097183: train_loss -1.4449
2023-09-02 07:15:09.098871: val_loss -1.002
2023-09-02 07:15:09.100150: Pseudo dice [0.913]
2023-09-02 07:15:09.101203: Epoch time: 371.8 s
2023-09-02 07:15:10.191310: 
2023-09-02 07:15:10.192863: Epoch 236
2023-09-02 07:15:10.193880: Current learning rate: backbone 0.00024897, others 0.00024897
2023-09-02 07:15:10.195245: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:16:11.898781: finished training epoch 236
2023-09-02 07:16:11.927863: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:16:11.929601: The split file contains 1 splits.
2023-09-02 07:16:11.930607: Desired fold for training: 0
2023-09-02 07:16:11.931506: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:21:13.934355: dsc: 91.21%
2023-09-02 07:21:13.936056: miou: 83.84%
2023-09-02 07:21:13.937283: acc: 95.58%, sen: 91.11%, spe: 97.09%
2023-09-02 07:21:13.939241: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:21:13.940532: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:21:13.941738: finished real validation
2023-09-02 07:21:18.353172: train_loss -1.445
2023-09-02 07:21:18.354738: val_loss -1.0304
2023-09-02 07:21:18.356035: Pseudo dice [0.916]
2023-09-02 07:21:18.357114: Epoch time: 368.16 s
2023-09-02 07:21:18.358130: Yayy! New best EMA pseudo Dice: 0.9134
2023-09-02 07:21:21.008229: 
2023-09-02 07:21:21.009549: Epoch 237
2023-09-02 07:21:21.010618: Current learning rate: backbone 0.00024547, others 0.00024547
2023-09-02 07:21:21.012005: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:22:22.864976: finished training epoch 237
2023-09-02 07:22:22.895956: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:22:22.898062: The split file contains 1 splits.
2023-09-02 07:22:22.899072: Desired fold for training: 0
2023-09-02 07:22:22.900009: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:27:37.691789: dsc: 91.18%
2023-09-02 07:27:37.693574: miou: 83.78%
2023-09-02 07:27:37.694618: acc: 95.56%, sen: 91.22%, spe: 97.02%
2023-09-02 07:27:37.695867: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:27:37.696889: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:27:37.697831: finished real validation
2023-09-02 07:27:42.117471: train_loss -1.4452
2023-09-02 07:27:42.119043: val_loss -0.9975
2023-09-02 07:27:42.120336: Pseudo dice [0.9129]
2023-09-02 07:27:42.121464: Epoch time: 381.11 s
2023-09-02 07:27:43.327801: 
2023-09-02 07:27:43.329228: Epoch 238
2023-09-02 07:27:43.330364: Current learning rate: backbone 0.00024196, others 0.00024196
2023-09-02 07:27:43.331869: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:28:45.257472: finished training epoch 238
2023-09-02 07:28:45.287229: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:28:45.289076: The split file contains 1 splits.
2023-09-02 07:28:45.290092: Desired fold for training: 0
2023-09-02 07:28:45.291058: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:33:59.504526: dsc: 91.23%
2023-09-02 07:33:59.506160: miou: 83.87%
2023-09-02 07:33:59.507225: acc: 95.60%, sen: 90.85%, spe: 97.20%
2023-09-02 07:33:59.508594: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:33:59.509685: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:33:59.510695: finished real validation
2023-09-02 07:34:03.903727: train_loss -1.4454
2023-09-02 07:34:03.905341: val_loss -0.9944
2023-09-02 07:34:03.906691: Pseudo dice [0.9117]
2023-09-02 07:34:03.907881: Epoch time: 380.58 s
2023-09-02 07:34:05.000582: 
2023-09-02 07:34:05.002592: Epoch 239
2023-09-02 07:34:05.003920: Current learning rate: backbone 0.00023844, others 0.00023844
2023-09-02 07:34:05.005792: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:35:06.691510: finished training epoch 239
2023-09-02 07:35:06.719619: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:35:06.721400: The split file contains 1 splits.
2023-09-02 07:35:06.722417: Desired fold for training: 0
2023-09-02 07:35:06.723862: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:40:15.607605: dsc: 91.22%
2023-09-02 07:40:15.609046: miou: 83.86%
2023-09-02 07:40:15.610012: acc: 95.59%, sen: 91.10%, spe: 97.10%
2023-09-02 07:40:15.611220: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:40:15.612185: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:40:15.613079: finished real validation
2023-09-02 07:40:20.020066: train_loss -1.4455
2023-09-02 07:40:20.021702: val_loss -1.0245
2023-09-02 07:40:20.022990: Pseudo dice [0.9165]
2023-09-02 07:40:20.024090: Epoch time: 375.02 s
2023-09-02 07:40:21.569438: Yayy! New best EMA pseudo Dice: 0.9135
2023-09-02 07:40:24.200040: 
2023-09-02 07:40:24.201358: Epoch 240
2023-09-02 07:40:24.202462: Current learning rate: backbone 0.00023492, others 0.00023492
2023-09-02 07:40:24.204090: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:41:25.952187: finished training epoch 240
2023-09-02 07:41:25.980869: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:41:25.982799: The split file contains 1 splits.
2023-09-02 07:41:25.984271: Desired fold for training: 0
2023-09-02 07:41:25.985420: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:46:37.792814: dsc: 91.21%
2023-09-02 07:46:37.794353: miou: 83.85%
2023-09-02 07:46:37.795449: acc: 95.56%, sen: 91.56%, spe: 96.91%
2023-09-02 07:46:37.796826: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:46:37.797862: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:46:37.798809: finished real validation
2023-09-02 07:46:42.208468: train_loss -1.445
2023-09-02 07:46:42.210058: val_loss -0.9562
2023-09-02 07:46:42.211472: Pseudo dice [0.9101]
2023-09-02 07:46:42.212655: Epoch time: 378.01 s
2023-09-02 07:46:43.324925: 
2023-09-02 07:46:43.326403: Epoch 241
2023-09-02 07:46:43.327530: Current learning rate: backbone 0.0002314, others 0.0002314
2023-09-02 07:46:43.329108: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:47:45.131900: finished training epoch 241
2023-09-02 07:47:45.162021: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:47:45.164126: The split file contains 1 splits.
2023-09-02 07:47:45.165190: Desired fold for training: 0
2023-09-02 07:47:45.166187: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:53:01.822397: dsc: 91.18%
2023-09-02 07:53:01.824064: miou: 83.79%
2023-09-02 07:53:01.825070: acc: 95.57%, sen: 90.99%, spe: 97.11%
2023-09-02 07:53:01.826367: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:53:01.827349: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:53:01.828294: finished real validation
2023-09-02 07:53:06.225353: train_loss -1.4454
2023-09-02 07:53:06.226897: val_loss -0.9986
2023-09-02 07:53:06.228132: Pseudo dice [0.9124]
2023-09-02 07:53:06.229679: Epoch time: 382.9 s
2023-09-02 07:53:07.335172: 
2023-09-02 07:53:07.336576: Epoch 242
2023-09-02 07:53:07.337678: Current learning rate: backbone 0.00022786, others 0.00022786
2023-09-02 07:53:07.339082: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 07:54:09.095987: finished training epoch 242
2023-09-02 07:54:09.122824: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 07:54:09.124665: The split file contains 1 splits.
2023-09-02 07:54:09.126050: Desired fold for training: 0
2023-09-02 07:54:09.127415: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 07:59:22.965604: dsc: 91.20%
2023-09-02 07:59:22.967323: miou: 83.83%
2023-09-02 07:59:22.968379: acc: 95.58%, sen: 91.18%, spe: 97.05%
2023-09-02 07:59:22.969724: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:59:22.970735: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 07:59:22.971665: finished real validation
2023-09-02 07:59:27.370419: train_loss -1.4454
2023-09-02 07:59:27.371993: val_loss -0.9963
2023-09-02 07:59:27.373311: Pseudo dice [0.9108]
2023-09-02 07:59:27.374491: Epoch time: 380.04 s
2023-09-02 07:59:28.501900: 
2023-09-02 07:59:28.503933: Epoch 243
2023-09-02 07:59:28.505114: Current learning rate: backbone 0.00022433, others 0.00022433
2023-09-02 07:59:28.507352: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:00:30.252265: finished training epoch 243
2023-09-02 08:00:30.289334: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:00:30.291322: The split file contains 1 splits.
2023-09-02 08:00:30.292498: Desired fold for training: 0
2023-09-02 08:00:30.293610: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:06:01.112941: dsc: 91.23%
2023-09-02 08:06:01.114549: miou: 83.87%
2023-09-02 08:06:01.115599: acc: 95.60%, sen: 90.97%, spe: 97.16%
2023-09-02 08:06:01.117074: current best miou: 0.8403022700294399 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 08:06:01.118084: current best dsc: 0.9132220110949462 at epoch: 188, (188, 0.8403022700294399, 0.9132220110949462)
2023-09-02 08:06:01.119005: finished real validation
2023-09-02 08:06:05.538569: train_loss -1.4456
2023-09-02 08:06:05.540129: val_loss -0.9795
2023-09-02 08:06:05.541457: Pseudo dice [0.9106]
2023-09-02 08:06:05.542567: Epoch time: 397.04 s
2023-09-02 08:06:06.689132: 
2023-09-02 08:06:06.690679: Epoch 244
2023-09-02 08:06:06.691817: Current learning rate: backbone 0.00022078, others 0.00022078
2023-09-02 08:06:06.693362: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:07:08.465153: finished training epoch 244
2023-09-02 08:07:08.495763: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:07:08.498319: The split file contains 1 splits.
2023-09-02 08:07:08.500277: Desired fold for training: 0
2023-09-02 08:07:08.501864: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:12:29.179327: dsc: 91.32%
2023-09-02 08:12:29.181241: miou: 84.03%
2023-09-02 08:12:29.182325: acc: 95.64%, sen: 91.25%, spe: 97.11%
2023-09-02 08:12:29.183690: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:12:29.184993: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:12:30.885358: finished real validation
2023-09-02 08:12:35.278885: train_loss -1.4458
2023-09-02 08:12:35.280448: val_loss -0.9875
2023-09-02 08:12:35.281736: Pseudo dice [0.9127]
2023-09-02 08:12:35.282897: Epoch time: 388.59 s
2023-09-02 08:12:36.376095: 
2023-09-02 08:12:36.377593: Epoch 245
2023-09-02 08:12:36.378795: Current learning rate: backbone 0.00021723, others 0.00021723
2023-09-02 08:12:36.380266: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:13:38.065276: finished training epoch 245
2023-09-02 08:13:38.095263: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:13:38.097975: The split file contains 1 splits.
2023-09-02 08:13:38.099441: Desired fold for training: 0
2023-09-02 08:13:38.100611: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:18:52.189621: dsc: 91.18%
2023-09-02 08:18:52.191550: miou: 83.78%
2023-09-02 08:18:52.192653: acc: 95.57%, sen: 90.98%, spe: 97.11%
2023-09-02 08:18:52.194058: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:18:52.195118: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:18:52.196113: finished real validation
2023-09-02 08:18:56.596361: train_loss -1.4455
2023-09-02 08:18:56.598020: val_loss -0.9701
2023-09-02 08:18:56.599430: Pseudo dice [0.9104]
2023-09-02 08:18:56.600532: Epoch time: 380.22 s
2023-09-02 08:18:57.722341: 
2023-09-02 08:18:57.723762: Epoch 246
2023-09-02 08:18:57.724895: Current learning rate: backbone 0.00021367, others 0.00021367
2023-09-02 08:18:57.726417: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:19:59.451354: finished training epoch 246
2023-09-02 08:19:59.481421: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:19:59.483312: The split file contains 1 splits.
2023-09-02 08:19:59.484397: Desired fold for training: 0
2023-09-02 08:19:59.485403: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:25:09.721074: dsc: 91.20%
2023-09-02 08:25:09.723076: miou: 83.82%
2023-09-02 08:25:09.724217: acc: 95.58%, sen: 90.99%, spe: 97.12%
2023-09-02 08:25:09.725660: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:25:09.726755: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:25:09.727787: finished real validation
2023-09-02 08:25:14.128633: train_loss -1.4457
2023-09-02 08:25:14.130233: val_loss -0.9861
2023-09-02 08:25:14.131594: Pseudo dice [0.9129]
2023-09-02 08:25:14.132696: Epoch time: 376.41 s
2023-09-02 08:25:15.249887: 
2023-09-02 08:25:15.251466: Epoch 247
2023-09-02 08:25:15.252684: Current learning rate: backbone 0.00021011, others 0.00021011
2023-09-02 08:25:15.254119: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:26:17.009954: finished training epoch 247
2023-09-02 08:26:17.053091: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:26:17.055204: The split file contains 1 splits.
2023-09-02 08:26:17.056278: Desired fold for training: 0
2023-09-02 08:26:17.057318: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:31:29.344084: dsc: 91.10%
2023-09-02 08:31:29.346243: miou: 83.66%
2023-09-02 08:31:29.347804: acc: 95.53%, sen: 90.98%, spe: 97.06%
2023-09-02 08:31:29.349252: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:31:29.350588: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:31:29.351544: finished real validation
2023-09-02 08:31:33.761044: train_loss -1.4459
2023-09-02 08:31:33.762714: val_loss -0.9966
2023-09-02 08:31:33.764340: Pseudo dice [0.9112]
2023-09-02 08:31:33.765659: Epoch time: 378.51 s
2023-09-02 08:31:34.879235: 
2023-09-02 08:31:34.880558: Epoch 248
2023-09-02 08:31:34.881643: Current learning rate: backbone 0.00020654, others 0.00020654
2023-09-02 08:31:34.883192: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:32:36.765040: finished training epoch 248
2023-09-02 08:32:36.793422: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:32:36.795280: The split file contains 1 splits.
2023-09-02 08:32:36.796392: Desired fold for training: 0
2023-09-02 08:32:36.797400: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:37:49.596454: dsc: 91.28%
2023-09-02 08:37:49.598320: miou: 83.96%
2023-09-02 08:37:49.599711: acc: 95.60%, sen: 91.65%, spe: 96.92%
2023-09-02 08:37:49.601971: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:37:49.603255: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:37:49.604553: finished real validation
2023-09-02 08:37:54.014660: train_loss -1.4458
2023-09-02 08:37:54.016314: val_loss -1.0024
2023-09-02 08:37:54.017620: Pseudo dice [0.9141]
2023-09-02 08:37:54.018683: Epoch time: 379.14 s
2023-09-02 08:37:55.124938: 
2023-09-02 08:37:55.126383: Epoch 249
2023-09-02 08:37:55.127523: Current learning rate: backbone 0.00020296, others 0.00020296
2023-09-02 08:37:55.129011: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:38:56.835510: finished training epoch 249
2023-09-02 08:38:56.864689: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:38:56.866866: The split file contains 1 splits.
2023-09-02 08:38:56.868113: Desired fold for training: 0
2023-09-02 08:38:56.869310: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:44:13.184878: dsc: 91.20%
2023-09-02 08:44:13.186384: miou: 83.83%
2023-09-02 08:44:13.187645: acc: 95.57%, sen: 91.22%, spe: 97.04%
2023-09-02 08:44:13.189007: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:44:13.190087: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:44:13.191132: finished real validation
2023-09-02 08:44:17.595326: train_loss -1.4454
2023-09-02 08:44:17.597104: val_loss -0.9712
2023-09-02 08:44:17.598633: Pseudo dice [0.9108]
2023-09-02 08:44:17.599896: Epoch time: 382.47 s
2023-09-02 08:44:20.272659: 
2023-09-02 08:44:20.274186: Epoch 250
2023-09-02 08:44:20.275399: Current learning rate: backbone 0.00019937, others 0.00019937
2023-09-02 08:44:20.277076: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:45:22.106927: finished training epoch 250
2023-09-02 08:45:22.135520: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:45:22.137403: The split file contains 1 splits.
2023-09-02 08:45:22.138853: Desired fold for training: 0
2023-09-02 08:45:22.140195: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:50:37.092775: dsc: 91.25%
2023-09-02 08:50:37.094348: miou: 83.92%
2023-09-02 08:50:37.095422: acc: 95.61%, sen: 90.98%, spe: 97.17%
2023-09-02 08:50:37.096726: current best miou: 0.8403191425293424 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:50:37.097864: current best dsc: 0.9132319749436548 at epoch: 244, (244, 0.8403191425293424, 0.9132319749436548)
2023-09-02 08:50:37.098832: finished real validation
2023-09-02 08:50:41.503425: train_loss -1.4457
2023-09-02 08:50:41.505077: val_loss -1.0018
2023-09-02 08:50:41.506438: Pseudo dice [0.9132]
2023-09-02 08:50:41.507558: Epoch time: 381.23 s
2023-09-02 08:50:42.626501: 
2023-09-02 08:50:42.628060: Epoch 251
2023-09-02 08:50:42.629210: Current learning rate: backbone 0.00019578, others 0.00019578
2023-09-02 08:50:42.630697: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:51:44.413936: finished training epoch 251
2023-09-02 08:51:44.449086: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:51:44.451604: The split file contains 1 splits.
2023-09-02 08:51:44.452866: Desired fold for training: 0
2023-09-02 08:51:44.454008: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 08:56:58.581921: dsc: 91.36%
2023-09-02 08:56:58.583500: miou: 84.09%
2023-09-02 08:56:58.584612: acc: 95.66%, sen: 91.32%, spe: 97.11%
2023-09-02 08:56:58.585967: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 08:56:58.587003: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 08:57:00.139749: finished real validation
2023-09-02 08:57:04.542684: train_loss -1.4454
2023-09-02 08:57:04.544698: val_loss -0.9491
2023-09-02 08:57:04.546563: Pseudo dice [0.9113]
2023-09-02 08:57:04.548133: Epoch time: 381.92 s
2023-09-02 08:57:05.665812: 
2023-09-02 08:57:05.667277: Epoch 252
2023-09-02 08:57:05.668421: Current learning rate: backbone 0.00019218, others 0.00019218
2023-09-02 08:57:05.670064: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 08:58:07.454185: finished training epoch 252
2023-09-02 08:58:07.483000: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 08:58:07.485974: The split file contains 1 splits.
2023-09-02 08:58:07.487182: Desired fold for training: 0
2023-09-02 08:58:07.488186: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:03:25.778414: dsc: 91.18%
2023-09-02 09:03:25.780109: miou: 83.80%
2023-09-02 09:03:25.781225: acc: 95.58%, sen: 90.88%, spe: 97.16%
2023-09-02 09:03:25.782625: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:03:25.783682: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:03:25.784682: finished real validation
2023-09-02 09:03:30.188518: train_loss -1.4457
2023-09-02 09:03:30.190173: val_loss -1.0048
2023-09-02 09:03:30.191582: Pseudo dice [0.9166]
2023-09-02 09:03:30.192679: Epoch time: 384.52 s
2023-09-02 09:03:31.309272: 
2023-09-02 09:03:31.310877: Epoch 253
2023-09-02 09:03:31.312013: Current learning rate: backbone 0.00018857, others 0.00018857
2023-09-02 09:03:31.313661: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:04:33.101184: finished training epoch 253
2023-09-02 09:04:33.135033: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:04:33.137457: The split file contains 1 splits.
2023-09-02 09:04:33.138553: Desired fold for training: 0
2023-09-02 09:04:33.139499: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:09:55.189571: dsc: 91.23%
2023-09-02 09:09:55.191193: miou: 83.87%
2023-09-02 09:09:55.192344: acc: 95.60%, sen: 90.99%, spe: 97.15%
2023-09-02 09:09:55.193727: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:09:55.194911: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:09:55.195915: finished real validation
2023-09-02 09:09:59.604695: train_loss -1.4457
2023-09-02 09:09:59.606351: val_loss -0.971
2023-09-02 09:09:59.607717: Pseudo dice [0.9112]
2023-09-02 09:09:59.608921: Epoch time: 388.3 s
2023-09-02 09:10:00.719428: 
2023-09-02 09:10:00.721038: Epoch 254
2023-09-02 09:10:00.722194: Current learning rate: backbone 0.00018496, others 0.00018496
2023-09-02 09:10:00.723686: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:11:02.567131: finished training epoch 254
2023-09-02 09:11:02.600469: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:11:02.602791: The split file contains 1 splits.
2023-09-02 09:11:02.604049: Desired fold for training: 0
2023-09-02 09:11:02.605238: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:16:20.870829: dsc: 91.21%
2023-09-02 09:16:20.872545: miou: 83.84%
2023-09-02 09:16:20.873666: acc: 95.59%, sen: 91.03%, spe: 97.12%
2023-09-02 09:16:20.875158: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:16:20.876295: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:16:20.877386: finished real validation
2023-09-02 09:16:25.278210: train_loss -1.4458
2023-09-02 09:16:25.279985: val_loss -0.9956
2023-09-02 09:16:25.281458: Pseudo dice [0.9127]
2023-09-02 09:16:25.282667: Epoch time: 384.56 s
2023-09-02 09:16:26.398673: 
2023-09-02 09:16:26.400393: Epoch 255
2023-09-02 09:16:26.401769: Current learning rate: backbone 0.00018134, others 0.00018134
2023-09-02 09:16:26.403424: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:17:28.342786: finished training epoch 255
2023-09-02 09:17:28.376439: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:17:28.378593: The split file contains 1 splits.
2023-09-02 09:17:28.379713: Desired fold for training: 0
2023-09-02 09:17:28.380789: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:22:45.264322: dsc: 91.22%
2023-09-02 09:22:45.266041: miou: 83.86%
2023-09-02 09:22:45.267155: acc: 95.58%, sen: 91.21%, spe: 97.05%
2023-09-02 09:22:45.268470: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:22:45.269522: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:22:45.270520: finished real validation
2023-09-02 09:22:49.688814: train_loss -1.4449
2023-09-02 09:22:49.690534: val_loss -0.9937
2023-09-02 09:22:49.692005: Pseudo dice [0.9121]
2023-09-02 09:22:49.693163: Epoch time: 383.29 s
2023-09-02 09:22:50.796936: 
2023-09-02 09:22:50.798400: Epoch 256
2023-09-02 09:22:50.799686: Current learning rate: backbone 0.0001777, others 0.0001777
2023-09-02 09:22:50.801323: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:23:52.688913: finished training epoch 256
2023-09-02 09:23:52.718750: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:23:52.720635: The split file contains 1 splits.
2023-09-02 09:23:52.721735: Desired fold for training: 0
2023-09-02 09:23:52.722768: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:29:10.429394: dsc: 91.19%
2023-09-02 09:29:10.431104: miou: 83.80%
2023-09-02 09:29:10.432259: acc: 95.58%, sen: 90.98%, spe: 97.12%
2023-09-02 09:29:10.433662: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:29:10.434785: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:29:10.435856: finished real validation
2023-09-02 09:29:14.846994: train_loss -1.4458
2023-09-02 09:29:14.848662: val_loss -0.9595
2023-09-02 09:29:14.850151: Pseudo dice [0.9105]
2023-09-02 09:29:14.851298: Epoch time: 384.05 s
2023-09-02 09:29:15.955873: 
2023-09-02 09:29:15.957448: Epoch 257
2023-09-02 09:29:15.958690: Current learning rate: backbone 0.00017407, others 0.00017407
2023-09-02 09:29:15.960518: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:30:17.791722: finished training epoch 257
2023-09-02 09:30:17.821495: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:30:17.823511: The split file contains 1 splits.
2023-09-02 09:30:17.824953: Desired fold for training: 0
2023-09-02 09:30:17.826361: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:35:36.601405: dsc: 91.24%
2023-09-02 09:35:36.603150: miou: 83.89%
2023-09-02 09:35:36.604423: acc: 95.58%, sen: 91.55%, spe: 96.93%
2023-09-02 09:35:36.606063: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:35:36.607170: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:35:36.608209: finished real validation
2023-09-02 09:35:41.014050: train_loss -1.4459
2023-09-02 09:35:41.015628: val_loss -1.0173
2023-09-02 09:35:41.016928: Pseudo dice [0.9141]
2023-09-02 09:35:41.018046: Epoch time: 385.06 s
2023-09-02 09:35:42.120079: 
2023-09-02 09:35:42.121699: Epoch 258
2023-09-02 09:35:42.122907: Current learning rate: backbone 0.00017042, others 0.00017042
2023-09-02 09:35:42.124454: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:36:43.991616: finished training epoch 258
2023-09-02 09:36:44.020811: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:36:44.023751: The split file contains 1 splits.
2023-09-02 09:36:44.025121: Desired fold for training: 0
2023-09-02 09:36:44.026379: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:42:03.330074: dsc: 91.23%
2023-09-02 09:42:03.331789: miou: 83.87%
2023-09-02 09:42:03.332874: acc: 95.59%, sen: 91.27%, spe: 97.04%
2023-09-02 09:42:03.334285: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:42:03.335442: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:42:03.336577: finished real validation
2023-09-02 09:42:07.746058: train_loss -1.4453
2023-09-02 09:42:07.747811: val_loss -1.01
2023-09-02 09:42:07.749216: Pseudo dice [0.9149]
2023-09-02 09:42:07.750363: Epoch time: 385.63 s
2023-09-02 09:42:08.847860: 
2023-09-02 09:42:08.849411: Epoch 259
2023-09-02 09:42:08.850641: Current learning rate: backbone 0.00016676, others 0.00016676
2023-09-02 09:42:08.852251: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:43:10.640567: finished training epoch 259
2023-09-02 09:43:10.671581: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:43:10.673795: The split file contains 1 splits.
2023-09-02 09:43:10.674860: Desired fold for training: 0
2023-09-02 09:43:10.675936: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:48:28.961188: dsc: 91.27%
2023-09-02 09:48:28.962894: miou: 83.95%
2023-09-02 09:48:28.964271: acc: 95.62%, sen: 91.17%, spe: 97.11%
2023-09-02 09:48:28.966632: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:48:28.968106: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:48:28.969504: finished real validation
2023-09-02 09:48:33.386024: train_loss -1.4454
2023-09-02 09:48:33.387583: val_loss -1.0005
2023-09-02 09:48:33.388915: Pseudo dice [0.9141]
2023-09-02 09:48:33.390072: Epoch time: 384.54 s
2023-09-02 09:48:36.002313: 
2023-09-02 09:48:36.004053: Epoch 260
2023-09-02 09:48:36.005283: Current learning rate: backbone 0.0001631, others 0.0001631
2023-09-02 09:48:36.006853: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:49:37.735823: finished training epoch 260
2023-09-02 09:49:37.764371: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:49:37.766521: The split file contains 1 splits.
2023-09-02 09:49:37.767865: Desired fold for training: 0
2023-09-02 09:49:37.769003: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 09:54:52.997345: dsc: 91.17%
2023-09-02 09:54:52.999096: miou: 83.77%
2023-09-02 09:54:53.000214: acc: 95.56%, sen: 91.06%, spe: 97.08%
2023-09-02 09:54:53.001585: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:54:53.002681: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 09:54:53.003705: finished real validation
2023-09-02 09:54:57.414522: train_loss -1.446
2023-09-02 09:54:57.416553: val_loss -0.9755
2023-09-02 09:54:57.417943: Pseudo dice [0.9119]
2023-09-02 09:54:57.419117: Epoch time: 381.41 s
2023-09-02 09:54:58.510479: 
2023-09-02 09:54:58.511995: Epoch 261
2023-09-02 09:54:58.513181: Current learning rate: backbone 0.00015942, others 0.00015942
2023-09-02 09:54:58.514721: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 09:56:00.266443: finished training epoch 261
2023-09-02 09:56:00.295194: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 09:56:00.297133: The split file contains 1 splits.
2023-09-02 09:56:00.298268: Desired fold for training: 0
2023-09-02 09:56:00.299361: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:01:13.310527: dsc: 91.23%
2023-09-02 10:01:13.312206: miou: 83.88%
2023-09-02 10:01:13.313416: acc: 95.59%, sen: 91.33%, spe: 97.02%
2023-09-02 10:01:13.314855: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:01:13.316044: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:01:13.317112: finished real validation
2023-09-02 10:01:17.730042: train_loss -1.4459
2023-09-02 10:01:17.731675: val_loss -0.9952
2023-09-02 10:01:17.733191: Pseudo dice [0.9143]
2023-09-02 10:01:17.734418: Epoch time: 379.22 s
2023-09-02 10:01:18.843002: 
2023-09-02 10:01:18.844665: Epoch 262
2023-09-02 10:01:18.845861: Current learning rate: backbone 0.00015574, others 0.00015574
2023-09-02 10:01:18.847427: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:02:20.689183: finished training epoch 262
2023-09-02 10:02:20.718907: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:02:20.720884: The split file contains 1 splits.
2023-09-02 10:02:20.722115: Desired fold for training: 0
2023-09-02 10:02:20.723164: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:07:35.298405: dsc: 91.21%
2023-09-02 10:07:35.300106: miou: 83.84%
2023-09-02 10:07:35.301353: acc: 95.58%, sen: 91.11%, spe: 97.09%
2023-09-02 10:07:35.302794: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:07:35.303982: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:07:35.305084: finished real validation
2023-09-02 10:07:39.712186: train_loss -1.4456
2023-09-02 10:07:40.378752: val_loss -0.9817
2023-09-02 10:07:40.380155: Pseudo dice [0.9128]
2023-09-02 10:07:40.381324: Epoch time: 380.87 s
2023-09-02 10:07:41.482663: 
2023-09-02 10:07:41.484173: Epoch 263
2023-09-02 10:07:41.485347: Current learning rate: backbone 0.00015205, others 0.00015205
2023-09-02 10:07:41.486885: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:08:43.286559: finished training epoch 263
2023-09-02 10:08:43.315665: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:08:43.317572: The split file contains 1 splits.
2023-09-02 10:08:43.319660: Desired fold for training: 0
2023-09-02 10:08:43.321147: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:14:01.363725: dsc: 91.20%
2023-09-02 10:14:01.365726: miou: 83.83%
2023-09-02 10:14:01.366978: acc: 95.58%, sen: 91.13%, spe: 97.07%
2023-09-02 10:14:01.368546: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:14:01.369718: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:14:01.370806: finished real validation
2023-09-02 10:14:05.777138: train_loss -1.446
2023-09-02 10:14:05.778929: val_loss -0.9956
2023-09-02 10:14:05.780305: Pseudo dice [0.9125]
2023-09-02 10:14:05.781473: Epoch time: 384.3 s
2023-09-02 10:14:06.880916: 
2023-09-02 10:14:06.882427: Epoch 264
2023-09-02 10:14:06.883682: Current learning rate: backbone 0.00014834, others 0.00014834
2023-09-02 10:14:06.885298: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:15:08.605695: finished training epoch 264
2023-09-02 10:15:08.634482: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:15:08.636380: The split file contains 1 splits.
2023-09-02 10:15:08.637717: Desired fold for training: 0
2023-09-02 10:15:08.638790: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:20:24.036553: dsc: 91.25%
2023-09-02 10:20:24.038600: miou: 83.91%
2023-09-02 10:20:24.040137: acc: 95.60%, sen: 91.12%, spe: 97.11%
2023-09-02 10:20:24.042407: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:20:24.043817: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:20:24.045194: finished real validation
2023-09-02 10:20:28.450860: train_loss -1.4463
2023-09-02 10:20:28.452836: val_loss -0.9713
2023-09-02 10:20:28.454879: Pseudo dice [0.9083]
2023-09-02 10:20:28.456320: Epoch time: 381.57 s
2023-09-02 10:20:29.571647: 
2023-09-02 10:20:29.573093: Epoch 265
2023-09-02 10:20:29.574296: Current learning rate: backbone 0.00014463, others 0.00014463
2023-09-02 10:20:29.576046: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:21:31.404969: finished training epoch 265
2023-09-02 10:21:31.434126: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:21:31.435973: The split file contains 1 splits.
2023-09-02 10:21:31.437094: Desired fold for training: 0
2023-09-02 10:21:31.438128: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:26:56.387703: dsc: 91.18%
2023-09-02 10:26:56.406600: miou: 83.78%
2023-09-02 10:26:56.408178: acc: 95.57%, sen: 91.04%, spe: 97.09%
2023-09-02 10:26:56.410597: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:26:56.412159: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:26:56.413655: finished real validation
2023-09-02 10:27:00.832551: train_loss -1.4459
2023-09-02 10:27:00.834121: val_loss -0.9695
2023-09-02 10:27:00.835480: Pseudo dice [0.9123]
2023-09-02 10:27:00.836659: Epoch time: 391.26 s
2023-09-02 10:27:01.943992: 
2023-09-02 10:27:01.945452: Epoch 266
2023-09-02 10:27:01.946646: Current learning rate: backbone 0.0001409, others 0.0001409
2023-09-02 10:27:01.948159: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:28:03.690790: finished training epoch 266
2023-09-02 10:28:03.719368: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:28:03.721382: The split file contains 1 splits.
2023-09-02 10:28:03.722561: Desired fold for training: 0
2023-09-02 10:28:03.723723: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:33:18.791893: dsc: 91.25%
2023-09-02 10:33:18.793772: miou: 83.91%
2023-09-02 10:33:18.794926: acc: 95.60%, sen: 91.30%, spe: 97.04%
2023-09-02 10:33:18.796307: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:33:18.797437: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:33:18.798505: finished real validation
2023-09-02 10:33:23.197589: train_loss -1.4462
2023-09-02 10:33:23.199291: val_loss -0.998
2023-09-02 10:33:23.200725: Pseudo dice [0.9145]
2023-09-02 10:33:23.201971: Epoch time: 381.25 s
2023-09-02 10:33:24.298180: 
2023-09-02 10:33:24.299875: Epoch 267
2023-09-02 10:33:24.301108: Current learning rate: backbone 0.00013717, others 0.00013717
2023-09-02 10:33:24.302697: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:34:25.988950: finished training epoch 267
2023-09-02 10:34:26.017881: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:34:26.019827: The split file contains 1 splits.
2023-09-02 10:34:26.021119: Desired fold for training: 0
2023-09-02 10:34:26.022462: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:39:41.320468: dsc: 91.28%
2023-09-02 10:39:41.321980: miou: 83.96%
2023-09-02 10:39:41.323074: acc: 95.62%, sen: 91.23%, spe: 97.09%
2023-09-02 10:39:41.324460: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:39:41.325589: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:39:41.326675: finished real validation
2023-09-02 10:39:45.733672: train_loss -1.4458
2023-09-02 10:39:45.735549: val_loss -1.0115
2023-09-02 10:39:45.737614: Pseudo dice [0.9138]
2023-09-02 10:39:45.739323: Epoch time: 381.44 s
2023-09-02 10:39:46.836879: 
2023-09-02 10:39:46.838334: Epoch 268
2023-09-02 10:39:46.839555: Current learning rate: backbone 0.00013342, others 0.00013342
2023-09-02 10:39:46.841155: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:40:48.644293: finished training epoch 268
2023-09-02 10:40:56.202939: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:40:56.205016: The split file contains 1 splits.
2023-09-02 10:40:56.206140: Desired fold for training: 0
2023-09-02 10:40:56.207238: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:47:24.396836: dsc: 91.28%
2023-09-02 10:47:24.398523: miou: 83.95%
2023-09-02 10:47:24.399741: acc: 95.60%, sen: 91.47%, spe: 96.99%
2023-09-02 10:47:24.401227: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:47:24.402404: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:47:24.403493: finished real validation
2023-09-02 10:47:28.867569: train_loss -1.4458
2023-09-02 10:47:28.869382: val_loss -1.0252
2023-09-02 10:47:28.870839: Pseudo dice [0.9167]
2023-09-02 10:47:28.872097: Epoch time: 462.03 s
2023-09-02 10:47:30.117571: 
2023-09-02 10:47:30.119290: Epoch 269
2023-09-02 10:47:30.120530: Current learning rate: backbone 0.00012966, others 0.00012966
2023-09-02 10:47:30.122284: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:48:32.255191: finished training epoch 269
2023-09-02 10:48:32.284814: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:48:32.286855: The split file contains 1 splits.
2023-09-02 10:48:32.287992: Desired fold for training: 0
2023-09-02 10:48:32.289018: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 10:53:49.940666: dsc: 91.19%
2023-09-02 10:53:49.946885: miou: 83.81%
2023-09-02 10:53:49.948663: acc: 95.57%, sen: 91.22%, spe: 97.03%
2023-09-02 10:53:49.951002: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:53:49.952751: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 10:53:49.954787: finished real validation
2023-09-02 10:53:54.362466: train_loss -1.4464
2023-09-02 10:53:54.364337: val_loss -0.9414
2023-09-02 10:53:54.366196: Pseudo dice [0.9109]
2023-09-02 10:53:54.368051: Epoch time: 384.25 s
2023-09-02 10:53:57.006040: 
2023-09-02 10:53:57.007515: Epoch 270
2023-09-02 10:53:57.008753: Current learning rate: backbone 0.00012589, others 0.00012589
2023-09-02 10:53:57.010359: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 10:54:58.929423: finished training epoch 270
2023-09-02 10:54:58.958848: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 10:54:58.961207: The split file contains 1 splits.
2023-09-02 10:54:58.962495: Desired fold for training: 0
2023-09-02 10:54:58.963746: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:00:17.335501: dsc: 91.23%
2023-09-02 11:00:17.337237: miou: 83.87%
2023-09-02 11:00:17.338452: acc: 95.59%, sen: 91.30%, spe: 97.02%
2023-09-02 11:00:17.339883: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:00:17.341065: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:00:17.342136: finished real validation
2023-09-02 11:00:21.727186: train_loss -1.4459
2023-09-02 11:00:21.729008: val_loss -0.9894
2023-09-02 11:00:21.730467: Pseudo dice [0.9118]
2023-09-02 11:00:21.731733: Epoch time: 384.72 s
2023-09-02 11:00:22.839053: 
2023-09-02 11:00:22.840807: Epoch 271
2023-09-02 11:00:22.842133: Current learning rate: backbone 0.00012211, others 0.00012211
2023-09-02 11:00:22.843776: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:01:24.865343: finished training epoch 271
2023-09-02 11:01:24.896508: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:01:24.898959: The split file contains 1 splits.
2023-09-02 11:01:24.901322: Desired fold for training: 0
2023-09-02 11:01:24.902744: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:06:53.752986: dsc: 91.21%
2023-09-02 11:06:53.754546: miou: 83.84%
2023-09-02 11:06:53.755751: acc: 95.58%, sen: 91.17%, spe: 97.06%
2023-09-02 11:06:53.757226: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:06:53.758361: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:06:53.759449: finished real validation
2023-09-02 11:06:58.168361: train_loss -1.4462
2023-09-02 11:06:58.170175: val_loss -1.0264
2023-09-02 11:06:58.171730: Pseudo dice [0.9166]
2023-09-02 11:06:58.173050: Epoch time: 395.33 s
2023-09-02 11:06:59.334655: 
2023-09-02 11:06:59.336248: Epoch 272
2023-09-02 11:06:59.337524: Current learning rate: backbone 0.00011831, others 0.00011831
2023-09-02 11:06:59.339064: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:08:01.471072: finished training epoch 272
2023-09-02 11:08:01.519737: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:08:01.522290: The split file contains 1 splits.
2023-09-02 11:08:01.523648: Desired fold for training: 0
2023-09-02 11:08:01.524968: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:13:38.806893: dsc: 91.23%
2023-09-02 11:13:38.808765: miou: 83.88%
2023-09-02 11:13:38.810080: acc: 95.58%, sen: 91.50%, spe: 96.95%
2023-09-02 11:13:38.811869: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:13:38.813080: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:13:38.814315: finished real validation
2023-09-02 11:13:43.230973: train_loss -1.446
2023-09-02 11:13:43.232820: val_loss -0.978
2023-09-02 11:13:43.234364: Pseudo dice [0.9127]
2023-09-02 11:13:43.235676: Epoch time: 403.9 s
2023-09-02 11:13:44.398468: 
2023-09-02 11:13:44.400220: Epoch 273
2023-09-02 11:13:44.401687: Current learning rate: backbone 0.0001145, others 0.0001145
2023-09-02 11:13:44.403404: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:14:46.588149: finished training epoch 273
2023-09-02 11:14:46.663413: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:14:46.665787: The split file contains 1 splits.
2023-09-02 11:14:46.667167: Desired fold for training: 0
2023-09-02 11:14:46.668429: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:20:29.542320: dsc: 91.24%
2023-09-02 11:20:29.544450: miou: 83.90%
2023-09-02 11:20:29.545770: acc: 95.60%, sen: 91.22%, spe: 97.07%
2023-09-02 11:20:29.548135: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:20:29.549882: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:20:29.551439: finished real validation
2023-09-02 11:20:33.952594: train_loss -1.4469
2023-09-02 11:20:33.954494: val_loss -0.9722
2023-09-02 11:20:33.956066: Pseudo dice [0.9136]
2023-09-02 11:20:33.957330: Epoch time: 409.56 s
2023-09-02 11:20:35.130343: 
2023-09-02 11:20:35.132249: Epoch 274
2023-09-02 11:20:35.133584: Current learning rate: backbone 0.00011068, others 0.00011068
2023-09-02 11:20:35.135409: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:21:37.280673: finished training epoch 274
2023-09-02 11:21:37.330414: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:21:37.333200: The split file contains 1 splits.
2023-09-02 11:21:37.334632: Desired fold for training: 0
2023-09-02 11:21:37.335932: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:27:16.138669: dsc: 91.21%
2023-09-02 11:27:16.140426: miou: 83.84%
2023-09-02 11:27:16.141625: acc: 95.59%, sen: 91.06%, spe: 97.11%
2023-09-02 11:27:16.143127: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:27:16.144302: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:27:16.145420: finished real validation
2023-09-02 11:27:20.546108: train_loss -1.4468
2023-09-02 11:27:20.547949: val_loss -0.9769
2023-09-02 11:27:20.549452: Pseudo dice [0.912]
2023-09-02 11:27:20.550748: Epoch time: 405.42 s
2023-09-02 11:27:21.722782: 
2023-09-02 11:27:21.724771: Epoch 275
2023-09-02 11:27:21.726242: Current learning rate: backbone 0.00010684, others 0.00010684
2023-09-02 11:27:21.727894: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:28:23.949329: finished training epoch 275
2023-09-02 11:28:23.990572: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:28:23.993853: The split file contains 1 splits.
2023-09-02 11:28:23.996008: Desired fold for training: 0
2023-09-02 11:28:24.000698: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:34:05.045082: dsc: 91.23%
2023-09-02 11:34:05.046849: miou: 83.87%
2023-09-02 11:34:05.048016: acc: 95.59%, sen: 91.20%, spe: 97.06%
2023-09-02 11:34:05.049433: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:34:05.050648: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:34:05.051726: finished real validation
2023-09-02 11:34:09.439005: train_loss -1.4463
2023-09-02 11:34:09.440737: val_loss -0.9676
2023-09-02 11:34:09.442160: Pseudo dice [0.9137]
2023-09-02 11:34:09.443428: Epoch time: 407.72 s
2023-09-02 11:34:10.610736: 
2023-09-02 11:34:10.612435: Epoch 276
2023-09-02 11:34:10.613720: Current learning rate: backbone 0.00010299, others 0.00010299
2023-09-02 11:34:10.615330: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:35:12.780278: finished training epoch 276
2023-09-02 11:35:12.832119: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:35:12.834641: The split file contains 1 splits.
2023-09-02 11:35:12.835898: Desired fold for training: 0
2023-09-02 11:35:12.837003: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:40:53.435680: dsc: 91.23%
2023-09-02 11:40:53.437316: miou: 83.87%
2023-09-02 11:40:53.438471: acc: 95.61%, sen: 90.86%, spe: 97.20%
2023-09-02 11:40:53.439880: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:40:53.441031: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:40:53.442101: finished real validation
2023-09-02 11:40:57.802291: train_loss -1.4467
2023-09-02 11:40:57.804500: val_loss -1.0001
2023-09-02 11:40:57.806369: Pseudo dice [0.9128]
2023-09-02 11:40:57.807843: Epoch time: 407.19 s
2023-09-02 11:40:58.942404: 
2023-09-02 11:40:58.944379: Epoch 277
2023-09-02 11:40:58.945950: Current learning rate: backbone 9.912e-05, others 9.912e-05
2023-09-02 11:40:58.948369: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:42:00.359185: finished training epoch 277
2023-09-02 11:42:00.397328: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:42:00.399480: The split file contains 1 splits.
2023-09-02 11:42:00.400705: Desired fold for training: 0
2023-09-02 11:42:00.401856: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:47:17.707016: dsc: 91.20%
2023-09-02 11:47:17.708769: miou: 83.82%
2023-09-02 11:47:17.710223: acc: 95.57%, sen: 91.27%, spe: 97.01%
2023-09-02 11:47:17.712624: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:47:17.714072: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:47:17.715503: finished real validation
2023-09-02 11:47:22.113067: train_loss -1.4467
2023-09-02 11:47:22.115401: val_loss -0.9947
2023-09-02 11:47:22.117591: Pseudo dice [0.914]
2023-09-02 11:47:22.119461: Epoch time: 383.17 s
2023-09-02 11:47:23.232860: 
2023-09-02 11:47:23.234505: Epoch 278
2023-09-02 11:47:23.235813: Current learning rate: backbone 9.523e-05, others 9.523e-05
2023-09-02 11:47:23.237532: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:48:25.389575: finished training epoch 278
2023-09-02 11:48:25.423889: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:48:25.426708: The split file contains 1 splits.
2023-09-02 11:48:25.428593: Desired fold for training: 0
2023-09-02 11:48:25.430456: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 11:53:40.894197: dsc: 91.18%
2023-09-02 11:53:40.896025: miou: 83.78%
2023-09-02 11:53:40.897276: acc: 95.57%, sen: 90.97%, spe: 97.12%
2023-09-02 11:53:40.898823: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:53:40.900071: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 11:53:40.901196: finished real validation
2023-09-02 11:53:45.290894: train_loss -1.4461
2023-09-02 11:53:45.292727: val_loss -0.9987
2023-09-02 11:53:45.294163: Pseudo dice [0.9127]
2023-09-02 11:53:45.295432: Epoch time: 382.06 s
2023-09-02 11:53:46.399921: 
2023-09-02 11:53:46.401434: Epoch 279
2023-09-02 11:53:46.402720: Current learning rate: backbone 9.132e-05, others 9.132e-05
2023-09-02 11:53:46.404441: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 11:54:48.207301: finished training epoch 279
2023-09-02 11:54:48.237059: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 11:54:48.239267: The split file contains 1 splits.
2023-09-02 11:54:48.240589: Desired fold for training: 0
2023-09-02 11:54:48.241951: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:00:40.008930: dsc: 91.16%
2023-09-02 12:00:40.010794: miou: 83.75%
2023-09-02 12:00:40.012088: acc: 95.56%, sen: 91.05%, spe: 97.07%
2023-09-02 12:00:40.013610: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:00:40.014916: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:00:40.016086: finished real validation
2023-09-02 12:00:44.403796: train_loss -1.4465
2023-09-02 12:00:44.405779: val_loss -0.9951
2023-09-02 12:00:44.407236: Pseudo dice [0.9145]
2023-09-02 12:00:44.408434: Epoch time: 418.01 s
2023-09-02 12:00:47.029663: 
2023-09-02 12:00:47.031310: Epoch 280
2023-09-02 12:00:47.032636: Current learning rate: backbone 8.74e-05, others 8.74e-05
2023-09-02 12:00:47.034285: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:01:48.740677: finished training epoch 280
2023-09-02 12:01:48.770529: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:01:48.772575: The split file contains 1 splits.
2023-09-02 12:01:48.773927: Desired fold for training: 0
2023-09-02 12:01:48.775179: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:07:08.609212: dsc: 91.24%
2023-09-02 12:07:08.610853: miou: 83.88%
2023-09-02 12:07:08.612029: acc: 95.59%, sen: 91.32%, spe: 97.02%
2023-09-02 12:07:08.613561: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:07:08.614923: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:07:08.615999: finished real validation
2023-09-02 12:07:13.015544: train_loss -1.4469
2023-09-02 12:07:13.017322: val_loss -1.0139
2023-09-02 12:07:13.018766: Pseudo dice [0.9151]
2023-09-02 12:07:13.020060: Epoch time: 385.99 s
2023-09-02 12:07:14.123048: 
2023-09-02 12:07:14.124853: Epoch 281
2023-09-02 12:07:14.126169: Current learning rate: backbone 8.346e-05, others 8.346e-05
2023-09-02 12:07:14.127815: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:08:15.907863: finished training epoch 281
2023-09-02 12:08:15.936323: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:08:15.938361: The split file contains 1 splits.
2023-09-02 12:08:15.939634: Desired fold for training: 0
2023-09-02 12:08:15.940835: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:13:29.022094: dsc: 91.15%
2023-09-02 12:13:29.024021: miou: 83.73%
2023-09-02 12:13:29.025293: acc: 95.54%, sen: 91.23%, spe: 96.99%
2023-09-02 12:13:29.026879: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:13:29.028157: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:13:29.029282: finished real validation
2023-09-02 12:13:33.430589: train_loss -1.4462
2023-09-02 12:13:33.432565: val_loss -0.9709
2023-09-02 12:13:33.434061: Pseudo dice [0.9105]
2023-09-02 12:13:33.435324: Epoch time: 379.31 s
2023-09-02 12:13:34.559479: 
2023-09-02 12:13:34.561270: Epoch 282
2023-09-02 12:13:34.562572: Current learning rate: backbone 7.949e-05, others 7.949e-05
2023-09-02 12:13:34.564237: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:14:36.380317: finished training epoch 282
2023-09-02 12:14:36.420401: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:14:36.422790: The split file contains 1 splits.
2023-09-02 12:14:36.429762: Desired fold for training: 0
2023-09-02 12:14:36.431608: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:20:05.240361: dsc: 91.15%
2023-09-02 12:20:05.242548: miou: 83.74%
2023-09-02 12:20:05.243854: acc: 95.54%, sen: 91.28%, spe: 96.97%
2023-09-02 12:20:05.245422: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:20:05.246727: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:20:05.247929: finished real validation
2023-09-02 12:20:09.666434: train_loss -1.4464
2023-09-02 12:20:09.668554: val_loss -0.9671
2023-09-02 12:20:09.670263: Pseudo dice [0.9121]
2023-09-02 12:20:09.671911: Epoch time: 395.11 s
2023-09-02 12:20:10.829248: 
2023-09-02 12:20:10.830889: Epoch 283
2023-09-02 12:20:10.832294: Current learning rate: backbone 7.551e-05, others 7.551e-05
2023-09-02 12:20:10.834265: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:21:12.934813: finished training epoch 283
2023-09-02 12:21:12.984648: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:21:12.987103: The split file contains 1 splits.
2023-09-02 12:21:12.988421: Desired fold for training: 0
2023-09-02 12:21:12.989646: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:26:54.886608: dsc: 91.17%
2023-09-02 12:26:54.888355: miou: 83.77%
2023-09-02 12:26:54.889672: acc: 95.55%, sen: 91.30%, spe: 96.98%
2023-09-02 12:26:54.891283: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:26:54.892566: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:26:54.893808: finished real validation
2023-09-02 12:26:59.306175: train_loss -1.447
2023-09-02 12:26:59.307963: val_loss -0.9945
2023-09-02 12:26:59.309553: Pseudo dice [0.9124]
2023-09-02 12:26:59.310931: Epoch time: 408.48 s
2023-09-02 12:27:00.405477: 
2023-09-02 12:27:00.407225: Epoch 284
2023-09-02 12:27:00.408590: Current learning rate: backbone 7.15e-05, others 7.15e-05
2023-09-02 12:27:00.410318: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:28:02.174756: finished training epoch 284
2023-09-02 12:28:02.215321: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:28:02.217729: The split file contains 1 splits.
2023-09-02 12:28:02.219010: Desired fold for training: 0
2023-09-02 12:28:02.220200: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:33:35.159706: dsc: 91.21%
2023-09-02 12:33:35.161452: miou: 83.84%
2023-09-02 12:33:35.162719: acc: 95.58%, sen: 91.13%, spe: 97.08%
2023-09-02 12:33:35.164219: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:33:35.165518: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:33:35.166890: finished real validation
2023-09-02 12:33:39.594371: train_loss -1.4467
2023-09-02 12:33:39.596138: val_loss -0.9848
2023-09-02 12:33:39.597724: Pseudo dice [0.9147]
2023-09-02 12:33:39.599152: Epoch time: 399.19 s
2023-09-02 12:33:40.752669: 
2023-09-02 12:33:40.754331: Epoch 285
2023-09-02 12:33:40.755688: Current learning rate: backbone 6.746e-05, others 6.746e-05
2023-09-02 12:33:40.757394: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:34:42.942786: finished training epoch 285
2023-09-02 12:34:42.989733: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:34:42.992285: The split file contains 1 splits.
2023-09-02 12:34:42.993640: Desired fold for training: 0
2023-09-02 12:34:42.994909: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:40:17.418953: dsc: 91.22%
2023-09-02 12:40:17.420805: miou: 83.85%
2023-09-02 12:40:17.422132: acc: 95.58%, sen: 91.17%, spe: 97.07%
2023-09-02 12:40:17.423764: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:40:17.425053: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:40:17.426247: finished real validation
2023-09-02 12:40:21.842129: train_loss -1.4469
2023-09-02 12:40:21.843895: val_loss -1.003
2023-09-02 12:40:21.845407: Pseudo dice [0.9154]
2023-09-02 12:40:21.846748: Epoch time: 401.09 s
2023-09-02 12:40:23.056623: 
2023-09-02 12:40:23.058269: Epoch 286
2023-09-02 12:40:23.059607: Current learning rate: backbone 6.34e-05, others 6.34e-05
2023-09-02 12:40:23.061358: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:41:25.174576: finished training epoch 286
2023-09-02 12:41:25.221452: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:41:25.224529: The split file contains 1 splits.
2023-09-02 12:41:25.227458: Desired fold for training: 0
2023-09-02 12:41:25.228766: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:46:56.252686: dsc: 91.20%
2023-09-02 12:46:56.254379: miou: 83.83%
2023-09-02 12:46:56.255629: acc: 95.58%, sen: 91.00%, spe: 97.12%
2023-09-02 12:46:56.257105: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:46:56.258295: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:46:56.259430: finished real validation
2023-09-02 12:47:00.661441: train_loss -1.4464
2023-09-02 12:47:00.663191: val_loss -1.0018
2023-09-02 12:47:00.664682: Pseudo dice [0.9125]
2023-09-02 12:47:00.665935: Epoch time: 397.61 s
2023-09-02 12:47:01.787345: 
2023-09-02 12:47:01.789216: Epoch 287
2023-09-02 12:47:01.790541: Current learning rate: backbone 5.931e-05, others 5.931e-05
2023-09-02 12:47:01.792216: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:48:03.599095: finished training epoch 287
2023-09-02 12:48:03.629946: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:48:03.633277: The split file contains 1 splits.
2023-09-02 12:48:03.634801: Desired fold for training: 0
2023-09-02 12:48:03.636088: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 12:53:41.663022: dsc: 91.22%
2023-09-02 12:53:41.664766: miou: 83.85%
2023-09-02 12:53:41.666112: acc: 95.59%, sen: 91.09%, spe: 97.10%
2023-09-02 12:53:41.667713: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:53:41.669005: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 12:53:41.670253: finished real validation
2023-09-02 12:53:46.074165: train_loss -1.4467
2023-09-02 12:53:46.076237: val_loss -0.9842
2023-09-02 12:53:46.077908: Pseudo dice [0.9127]
2023-09-02 12:53:46.079321: Epoch time: 404.29 s
2023-09-02 12:53:47.234872: 
2023-09-02 12:53:47.236664: Epoch 288
2023-09-02 12:53:47.238101: Current learning rate: backbone 5.519e-05, others 5.519e-05
2023-09-02 12:53:47.239866: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 12:54:49.165909: finished training epoch 288
2023-09-02 12:54:49.206498: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 12:54:49.209024: The split file contains 1 splits.
2023-09-02 12:54:49.210337: Desired fold for training: 0
2023-09-02 12:54:49.211568: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:00:10.540962: dsc: 91.24%
2023-09-02 13:00:10.542713: miou: 83.90%
2023-09-02 13:00:10.543983: acc: 95.60%, sen: 91.19%, spe: 97.08%
2023-09-02 13:00:10.545576: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:00:10.546831: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:00:10.547999: finished real validation
2023-09-02 13:00:14.950052: train_loss -1.4462
2023-09-02 13:00:14.951853: val_loss -0.9322
2023-09-02 13:00:14.953467: Pseudo dice [0.9071]
2023-09-02 13:00:14.954789: Epoch time: 387.72 s
2023-09-02 13:00:16.077208: 
2023-09-02 13:00:16.078972: Epoch 289
2023-09-02 13:00:16.080301: Current learning rate: backbone 5.103e-05, others 5.103e-05
2023-09-02 13:00:16.082162: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:01:18.009311: finished training epoch 289
2023-09-02 13:01:18.039251: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:01:18.041381: The split file contains 1 splits.
2023-09-02 13:01:18.042970: Desired fold for training: 0
2023-09-02 13:01:18.044141: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:06:34.098037: dsc: 91.20%
2023-09-02 13:06:34.099973: miou: 83.83%
2023-09-02 13:06:34.101216: acc: 95.58%, sen: 91.05%, spe: 97.11%
2023-09-02 13:06:34.102723: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:06:34.103994: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:06:34.105158: finished real validation
2023-09-02 13:06:38.479797: train_loss -1.4468
2023-09-02 13:06:38.482025: val_loss -0.9959
2023-09-02 13:06:38.484269: Pseudo dice [0.9146]
2023-09-02 13:06:38.486257: Epoch time: 382.4 s
2023-09-02 13:06:41.184072: 
2023-09-02 13:06:41.185663: Epoch 290
2023-09-02 13:06:41.186960: Current learning rate: backbone 4.684e-05, others 4.684e-05
2023-09-02 13:06:41.188784: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:07:42.884378: finished training epoch 290
2023-09-02 13:07:42.919856: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:07:42.922619: The split file contains 1 splits.
2023-09-02 13:07:42.924276: Desired fold for training: 0
2023-09-02 13:07:42.925783: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:12:59.923929: dsc: 91.18%
2023-09-02 13:12:59.925828: miou: 83.78%
2023-09-02 13:12:59.927125: acc: 95.56%, sen: 91.16%, spe: 97.04%
2023-09-02 13:12:59.928746: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:12:59.930229: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:12:59.931430: finished real validation
2023-09-02 13:13:04.311478: train_loss -1.4468
2023-09-02 13:13:04.313466: val_loss -0.9697
2023-09-02 13:13:04.315052: Pseudo dice [0.9094]
2023-09-02 13:13:04.316432: Epoch time: 383.13 s
2023-09-02 13:13:05.441067: 
2023-09-02 13:13:05.442775: Epoch 291
2023-09-02 13:13:05.444155: Current learning rate: backbone 4.26e-05, others 4.26e-05
2023-09-02 13:13:05.445874: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:14:07.241696: finished training epoch 291
2023-09-02 13:14:07.270769: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:14:07.273810: The split file contains 1 splits.
2023-09-02 13:14:07.275529: Desired fold for training: 0
2023-09-02 13:14:07.276959: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:19:22.309038: dsc: 91.18%
2023-09-02 13:19:22.311769: miou: 83.78%
2023-09-02 13:19:22.313538: acc: 95.56%, sen: 91.13%, spe: 97.05%
2023-09-02 13:19:22.316607: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:19:22.318489: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:19:22.321586: finished real validation
2023-09-02 13:19:26.718942: train_loss -1.4467
2023-09-02 13:19:26.721079: val_loss -0.9738
2023-09-02 13:19:26.722822: Pseudo dice [0.913]
2023-09-02 13:19:26.724216: Epoch time: 381.28 s
2023-09-02 13:19:27.853597: 
2023-09-02 13:19:27.855505: Epoch 292
2023-09-02 13:19:27.856930: Current learning rate: backbone 3.832e-05, others 3.832e-05
2023-09-02 13:19:27.858823: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:20:29.593720: finished training epoch 292
2023-09-02 13:20:29.631919: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:20:29.633986: The split file contains 1 splits.
2023-09-02 13:20:29.635229: Desired fold for training: 0
2023-09-02 13:20:29.636447: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:25:59.891033: dsc: 91.20%
2023-09-02 13:25:59.892949: miou: 83.83%
2023-09-02 13:25:59.894237: acc: 95.57%, sen: 91.20%, spe: 97.05%
2023-09-02 13:25:59.895848: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:25:59.897115: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:25:59.898381: finished real validation
2023-09-02 13:26:04.312141: train_loss -1.447
2023-09-02 13:26:04.314036: val_loss -0.9294
2023-09-02 13:26:04.315600: Pseudo dice [0.9065]
2023-09-02 13:26:04.317014: Epoch time: 396.46 s
2023-09-02 13:26:05.439395: 
2023-09-02 13:26:05.441163: Epoch 293
2023-09-02 13:26:05.442537: Current learning rate: backbone 3.398e-05, others 3.398e-05
2023-09-02 13:26:05.444420: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:27:07.478042: finished training epoch 293
2023-09-02 13:27:07.512672: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:27:07.514820: The split file contains 1 splits.
2023-09-02 13:27:07.516097: Desired fold for training: 0
2023-09-02 13:27:07.517295: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:32:30.626851: dsc: 91.19%
2023-09-02 13:32:30.628830: miou: 83.80%
2023-09-02 13:32:30.630143: acc: 95.56%, sen: 91.31%, spe: 96.99%
2023-09-02 13:32:30.631738: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:32:30.632987: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:32:30.634276: finished real validation
2023-09-02 13:32:35.045217: train_loss -1.447
2023-09-02 13:32:35.047361: val_loss -0.995
2023-09-02 13:32:35.049148: Pseudo dice [0.9153]
2023-09-02 13:32:35.050684: Epoch time: 389.61 s
2023-09-02 13:32:36.227159: 
2023-09-02 13:32:36.229290: Epoch 294
2023-09-02 13:32:36.230665: Current learning rate: backbone 2.958e-05, others 2.958e-05
2023-09-02 13:32:36.232578: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:33:38.077679: finished training epoch 294
2023-09-02 13:33:38.116214: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:33:38.118901: The split file contains 1 splits.
2023-09-02 13:33:38.120267: Desired fold for training: 0
2023-09-02 13:33:38.121557: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:38:59.817559: dsc: 91.18%
2023-09-02 13:38:59.819470: miou: 83.79%
2023-09-02 13:38:59.820810: acc: 95.57%, sen: 91.14%, spe: 97.05%
2023-09-02 13:38:59.822598: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:38:59.823902: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:38:59.825146: finished real validation
2023-09-02 13:39:04.234204: train_loss -1.447
2023-09-02 13:39:04.236212: val_loss -0.9729
2023-09-02 13:39:04.237813: Pseudo dice [0.9136]
2023-09-02 13:39:04.239153: Epoch time: 388.01 s
2023-09-02 13:39:05.358482: 
2023-09-02 13:39:05.360116: Epoch 295
2023-09-02 13:39:05.361492: Current learning rate: backbone 2.51e-05, others 2.51e-05
2023-09-02 13:39:05.363278: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:40:07.113117: finished training epoch 295
2023-09-02 13:40:07.143116: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:40:07.145653: The split file contains 1 splits.
2023-09-02 13:40:07.147128: Desired fold for training: 0
2023-09-02 13:40:07.148514: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:45:22.561852: dsc: 91.22%
2023-09-02 13:45:22.563634: miou: 83.86%
2023-09-02 13:45:22.564933: acc: 95.59%, sen: 91.15%, spe: 97.08%
2023-09-02 13:45:22.567067: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:45:22.568338: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:45:22.569592: finished real validation
2023-09-02 13:45:26.979096: train_loss -1.4469
2023-09-02 13:45:26.980866: val_loss -0.9598
2023-09-02 13:45:26.982500: Pseudo dice [0.912]
2023-09-02 13:45:26.983910: Epoch time: 381.62 s
2023-09-02 13:45:28.107969: 
2023-09-02 13:45:28.109595: Epoch 296
2023-09-02 13:45:28.111063: Current learning rate: backbone 2.053e-05, others 2.053e-05
2023-09-02 13:45:28.112801: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:46:29.907653: finished training epoch 296
2023-09-02 13:46:29.937719: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:46:29.939836: The split file contains 1 splits.
2023-09-02 13:46:29.941177: Desired fold for training: 0
2023-09-02 13:46:29.942427: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:51:46.845231: dsc: 91.21%
2023-09-02 13:51:46.847164: miou: 83.84%
2023-09-02 13:51:46.848571: acc: 95.58%, sen: 91.13%, spe: 97.08%
2023-09-02 13:51:46.850265: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:51:46.851605: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:51:46.852900: finished real validation
2023-09-02 13:51:51.269024: train_loss -1.447
2023-09-02 13:51:51.270841: val_loss -0.9488
2023-09-02 13:51:51.272455: Pseudo dice [0.9106]
2023-09-02 13:51:51.273913: Epoch time: 383.16 s
2023-09-02 13:51:52.392615: 
2023-09-02 13:51:52.394266: Epoch 297
2023-09-02 13:51:52.395707: Current learning rate: backbone 1.585e-05, others 1.585e-05
2023-09-02 13:51:52.397498: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:52:54.226117: finished training epoch 297
2023-09-02 13:52:54.258298: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:52:54.260723: The split file contains 1 splits.
2023-09-02 13:52:54.262010: Desired fold for training: 0
2023-09-02 13:52:54.263215: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 13:58:11.973706: dsc: 91.23%
2023-09-02 13:58:11.975649: miou: 83.87%
2023-09-02 13:58:11.977014: acc: 95.59%, sen: 91.11%, spe: 97.10%
2023-09-02 13:58:11.978788: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:58:11.980395: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 13:58:11.982029: finished real validation
2023-09-02 13:58:16.381843: train_loss -1.447
2023-09-02 13:58:16.384176: val_loss -0.9819
2023-09-02 13:58:16.386236: Pseudo dice [0.9129]
2023-09-02 13:58:16.388038: Epoch time: 383.99 s
2023-09-02 13:58:17.537948: 
2023-09-02 13:58:17.539721: Epoch 298
2023-09-02 13:58:17.541088: Current learning rate: backbone 1.1e-05, others 1.1e-05
2023-09-02 13:58:17.542864: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 13:59:19.397053: finished training epoch 298
2023-09-02 13:59:19.448304: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 13:59:19.450594: The split file contains 1 splits.
2023-09-02 13:59:19.452077: Desired fold for training: 0
2023-09-02 13:59:19.453298: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 14:04:39.659474: dsc: 91.22%
2023-09-02 14:04:39.661268: miou: 83.85%
2023-09-02 14:04:39.662532: acc: 95.59%, sen: 91.06%, spe: 97.11%
2023-09-02 14:04:39.664056: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 14:04:39.665278: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 14:04:39.666536: finished real validation
2023-09-02 14:04:44.048214: train_loss -1.4467
2023-09-02 14:04:44.050748: val_loss -0.9533
2023-09-02 14:04:44.053153: Pseudo dice [0.9096]
2023-09-02 14:04:44.055121: Epoch time: 386.51 s
2023-09-02 14:04:45.177571: 
2023-09-02 14:04:45.179400: Epoch 299
2023-09-02 14:04:45.180811: Current learning rate: backbone 5.9e-06, others 5.9e-06
2023-09-02 14:04:45.182700: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-02 14:05:46.966037: finished training epoch 299
2023-09-02 14:05:46.995296: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 14:05:46.997555: The split file contains 1 splits.
2023-09-02 14:05:46.999058: Desired fold for training: 0
2023-09-02 14:05:47.000313: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-02 14:10:57.310596: dsc: 91.22%
2023-09-02 14:10:57.312768: miou: 83.86%
2023-09-02 14:10:57.314152: acc: 95.59%, sen: 91.07%, spe: 97.11%
2023-09-02 14:10:57.315920: current best miou: 0.8409383718675693 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 14:10:57.317366: current best dsc: 0.9135975269117411 at epoch: 251, (251, 0.8409383718675693, 0.9135975269117411)
2023-09-02 14:10:57.318684: finished real validation
2023-09-02 14:11:01.723977: train_loss -1.4468
2023-09-02 14:11:01.725899: val_loss -0.9622
2023-09-02 14:11:01.727696: Pseudo dice [0.9114]
2023-09-02 14:11:01.729511: Epoch time: 376.55 s
2023-09-02 14:11:04.439790: Training done.
2023-09-02 14:11:04.521960: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-02 14:11:04.524019: The split file contains 1 splits.
2023-09-02 14:11:04.525362: Desired fold for training: 0
2023-09-02 14:11:04.526697: This split has 1886 training and 808 validation cases.
2023-09-02 14:11:04.544122: predicting val_0
2023-09-02 14:11:04.723888: predicting val_1
2023-09-02 14:11:04.871536: predicting val_10
2023-09-02 14:11:05.017322: predicting val_100
2023-09-02 14:11:05.168717: predicting val_101
2023-09-02 14:11:05.298301: predicting val_102
2023-09-02 14:11:05.427700: predicting val_103
2023-09-02 14:11:05.557707: predicting val_104
2023-09-02 14:11:05.686896: predicting val_105
2023-09-02 14:11:05.816719: predicting val_106
2023-09-02 14:11:05.952627: predicting val_107
2023-09-02 14:11:06.082367: predicting val_108
2023-09-02 14:11:06.212873: predicting val_109
2023-09-02 14:11:06.346853: predicting val_11
2023-09-02 14:11:06.544292: predicting val_110
2023-09-02 14:11:06.702721: predicting val_111
2023-09-02 14:11:06.866106: predicting val_112
2023-09-02 14:11:07.027699: predicting val_113
2023-09-02 14:11:07.188579: predicting val_114
2023-09-02 14:11:07.348164: predicting val_115
2023-09-02 14:11:07.507256: predicting val_116
2023-09-02 14:11:07.671437: predicting val_117
2023-09-02 14:11:07.832105: predicting val_118
2023-09-02 14:11:07.992970: predicting val_119
2023-09-02 14:11:17.816436: predicting val_12
2023-09-02 14:11:17.987831: predicting val_120
2023-09-02 14:11:18.145234: predicting val_121
2023-09-02 14:11:18.301882: predicting val_122
2023-09-02 14:11:18.456660: predicting val_123
2023-09-02 14:11:18.590093: predicting val_124
2023-09-02 14:11:18.722300: predicting val_125
2023-09-02 14:11:18.853080: predicting val_126
2023-09-02 14:11:18.985194: predicting val_127
2023-09-02 14:11:19.116439: predicting val_128
2023-09-02 14:11:19.248640: predicting val_129
2023-09-02 14:11:19.379059: predicting val_13
2023-09-02 14:11:19.510500: predicting val_130
2023-09-02 14:11:19.641429: predicting val_131
2023-09-02 14:11:19.773866: predicting val_132
2023-09-02 14:11:19.905853: predicting val_133
2023-09-02 14:11:20.037775: predicting val_134
2023-09-02 14:11:20.168431: predicting val_135
2023-09-02 14:11:20.307743: predicting val_136
2023-09-02 14:11:20.445742: predicting val_137
2023-09-02 14:11:20.584799: predicting val_138
2023-09-02 14:11:20.719700: predicting val_139
2023-09-02 14:11:20.851480: predicting val_14
2023-09-02 14:11:20.982899: predicting val_140
2023-09-02 14:11:21.115104: predicting val_141
2023-09-02 14:11:21.248029: predicting val_142
2023-09-02 14:11:22.179702: predicting val_143
2023-09-02 14:11:22.312513: predicting val_144
2023-09-02 14:11:22.443823: predicting val_145
2023-09-02 14:11:22.575526: predicting val_146
2023-09-02 14:11:22.707909: predicting val_147
2023-09-02 14:11:22.838635: predicting val_148
2023-09-02 14:11:22.969796: predicting val_149
2023-09-02 14:11:23.102357: predicting val_15
2023-09-02 14:11:23.233824: predicting val_150
2023-09-02 14:11:23.370136: predicting val_151
2023-09-02 14:11:23.505978: predicting val_152
2023-09-02 14:11:23.639632: predicting val_153
2023-09-02 14:11:23.770153: predicting val_154
2023-09-02 14:11:23.900876: predicting val_155
2023-09-02 14:11:24.032837: predicting val_156
2023-09-02 14:11:24.165233: predicting val_157
2023-09-02 14:11:24.296826: predicting val_158
2023-09-02 14:11:24.431561: predicting val_159
2023-09-02 14:11:24.563715: predicting val_16
2023-09-02 14:11:24.698011: predicting val_160
2023-09-02 14:11:24.830327: predicting val_161
2023-09-02 14:11:24.962258: predicting val_162
2023-09-02 14:11:25.094899: predicting val_163
2023-09-02 14:11:25.228472: predicting val_164
2023-09-02 14:11:25.364594: predicting val_165
2023-09-02 14:11:25.496643: predicting val_166
2023-09-02 14:11:25.628072: predicting val_167
2023-09-02 14:11:25.760023: predicting val_168
2023-09-02 14:11:25.893181: predicting val_169
2023-09-02 14:11:26.024820: predicting val_17
2023-09-02 14:11:26.157156: predicting val_170
2023-09-02 14:11:26.290573: predicting val_171
2023-09-02 14:11:26.422641: predicting val_172
2023-09-02 14:11:26.557492: predicting val_173
2023-09-02 14:11:26.693774: predicting val_174
2023-09-02 14:11:26.827826: predicting val_175
2023-09-02 14:11:26.964643: predicting val_176
2023-09-02 14:11:27.097548: predicting val_177
2023-09-02 14:11:27.230108: predicting val_178
2023-09-02 14:11:27.361915: predicting val_179
2023-09-02 14:11:27.494181: predicting val_18
2023-09-02 14:11:27.625237: predicting val_180
2023-09-02 14:11:27.756157: predicting val_181
2023-09-02 14:11:27.888978: predicting val_182
2023-09-02 14:11:28.019681: predicting val_183
2023-09-02 14:11:28.150903: predicting val_184
2023-09-02 14:11:28.285908: predicting val_185
2023-09-02 14:11:28.416650: predicting val_186
2023-09-02 14:11:28.549478: predicting val_187
2023-09-02 14:11:28.682274: predicting val_188
2023-09-02 14:11:28.817332: predicting val_189
2023-09-02 14:11:28.949405: predicting val_19
2023-09-02 14:11:29.080022: predicting val_190
2023-09-02 14:11:29.213134: predicting val_191
2023-09-02 14:11:29.351539: predicting val_192
2023-09-02 14:11:29.490446: predicting val_193
2023-09-02 14:11:29.628104: predicting val_194
2023-09-02 14:11:29.765753: predicting val_195
2023-09-02 14:11:29.900056: predicting val_196
2023-09-02 14:11:30.033164: predicting val_197
2023-09-02 14:11:30.169807: predicting val_198
2023-09-02 14:11:30.304818: predicting val_199
2023-09-02 14:11:30.436639: predicting val_2
2023-09-02 14:11:30.568856: predicting val_20
2023-09-02 14:11:30.700323: predicting val_200
2023-09-02 14:11:30.834705: predicting val_201
2023-09-02 14:11:30.966442: predicting val_202
2023-09-02 14:11:31.097530: predicting val_203
2023-09-02 14:11:31.231869: predicting val_204
2023-09-02 14:11:31.363794: predicting val_205
2023-09-02 14:11:31.496137: predicting val_206
2023-09-02 14:11:31.630875: predicting val_207
2023-09-02 14:11:31.768173: predicting val_208
2023-09-02 14:11:31.906345: predicting val_209
2023-09-02 14:11:32.039934: predicting val_21
2023-09-02 14:11:32.178433: predicting val_210
2023-09-02 14:11:32.312356: predicting val_211
2023-09-02 14:11:32.444698: predicting val_212
2023-09-02 14:11:32.584767: predicting val_213
2023-09-02 14:11:32.736316: predicting val_214
2023-09-02 14:11:32.887943: predicting val_215
2023-09-02 14:11:33.028715: predicting val_216
2023-09-02 14:11:33.161099: predicting val_217
2023-09-02 14:11:33.300183: predicting val_218
2023-09-02 14:11:33.434093: predicting val_219
2023-09-02 14:11:33.576532: predicting val_22
2023-09-02 14:11:33.713272: predicting val_220
2023-09-02 14:11:33.845213: predicting val_221
2023-09-02 14:11:33.976941: predicting val_222
2023-09-02 14:11:34.108243: predicting val_223
2023-09-02 14:11:34.240916: predicting val_224
2023-09-02 14:11:34.375047: predicting val_225
2023-09-02 14:11:34.509177: predicting val_226
2023-09-02 14:11:34.643196: predicting val_227
2023-09-02 14:11:34.774945: predicting val_228
2023-09-02 14:11:34.910863: predicting val_229
2023-09-02 14:11:35.043660: predicting val_23
2023-09-02 14:11:35.176706: predicting val_230
2023-09-02 14:11:35.312364: predicting val_231
2023-09-02 14:11:35.445299: predicting val_232
2023-09-02 14:11:35.577965: predicting val_233
2023-09-02 14:11:35.708834: predicting val_234
2023-09-02 14:11:35.838516: predicting val_235
2023-09-02 14:11:35.971547: predicting val_236
2023-09-02 14:11:36.104819: predicting val_237
2023-09-02 14:11:36.239850: predicting val_238
2023-09-02 14:11:36.375870: predicting val_239
2023-09-02 14:11:36.512606: predicting val_24
2023-09-02 14:11:36.645569: predicting val_240
2023-09-02 14:11:36.777104: predicting val_241
2023-09-02 14:11:36.909317: predicting val_242
2023-09-02 14:11:37.039677: predicting val_243
2023-09-02 14:11:37.174076: predicting val_244
2023-09-02 14:11:37.311264: predicting val_245
2023-09-02 14:11:37.444857: predicting val_246
2023-09-02 14:11:37.577760: predicting val_247
2023-09-02 14:11:37.709049: predicting val_248
2023-09-02 14:11:37.841311: predicting val_249
2023-09-02 14:11:37.974849: predicting val_25
2023-09-02 14:11:38.109576: predicting val_250
2023-09-02 14:11:38.241368: predicting val_251
2023-09-02 14:11:38.375125: predicting val_252
2023-09-02 14:11:38.509241: predicting val_253
2023-09-02 14:11:38.642761: predicting val_254
2023-09-02 14:11:38.777364: predicting val_255
2023-09-02 14:11:38.912726: predicting val_256
2023-09-02 14:11:39.044828: predicting val_257
2023-09-02 14:11:39.179235: predicting val_258
2023-09-02 14:11:39.314308: predicting val_259
2023-09-02 14:11:39.449819: predicting val_26
2023-09-02 14:11:39.583234: predicting val_260
2023-09-02 14:11:39.717921: predicting val_261
2023-09-02 14:11:39.859355: predicting val_262
2023-09-02 14:11:39.994225: predicting val_263
2023-09-02 14:11:40.127726: predicting val_264
2023-09-02 14:11:40.260837: predicting val_265
2023-09-02 14:11:40.394408: predicting val_266
2023-09-02 14:11:40.530363: predicting val_267
2023-09-02 14:11:40.665199: predicting val_268
2023-09-02 14:11:40.799224: predicting val_269
2023-09-02 14:11:40.930635: predicting val_27
2023-09-02 14:11:41.065415: predicting val_270
2023-09-02 14:11:41.198320: predicting val_271
2023-09-02 14:11:41.333459: predicting val_272
2023-09-02 14:11:41.465816: predicting val_273
2023-09-02 14:11:41.599703: predicting val_274
2023-09-02 14:11:41.733184: predicting val_275
2023-09-02 14:11:41.868402: predicting val_276
2023-09-02 14:11:42.004536: predicting val_277
2023-09-02 14:11:42.138114: predicting val_278
2023-09-02 14:11:42.271434: predicting val_279
2023-09-02 14:11:42.404835: predicting val_28
2023-09-02 14:11:42.539231: predicting val_280
2023-09-02 14:11:42.672354: predicting val_281
2023-09-02 14:11:42.805248: predicting val_282
2023-09-02 14:11:42.938168: predicting val_283
2023-09-02 14:11:43.071261: predicting val_284
2023-09-02 14:11:43.204826: predicting val_285
2023-09-02 14:11:43.337500: predicting val_286
2023-09-02 14:11:43.469048: predicting val_287
2023-09-02 14:11:43.601225: predicting val_288
2023-09-02 14:11:43.732633: predicting val_289
2023-09-02 14:11:43.866321: predicting val_29
2023-09-02 14:11:44.000432: predicting val_290
2023-09-02 14:11:44.133872: predicting val_291
2023-09-02 14:11:44.268369: predicting val_292
2023-09-02 14:11:44.400976: predicting val_293
2023-09-02 14:11:44.535105: predicting val_294
2023-09-02 14:11:44.667062: predicting val_295
2023-09-02 14:11:44.800304: predicting val_296
2023-09-02 14:11:44.937720: predicting val_297
2023-09-02 14:11:45.071379: predicting val_298
2023-09-02 14:11:45.206509: predicting val_299
2023-09-02 14:11:45.340355: predicting val_3
2023-09-02 14:11:45.473337: predicting val_30
2023-09-02 14:11:45.604591: predicting val_300
2023-09-02 14:11:45.737015: predicting val_301
2023-09-02 14:11:45.870447: predicting val_302
2023-09-02 14:11:46.012156: predicting val_303
2023-09-02 14:11:46.145193: predicting val_304
2023-09-02 14:11:46.278896: predicting val_305
2023-09-02 14:11:46.412541: predicting val_306
2023-09-02 14:11:46.546497: predicting val_307
2023-09-02 14:11:46.679818: predicting val_308
2023-09-02 14:11:46.812951: predicting val_309
2023-09-02 14:11:46.946099: predicting val_31
2023-09-02 14:11:47.079701: predicting val_310
2023-09-02 14:11:47.213224: predicting val_311
2023-09-02 14:11:47.346084: predicting val_312
2023-09-02 14:11:47.478838: predicting val_313
2023-09-02 14:11:47.611230: predicting val_314
2023-09-02 14:11:47.742108: predicting val_315
2023-09-02 14:11:47.876034: predicting val_316
2023-09-02 14:11:48.010671: predicting val_317
2023-09-02 14:11:48.143672: predicting val_318
2023-09-02 14:11:48.275712: predicting val_319
2023-09-02 14:11:48.408531: predicting val_32
2023-09-02 14:11:48.542675: predicting val_320
2023-09-02 14:11:48.677451: predicting val_321
2023-09-02 14:11:48.809427: predicting val_322
2023-09-02 14:11:48.941405: predicting val_323
2023-09-02 14:11:49.074396: predicting val_324
2023-09-02 14:11:49.208674: predicting val_325
2023-09-02 14:11:49.341657: predicting val_326
2023-09-02 14:11:49.474117: predicting val_327
2023-09-02 14:11:49.605928: predicting val_328
2023-09-02 14:11:49.741440: predicting val_329
2023-09-02 14:11:49.875585: predicting val_33
2023-09-02 14:11:50.011232: predicting val_330
2023-09-02 14:11:50.143025: predicting val_331
2023-09-02 14:11:50.282746: predicting val_332
2023-09-02 14:11:50.420347: predicting val_333
2023-09-02 14:11:50.553793: predicting val_334
2023-09-02 14:11:50.686926: predicting val_335
2023-09-02 14:11:50.821407: predicting val_336
2023-09-02 14:11:50.955659: predicting val_337
2023-09-02 14:11:51.089580: predicting val_338
2023-09-02 14:11:51.224063: predicting val_339
2023-09-02 14:11:51.358469: predicting val_34
2023-09-02 14:11:51.492703: predicting val_340
2023-09-02 14:11:51.626544: predicting val_341
2023-09-02 14:11:51.761027: predicting val_342
2023-09-02 14:11:51.891919: predicting val_343
2023-09-02 14:11:52.024579: predicting val_344
2023-09-02 14:11:52.158754: predicting val_345
2023-09-02 14:11:52.293892: predicting val_346
2023-09-02 14:11:52.427465: predicting val_347
2023-09-02 14:11:52.560708: predicting val_348
2023-09-02 14:11:52.696155: predicting val_349
2023-09-02 14:11:52.829124: predicting val_35
2023-09-02 14:11:52.963555: predicting val_350
2023-09-02 14:11:53.095248: predicting val_351
2023-09-02 14:11:53.228061: predicting val_352
2023-09-02 14:11:53.364390: predicting val_353
2023-09-02 14:11:53.496969: predicting val_354
2023-09-02 14:11:53.629012: predicting val_355
2023-09-02 14:11:53.762782: predicting val_356
2023-09-02 14:11:53.896381: predicting val_357
2023-09-02 14:11:54.030635: predicting val_358
2023-09-02 14:11:54.162947: predicting val_359
2023-09-02 14:11:54.295232: predicting val_36
2023-09-02 14:11:54.426963: predicting val_360
2023-09-02 14:11:54.559540: predicting val_361
2023-09-02 14:11:54.692977: predicting val_362
2023-09-02 14:11:54.826396: predicting val_363
2023-09-02 14:11:54.960295: predicting val_364
2023-09-02 14:11:55.094264: predicting val_365
2023-09-02 14:11:55.226349: predicting val_366
2023-09-02 14:11:55.360869: predicting val_367
2023-09-02 14:11:55.493125: predicting val_368
2023-09-02 14:11:55.625634: predicting val_369
2023-09-02 14:11:55.759256: predicting val_37
2023-09-02 14:11:55.892132: predicting val_370
2023-09-02 14:11:56.024079: predicting val_371
2023-09-02 14:11:56.158989: predicting val_372
2023-09-02 14:11:56.289632: predicting val_373
2023-09-02 14:11:56.424948: predicting val_374
2023-09-02 14:11:56.560222: predicting val_375
2023-09-02 14:11:56.694249: predicting val_376
2023-09-02 14:11:56.827048: predicting val_377
2023-09-02 14:11:56.962111: predicting val_378
2023-09-02 14:11:57.095209: predicting val_379
2023-09-02 14:11:57.230952: predicting val_38
2023-09-02 14:11:57.367571: predicting val_380
2023-09-02 14:11:57.499732: predicting val_381
2023-09-02 14:11:57.635041: predicting val_382
2023-09-02 14:11:57.767627: predicting val_383
2023-09-02 14:11:57.900893: predicting val_384
2023-09-02 14:11:58.034710: predicting val_385
2023-09-02 14:11:58.170224: predicting val_386
2023-09-02 14:11:58.304171: predicting val_387
2023-09-02 14:11:58.435706: predicting val_388
2023-09-02 14:11:58.569406: predicting val_389
2023-09-02 14:11:58.702332: predicting val_39
2023-09-02 14:11:58.836627: predicting val_390
2023-09-02 14:11:58.970853: predicting val_391
2023-09-02 14:11:59.103323: predicting val_392
2023-09-02 14:11:59.238145: predicting val_393
2023-09-02 14:11:59.373268: predicting val_394
2023-09-02 14:11:59.506037: predicting val_395
2023-09-02 14:11:59.639923: predicting val_396
2023-09-02 14:11:59.773689: predicting val_397
2023-09-02 14:11:59.907037: predicting val_398
2023-09-02 14:12:00.038881: predicting val_399
2023-09-02 14:12:00.173077: predicting val_4
2023-09-02 14:12:00.306661: predicting val_40
2023-09-02 14:12:00.439747: predicting val_400
2023-09-02 14:12:00.569126: predicting val_401
2023-09-02 14:12:00.701982: predicting val_402
2023-09-02 14:12:00.853673: predicting val_403
2023-09-02 14:12:00.988279: predicting val_404
2023-09-02 14:12:01.126527: predicting val_405
2023-09-02 14:12:01.262212: predicting val_406
2023-09-02 14:12:01.398818: predicting val_407
2023-09-02 14:12:01.533298: predicting val_408
2023-09-02 14:12:01.666008: predicting val_409
2023-09-02 14:12:01.799970: predicting val_41
2023-09-02 14:12:01.933212: predicting val_410
2023-09-02 14:12:02.064730: predicting val_411
2023-09-02 14:12:02.198015: predicting val_412
2023-09-02 14:12:02.332901: predicting val_413
2023-09-02 14:12:02.465379: predicting val_414
2023-09-02 14:12:02.598191: predicting val_415
2023-09-02 14:12:02.728522: predicting val_416
2023-09-02 14:12:02.861711: predicting val_417
2023-09-02 14:12:02.994922: predicting val_418
2023-09-02 14:12:03.129163: predicting val_419
2023-09-02 14:12:03.263096: predicting val_42
2023-09-02 14:12:03.394949: predicting val_420
2023-09-02 14:12:03.530154: predicting val_421
2023-09-02 14:12:03.665264: predicting val_422
2023-09-02 14:12:03.798092: predicting val_423
2023-09-02 14:12:03.931365: predicting val_424
2023-09-02 14:12:04.065192: predicting val_425
2023-09-02 14:12:04.198073: predicting val_426
2023-09-02 14:12:04.331801: predicting val_427
2023-09-02 14:12:04.465688: predicting val_428
2023-09-02 14:12:04.598612: predicting val_429
2023-09-02 14:12:04.734286: predicting val_43
2023-09-02 14:12:04.865307: predicting val_430
2023-09-02 14:12:05.000889: predicting val_431
2023-09-02 14:12:05.134672: predicting val_432
2023-09-02 14:12:05.266816: predicting val_433
2023-09-02 14:12:05.401033: predicting val_434
2023-09-02 14:12:05.533567: predicting val_435
2023-09-02 14:12:05.667642: predicting val_436
2023-09-02 14:12:05.800804: predicting val_437
2023-09-02 14:12:05.933645: predicting val_438
2023-09-02 14:12:06.068789: predicting val_439
2023-09-02 14:12:06.201630: predicting val_44
2023-09-02 14:12:06.335001: predicting val_440
2023-09-02 14:12:06.468623: predicting val_441
2023-09-02 14:12:06.602235: predicting val_442
2023-09-02 14:12:06.734169: predicting val_443
2023-09-02 14:12:06.867231: predicting val_444
2023-09-02 14:12:06.997397: predicting val_445
2023-09-02 14:12:07.131833: predicting val_446
2023-09-02 14:12:07.266087: predicting val_447
2023-09-02 14:12:07.401627: predicting val_448
2023-09-02 14:12:07.536346: predicting val_449
2023-09-02 14:12:07.671857: predicting val_45
2023-09-02 14:12:07.805147: predicting val_450
2023-09-02 14:12:07.939998: predicting val_451
2023-09-02 14:12:08.070543: predicting val_452
2023-09-02 14:12:08.204470: predicting val_453
2023-09-02 14:12:08.337836: predicting val_454
2023-09-02 14:12:08.470810: predicting val_455
2023-09-02 14:12:08.604388: predicting val_456
2023-09-02 14:12:08.737529: predicting val_457
2023-09-02 14:12:08.871487: predicting val_458
2023-09-02 14:12:09.004791: predicting val_459
2023-09-02 14:12:09.136460: predicting val_46
2023-09-02 14:12:09.269592: predicting val_460
2023-09-02 14:12:09.402220: predicting val_461
2023-09-02 14:12:09.535046: predicting val_462
2023-09-02 14:12:09.667649: predicting val_463
2023-09-02 14:12:09.798618: predicting val_464
2023-09-02 14:12:09.929902: predicting val_465
2023-09-02 14:12:10.063103: predicting val_466
2023-09-02 14:12:10.193991: predicting val_467
2023-09-02 14:12:10.327488: predicting val_468
2023-09-02 14:12:10.462215: predicting val_469
2023-09-02 14:12:10.593511: predicting val_47
2023-09-02 14:12:10.724748: predicting val_470
2023-09-02 14:12:10.856825: predicting val_471
2023-09-02 14:12:10.991211: predicting val_472
2023-09-02 14:12:11.122844: predicting val_473
2023-09-02 14:12:11.251387: predicting val_474
2023-09-02 14:12:11.385835: predicting val_475
2023-09-02 14:12:11.518803: predicting val_476
2023-09-02 14:12:11.651186: predicting val_477
2023-09-02 14:12:11.782803: predicting val_478
2023-09-02 14:12:11.914509: predicting val_479
2023-09-02 14:12:12.047246: predicting val_48
2023-09-02 14:12:12.177860: predicting val_480
2023-09-02 14:12:12.309476: predicting val_481
2023-09-02 14:12:12.441694: predicting val_482
2023-09-02 14:12:12.574335: predicting val_483
2023-09-02 14:12:12.707853: predicting val_484
2023-09-02 14:12:12.840761: predicting val_485
2023-09-02 14:12:12.972347: predicting val_486
2023-09-02 14:12:13.103210: predicting val_487
2023-09-02 14:12:13.235419: predicting val_488
2023-09-02 14:12:13.365343: predicting val_489
2023-09-02 14:12:13.499117: predicting val_49
2023-09-02 14:12:13.631966: predicting val_490
2023-09-02 14:12:13.768043: predicting val_491
2023-09-02 14:12:13.898872: predicting val_492
2023-09-02 14:12:14.032310: predicting val_493
2023-09-02 14:12:14.164834: predicting val_494
2023-09-02 14:12:14.298105: predicting val_495
2023-09-02 14:12:14.429680: predicting val_496
2023-09-02 14:12:14.562517: predicting val_497
2023-09-02 14:12:14.694767: predicting val_498
2023-09-02 14:12:14.827937: predicting val_499
2023-09-02 14:12:14.960049: predicting val_5
2023-09-02 14:12:15.091311: predicting val_50
2023-09-02 14:12:15.223099: predicting val_500
2023-09-02 14:12:15.356327: predicting val_501
2023-09-02 14:12:15.487755: predicting val_502
2023-09-02 14:12:15.619950: predicting val_503
2023-09-02 14:12:15.752423: predicting val_504
2023-09-02 14:12:15.885991: predicting val_505
2023-09-02 14:12:16.017479: predicting val_506
2023-09-02 14:12:16.148805: predicting val_507
2023-09-02 14:12:16.282670: predicting val_508
2023-09-02 14:12:16.414900: predicting val_509
2023-09-02 14:12:16.554692: predicting val_51
2023-09-02 14:12:16.689080: predicting val_510
2023-09-02 14:12:16.820218: predicting val_511
2023-09-02 14:12:16.953181: predicting val_512
2023-09-02 14:12:17.086736: predicting val_513
2023-09-02 14:12:17.219270: predicting val_514
2023-09-02 14:12:17.353023: predicting val_515
2023-09-02 14:12:17.487020: predicting val_516
2023-09-02 14:12:17.617188: predicting val_517
2023-09-02 14:12:17.750966: predicting val_518
2023-09-02 14:12:17.881370: predicting val_519
2023-09-02 14:12:18.017116: predicting val_52
2023-09-02 14:12:18.151397: predicting val_520
2023-09-02 14:12:18.286474: predicting val_521
2023-09-02 14:12:18.419289: predicting val_522
2023-09-02 14:12:18.552267: predicting val_523
2023-09-02 14:12:18.683197: predicting val_524
2023-09-02 14:12:18.814609: predicting val_525
2023-09-02 14:12:18.945803: predicting val_526
2023-09-02 14:12:19.078631: predicting val_527
2023-09-02 14:12:19.212744: predicting val_528
2023-09-02 14:12:19.347348: predicting val_529
2023-09-02 14:12:19.482228: predicting val_53
2023-09-02 14:12:19.614439: predicting val_530
2023-09-02 14:12:19.744663: predicting val_531
2023-09-02 14:12:19.875884: predicting val_532
2023-09-02 14:12:20.007644: predicting val_533
2023-09-02 14:12:20.141677: predicting val_534
2023-09-02 14:12:20.274865: predicting val_535
2023-09-02 14:12:20.409572: predicting val_536
2023-09-02 14:12:20.543859: predicting val_537
2023-09-02 14:12:20.677731: predicting val_538
2023-09-02 14:12:20.807236: predicting val_539
2023-09-02 14:12:20.940727: predicting val_54
2023-09-02 14:12:21.071570: predicting val_540
2023-09-02 14:12:21.205336: predicting val_541
2023-09-02 14:12:21.339921: predicting val_542
2023-09-02 14:12:21.475125: predicting val_543
2023-09-02 14:12:21.608550: predicting val_544
2023-09-02 14:12:21.744213: predicting val_545
2023-09-02 14:12:21.879520: predicting val_546
2023-09-02 14:12:22.016643: predicting val_547
2023-09-02 14:12:22.156199: predicting val_548
2023-09-02 14:12:22.287263: predicting val_549
2023-09-02 14:12:22.419757: predicting val_55
2023-09-02 14:12:22.562776: predicting val_550
2023-09-02 14:12:22.696066: predicting val_551
2023-09-02 14:12:22.829462: predicting val_552
2023-09-02 14:12:22.965685: predicting val_553
2023-09-02 14:12:23.098534: predicting val_554
2023-09-02 14:12:23.229571: predicting val_555
2023-09-02 14:12:23.364063: predicting val_556
2023-09-02 14:12:23.497156: predicting val_557
2023-09-02 14:12:23.630596: predicting val_558
2023-09-02 14:12:23.764256: predicting val_559
2023-09-02 14:12:23.897596: predicting val_56
2023-09-02 14:12:24.029888: predicting val_560
2023-09-02 14:12:24.160949: predicting val_561
2023-09-02 14:12:24.292864: predicting val_562
2023-09-02 14:12:24.425246: predicting val_563
2023-09-02 14:12:24.560316: predicting val_564
2023-09-02 14:12:24.694979: predicting val_565
2023-09-02 14:12:24.830306: predicting val_566
2023-09-02 14:12:24.964096: predicting val_567
2023-09-02 14:12:25.095445: predicting val_568
2023-09-02 14:12:25.231076: predicting val_569
2023-09-02 14:12:25.365327: predicting val_57
2023-09-02 14:12:25.498371: predicting val_570
2023-09-02 14:12:25.632549: predicting val_571
2023-09-02 14:12:25.769536: predicting val_572
2023-09-02 14:12:25.903688: predicting val_573
2023-09-02 14:12:26.039600: predicting val_574
2023-09-02 14:12:26.176784: predicting val_575
2023-09-02 14:12:26.309615: predicting val_576
2023-09-02 14:12:26.441908: predicting val_577
2023-09-02 14:12:26.573635: predicting val_578
2023-09-02 14:12:26.706799: predicting val_579
2023-09-02 14:12:26.841574: predicting val_58
2023-09-02 14:12:26.976985: predicting val_580
2023-09-02 14:12:27.109429: predicting val_581
2023-09-02 14:12:27.241303: predicting val_582
2023-09-02 14:12:27.374582: predicting val_583
2023-09-02 14:12:27.510903: predicting val_584
2023-09-02 14:12:27.643840: predicting val_585
2023-09-02 14:12:27.781409: predicting val_586
2023-09-02 14:12:27.913773: predicting val_587
2023-09-02 14:12:28.049235: predicting val_588
2023-09-02 14:12:28.183240: predicting val_589
2023-09-02 14:12:28.320988: predicting val_59
2023-09-02 14:12:28.451495: predicting val_590
2023-09-02 14:12:28.584797: predicting val_591
2023-09-02 14:12:28.719574: predicting val_592
2023-09-02 14:12:28.853520: predicting val_593
2023-09-02 14:12:28.986213: predicting val_594
2023-09-02 14:12:29.118160: predicting val_595
2023-09-02 14:12:29.258428: predicting val_596
2023-09-02 14:12:29.389920: predicting val_597
2023-09-02 14:12:29.521107: predicting val_598
2023-09-02 14:12:29.654947: predicting val_599
2023-09-02 14:12:29.787046: predicting val_6
2023-09-02 14:12:29.920768: predicting val_60
2023-09-02 14:12:30.055582: predicting val_600
2023-09-02 14:12:30.188981: predicting val_601
2023-09-02 14:12:30.324954: predicting val_602
2023-09-02 14:12:30.455219: predicting val_603
2023-09-02 14:12:30.586123: predicting val_604
2023-09-02 14:12:30.722649: predicting val_605
2023-09-02 14:12:30.853613: predicting val_606
2023-09-02 14:12:30.987894: predicting val_607
2023-09-02 14:12:31.122321: predicting val_608
2023-09-02 14:12:31.255808: predicting val_609
2023-09-02 14:12:31.390133: predicting val_61
2023-09-02 14:12:31.520045: predicting val_610
2023-09-02 14:12:31.654009: predicting val_611
2023-09-02 14:12:31.787096: predicting val_612
2023-09-02 14:12:31.919592: predicting val_613
2023-09-02 14:12:32.058839: predicting val_614
2023-09-02 14:12:32.192049: predicting val_615
2023-09-02 14:12:32.325096: predicting val_616
2023-09-02 14:12:32.457131: predicting val_617
2023-09-02 14:12:32.588126: predicting val_618
2023-09-02 14:12:32.721705: predicting val_619
2023-09-02 14:12:32.856461: predicting val_62
2023-09-02 14:12:32.990254: predicting val_620
2023-09-02 14:12:33.122076: predicting val_621
2023-09-02 14:12:33.254589: predicting val_622
2023-09-02 14:12:33.390693: predicting val_623
2023-09-02 14:12:33.523567: predicting val_624
2023-09-02 14:12:33.653121: predicting val_625
2023-09-02 14:12:33.787097: predicting val_626
2023-09-02 14:12:33.921216: predicting val_627
2023-09-02 14:12:34.055259: predicting val_628
2023-09-02 14:12:34.190558: predicting val_629
2023-09-02 14:12:34.324430: predicting val_63
2023-09-02 14:12:34.457010: predicting val_630
2023-09-02 14:12:34.587798: predicting val_631
2023-09-02 14:12:34.726725: predicting val_632
2023-09-02 14:12:34.861599: predicting val_633
2023-09-02 14:12:34.995637: predicting val_634
2023-09-02 14:12:35.128565: predicting val_635
2023-09-02 14:12:35.261390: predicting val_636
2023-09-02 14:12:35.394041: predicting val_637
2023-09-02 14:12:35.526810: predicting val_638
2023-09-02 14:12:35.659881: predicting val_639
2023-09-02 14:12:35.790477: predicting val_64
2023-09-02 14:12:35.924152: predicting val_640
2023-09-02 14:12:36.055954: predicting val_641
2023-09-02 14:12:36.192473: predicting val_642
2023-09-02 14:12:36.327001: predicting val_643
2023-09-02 14:12:36.460861: predicting val_644
2023-09-02 14:12:36.593173: predicting val_645
2023-09-02 14:12:36.726561: predicting val_646
2023-09-02 14:12:36.862036: predicting val_647
2023-09-02 14:12:37.000712: predicting val_648
2023-09-02 14:12:37.131946: predicting val_649
2023-09-02 14:12:37.263003: predicting val_65
2023-09-02 14:12:37.398160: predicting val_650
2023-09-02 14:12:37.535345: predicting val_651
2023-09-02 14:12:37.670714: predicting val_652
2023-09-02 14:12:37.804082: predicting val_653
2023-09-02 14:12:37.936211: predicting val_654
2023-09-02 14:12:38.073778: predicting val_655
2023-09-02 14:12:38.206096: predicting val_656
2023-09-02 14:12:38.341013: predicting val_657
2023-09-02 14:12:38.474272: predicting val_658
2023-09-02 14:12:38.609101: predicting val_659
2023-09-02 14:12:38.741445: predicting val_66
2023-09-02 14:12:38.874681: predicting val_660
2023-09-02 14:12:39.007434: predicting val_661
2023-09-02 14:12:39.143560: predicting val_662
2023-09-02 14:12:39.276836: predicting val_663
2023-09-02 14:12:39.409219: predicting val_664
2023-09-02 14:12:39.540662: predicting val_665
2023-09-02 14:12:39.672201: predicting val_666
2023-09-02 14:12:39.805042: predicting val_667
2023-09-02 14:12:39.939422: predicting val_668
2023-09-02 14:12:40.069626: predicting val_669
2023-09-02 14:12:40.204830: predicting val_67
2023-09-02 14:12:40.335726: predicting val_670
2023-09-02 14:12:40.468921: predicting val_671
2023-09-02 14:12:40.603904: predicting val_672
2023-09-02 14:12:40.736024: predicting val_673
2023-09-02 14:12:40.875888: predicting val_674
2023-09-02 14:12:41.017528: predicting val_675
2023-09-02 14:12:41.160754: predicting val_676
2023-09-02 14:12:41.299673: predicting val_677
2023-09-02 14:12:41.435398: predicting val_678
2023-09-02 14:12:41.574186: predicting val_679
2023-09-02 14:12:41.716475: predicting val_68
2023-09-02 14:12:41.853953: predicting val_680
2023-09-02 14:12:41.992261: predicting val_681
2023-09-02 14:12:42.126607: predicting val_682
2023-09-02 14:12:42.258735: predicting val_683
2023-09-02 14:12:42.397842: predicting val_684
2023-09-02 14:12:42.528329: predicting val_685
2023-09-02 14:12:42.662677: predicting val_686
2023-09-02 14:12:42.799519: predicting val_687
2023-09-02 14:12:42.936246: predicting val_688
2023-09-02 14:12:43.070686: predicting val_689
2023-09-02 14:12:43.206356: predicting val_69
2023-09-02 14:12:43.335916: predicting val_690
2023-09-02 14:12:43.468501: predicting val_691
2023-09-02 14:12:43.600826: predicting val_692
2023-09-02 14:12:43.733346: predicting val_693
2023-09-02 14:12:43.866189: predicting val_694
2023-09-02 14:12:43.999954: predicting val_695
2023-09-02 14:12:44.132850: predicting val_696
2023-09-02 14:12:44.266742: predicting val_697
2023-09-02 14:12:44.401627: predicting val_698
2023-09-02 14:12:44.537245: predicting val_699
2023-09-02 14:12:44.668431: predicting val_7
2023-09-02 14:12:44.800912: predicting val_70
2023-09-02 14:12:44.933124: predicting val_700
2023-09-02 14:12:45.066934: predicting val_701
2023-09-02 14:12:45.200576: predicting val_702
2023-09-02 14:12:45.334959: predicting val_703
2023-09-02 14:12:45.466582: predicting val_704
2023-09-02 14:12:45.608977: predicting val_705
2023-09-02 14:12:45.742371: predicting val_706
2023-09-02 14:12:45.875132: predicting val_707
2023-09-02 14:12:46.010879: predicting val_708
2023-09-02 14:12:46.144062: predicting val_709
2023-09-02 14:12:46.279258: predicting val_71
2023-09-02 14:12:46.412001: predicting val_710
2023-09-02 14:12:46.543446: predicting val_711
2023-09-02 14:12:46.676944: predicting val_712
2023-09-02 14:12:46.809458: predicting val_713
2023-09-02 14:12:46.942104: predicting val_714
2023-09-02 14:12:47.075826: predicting val_715
2023-09-02 14:12:47.208281: predicting val_716
2023-09-02 14:12:47.341236: predicting val_717
2023-09-02 14:12:47.473020: predicting val_718
2023-09-02 14:12:47.602496: predicting val_719
2023-09-02 14:12:47.734585: predicting val_72
2023-09-02 14:12:47.868027: predicting val_720
2023-09-02 14:12:48.002662: predicting val_721
2023-09-02 14:12:48.135819: predicting val_722
2023-09-02 14:12:48.270310: predicting val_723
2023-09-02 14:12:48.403529: predicting val_724
2023-09-02 14:12:48.536706: predicting val_725
2023-09-02 14:12:48.667034: predicting val_726
2023-09-02 14:12:48.800958: predicting val_727
2023-09-02 14:12:48.936051: predicting val_728
2023-09-02 14:12:49.070896: predicting val_729
2023-09-02 14:12:49.208635: predicting val_73
2023-09-02 14:12:49.341775: predicting val_730
2023-09-02 14:12:49.474122: predicting val_731
2023-09-02 14:12:49.607335: predicting val_732
2023-09-02 14:12:49.739004: predicting val_733
2023-09-02 14:12:49.873559: predicting val_734
2023-09-02 14:12:50.011355: predicting val_735
2023-09-02 14:12:50.145361: predicting val_736
2023-09-02 14:12:50.279496: predicting val_737
2023-09-02 14:12:50.413542: predicting val_738
2023-09-02 14:12:50.548569: predicting val_739
2023-09-02 14:12:50.680726: predicting val_74
2023-09-02 14:12:50.813960: predicting val_740
2023-09-02 14:12:50.947977: predicting val_741
2023-09-02 14:12:51.082300: predicting val_742
2023-09-02 14:12:51.223927: predicting val_743
2023-09-02 14:12:51.359891: predicting val_744
2023-09-02 14:12:51.493434: predicting val_745
2023-09-02 14:12:51.626952: predicting val_746
2023-09-02 14:12:51.760568: predicting val_747
2023-09-02 14:12:51.892214: predicting val_748
2023-09-02 14:12:52.025695: predicting val_749
2023-09-02 14:12:52.161875: predicting val_75
2023-09-02 14:12:52.295732: predicting val_750
2023-09-02 14:12:52.428581: predicting val_751
2023-09-02 14:12:52.563336: predicting val_752
2023-09-02 14:12:52.698071: predicting val_753
2023-09-02 14:12:52.831828: predicting val_754
2023-09-02 14:12:52.964030: predicting val_755
2023-09-02 14:12:53.097189: predicting val_756
2023-09-02 14:12:53.228997: predicting val_757
2023-09-02 14:12:53.362616: predicting val_758
2023-09-02 14:12:53.499646: predicting val_759
2023-09-02 14:12:53.634072: predicting val_76
2023-09-02 14:12:53.767748: predicting val_760
2023-09-02 14:12:53.901087: predicting val_761
2023-09-02 14:12:54.033879: predicting val_762
2023-09-02 14:12:54.168990: predicting val_763
2023-09-02 14:12:54.301985: predicting val_764
2023-09-02 14:12:54.435446: predicting val_765
2023-09-02 14:12:54.568057: predicting val_766
2023-09-02 14:12:54.705467: predicting val_767
2023-09-02 14:12:54.838057: predicting val_768
2023-09-02 14:12:54.972103: predicting val_769
2023-09-02 14:12:55.103657: predicting val_77
2023-09-02 14:12:55.241105: predicting val_770
2023-09-02 14:12:55.373685: predicting val_771
2023-09-02 14:12:55.508414: predicting val_772
2023-09-02 14:12:55.642033: predicting val_773
2023-09-02 14:12:55.775194: predicting val_774
2023-09-02 14:12:55.908517: predicting val_775
2023-09-02 14:12:56.042746: predicting val_776
2023-09-02 14:12:56.173826: predicting val_777
2023-09-02 14:12:56.307990: predicting val_778
2023-09-02 14:12:56.439403: predicting val_779
2023-09-02 14:12:56.572181: predicting val_78
2023-09-02 14:12:56.707697: predicting val_780
2023-09-02 14:12:56.840305: predicting val_781
2023-09-02 14:12:56.973329: predicting val_782
2023-09-02 14:12:57.106160: predicting val_783
2023-09-02 14:12:57.238358: predicting val_784
2023-09-02 14:12:57.371317: predicting val_785
2023-09-02 14:12:57.505644: predicting val_786
2023-09-02 14:12:57.637534: predicting val_787
2023-09-02 14:12:57.770276: predicting val_788
2023-09-02 14:12:57.903257: predicting val_789
2023-09-02 14:12:58.035926: predicting val_79
2023-09-02 14:12:58.168795: predicting val_790
2023-09-02 14:12:58.301117: predicting val_791
2023-09-02 14:12:58.432747: predicting val_792
2023-09-02 14:12:58.568402: predicting val_793
2023-09-02 14:12:58.704465: predicting val_794
2023-09-02 14:12:58.837592: predicting val_795
2023-09-02 14:12:58.971444: predicting val_796
2023-09-02 14:12:59.104689: predicting val_797
2023-09-02 14:12:59.237149: predicting val_798
2023-09-02 14:12:59.368477: predicting val_799
2023-09-02 14:12:59.502843: predicting val_8
2023-09-02 14:12:59.637406: predicting val_80
2023-09-02 14:12:59.771520: predicting val_800
2023-09-02 14:12:59.907405: predicting val_801
2023-09-02 14:13:00.043626: predicting val_802
2023-09-02 14:13:00.178528: predicting val_803
2023-09-02 14:13:00.312983: predicting val_804
2023-09-02 14:13:00.446317: predicting val_805
2023-09-02 14:13:00.584759: predicting val_806
2023-09-02 14:13:00.718845: predicting val_807
2023-09-02 14:13:00.850203: predicting val_81
2023-09-02 14:13:00.982360: predicting val_82
2023-09-02 14:13:01.115870: predicting val_83
2023-09-02 14:13:01.250411: predicting val_84
2023-09-02 14:13:01.384551: predicting val_85
2023-09-02 14:13:01.513911: predicting val_86
2023-09-02 14:13:01.649385: predicting val_87
2023-09-02 14:13:01.783310: predicting val_88
2023-09-02 14:13:01.917168: predicting val_89
2023-09-02 14:13:02.050719: predicting val_9
2023-09-02 14:13:02.182999: predicting val_90
2023-09-02 14:13:02.316340: predicting val_91
2023-09-02 14:13:02.449156: predicting val_92
2023-09-02 14:13:02.581012: predicting val_93
2023-09-02 14:13:02.715165: predicting val_94
2023-09-02 14:13:02.847265: predicting val_95
2023-09-02 14:13:02.978941: predicting val_96
2023-09-02 14:13:03.111482: predicting val_97
2023-09-02 14:13:03.245700: predicting val_98
2023-09-02 14:13:03.377724: predicting val_99
2023-09-02 14:13:16.583200: Validation complete
2023-09-02 14:13:16.584719: Mean Validation Dice:  0.9033728997419758
