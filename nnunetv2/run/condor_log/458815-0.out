OrderedDict([('self', <Parameter "self">), ('plans', <Parameter "plans: dict">), ('configuration', <Parameter "configuration: str">), ('fold', <Parameter "fold: int">), ('dataset_json', <Parameter "dataset_json: dict">), ('unpack_dataset', <Parameter "unpack_dataset: bool = True">), ('device', <Parameter "device: torch.device = device(type='cuda')">), ('debug', <Parameter "debug=True">), ('job_id', <Parameter "job_id=None">)])
Using device: cuda:0
==========================initial_lr: 0.005===========================
2023-09-03 09:59:11.468050: I am training on qa-rtx6k-009.crc.nd.edu
2023-09-03 09:59:11.469429: output folder: /afs/crc.nd.edu/user/y/ypeng4/data/trained_models/Dataset124_ISIC2018/ISICTrainer__nnUNetPlans__2d/458815_my_unet_FusedMBConv_16/fold_0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
loading /afs/crc.nd.edu/user/y/ypeng4/Polyp-PVT_2/pvt_pth/pvt_v2_b2.pth
loading /afs/crc.nd.edu/user/y/ypeng4/Polyp-PVT_2/pvt_pth/pvt_v2_b2.pth
model: PVTUNet(
  (backbone): Identity()
  (model): Unet(
    (encoder): PVTEncoder(
      (backbone): pvt_v2_b2(
        (patch_embed1): OverlapPatchEmbed(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed2): OverlapPatchEmbed(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed3): OverlapPatchEmbed(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed4): OverlapPatchEmbed(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (block1): ModuleList(
          (0): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.007)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.013)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (block2): ModuleList(
          (0): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.020)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.033)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): Block(
            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.040)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=1024, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1024, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (block3): ModuleList(
          (0): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.047)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.053)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.060)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.067)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.073)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): Block(
            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.080)
            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (block4): ModuleList(
          (0): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.087)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.093)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
    )
    (decoder): UnetDecoder(
      (center): Identity()
      (blocks): ModuleList(
        (0): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(832, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (1): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (2): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (3): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
        (4): DecoderBlock(
          (conv1): Conv2dReLU(
            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention1): Attention(
            (attention): Identity()
          )
          (conv2): Conv2dReLU(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (attention2): Attention(
            (attention): Identity()
          )
        )
      )
    )
    (segmentation_head): SegmentationHead(
      (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): Identity()
      (2): Activation(
        (activation): Identity()
      )
    )
  )
)
================<class 'nnunetv2.training.network.model.dim2.pvt.pvt_unet.PVTUNet'>=================
ds wegihts: [0.53333333 0.26666667 0.13333333 0.06666667]

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'UNet_class_name': 'PlainConvUNet', 'nnUNet_UNet': False, 'my_net_class': 'pvt_unet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset124_ISIC2018', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 256, 256], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 160.57754516601562, 'median': 164.0, 'min': 0.0, 'percentile_00_5': 29.0, 'percentile_99_5': 253.0, 'std': 42.08180618286133}, '1': {'max': 255.0, 'mean': 111.1130142211914, 'median': 113.0, 'min': 0.0, 'percentile_00_5': 8.0, 'percentile_99_5': 222.0, 'std': 43.864933013916016}, '2': {'max': 255.0, 'mean': 91.45153045654297, 'median': 91.0, 'min': 0.0, 'percentile_00_5': 4.0, 'percentile_99_5': 209.0, 'std': 43.73163604736328}}} 

2023-09-03 10:02:30.617280: unpacking dataset...
2023-09-03 10:03:10.243037: unpacking done...
2023-09-03 10:03:10.244663: do_dummy_2d_data_aug: False
2023-09-03 10:03:10.264081: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:03:10.265459: The split file contains 1 splits.
2023-09-03 10:03:10.266009: Desired fold for training: 0
2023-09-03 10:03:10.266335: This split has 1886 training and 808 validation cases.
==================batch size: 49==================
2023-09-03 10:03:10.301572: Unable to plot network architecture:
2023-09-03 10:03:10.301988: No module named 'hiddenlayer'
PVTUNet
===================debug: False===================
2023-09-03 10:03:12.028991: 
2023-09-03 10:03:12.029951: Epoch 0
2023-09-03 10:03:12.030765: Current learning rate: backbone 0.001, others 0.001
2023-09-03 10:03:12.031428: start training, 250
==========num_iterations_per_epoch: 250===========
using pin_memory on device 0
2023-09-03 10:04:39.237439: finished training epoch 0
2023-09-03 10:04:39.265619: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:04:39.267128: The split file contains 1 splits.
2023-09-03 10:04:39.267836: Desired fold for training: 0
2023-09-03 10:04:39.268359: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:09:39.527573: dsc: 88.74%
2023-09-03 10:09:39.528900: miou: 79.76%
2023-09-03 10:09:39.529571: acc: 94.56%, sen: 85.30%, spe: 97.67%
2023-09-03 10:09:39.530697: current best miou: 0.7976401281013936 at epoch: 0, (0, 0.7976401281013936, 0.8874302655268761)
2023-09-03 10:09:39.531370: current best dsc: 0.8874302655268761 at epoch: 0, (0, 0.7976401281013936, 0.8874302655268761)
2023-09-03 10:09:41.201522: finished real validation
using pin_memory on device 0
2023-09-03 10:09:46.897041: train_loss -1.0039
2023-09-03 10:09:46.898283: val_loss -1.1512
2023-09-03 10:09:46.899796: Pseudo dice [0.8895]
2023-09-03 10:09:46.900727: Epoch time: 394.87 s
2023-09-03 10:09:46.901381: Yayy! New best EMA pseudo Dice: 0.8895
2023-09-03 10:09:49.588472: 
2023-09-03 10:09:49.589598: Epoch 1
2023-09-03 10:09:49.590264: Current learning rate: backbone 0.000997, others 0.000997
2023-09-03 10:09:49.591469: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:11:03.451053: finished training epoch 1
2023-09-03 10:11:03.485238: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:11:03.487193: The split file contains 1 splits.
2023-09-03 10:11:03.488066: Desired fold for training: 0
2023-09-03 10:11:03.488734: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:16:25.260875: dsc: 90.73%
2023-09-03 10:16:25.261930: miou: 83.03%
2023-09-03 10:16:25.262538: acc: 95.40%, sen: 89.39%, spe: 97.42%
2023-09-03 10:16:25.263492: current best miou: 0.8302629598743257 at epoch: 1, (1, 0.8302629598743257, 0.907260845109749)
2023-09-03 10:16:25.264061: current best dsc: 0.907260845109749 at epoch: 1, (1, 0.8302629598743257, 0.907260845109749)
2023-09-03 10:16:27.117095: finished real validation
2023-09-03 10:16:32.059101: train_loss -1.2482
2023-09-03 10:16:32.060264: val_loss -1.213
2023-09-03 10:16:32.061233: Pseudo dice [0.9078]
2023-09-03 10:16:32.061936: Epoch time: 402.47 s
2023-09-03 10:16:32.062540: Yayy! New best EMA pseudo Dice: 0.8913
2023-09-03 10:16:34.888307: 
2023-09-03 10:16:34.889297: Epoch 2
2023-09-03 10:16:34.890075: Current learning rate: backbone 0.000994, others 0.000994
2023-09-03 10:16:34.891151: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:17:48.331135: finished training epoch 2
2023-09-03 10:17:48.360004: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:17:48.362516: The split file contains 1 splits.
2023-09-03 10:17:48.363721: Desired fold for training: 0
2023-09-03 10:17:48.364556: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:23:11.316344: dsc: 90.44%
2023-09-03 10:23:11.317316: miou: 82.55%
2023-09-03 10:23:11.317916: acc: 95.15%, sen: 91.27%, spe: 96.45%
2023-09-03 10:23:11.318717: current best miou: 0.8302629598743257 at epoch: 1, (1, 0.8302629598743257, 0.907260845109749)
2023-09-03 10:23:11.319340: current best dsc: 0.907260845109749 at epoch: 1, (1, 0.8302629598743257, 0.907260845109749)
2023-09-03 10:23:11.319816: finished real validation
2023-09-03 10:23:16.259221: train_loss -1.2855
2023-09-03 10:23:16.260221: val_loss -1.1905
2023-09-03 10:23:16.261058: Pseudo dice [0.9039]
2023-09-03 10:23:16.261688: Epoch time: 401.37 s
2023-09-03 10:23:16.262211: Yayy! New best EMA pseudo Dice: 0.8925
2023-09-03 10:23:19.247165: 
2023-09-03 10:23:19.248423: Epoch 3
2023-09-03 10:23:19.249159: Current learning rate: backbone 0.000991, others 0.000991
2023-09-03 10:23:19.250416: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:24:32.791820: finished training epoch 3
2023-09-03 10:24:32.832270: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:24:32.834011: The split file contains 1 splits.
2023-09-03 10:24:32.834789: Desired fold for training: 0
2023-09-03 10:24:32.835412: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:29:55.909076: dsc: 91.21%
2023-09-03 10:29:55.910109: miou: 83.84%
2023-09-03 10:29:55.910921: acc: 95.53%, sen: 92.17%, spe: 96.66%
2023-09-03 10:29:55.912188: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:29:55.912766: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:29:57.713635: finished real validation
2023-09-03 10:30:02.662068: train_loss -1.3131
2023-09-03 10:30:02.663321: val_loss -1.2165
2023-09-03 10:30:02.664362: Pseudo dice [0.915]
2023-09-03 10:30:02.665088: Epoch time: 403.42 s
2023-09-03 10:30:02.665670: Yayy! New best EMA pseudo Dice: 0.8948
2023-09-03 10:30:05.633948: 
2023-09-03 10:30:05.634965: Epoch 4
2023-09-03 10:30:05.635648: Current learning rate: backbone 0.00098799, others 0.00098799
2023-09-03 10:30:05.637314: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:31:19.138010: finished training epoch 4
2023-09-03 10:31:19.166929: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:31:19.168261: The split file contains 1 splits.
2023-09-03 10:31:19.169286: Desired fold for training: 0
2023-09-03 10:31:19.169799: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:36:59.145559: dsc: 90.77%
2023-09-03 10:36:59.146548: miou: 83.11%
2023-09-03 10:36:59.147200: acc: 95.22%, sen: 93.43%, spe: 95.82%
2023-09-03 10:36:59.148420: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:36:59.150006: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:36:59.150663: finished real validation
2023-09-03 10:37:04.089576: train_loss -1.3177
2023-09-03 10:37:04.091005: val_loss -1.1848
2023-09-03 10:37:04.092816: Pseudo dice [0.9055]
2023-09-03 10:37:04.094078: Epoch time: 418.46 s
2023-09-03 10:37:04.095104: Yayy! New best EMA pseudo Dice: 0.8959
2023-09-03 10:37:07.107599: 
2023-09-03 10:37:07.108570: Epoch 5
2023-09-03 10:37:07.109244: Current learning rate: backbone 0.00098499, others 0.00098499
2023-09-03 10:37:07.111106: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:38:20.667660: finished training epoch 5
2023-09-03 10:38:20.706692: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:38:20.708236: The split file contains 1 splits.
2023-09-03 10:38:20.708906: Desired fold for training: 0
2023-09-03 10:38:20.712579: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:43:42.846998: dsc: 90.26%
2023-09-03 10:43:42.848052: miou: 82.24%
2023-09-03 10:43:42.848642: acc: 95.22%, sen: 87.96%, spe: 97.66%
2023-09-03 10:43:42.849558: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:43:42.850152: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:43:42.850832: finished real validation
2023-09-03 10:43:47.845438: train_loss -1.3331
2023-09-03 10:43:47.846637: val_loss -1.1631
2023-09-03 10:43:47.847581: Pseudo dice [0.901]
2023-09-03 10:43:47.848331: Epoch time: 400.74 s
2023-09-03 10:43:47.848998: Yayy! New best EMA pseudo Dice: 0.8964
2023-09-03 10:43:50.798586: 
2023-09-03 10:43:50.799634: Epoch 6
2023-09-03 10:43:50.800368: Current learning rate: backbone 0.00098198, others 0.00098198
2023-09-03 10:43:50.801429: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:45:04.358574: finished training epoch 6
2023-09-03 10:45:04.387078: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:45:04.389617: The split file contains 1 splits.
2023-09-03 10:45:04.391233: Desired fold for training: 0
2023-09-03 10:45:04.392527: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:50:30.475403: dsc: 90.99%
2023-09-03 10:50:30.476547: miou: 83.47%
2023-09-03 10:50:30.477226: acc: 95.41%, sen: 92.16%, spe: 96.50%
2023-09-03 10:50:30.478117: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:50:30.478756: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:50:30.479280: finished real validation
2023-09-03 10:50:35.428218: train_loss -1.3436
2023-09-03 10:50:35.429827: val_loss -1.215
2023-09-03 10:50:35.432415: Pseudo dice [0.9145]
2023-09-03 10:50:35.433657: Epoch time: 404.63 s
2023-09-03 10:50:35.434707: Yayy! New best EMA pseudo Dice: 0.8982
2023-09-03 10:50:38.415229: 
2023-09-03 10:50:38.416430: Epoch 7
2023-09-03 10:50:38.417167: Current learning rate: backbone 0.00097898, others 0.00097898
2023-09-03 10:50:38.418342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:51:51.988822: finished training epoch 7
2023-09-03 10:51:52.027000: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:51:52.029422: The split file contains 1 splits.
2023-09-03 10:51:52.030576: Desired fold for training: 0
2023-09-03 10:51:52.031509: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 10:57:54.296858: dsc: 90.43%
2023-09-03 10:57:54.298870: miou: 82.52%
2023-09-03 10:57:54.300324: acc: 95.11%, sen: 91.83%, spe: 96.21%
2023-09-03 10:57:54.301307: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:57:54.302021: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 10:57:54.302589: finished real validation
2023-09-03 10:57:59.250344: train_loss -1.349
2023-09-03 10:57:59.251695: val_loss -1.1651
2023-09-03 10:57:59.252847: Pseudo dice [0.9022]
2023-09-03 10:57:59.253625: Epoch time: 440.84 s
2023-09-03 10:57:59.254393: Yayy! New best EMA pseudo Dice: 0.8986
2023-09-03 10:58:02.400874: 
2023-09-03 10:58:02.402217: Epoch 8
2023-09-03 10:58:02.403477: Current learning rate: backbone 0.00097597, others 0.00097597
2023-09-03 10:58:02.405985: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 10:59:16.338144: finished training epoch 8
2023-09-03 10:59:16.367888: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 10:59:16.369668: The split file contains 1 splits.
2023-09-03 10:59:16.370466: Desired fold for training: 0
2023-09-03 10:59:16.371149: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:05:19.963341: dsc: 90.49%
2023-09-03 11:05:19.965035: miou: 82.63%
2023-09-03 11:05:19.966128: acc: 95.08%, sen: 93.11%, spe: 95.73%
2023-09-03 11:05:19.967999: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:05:19.968984: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:05:19.969844: finished real validation
2023-09-03 11:05:24.920323: train_loss -1.3561
2023-09-03 11:05:24.921519: val_loss -1.1658
2023-09-03 11:05:24.922484: Pseudo dice [0.9033]
2023-09-03 11:05:24.923195: Epoch time: 442.52 s
2023-09-03 11:05:24.924064: Yayy! New best EMA pseudo Dice: 0.8991
2023-09-03 11:05:27.956498: 
2023-09-03 11:05:27.957656: Epoch 9
2023-09-03 11:05:27.958456: Current learning rate: backbone 0.00097296, others 0.00097296
2023-09-03 11:05:27.959695: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:06:41.765832: finished training epoch 9
2023-09-03 11:06:41.809992: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:06:41.811481: The split file contains 1 splits.
2023-09-03 11:06:41.812439: Desired fold for training: 0
2023-09-03 11:06:41.813134: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:13:16.120561: dsc: 91.18%
2023-09-03 11:13:16.121909: miou: 83.78%
2023-09-03 11:13:16.122565: acc: 95.60%, sen: 90.44%, spe: 97.33%
2023-09-03 11:13:16.123679: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:13:16.124461: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:13:16.125185: finished real validation
2023-09-03 11:13:21.083961: train_loss -1.3605
2023-09-03 11:13:21.085259: val_loss -1.1737
2023-09-03 11:13:21.086283: Pseudo dice [0.9064]
2023-09-03 11:13:21.087085: Epoch time: 473.13 s
2023-09-03 11:13:23.045356: Yayy! New best EMA pseudo Dice: 0.8998
2023-09-03 11:13:25.939543: 
2023-09-03 11:13:25.940773: Epoch 10
2023-09-03 11:13:25.941473: Current learning rate: backbone 0.00096995, others 0.00096995
2023-09-03 11:13:25.942614: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:14:39.519138: finished training epoch 10
2023-09-03 11:14:39.565779: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:14:39.567523: The split file contains 1 splits.
2023-09-03 11:14:39.568442: Desired fold for training: 0
2023-09-03 11:14:39.569237: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:20:10.545082: dsc: 90.80%
2023-09-03 11:20:10.546754: miou: 83.15%
2023-09-03 11:20:10.547607: acc: 95.34%, sen: 91.37%, spe: 96.68%
2023-09-03 11:20:10.548579: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:20:10.549359: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:20:10.549928: finished real validation
2023-09-03 11:20:15.506379: train_loss -1.3653
2023-09-03 11:20:15.507526: val_loss -1.1565
2023-09-03 11:20:15.508432: Pseudo dice [0.9029]
2023-09-03 11:20:15.509219: Epoch time: 409.57 s
2023-09-03 11:20:15.509811: Yayy! New best EMA pseudo Dice: 0.9001
2023-09-03 11:20:18.396090: 
2023-09-03 11:20:18.397357: Epoch 11
2023-09-03 11:20:18.398127: Current learning rate: backbone 0.00096694, others 0.00096694
2023-09-03 11:20:18.399224: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:21:32.219070: finished training epoch 11
2023-09-03 11:21:32.262169: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:21:32.263655: The split file contains 1 splits.
2023-09-03 11:21:32.264343: Desired fold for training: 0
2023-09-03 11:21:32.264986: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:27:36.764021: dsc: 90.66%
2023-09-03 11:27:36.765201: miou: 82.92%
2023-09-03 11:27:36.765949: acc: 95.33%, sen: 90.15%, spe: 97.07%
2023-09-03 11:27:36.766874: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:27:36.767586: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:27:36.768201: finished real validation
2023-09-03 11:27:41.732624: train_loss -1.3712
2023-09-03 11:27:41.733867: val_loss -1.1741
2023-09-03 11:27:41.734993: Pseudo dice [0.908]
2023-09-03 11:27:41.735877: Epoch time: 443.34 s
2023-09-03 11:27:41.737202: Yayy! New best EMA pseudo Dice: 0.9009
2023-09-03 11:27:44.659463: 
2023-09-03 11:27:44.660948: Epoch 12
2023-09-03 11:27:44.662108: Current learning rate: backbone 0.00096393, others 0.00096393
2023-09-03 11:27:44.663813: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:28:58.533447: finished training epoch 12
2023-09-03 11:28:58.563829: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:28:58.566239: The split file contains 1 splits.
2023-09-03 11:28:58.567591: Desired fold for training: 0
2023-09-03 11:28:58.568170: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:35:36.456504: dsc: 91.10%
2023-09-03 11:35:36.457850: miou: 83.66%
2023-09-03 11:35:36.458654: acc: 95.49%, sen: 91.89%, spe: 96.69%
2023-09-03 11:35:36.459648: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:35:36.460422: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:35:36.461047: finished real validation
2023-09-03 11:35:41.403003: train_loss -1.3756
2023-09-03 11:35:41.404212: val_loss -1.1649
2023-09-03 11:35:41.405239: Pseudo dice [0.9081]
2023-09-03 11:35:41.406021: Epoch time: 476.74 s
2023-09-03 11:35:41.406805: Yayy! New best EMA pseudo Dice: 0.9016
2023-09-03 11:35:44.603344: 
2023-09-03 11:35:44.605046: Epoch 13
2023-09-03 11:35:44.605930: Current learning rate: backbone 0.00096091, others 0.00096091
2023-09-03 11:35:44.608234: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:36:58.855601: finished training epoch 13
2023-09-03 11:36:58.886298: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:36:58.888123: The split file contains 1 splits.
2023-09-03 11:36:58.888882: Desired fold for training: 0
2023-09-03 11:36:58.889483: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:42:25.420568: dsc: 90.78%
2023-09-03 11:42:25.421736: miou: 83.12%
2023-09-03 11:42:25.422626: acc: 95.33%, sen: 91.45%, spe: 96.63%
2023-09-03 11:42:25.424071: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:42:25.424824: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:42:25.425456: finished real validation
2023-09-03 11:42:30.381012: train_loss -1.3792
2023-09-03 11:42:30.382220: val_loss -1.1757
2023-09-03 11:42:30.383174: Pseudo dice [0.9069]
2023-09-03 11:42:30.383981: Epoch time: 405.78 s
2023-09-03 11:42:30.384745: Yayy! New best EMA pseudo Dice: 0.9021
2023-09-03 11:42:33.425897: 
2023-09-03 11:42:33.427153: Epoch 14
2023-09-03 11:42:33.428272: Current learning rate: backbone 0.0009579, others 0.0009579
2023-09-03 11:42:33.429517: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:43:47.319278: finished training epoch 14
2023-09-03 11:43:47.355976: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:43:47.357772: The split file contains 1 splits.
2023-09-03 11:43:47.358541: Desired fold for training: 0
2023-09-03 11:43:47.359569: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:49:06.024746: dsc: 91.01%
2023-09-03 11:49:06.026504: miou: 83.50%
2023-09-03 11:49:06.028104: acc: 95.41%, sen: 92.40%, spe: 96.42%
2023-09-03 11:49:06.029837: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:49:06.031088: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:49:06.032423: finished real validation
2023-09-03 11:49:10.996952: train_loss -1.3821
2023-09-03 11:49:10.998924: val_loss -1.1616
2023-09-03 11:49:11.000108: Pseudo dice [0.9098]
2023-09-03 11:49:11.000923: Epoch time: 397.57 s
2023-09-03 11:49:11.001840: Yayy! New best EMA pseudo Dice: 0.9029
2023-09-03 11:49:13.828313: 
2023-09-03 11:49:13.829924: Epoch 15
2023-09-03 11:49:13.831037: Current learning rate: backbone 0.00095489, others 0.00095489
2023-09-03 11:49:13.833303: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:50:27.468435: finished training epoch 15
2023-09-03 11:50:27.521580: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:50:27.523503: The split file contains 1 splits.
2023-09-03 11:50:27.524246: Desired fold for training: 0
2023-09-03 11:50:27.525055: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 11:56:11.839592: dsc: 91.14%
2023-09-03 11:56:11.850859: miou: 83.73%
2023-09-03 11:56:11.872196: acc: 95.53%, sen: 91.45%, spe: 96.90%
2023-09-03 11:56:11.888883: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:56:11.890146: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 11:56:11.891130: finished real validation
2023-09-03 11:56:16.851339: train_loss -1.383
2023-09-03 11:56:16.856006: val_loss -1.1763
2023-09-03 11:56:16.867127: Pseudo dice [0.91]
2023-09-03 11:56:16.877653: Epoch time: 423.02 s
2023-09-03 11:56:16.887923: Yayy! New best EMA pseudo Dice: 0.9036
2023-09-03 11:56:19.713512: 
2023-09-03 11:56:19.717988: Epoch 16
2023-09-03 11:56:19.729055: Current learning rate: backbone 0.00095187, others 0.00095187
2023-09-03 11:56:19.739751: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 11:57:33.295146: finished training epoch 16
2023-09-03 11:57:33.345886: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 11:57:33.347696: The split file contains 1 splits.
2023-09-03 11:57:33.348626: Desired fold for training: 0
2023-09-03 11:57:33.349666: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:02:57.585463: dsc: 91.16%
2023-09-03 12:02:57.586731: miou: 83.75%
2023-09-03 12:02:57.587725: acc: 95.50%, sen: 92.23%, spe: 96.60%
2023-09-03 12:02:57.588747: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:02:57.589676: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:02:57.590566: finished real validation
2023-09-03 12:03:02.553366: train_loss -1.387
2023-09-03 12:03:02.554861: val_loss -1.1754
2023-09-03 12:03:02.556187: Pseudo dice [0.9095]
2023-09-03 12:03:02.557221: Epoch time: 402.84 s
2023-09-03 12:03:02.558392: Yayy! New best EMA pseudo Dice: 0.9042
2023-09-03 12:03:05.590075: 
2023-09-03 12:03:05.592046: Epoch 17
2023-09-03 12:03:05.593186: Current learning rate: backbone 0.00094885, others 0.00094885
2023-09-03 12:03:05.594336: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:04:19.149074: finished training epoch 17
2023-09-03 12:04:19.186203: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:04:19.187950: The split file contains 1 splits.
2023-09-03 12:04:19.188656: Desired fold for training: 0
2023-09-03 12:04:19.189267: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:09:57.819940: dsc: 90.97%
2023-09-03 12:09:57.821599: miou: 83.44%
2023-09-03 12:09:57.822502: acc: 95.43%, sen: 91.51%, spe: 96.75%
2023-09-03 12:09:57.823486: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:09:57.824239: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:09:57.824903: finished real validation
2023-09-03 12:10:02.782454: train_loss -1.3904
2023-09-03 12:10:29.048688: val_loss -1.1603
2023-09-03 12:10:29.050939: Pseudo dice [0.9064]
2023-09-03 12:10:29.052944: Epoch time: 417.19 s
2023-09-03 12:10:29.055331: Yayy! New best EMA pseudo Dice: 0.9044
2023-09-03 12:10:33.138664: 
2023-09-03 12:10:33.140619: Epoch 18
2023-09-03 12:10:33.142017: Current learning rate: backbone 0.00094583, others 0.00094583
2023-09-03 12:10:33.143717: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:11:46.589187: finished training epoch 18
2023-09-03 12:11:46.634362: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:11:46.654080: The split file contains 1 splits.
2023-09-03 12:11:46.678750: Desired fold for training: 0
2023-09-03 12:11:46.703294: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:17:14.096798: dsc: 90.94%
2023-09-03 12:17:14.100400: miou: 83.39%
2023-09-03 12:17:14.114128: acc: 95.44%, sen: 90.93%, spe: 96.96%
2023-09-03 12:17:14.143403: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:17:14.149859: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:17:14.151192: finished real validation
2023-09-03 12:17:19.100982: train_loss -1.3922
2023-09-03 12:17:19.126125: val_loss -1.1482
2023-09-03 12:17:19.155196: Pseudo dice [0.9069]
2023-09-03 12:17:19.182999: Epoch time: 405.96 s
2023-09-03 12:17:19.197391: Yayy! New best EMA pseudo Dice: 0.9047
2023-09-03 12:17:22.180538: 
2023-09-03 12:17:22.219362: Epoch 19
2023-09-03 12:17:22.247276: Current learning rate: backbone 0.00094282, others 0.00094282
2023-09-03 12:17:22.276137: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:18:35.757969: finished training epoch 19
2023-09-03 12:18:35.787758: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:18:35.790195: The split file contains 1 splits.
2023-09-03 12:18:35.791237: Desired fold for training: 0
2023-09-03 12:18:35.792060: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:24:02.518749: dsc: 90.88%
2023-09-03 12:24:02.520875: miou: 83.29%
2023-09-03 12:24:02.522548: acc: 95.46%, sen: 90.08%, spe: 97.26%
2023-09-03 12:24:02.524386: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:24:02.526101: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:24:02.527568: finished real validation
2023-09-03 12:24:07.493062: train_loss -1.3953
2023-09-03 12:24:07.494539: val_loss -1.16
2023-09-03 12:24:07.495734: Pseudo dice [0.9082]
2023-09-03 12:24:07.496499: Epoch time: 405.31 s
2023-09-03 12:24:09.335169: Yayy! New best EMA pseudo Dice: 0.905
2023-09-03 12:24:12.341091: 
2023-09-03 12:24:12.342498: Epoch 20
2023-09-03 12:24:12.343450: Current learning rate: backbone 0.00093979, others 0.00093979
2023-09-03 12:24:12.344651: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:25:25.980087: finished training epoch 20
2023-09-03 12:25:26.019269: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:25:26.020908: The split file contains 1 splits.
2023-09-03 12:25:26.021717: Desired fold for training: 0
2023-09-03 12:25:26.022479: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:30:55.309766: dsc: 91.07%
2023-09-03 12:30:55.311950: miou: 83.61%
2023-09-03 12:30:55.315770: acc: 95.48%, sen: 91.71%, spe: 96.74%
2023-09-03 12:30:55.320622: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:30:55.322306: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:30:55.325064: finished real validation
2023-09-03 12:31:00.281382: train_loss -1.394
2023-09-03 12:31:00.282529: val_loss -1.1693
2023-09-03 12:31:00.283573: Pseudo dice [0.91]
2023-09-03 12:31:00.284436: Epoch time: 407.94 s
2023-09-03 12:31:00.285304: Yayy! New best EMA pseudo Dice: 0.9055
2023-09-03 12:31:03.410081: 
2023-09-03 12:31:03.412418: Epoch 21
2023-09-03 12:31:03.413869: Current learning rate: backbone 0.00093677, others 0.00093677
2023-09-03 12:31:03.415119: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:32:17.136233: finished training epoch 21
2023-09-03 12:32:17.195259: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:32:17.217641: The split file contains 1 splits.
2023-09-03 12:32:17.232212: Desired fold for training: 0
2023-09-03 12:32:17.246725: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:37:49.234542: dsc: 90.50%
2023-09-03 12:37:49.241179: miou: 82.65%
2023-09-03 12:37:49.262137: acc: 95.21%, sen: 90.79%, spe: 96.69%
2023-09-03 12:37:49.285760: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:37:49.320680: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:37:49.343723: finished real validation
2023-09-03 12:37:54.328150: train_loss -1.3983
2023-09-03 12:37:54.329545: val_loss -1.1619
2023-09-03 12:37:54.330760: Pseudo dice [0.9078]
2023-09-03 12:37:54.331645: Epoch time: 410.92 s
2023-09-03 12:37:54.332443: Yayy! New best EMA pseudo Dice: 0.9058
2023-09-03 12:37:57.313559: 
2023-09-03 12:37:57.314917: Epoch 22
2023-09-03 12:37:57.315775: Current learning rate: backbone 0.00093375, others 0.00093375
2023-09-03 12:37:57.317060: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:39:10.953625: finished training epoch 22
2023-09-03 12:39:11.005188: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:39:11.007022: The split file contains 1 splits.
2023-09-03 12:39:11.007831: Desired fold for training: 0
2023-09-03 12:39:11.008572: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:44:41.957909: dsc: 90.98%
2023-09-03 12:44:41.959260: miou: 83.45%
2023-09-03 12:44:41.960092: acc: 95.44%, sen: 91.35%, spe: 96.82%
2023-09-03 12:44:41.961118: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:44:41.961859: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:44:41.962563: finished real validation
2023-09-03 12:44:46.915621: train_loss -1.4014
2023-09-03 12:44:46.916990: val_loss -1.1673
2023-09-03 12:44:46.918226: Pseudo dice [0.9106]
2023-09-03 12:44:46.919376: Epoch time: 409.6 s
2023-09-03 12:44:46.920194: Yayy! New best EMA pseudo Dice: 0.9062
2023-09-03 12:44:49.861954: 
2023-09-03 12:44:49.863340: Epoch 23
2023-09-03 12:44:49.864427: Current learning rate: backbone 0.00093073, others 0.00093073
2023-09-03 12:44:49.865994: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:46:03.468499: finished training epoch 23
2023-09-03 12:46:03.510087: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:46:03.511953: The split file contains 1 splits.
2023-09-03 12:46:03.512812: Desired fold for training: 0
2023-09-03 12:46:03.513752: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:52:10.511756: dsc: 90.57%
2023-09-03 12:52:10.513156: miou: 82.77%
2023-09-03 12:52:10.513928: acc: 95.23%, sen: 91.11%, spe: 96.61%
2023-09-03 12:52:10.515084: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:52:10.515853: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:52:10.516552: finished real validation
2023-09-03 12:52:15.461590: train_loss -1.4014
2023-09-03 12:52:15.462844: val_loss -1.1342
2023-09-03 12:52:15.463944: Pseudo dice [0.903]
2023-09-03 12:52:15.464808: Epoch time: 445.6 s
2023-09-03 12:52:16.558056: 
2023-09-03 12:52:16.559299: Epoch 24
2023-09-03 12:52:16.560160: Current learning rate: backbone 0.0009277, others 0.0009277
2023-09-03 12:52:16.561406: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 12:53:30.167353: finished training epoch 24
2023-09-03 12:53:30.200091: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 12:53:30.202099: The split file contains 1 splits.
2023-09-03 12:53:30.202971: Desired fold for training: 0
2023-09-03 12:53:30.203788: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 12:58:47.229637: dsc: 90.79%
2023-09-03 12:58:47.231079: miou: 83.13%
2023-09-03 12:58:47.231876: acc: 95.35%, sen: 91.15%, spe: 96.76%
2023-09-03 12:58:47.232899: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:58:47.233878: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 12:58:47.235315: finished real validation
2023-09-03 12:58:52.182555: train_loss -1.4036
2023-09-03 12:58:52.183978: val_loss -1.1371
2023-09-03 12:58:52.185094: Pseudo dice [0.9044]
2023-09-03 12:58:52.185976: Epoch time: 395.63 s
2023-09-03 12:58:53.288029: 
2023-09-03 12:58:53.289616: Epoch 25
2023-09-03 12:58:53.290585: Current learning rate: backbone 0.00092468, others 0.00092468
2023-09-03 12:58:53.291820: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:00:06.738643: finished training epoch 25
2023-09-03 13:00:06.767264: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:00:06.768734: The split file contains 1 splits.
2023-09-03 13:00:06.769534: Desired fold for training: 0
2023-09-03 13:00:06.770219: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:05:29.260059: dsc: 90.71%
2023-09-03 13:05:29.261325: miou: 83.00%
2023-09-03 13:05:29.262203: acc: 95.30%, sen: 91.29%, spe: 96.64%
2023-09-03 13:05:29.263587: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:05:29.264356: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:05:29.265057: finished real validation
2023-09-03 13:05:34.226275: train_loss -1.4057
2023-09-03 13:05:34.227615: val_loss -1.1068
2023-09-03 13:05:34.228735: Pseudo dice [0.9008]
2023-09-03 13:05:34.229638: Epoch time: 400.94 s
2023-09-03 13:05:35.332477: 
2023-09-03 13:05:35.333883: Epoch 26
2023-09-03 13:05:35.334777: Current learning rate: backbone 0.00092165, others 0.00092165
2023-09-03 13:05:35.336226: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:06:48.849705: finished training epoch 26
2023-09-03 13:06:48.878542: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:06:48.880231: The split file contains 1 splits.
2023-09-03 13:06:48.881043: Desired fold for training: 0
2023-09-03 13:06:48.882181: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:12:10.394155: dsc: 90.91%
2023-09-03 13:12:10.395367: miou: 83.33%
2023-09-03 13:12:10.396664: acc: 95.44%, sen: 90.73%, spe: 97.02%
2023-09-03 13:12:10.398146: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:12:10.399382: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:12:10.400980: finished real validation
2023-09-03 13:12:15.362597: train_loss -1.4078
2023-09-03 13:12:15.363859: val_loss -1.1657
2023-09-03 13:12:15.364992: Pseudo dice [0.9107]
2023-09-03 13:12:15.373267: Epoch time: 400.03 s
2023-09-03 13:12:16.513904: 
2023-09-03 13:12:16.515537: Epoch 27
2023-09-03 13:12:16.516419: Current learning rate: backbone 0.00091862, others 0.00091862
2023-09-03 13:12:16.517657: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:13:30.111614: finished training epoch 27
2023-09-03 13:13:30.148228: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:13:30.157847: The split file contains 1 splits.
2023-09-03 13:13:30.187420: Desired fold for training: 0
2023-09-03 13:13:30.194997: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:18:51.119121: dsc: 90.76%
2023-09-03 13:18:51.120275: miou: 83.08%
2023-09-03 13:18:51.121035: acc: 95.32%, sen: 91.33%, spe: 96.66%
2023-09-03 13:18:51.122000: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:18:51.122698: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:18:51.123436: finished real validation
2023-09-03 13:18:56.085233: train_loss -1.4077
2023-09-03 13:18:56.087348: val_loss -1.136
2023-09-03 13:18:56.088894: Pseudo dice [0.9079]
2023-09-03 13:18:56.089792: Epoch time: 399.57 s
2023-09-03 13:18:57.245136: 
2023-09-03 13:18:57.246811: Epoch 28
2023-09-03 13:18:57.247957: Current learning rate: backbone 0.00091559, others 0.00091559
2023-09-03 13:18:57.250302: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:20:11.042206: finished training epoch 28
2023-09-03 13:20:11.081573: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:20:11.083820: The split file contains 1 splits.
2023-09-03 13:20:11.084645: Desired fold for training: 0
2023-09-03 13:20:11.085550: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:25:33.608094: dsc: 91.03%
2023-09-03 13:25:33.609500: miou: 83.53%
2023-09-03 13:25:33.610330: acc: 95.44%, sen: 92.06%, spe: 96.57%
2023-09-03 13:25:33.611498: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:25:33.612289: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:25:33.613032: finished real validation
2023-09-03 13:25:38.585426: train_loss -1.4092
2023-09-03 13:25:38.586691: val_loss -1.1393
2023-09-03 13:25:38.587804: Pseudo dice [0.9085]
2023-09-03 13:25:38.588665: Epoch time: 401.34 s
2023-09-03 13:25:38.589432: Yayy! New best EMA pseudo Dice: 0.9063
2023-09-03 13:25:41.508065: 
2023-09-03 13:25:41.509369: Epoch 29
2023-09-03 13:25:41.510246: Current learning rate: backbone 0.00091256, others 0.00091256
2023-09-03 13:25:41.511546: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:26:55.363607: finished training epoch 29
2023-09-03 13:26:55.395855: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:26:55.400312: The split file contains 1 splits.
2023-09-03 13:26:55.403769: Desired fold for training: 0
2023-09-03 13:26:55.407188: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:32:16.020271: dsc: 91.09%
2023-09-03 13:32:16.021586: miou: 83.63%
2023-09-03 13:32:16.022401: acc: 95.51%, sen: 91.13%, spe: 96.99%
2023-09-03 13:32:16.023580: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:32:16.024493: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:32:16.025199: finished real validation
2023-09-03 13:32:21.007588: train_loss -1.4124
2023-09-03 13:32:21.009006: val_loss -1.1625
2023-09-03 13:32:21.010220: Pseudo dice [0.9118]
2023-09-03 13:32:21.011112: Epoch time: 399.5 s
2023-09-03 13:32:22.746620: Yayy! New best EMA pseudo Dice: 0.9068
2023-09-03 13:32:25.604606: 
2023-09-03 13:32:25.606432: Epoch 30
2023-09-03 13:32:25.607551: Current learning rate: backbone 0.00090953, others 0.00090953
2023-09-03 13:32:25.608864: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:33:39.932737: finished training epoch 30
2023-09-03 13:33:39.967543: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:33:39.969634: The split file contains 1 splits.
2023-09-03 13:33:39.970523: Desired fold for training: 0
2023-09-03 13:33:39.971276: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:39:21.228346: dsc: 91.08%
2023-09-03 13:39:21.230390: miou: 83.62%
2023-09-03 13:39:21.231530: acc: 95.52%, sen: 90.97%, spe: 97.05%
2023-09-03 13:39:21.233028: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:39:21.234091: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:39:21.235453: finished real validation
2023-09-03 13:39:26.221653: train_loss -1.412
2023-09-03 13:39:26.223008: val_loss -1.1403
2023-09-03 13:39:26.224084: Pseudo dice [0.9092]
2023-09-03 13:39:26.224994: Epoch time: 420.62 s
2023-09-03 13:39:26.225813: Yayy! New best EMA pseudo Dice: 0.9071
2023-09-03 13:39:29.053842: 
2023-09-03 13:39:29.055146: Epoch 31
2023-09-03 13:39:29.056104: Current learning rate: backbone 0.0009065, others 0.0009065
2023-09-03 13:39:29.057386: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:40:42.793160: finished training epoch 31
2023-09-03 13:40:42.830362: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:40:42.832097: The split file contains 1 splits.
2023-09-03 13:40:42.832999: Desired fold for training: 0
2023-09-03 13:40:42.833777: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:46:04.088244: dsc: 91.05%
2023-09-03 13:46:04.137687: miou: 83.57%
2023-09-03 13:46:04.139080: acc: 95.50%, sen: 90.89%, spe: 97.06%
2023-09-03 13:46:04.141432: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:46:04.142724: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:46:04.143967: finished real validation
2023-09-03 13:46:09.111152: train_loss -1.4139
2023-09-03 13:46:09.112695: val_loss -1.1536
2023-09-03 13:46:09.114475: Pseudo dice [0.9123]
2023-09-03 13:46:09.116047: Epoch time: 400.06 s
2023-09-03 13:46:09.117229: Yayy! New best EMA pseudo Dice: 0.9076
2023-09-03 13:46:11.964454: 
2023-09-03 13:46:11.965920: Epoch 32
2023-09-03 13:46:11.967293: Current learning rate: backbone 0.00090347, others 0.00090347
2023-09-03 13:46:11.969163: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:47:25.791837: finished training epoch 32
2023-09-03 13:47:25.827598: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:47:25.829262: The split file contains 1 splits.
2023-09-03 13:47:25.830098: Desired fold for training: 0
2023-09-03 13:47:25.830945: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:52:54.312751: dsc: 90.91%
2023-09-03 13:52:54.314046: miou: 83.34%
2023-09-03 13:52:54.314937: acc: 95.39%, sen: 91.65%, spe: 96.65%
2023-09-03 13:52:54.316068: current best miou: 0.8384393289210254 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:52:54.316911: current best dsc: 0.9121207490846086 at epoch: 3, (3, 0.8384393289210254, 0.9121207490846086)
2023-09-03 13:52:54.318027: finished real validation
2023-09-03 13:52:59.291299: train_loss -1.4145
2023-09-03 13:52:59.292671: val_loss -1.1542
2023-09-03 13:52:59.293842: Pseudo dice [0.9103]
2023-09-03 13:52:59.294755: Epoch time: 407.33 s
2023-09-03 13:52:59.295602: Yayy! New best EMA pseudo Dice: 0.9079
2023-09-03 13:53:02.116809: 
2023-09-03 13:53:02.118183: Epoch 33
2023-09-03 13:53:02.119134: Current learning rate: backbone 0.00090043, others 0.00090043
2023-09-03 13:53:02.120442: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 13:54:16.170069: finished training epoch 33
2023-09-03 13:54:16.199553: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 13:54:16.201239: The split file contains 1 splits.
2023-09-03 13:54:16.202151: Desired fold for training: 0
2023-09-03 13:54:16.202950: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 13:59:38.850671: dsc: 91.28%
2023-09-03 13:59:38.851927: miou: 83.96%
2023-09-03 13:59:38.852751: acc: 95.57%, sen: 92.12%, spe: 96.73%
2023-09-03 13:59:38.853854: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 13:59:38.854629: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 13:59:40.682650: finished real validation
2023-09-03 13:59:45.641492: train_loss -1.4156
2023-09-03 13:59:45.642761: val_loss -1.1673
2023-09-03 13:59:45.643869: Pseudo dice [0.9144]
2023-09-03 13:59:45.644924: Epoch time: 403.53 s
2023-09-03 13:59:45.645765: Yayy! New best EMA pseudo Dice: 0.9085
2023-09-03 13:59:48.613673: 
2023-09-03 13:59:48.615455: Epoch 34
2023-09-03 13:59:48.616736: Current learning rate: backbone 0.0008974, others 0.0008974
2023-09-03 13:59:48.618555: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:01:02.431310: finished training epoch 34
2023-09-03 14:01:02.463255: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:01:02.466491: The split file contains 1 splits.
2023-09-03 14:01:02.467753: Desired fold for training: 0
2023-09-03 14:01:02.468907: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:06:30.635592: dsc: 91.01%
2023-09-03 14:06:30.637107: miou: 83.50%
2023-09-03 14:06:30.638223: acc: 95.47%, sen: 91.19%, spe: 96.90%
2023-09-03 14:06:30.640138: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:06:30.641287: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:06:30.642389: finished real validation
2023-09-03 14:06:35.598269: train_loss -1.416
2023-09-03 14:06:35.599625: val_loss -1.1251
2023-09-03 14:06:35.600843: Pseudo dice [0.9078]
2023-09-03 14:06:35.601688: Epoch time: 406.99 s
2023-09-03 14:06:36.752174: 
2023-09-03 14:06:36.753563: Epoch 35
2023-09-03 14:06:36.754450: Current learning rate: backbone 0.00089436, others 0.00089436
2023-09-03 14:06:36.755800: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:07:50.544538: finished training epoch 35
2023-09-03 14:07:50.573750: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:07:50.575446: The split file contains 1 splits.
2023-09-03 14:07:50.576397: Desired fold for training: 0
2023-09-03 14:07:50.577165: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:13:13.028836: dsc: 90.95%
2023-09-03 14:13:13.030183: miou: 83.40%
2023-09-03 14:13:13.031077: acc: 95.41%, sen: 91.70%, spe: 96.65%
2023-09-03 14:13:13.032240: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:13:13.033040: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:13:13.033783: finished real validation
2023-09-03 14:13:18.005290: train_loss -1.4174
2023-09-03 14:13:18.006775: val_loss -1.1377
2023-09-03 14:13:18.008012: Pseudo dice [0.912]
2023-09-03 14:13:18.008966: Epoch time: 401.25 s
2023-09-03 14:13:18.009843: Yayy! New best EMA pseudo Dice: 0.9088
2023-09-03 14:13:21.058115: 
2023-09-03 14:13:21.059675: Epoch 36
2023-09-03 14:13:21.060644: Current learning rate: backbone 0.00089132, others 0.00089132
2023-09-03 14:13:21.062031: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:14:35.414012: finished training epoch 36
2023-09-03 14:14:35.443432: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:14:35.445781: The split file contains 1 splits.
2023-09-03 14:14:35.446916: Desired fold for training: 0
2023-09-03 14:14:35.447948: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:21:05.540260: dsc: 91.02%
2023-09-03 14:21:05.541829: miou: 83.52%
2023-09-03 14:21:05.542951: acc: 95.46%, sen: 91.50%, spe: 96.79%
2023-09-03 14:21:05.544786: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:21:05.545848: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:21:05.546857: finished real validation
2023-09-03 14:21:10.536597: train_loss -1.4183
2023-09-03 14:21:10.538476: val_loss -1.1537
2023-09-03 14:21:10.540266: Pseudo dice [0.9107]
2023-09-03 14:21:10.541610: Epoch time: 469.48 s
2023-09-03 14:21:10.542780: Yayy! New best EMA pseudo Dice: 0.909
2023-09-03 14:21:13.556815: 
2023-09-03 14:21:13.558534: Epoch 37
2023-09-03 14:21:13.559504: Current learning rate: backbone 0.00088828, others 0.00088828
2023-09-03 14:21:13.561800: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:22:28.085889: finished training epoch 37
2023-09-03 14:22:28.143249: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:22:28.148360: The split file contains 1 splits.
2023-09-03 14:22:28.149282: Desired fold for training: 0
2023-09-03 14:22:28.150108: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:27:54.209897: dsc: 91.12%
2023-09-03 14:27:54.212789: miou: 83.69%
2023-09-03 14:27:54.214785: acc: 95.54%, sen: 91.05%, spe: 97.04%
2023-09-03 14:27:54.217858: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:27:54.219548: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:27:54.221240: finished real validation
2023-09-03 14:27:59.189311: train_loss -1.4191
2023-09-03 14:27:59.191132: val_loss -1.1253
2023-09-03 14:27:59.193030: Pseudo dice [0.9099]
2023-09-03 14:27:59.194483: Epoch time: 405.63 s
2023-09-03 14:27:59.195673: Yayy! New best EMA pseudo Dice: 0.9091
2023-09-03 14:28:02.067342: 
2023-09-03 14:28:02.068895: Epoch 38
2023-09-03 14:28:02.069829: Current learning rate: backbone 0.00088524, others 0.00088524
2023-09-03 14:28:02.071351: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:29:16.766817: finished training epoch 38
2023-09-03 14:29:16.800325: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:29:16.803233: The split file contains 1 splits.
2023-09-03 14:29:16.804619: Desired fold for training: 0
2023-09-03 14:29:16.806193: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:35:01.960167: dsc: 91.02%
2023-09-03 14:35:01.961471: miou: 83.53%
2023-09-03 14:35:01.962386: acc: 95.47%, sen: 91.40%, spe: 96.84%
2023-09-03 14:35:01.963945: current best miou: 0.8395671572068677 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:35:01.964944: current best dsc: 0.912787721739538 at epoch: 33, (33, 0.8395671572068677, 0.912787721739538)
2023-09-03 14:35:01.966030: finished real validation
2023-09-03 14:35:07.003949: train_loss -1.42
2023-09-03 14:35:07.005455: val_loss -1.144
2023-09-03 14:35:07.006617: Pseudo dice [0.9112]
2023-09-03 14:35:07.007596: Epoch time: 424.94 s
2023-09-03 14:35:07.008521: Yayy! New best EMA pseudo Dice: 0.9093
2023-09-03 14:35:09.883223: 
2023-09-03 14:35:09.884530: Epoch 39
2023-09-03 14:35:09.885491: Current learning rate: backbone 0.0008822, others 0.0008822
2023-09-03 14:35:09.886810: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:36:23.972039: finished training epoch 39
2023-09-03 14:36:24.014034: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:36:24.016052: The split file contains 1 splits.
2023-09-03 14:36:24.016951: Desired fold for training: 0
2023-09-03 14:36:24.017790: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:42:05.334808: dsc: 91.34%
2023-09-03 14:42:05.336414: miou: 84.05%
2023-09-03 14:42:05.337301: acc: 95.62%, sen: 91.80%, spe: 96.90%
2023-09-03 14:42:05.338491: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:42:05.339356: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:42:07.187573: finished real validation
2023-09-03 14:42:12.152190: train_loss -1.4209
2023-09-03 14:42:12.153610: val_loss -1.1406
2023-09-03 14:42:12.154805: Pseudo dice [0.9122]
2023-09-03 14:42:12.155776: Epoch time: 422.27 s
2023-09-03 14:42:13.876264: Yayy! New best EMA pseudo Dice: 0.9096
2023-09-03 14:42:16.764596: 
2023-09-03 14:42:16.766017: Epoch 40
2023-09-03 14:42:16.767049: Current learning rate: backbone 0.00087916, others 0.00087916
2023-09-03 14:42:16.768381: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:43:30.507878: finished training epoch 40
2023-09-03 14:43:30.537947: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:43:30.539820: The split file contains 1 splits.
2023-09-03 14:43:30.540843: Desired fold for training: 0
2023-09-03 14:43:30.541586: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:48:56.161855: dsc: 91.06%
2023-09-03 14:48:56.163189: miou: 83.59%
2023-09-03 14:48:56.164093: acc: 95.50%, sen: 91.12%, spe: 96.97%
2023-09-03 14:48:56.165302: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:48:56.166126: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:48:56.166885: finished real validation
2023-09-03 14:49:01.143686: train_loss -1.4223
2023-09-03 14:49:01.145088: val_loss -1.1104
2023-09-03 14:49:01.146243: Pseudo dice [0.9085]
2023-09-03 14:49:01.147161: Epoch time: 404.38 s
2023-09-03 14:49:02.299599: 
2023-09-03 14:49:02.301151: Epoch 41
2023-09-03 14:49:02.302139: Current learning rate: backbone 0.00087611, others 0.00087611
2023-09-03 14:49:02.303562: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:50:16.296603: finished training epoch 41
2023-09-03 14:50:16.328137: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:50:16.330247: The split file contains 1 splits.
2023-09-03 14:50:16.331236: Desired fold for training: 0
2023-09-03 14:50:16.332097: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 14:55:39.525725: dsc: 91.05%
2023-09-03 14:55:39.527224: miou: 83.57%
2023-09-03 14:55:39.528076: acc: 95.45%, sen: 91.89%, spe: 96.65%
2023-09-03 14:55:39.529380: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:55:39.530198: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 14:55:39.530980: finished real validation
2023-09-03 14:55:44.498494: train_loss -1.4232
2023-09-03 14:55:44.500107: val_loss -1.1372
2023-09-03 14:55:44.501299: Pseudo dice [0.9136]
2023-09-03 14:55:44.502275: Epoch time: 402.2 s
2023-09-03 14:55:44.503163: Yayy! New best EMA pseudo Dice: 0.9099
2023-09-03 14:55:47.333570: 
2023-09-03 14:55:47.334903: Epoch 42
2023-09-03 14:55:47.335858: Current learning rate: backbone 0.00087307, others 0.00087307
2023-09-03 14:55:47.337250: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 14:57:01.071719: finished training epoch 42
2023-09-03 14:57:01.104164: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 14:57:01.106367: The split file contains 1 splits.
2023-09-03 14:57:01.107391: Desired fold for training: 0
2023-09-03 14:57:01.108313: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:02:39.248321: dsc: 91.25%
2023-09-03 15:02:39.250310: miou: 83.90%
2023-09-03 15:02:39.251160: acc: 95.55%, sen: 92.18%, spe: 96.68%
2023-09-03 15:02:39.252307: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:02:39.253515: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:02:39.254900: finished real validation
2023-09-03 15:02:44.237890: train_loss -1.4233
2023-09-03 15:02:44.240083: val_loss -1.1531
2023-09-03 15:02:44.242249: Pseudo dice [0.9148]
2023-09-03 15:02:44.243604: Epoch time: 416.91 s
2023-09-03 15:02:44.244720: Yayy! New best EMA pseudo Dice: 0.9104
2023-09-03 15:02:47.250657: 
2023-09-03 15:02:47.252160: Epoch 43
2023-09-03 15:02:47.254712: Current learning rate: backbone 0.00087002, others 0.00087002
2023-09-03 15:02:47.256434: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:04:01.402184: finished training epoch 43
2023-09-03 15:04:01.439863: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:04:01.441632: The split file contains 1 splits.
2023-09-03 15:04:01.442469: Desired fold for training: 0
2023-09-03 15:04:01.443249: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:09:26.296162: dsc: 91.09%
2023-09-03 15:09:26.297748: miou: 83.63%
2023-09-03 15:09:26.298618: acc: 95.50%, sen: 91.41%, spe: 96.87%
2023-09-03 15:09:26.299814: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:09:26.300659: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:09:26.301415: finished real validation
2023-09-03 15:09:31.318517: train_loss -1.4236
2023-09-03 15:09:31.319871: val_loss -1.1642
2023-09-03 15:09:31.321031: Pseudo dice [0.9164]
2023-09-03 15:09:31.322398: Epoch time: 404.07 s
2023-09-03 15:09:31.323244: Yayy! New best EMA pseudo Dice: 0.911
2023-09-03 15:09:34.496385: 
2023-09-03 15:09:34.498049: Epoch 44
2023-09-03 15:09:34.499256: Current learning rate: backbone 0.00086698, others 0.00086698
2023-09-03 15:09:34.500658: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:10:48.887091: finished training epoch 44
2023-09-03 15:10:48.933715: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:10:48.935447: The split file contains 1 splits.
2023-09-03 15:10:48.936410: Desired fold for training: 0
2023-09-03 15:10:48.937327: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:16:18.146331: dsc: 91.02%
2023-09-03 15:16:18.148107: miou: 83.52%
2023-09-03 15:16:18.150789: acc: 95.46%, sen: 91.48%, spe: 96.80%
2023-09-03 15:16:18.153806: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:16:18.155016: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:16:18.156106: finished real validation
2023-09-03 15:16:23.146199: train_loss -1.4249
2023-09-03 15:16:23.148069: val_loss -1.1337
2023-09-03 15:16:23.149339: Pseudo dice [0.9111]
2023-09-03 15:16:23.150714: Epoch time: 408.65 s
2023-09-03 15:16:23.151645: Yayy! New best EMA pseudo Dice: 0.911
2023-09-03 15:16:26.142601: 
2023-09-03 15:16:26.144425: Epoch 45
2023-09-03 15:16:26.145437: Current learning rate: backbone 0.00086393, others 0.00086393
2023-09-03 15:16:26.146743: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:17:40.387585: finished training epoch 45
2023-09-03 15:17:40.435823: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:17:40.437503: The split file contains 1 splits.
2023-09-03 15:17:40.438431: Desired fold for training: 0
2023-09-03 15:17:40.439320: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:23:09.905874: dsc: 90.81%
2023-09-03 15:23:09.907217: miou: 83.17%
2023-09-03 15:23:09.908205: acc: 95.39%, sen: 90.67%, spe: 96.97%
2023-09-03 15:23:09.909441: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:23:09.910349: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:23:09.911212: finished real validation
2023-09-03 15:23:14.897582: train_loss -1.4245
2023-09-03 15:23:14.898999: val_loss -1.1382
2023-09-03 15:23:14.900095: Pseudo dice [0.9111]
2023-09-03 15:23:14.901046: Epoch time: 408.76 s
2023-09-03 15:23:14.901893: Yayy! New best EMA pseudo Dice: 0.911
2023-09-03 15:23:17.797799: 
2023-09-03 15:23:17.799257: Epoch 46
2023-09-03 15:23:17.800657: Current learning rate: backbone 0.00086088, others 0.00086088
2023-09-03 15:23:17.802560: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:24:31.705199: finished training epoch 46
2023-09-03 15:24:31.733481: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:24:31.735163: The split file contains 1 splits.
2023-09-03 15:24:31.736080: Desired fold for training: 0
2023-09-03 15:24:31.736859: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:31:04.344640: dsc: 90.96%
2023-09-03 15:31:04.346126: miou: 83.42%
2023-09-03 15:31:04.346935: acc: 95.45%, sen: 91.03%, spe: 96.94%
2023-09-03 15:31:04.348064: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:31:04.349012: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:31:04.349816: finished real validation
2023-09-03 15:31:09.361550: train_loss -1.4246
2023-09-03 15:31:09.363178: val_loss -1.1235
2023-09-03 15:31:09.364496: Pseudo dice [0.9095]
2023-09-03 15:31:09.365574: Epoch time: 471.57 s
2023-09-03 15:31:10.486901: 
2023-09-03 15:31:10.488554: Epoch 47
2023-09-03 15:31:10.489690: Current learning rate: backbone 0.00085783, others 0.00085783
2023-09-03 15:31:10.491857: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:32:24.446532: finished training epoch 47
2023-09-03 15:32:24.476956: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:32:24.478951: The split file contains 1 splits.
2023-09-03 15:32:24.480221: Desired fold for training: 0
2023-09-03 15:32:24.481381: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:37:52.145756: dsc: 91.09%
2023-09-03 15:37:52.147310: miou: 83.63%
2023-09-03 15:37:52.148215: acc: 95.53%, sen: 90.82%, spe: 97.11%
2023-09-03 15:37:52.149406: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:37:52.150363: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:37:52.151252: finished real validation
2023-09-03 15:37:57.151559: train_loss -1.4257
2023-09-03 15:37:57.153304: val_loss -1.1439
2023-09-03 15:37:57.154605: Pseudo dice [0.9115]
2023-09-03 15:37:57.155636: Epoch time: 406.67 s
2023-09-03 15:37:58.300299: 
2023-09-03 15:37:58.301710: Epoch 48
2023-09-03 15:37:58.302696: Current learning rate: backbone 0.00085477, others 0.00085477
2023-09-03 15:37:58.304094: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:39:12.640287: finished training epoch 48
2023-09-03 15:39:12.674449: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:39:12.676537: The split file contains 1 splits.
2023-09-03 15:39:12.677517: Desired fold for training: 0
2023-09-03 15:39:12.678698: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:44:35.438090: dsc: 90.80%
2023-09-03 15:44:35.439912: miou: 83.15%
2023-09-03 15:44:35.440852: acc: 95.36%, sen: 90.95%, spe: 96.85%
2023-09-03 15:44:35.442227: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:44:35.443120: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:44:35.443937: finished real validation
2023-09-03 15:44:40.408718: train_loss -1.4256
2023-09-03 15:44:40.410219: val_loss -1.1257
2023-09-03 15:44:40.411437: Pseudo dice [0.91]
2023-09-03 15:44:40.412532: Epoch time: 402.11 s
2023-09-03 15:44:41.542427: 
2023-09-03 15:44:41.544050: Epoch 49
2023-09-03 15:44:41.545112: Current learning rate: backbone 0.00085172, others 0.00085172
2023-09-03 15:44:41.546659: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:45:55.681042: finished training epoch 49
2023-09-03 15:45:55.714827: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:45:55.717057: The split file contains 1 splits.
2023-09-03 15:45:55.718031: Desired fold for training: 0
2023-09-03 15:45:55.718867: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:51:36.925808: dsc: 91.03%
2023-09-03 15:51:36.927402: miou: 83.53%
2023-09-03 15:51:36.928335: acc: 95.43%, sen: 92.15%, spe: 96.53%
2023-09-03 15:51:36.929648: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:51:36.930560: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:51:36.931409: finished real validation
2023-09-03 15:51:41.889688: train_loss -1.4276
2023-09-03 15:51:41.891227: val_loss -1.1307
2023-09-03 15:51:41.892413: Pseudo dice [0.9108]
2023-09-03 15:51:41.893540: Epoch time: 420.35 s
2023-09-03 15:51:44.738001: 
2023-09-03 15:51:44.739294: Epoch 50
2023-09-03 15:51:44.740308: Current learning rate: backbone 0.00084867, others 0.00084867
2023-09-03 15:51:44.741853: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:52:58.590739: finished training epoch 50
2023-09-03 15:52:58.628233: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:52:58.629976: The split file contains 1 splits.
2023-09-03 15:52:58.631128: Desired fold for training: 0
2023-09-03 15:52:58.632204: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 15:58:27.598169: dsc: 91.25%
2023-09-03 15:58:27.599537: miou: 83.91%
2023-09-03 15:58:27.600459: acc: 95.56%, sen: 91.98%, spe: 96.77%
2023-09-03 15:58:27.601834: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:58:27.602814: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 15:58:27.603723: finished real validation
2023-09-03 15:58:32.563554: train_loss -1.4287
2023-09-03 15:58:32.565107: val_loss -1.133
2023-09-03 15:58:32.566269: Pseudo dice [0.9129]
2023-09-03 15:58:32.567271: Epoch time: 407.83 s
2023-09-03 15:58:32.568210: Yayy! New best EMA pseudo Dice: 0.911
2023-09-03 15:58:35.457792: 
2023-09-03 15:58:35.459167: Epoch 51
2023-09-03 15:58:35.460186: Current learning rate: backbone 0.00084561, others 0.00084561
2023-09-03 15:58:35.461594: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 15:59:49.408462: finished training epoch 51
2023-09-03 15:59:49.437880: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 15:59:49.439925: The split file contains 1 splits.
2023-09-03 15:59:49.440816: Desired fold for training: 0
2023-09-03 15:59:49.441623: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:06:05.456573: dsc: 91.25%
2023-09-03 16:06:05.458000: miou: 83.91%
2023-09-03 16:06:05.459014: acc: 95.59%, sen: 91.41%, spe: 97.00%
2023-09-03 16:06:05.460285: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:06:05.461241: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:06:05.462149: finished real validation
2023-09-03 16:06:10.432217: train_loss -1.4287
2023-09-03 16:06:10.433662: val_loss -1.1634
2023-09-03 16:06:10.434829: Pseudo dice [0.9177]
2023-09-03 16:06:10.435863: Epoch time: 454.98 s
2023-09-03 16:06:10.436826: Yayy! New best EMA pseudo Dice: 0.9117
2023-09-03 16:06:13.301597: 
2023-09-03 16:06:13.303082: Epoch 52
2023-09-03 16:06:13.304141: Current learning rate: backbone 0.00084255, others 0.00084255
2023-09-03 16:06:13.305563: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:07:27.400563: finished training epoch 52
2023-09-03 16:07:36.744752: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:07:36.746999: The split file contains 1 splits.
2023-09-03 16:07:36.748543: Desired fold for training: 0
2023-09-03 16:07:36.749770: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:13:03.167225: dsc: 91.03%
2023-09-03 16:13:11.598943: miou: 83.54%
2023-09-03 16:13:11.600332: acc: 95.48%, sen: 91.15%, spe: 96.94%
2023-09-03 16:13:11.603132: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:13:11.604469: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:13:11.605659: finished real validation
2023-09-03 16:13:16.564172: train_loss -1.4281
2023-09-03 16:13:16.565676: val_loss -1.1339
2023-09-03 16:13:16.566947: Pseudo dice [0.9139]
2023-09-03 16:13:16.568504: Epoch time: 423.26 s
2023-09-03 16:13:16.569804: Yayy! New best EMA pseudo Dice: 0.9119
2023-09-03 16:13:19.565544: 
2023-09-03 16:13:19.566853: Epoch 53
2023-09-03 16:13:19.567873: Current learning rate: backbone 0.0008395, others 0.0008395
2023-09-03 16:13:19.569295: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:14:33.423266: finished training epoch 53
2023-09-03 16:14:33.473454: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:14:33.476204: The split file contains 1 splits.
2023-09-03 16:14:33.477796: Desired fold for training: 0
2023-09-03 16:14:33.479088: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:20:02.906263: dsc: 91.12%
2023-09-03 16:20:02.907541: miou: 83.69%
2023-09-03 16:20:02.908502: acc: 95.52%, sen: 91.30%, spe: 96.94%
2023-09-03 16:20:02.909713: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:20:02.910742: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:20:02.911679: finished real validation
2023-09-03 16:20:07.882476: train_loss -1.4295
2023-09-03 16:20:07.884308: val_loss -1.153
2023-09-03 16:20:07.885776: Pseudo dice [0.9157]
2023-09-03 16:20:07.886807: Epoch time: 408.32 s
2023-09-03 16:20:07.887750: Yayy! New best EMA pseudo Dice: 0.9123
2023-09-03 16:20:10.833431: 
2023-09-03 16:20:10.834970: Epoch 54
2023-09-03 16:20:10.836052: Current learning rate: backbone 0.00083644, others 0.00083644
2023-09-03 16:20:10.837574: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:21:24.397236: finished training epoch 54
2023-09-03 16:21:24.446253: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:21:24.448257: The split file contains 1 splits.
2023-09-03 16:21:24.449253: Desired fold for training: 0
2023-09-03 16:21:24.450174: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:26:54.330677: dsc: 91.05%
2023-09-03 16:26:54.332210: miou: 83.57%
2023-09-03 16:26:54.333205: acc: 95.50%, sen: 90.91%, spe: 97.05%
2023-09-03 16:26:54.334519: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:26:54.335497: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:26:54.336444: finished real validation
2023-09-03 16:26:59.276941: train_loss -1.4306
2023-09-03 16:26:59.278449: val_loss -1.1357
2023-09-03 16:26:59.280401: Pseudo dice [0.912]
2023-09-03 16:26:59.281910: Epoch time: 408.44 s
2023-09-03 16:27:00.401942: 
2023-09-03 16:27:00.403448: Epoch 55
2023-09-03 16:27:00.404486: Current learning rate: backbone 0.00083337, others 0.00083337
2023-09-03 16:27:00.405866: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:28:14.122883: finished training epoch 55
2023-09-03 16:28:14.154290: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:28:14.156293: The split file contains 1 splits.
2023-09-03 16:28:14.157303: Desired fold for training: 0
2023-09-03 16:28:14.158230: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:33:57.062055: dsc: 91.06%
2023-09-03 16:33:57.063465: miou: 83.59%
2023-09-03 16:33:57.064379: acc: 95.50%, sen: 91.14%, spe: 96.97%
2023-09-03 16:33:57.065571: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:33:57.066491: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:33:57.067356: finished real validation
2023-09-03 16:34:02.030216: train_loss -1.4306
2023-09-03 16:34:02.031632: val_loss -1.1176
2023-09-03 16:34:02.032852: Pseudo dice [0.9099]
2023-09-03 16:34:02.033828: Epoch time: 421.63 s
2023-09-03 16:34:03.143517: 
2023-09-03 16:34:03.144934: Epoch 56
2023-09-03 16:34:03.146055: Current learning rate: backbone 0.00083031, others 0.00083031
2023-09-03 16:34:03.147473: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:35:17.524656: finished training epoch 56
2023-09-03 16:35:17.559848: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:35:17.561894: The split file contains 1 splits.
2023-09-03 16:35:17.563072: Desired fold for training: 0
2023-09-03 16:35:17.564101: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:41:02.744570: dsc: 90.88%
2023-09-03 16:41:02.745948: miou: 83.28%
2023-09-03 16:41:02.746819: acc: 95.40%, sen: 91.14%, spe: 96.83%
2023-09-03 16:41:02.748058: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:41:02.748984: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:41:02.749822: finished real validation
2023-09-03 16:41:07.708359: train_loss -1.4312
2023-09-03 16:41:07.709861: val_loss -1.1011
2023-09-03 16:41:07.711077: Pseudo dice [0.9075]
2023-09-03 16:41:07.712113: Epoch time: 424.57 s
2023-09-03 16:41:08.826198: 
2023-09-03 16:41:08.827595: Epoch 57
2023-09-03 16:41:08.828602: Current learning rate: backbone 0.00082725, others 0.00082725
2023-09-03 16:41:08.830049: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:42:22.989277: finished training epoch 57
2023-09-03 16:42:23.029442: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:42:23.031211: The split file contains 1 splits.
2023-09-03 16:42:23.032563: Desired fold for training: 0
2023-09-03 16:42:23.033524: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:49:01.189572: dsc: 90.93%
2023-09-03 16:49:01.191087: miou: 83.37%
2023-09-03 16:49:01.192137: acc: 95.42%, sen: 91.22%, spe: 96.84%
2023-09-03 16:49:01.193451: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:49:01.194452: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:49:01.195432: finished real validation
2023-09-03 16:49:06.205309: train_loss -1.4314
2023-09-03 16:49:06.207113: val_loss -1.096
2023-09-03 16:49:06.208497: Pseudo dice [0.9079]
2023-09-03 16:49:06.209539: Epoch time: 477.38 s
2023-09-03 16:49:07.375801: 
2023-09-03 16:49:07.377420: Epoch 58
2023-09-03 16:49:07.378492: Current learning rate: backbone 0.00082418, others 0.00082418
2023-09-03 16:49:07.380048: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:50:21.345807: finished training epoch 58
2023-09-03 16:50:21.377104: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:50:21.379014: The split file contains 1 splits.
2023-09-03 16:50:21.379996: Desired fold for training: 0
2023-09-03 16:50:21.380871: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 16:55:46.359949: dsc: 90.99%
2023-09-03 16:55:46.361391: miou: 83.47%
2023-09-03 16:55:46.362677: acc: 95.47%, sen: 90.96%, spe: 96.99%
2023-09-03 16:55:46.364667: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:55:46.366047: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 16:55:46.367173: finished real validation
2023-09-03 16:55:51.325934: train_loss -1.4312
2023-09-03 16:55:51.327987: val_loss -1.113
2023-09-03 16:55:51.330054: Pseudo dice [0.9116]
2023-09-03 16:55:51.331524: Epoch time: 403.95 s
2023-09-03 16:55:52.461203: 
2023-09-03 16:55:52.463153: Epoch 59
2023-09-03 16:55:52.464228: Current learning rate: backbone 0.00082112, others 0.00082112
2023-09-03 16:55:52.466031: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 16:57:06.827358: finished training epoch 59
2023-09-03 16:57:06.864779: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 16:57:06.867013: The split file contains 1 splits.
2023-09-03 16:57:06.868049: Desired fold for training: 0
2023-09-03 16:57:06.869018: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:02:27.833759: dsc: 91.13%
2023-09-03 17:02:27.835276: miou: 83.70%
2023-09-03 17:02:27.836290: acc: 95.53%, sen: 91.21%, spe: 96.99%
2023-09-03 17:02:27.837635: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:02:27.838764: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:02:27.839616: finished real validation
2023-09-03 17:02:32.802894: train_loss -1.4328
2023-09-03 17:02:32.804506: val_loss -1.1318
2023-09-03 17:02:32.805804: Pseudo dice [0.9142]
2023-09-03 17:02:32.806907: Epoch time: 400.34 s
2023-09-03 17:02:35.902177: 
2023-09-03 17:02:35.903563: Epoch 60
2023-09-03 17:02:35.904698: Current learning rate: backbone 0.00081805, others 0.00081805
2023-09-03 17:02:35.906123: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:03:49.589208: finished training epoch 60
2023-09-03 17:03:49.619843: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:03:49.621928: The split file contains 1 splits.
2023-09-03 17:03:49.623009: Desired fold for training: 0
2023-09-03 17:03:49.623952: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:09:12.885091: dsc: 91.05%
2023-09-03 17:09:12.887886: miou: 83.57%
2023-09-03 17:09:12.890698: acc: 95.45%, sen: 91.93%, spe: 96.64%
2023-09-03 17:09:12.893800: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:09:12.897319: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:09:12.898877: finished real validation
2023-09-03 17:09:17.874013: train_loss -1.4337
2023-09-03 17:09:17.875589: val_loss -1.1057
2023-09-03 17:09:17.876861: Pseudo dice [0.9082]
2023-09-03 17:09:17.877963: Epoch time: 401.97 s
2023-09-03 17:09:18.992694: 
2023-09-03 17:09:18.994251: Epoch 61
2023-09-03 17:09:18.995497: Current learning rate: backbone 0.00081498, others 0.00081498
2023-09-03 17:09:18.996880: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:10:32.664904: finished training epoch 61
2023-09-03 17:10:32.694303: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:10:32.696239: The split file contains 1 splits.
2023-09-03 17:10:32.697295: Desired fold for training: 0
2023-09-03 17:10:32.698193: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:15:59.473917: dsc: 91.14%
2023-09-03 17:15:59.475688: miou: 83.71%
2023-09-03 17:15:59.476972: acc: 95.54%, sen: 91.18%, spe: 97.00%
2023-09-03 17:15:59.479112: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:15:59.480446: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:15:59.481838: finished real validation
2023-09-03 17:16:04.463138: train_loss -1.433
2023-09-03 17:16:04.464628: val_loss -1.1052
2023-09-03 17:16:04.465910: Pseudo dice [0.9087]
2023-09-03 17:16:04.467239: Epoch time: 405.47 s
2023-09-03 17:16:05.822218: 
2023-09-03 17:16:05.823934: Epoch 62
2023-09-03 17:16:05.825063: Current learning rate: backbone 0.00081191, others 0.00081191
2023-09-03 17:16:05.826526: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:17:19.485810: finished training epoch 62
2023-09-03 17:17:19.537465: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:17:19.540050: The split file contains 1 splits.
2023-09-03 17:17:19.541263: Desired fold for training: 0
2023-09-03 17:17:19.542408: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:24:00.715348: dsc: 90.99%
2023-09-03 17:24:00.716758: miou: 83.47%
2023-09-03 17:24:00.717773: acc: 95.46%, sen: 91.15%, spe: 96.91%
2023-09-03 17:24:00.719061: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:24:00.720047: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:24:00.721030: finished real validation
2023-09-03 17:24:05.687562: train_loss -1.4338
2023-09-03 17:24:05.689053: val_loss -1.099
2023-09-03 17:24:05.690316: Pseudo dice [0.9098]
2023-09-03 17:24:05.691414: Epoch time: 479.87 s
2023-09-03 17:24:06.828283: 
2023-09-03 17:24:06.829819: Epoch 63
2023-09-03 17:24:06.830966: Current learning rate: backbone 0.00080884, others 0.00080884
2023-09-03 17:24:06.832453: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:25:20.684453: finished training epoch 63
2023-09-03 17:25:20.720823: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:25:20.723694: The split file contains 1 splits.
2023-09-03 17:25:20.725099: Desired fold for training: 0
2023-09-03 17:25:20.726389: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:31:10.811104: dsc: 91.05%
2023-09-03 17:31:10.812826: miou: 83.57%
2023-09-03 17:31:10.813909: acc: 95.50%, sen: 91.08%, spe: 96.98%
2023-09-03 17:31:10.815493: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:31:10.816544: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:31:10.817489: finished real validation
2023-09-03 17:31:15.778791: train_loss -1.4335
2023-09-03 17:31:15.780414: val_loss -1.1234
2023-09-03 17:31:15.781672: Pseudo dice [0.9124]
2023-09-03 17:31:15.782754: Epoch time: 428.95 s
2023-09-03 17:31:16.908409: 
2023-09-03 17:31:16.910246: Epoch 64
2023-09-03 17:31:16.911355: Current learning rate: backbone 0.00080577, others 0.00080577
2023-09-03 17:31:16.912959: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:32:30.632852: finished training epoch 64
2023-09-03 17:32:30.662918: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:32:30.665650: The split file contains 1 splits.
2023-09-03 17:32:30.667004: Desired fold for training: 0
2023-09-03 17:32:30.668183: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:37:58.338783: dsc: 91.02%
2023-09-03 17:37:58.340169: miou: 83.52%
2023-09-03 17:37:58.341086: acc: 95.48%, sen: 91.20%, spe: 96.91%
2023-09-03 17:37:58.342380: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:37:58.343282: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:37:58.344377: finished real validation
2023-09-03 17:38:03.319907: train_loss -1.4329
2023-09-03 17:38:03.322162: val_loss -1.0988
2023-09-03 17:38:03.324008: Pseudo dice [0.9069]
2023-09-03 17:38:03.325647: Epoch time: 406.41 s
2023-09-03 17:38:04.520134: 
2023-09-03 17:38:04.521727: Epoch 65
2023-09-03 17:38:04.522935: Current learning rate: backbone 0.0008027, others 0.0008027
2023-09-03 17:38:04.524927: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:39:18.626539: finished training epoch 65
2023-09-03 17:39:18.675954: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:39:18.677858: The split file contains 1 splits.
2023-09-03 17:39:18.679027: Desired fold for training: 0
2023-09-03 17:39:18.680044: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:44:43.838232: dsc: 91.13%
2023-09-03 17:44:43.839900: miou: 83.71%
2023-09-03 17:44:43.840950: acc: 95.52%, sen: 91.44%, spe: 96.90%
2023-09-03 17:44:43.842307: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:44:43.843407: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:44:43.844357: finished real validation
2023-09-03 17:44:48.809411: train_loss -1.4347
2023-09-03 17:44:48.811219: val_loss -1.105
2023-09-03 17:44:48.812619: Pseudo dice [0.9092]
2023-09-03 17:44:48.813733: Epoch time: 404.29 s
2023-09-03 17:44:49.929085: 
2023-09-03 17:44:49.930648: Epoch 66
2023-09-03 17:44:49.931679: Current learning rate: backbone 0.00079962, others 0.00079962
2023-09-03 17:44:49.933317: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:46:03.943856: finished training epoch 66
2023-09-03 17:46:03.997818: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:46:03.999692: The split file contains 1 splits.
2023-09-03 17:46:04.000754: Desired fold for training: 0
2023-09-03 17:46:04.001755: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:51:27.732694: dsc: 91.16%
2023-09-03 17:51:27.734228: miou: 83.75%
2023-09-03 17:51:27.735202: acc: 95.51%, sen: 91.94%, spe: 96.71%
2023-09-03 17:51:27.736464: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:51:27.737446: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:51:27.738393: finished real validation
2023-09-03 17:51:32.802589: train_loss -1.4343
2023-09-03 17:51:32.804341: val_loss -1.0949
2023-09-03 17:51:32.805762: Pseudo dice [0.9093]
2023-09-03 17:51:32.806994: Epoch time: 402.87 s
2023-09-03 17:51:33.987991: 
2023-09-03 17:51:33.989921: Epoch 67
2023-09-03 17:51:33.992376: Current learning rate: backbone 0.00079655, others 0.00079655
2023-09-03 17:51:33.993869: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 17:52:48.138334: finished training epoch 67
2023-09-03 17:52:48.183862: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 17:52:48.185856: The split file contains 1 splits.
2023-09-03 17:52:48.187000: Desired fold for training: 0
2023-09-03 17:52:48.188264: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 17:59:02.260162: dsc: 90.90%
2023-09-03 17:59:02.261728: miou: 83.31%
2023-09-03 17:59:02.262956: acc: 95.46%, sen: 90.03%, spe: 97.29%
2023-09-03 17:59:02.265233: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:59:02.266905: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 17:59:02.268286: finished real validation
2023-09-03 17:59:07.231303: train_loss -1.4359
2023-09-03 17:59:07.233267: val_loss -1.081
2023-09-03 17:59:07.235129: Pseudo dice [0.9069]
2023-09-03 17:59:07.236558: Epoch time: 453.24 s
2023-09-03 17:59:08.389723: 
2023-09-03 17:59:08.391328: Epoch 68
2023-09-03 17:59:08.392586: Current learning rate: backbone 0.00079347, others 0.00079347
2023-09-03 17:59:08.394132: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:00:22.366494: finished training epoch 68
2023-09-03 18:00:22.407403: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:00:22.415433: The split file contains 1 splits.
2023-09-03 18:00:22.416624: Desired fold for training: 0
2023-09-03 18:00:22.417613: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:06:57.636178: dsc: 91.13%
2023-09-03 18:06:57.638163: miou: 83.70%
2023-09-03 18:06:57.639394: acc: 95.51%, sen: 91.70%, spe: 96.79%
2023-09-03 18:06:57.641499: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:06:57.642735: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:06:57.643936: finished real validation
2023-09-03 18:07:02.625657: train_loss -1.4356
2023-09-03 18:07:02.627626: val_loss -1.0967
2023-09-03 18:07:02.629599: Pseudo dice [0.9087]
2023-09-03 18:07:02.631259: Epoch time: 474.24 s
2023-09-03 18:07:03.770576: 
2023-09-03 18:07:03.772175: Epoch 69
2023-09-03 18:07:03.773270: Current learning rate: backbone 0.00079039, others 0.00079039
2023-09-03 18:07:03.774710: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:08:17.643552: finished training epoch 69
2023-09-03 18:08:17.674569: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:08:17.676477: The split file contains 1 splits.
2023-09-03 18:08:17.677455: Desired fold for training: 0
2023-09-03 18:08:17.678385: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:14:39.729002: dsc: 91.04%
2023-09-03 18:14:39.730631: miou: 83.56%
2023-09-03 18:14:39.731670: acc: 95.49%, sen: 91.18%, spe: 96.94%
2023-09-03 18:14:39.732982: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:14:39.733998: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:14:39.734934: finished real validation
2023-09-03 18:14:44.750905: train_loss -1.4366
2023-09-03 18:14:44.752527: val_loss -1.086
2023-09-03 18:14:44.753927: Pseudo dice [0.9082]
2023-09-03 18:14:44.755087: Epoch time: 460.98 s
2023-09-03 18:14:47.662579: 
2023-09-03 18:14:47.664400: Epoch 70
2023-09-03 18:14:47.665576: Current learning rate: backbone 0.00078731, others 0.00078731
2023-09-03 18:14:47.667092: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:16:01.481337: finished training epoch 70
2023-09-03 18:16:01.542324: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:16:01.544486: The split file contains 1 splits.
2023-09-03 18:16:01.545529: Desired fold for training: 0
2023-09-03 18:16:01.546721: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:21:25.099761: dsc: 91.08%
2023-09-03 18:21:25.101308: miou: 83.62%
2023-09-03 18:21:25.102362: acc: 95.48%, sen: 91.71%, spe: 96.75%
2023-09-03 18:21:25.103732: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:21:25.104803: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:21:25.105795: finished real validation
2023-09-03 18:21:30.095590: train_loss -1.4358
2023-09-03 18:21:30.097125: val_loss -1.1067
2023-09-03 18:21:30.098463: Pseudo dice [0.9102]
2023-09-03 18:21:30.099581: Epoch time: 402.43 s
2023-09-03 18:21:31.243015: 
2023-09-03 18:21:31.244522: Epoch 71
2023-09-03 18:21:31.245604: Current learning rate: backbone 0.00078423, others 0.00078423
2023-09-03 18:21:31.247004: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:22:45.389510: finished training epoch 71
2023-09-03 18:22:45.421587: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:22:45.423688: The split file contains 1 splits.
2023-09-03 18:22:45.424674: Desired fold for training: 0
2023-09-03 18:22:45.425565: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:28:06.924001: dsc: 91.26%
2023-09-03 18:28:06.925583: miou: 83.93%
2023-09-03 18:28:06.926588: acc: 95.59%, sen: 91.67%, spe: 96.90%
2023-09-03 18:28:06.927858: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:28:06.928813: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:28:06.929746: finished real validation
2023-09-03 18:28:11.883516: train_loss -1.4363
2023-09-03 18:28:11.885245: val_loss -1.1206
2023-09-03 18:28:11.886587: Pseudo dice [0.9122]
2023-09-03 18:28:11.887728: Epoch time: 400.64 s
2023-09-03 18:28:13.006211: 
2023-09-03 18:28:13.007705: Epoch 72
2023-09-03 18:28:13.008860: Current learning rate: backbone 0.00078115, others 0.00078115
2023-09-03 18:28:13.010288: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:29:26.521951: finished training epoch 72
2023-09-03 18:29:26.566360: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:29:26.568459: The split file contains 1 splits.
2023-09-03 18:29:26.569561: Desired fold for training: 0
2023-09-03 18:29:26.570597: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:34:56.021456: dsc: 91.30%
2023-09-03 18:34:56.022954: miou: 84.00%
2023-09-03 18:34:56.023962: acc: 95.60%, sen: 91.81%, spe: 96.87%
2023-09-03 18:34:56.025288: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:34:56.026301: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:34:56.027237: finished real validation
2023-09-03 18:35:00.968103: train_loss -1.4369
2023-09-03 18:35:00.970400: val_loss -1.1184
2023-09-03 18:35:00.972300: Pseudo dice [0.9127]
2023-09-03 18:35:00.974074: Epoch time: 407.96 s
2023-09-03 18:35:02.146938: 
2023-09-03 18:35:02.148480: Epoch 73
2023-09-03 18:35:02.149690: Current learning rate: backbone 0.00077806, others 0.00077806
2023-09-03 18:35:02.151209: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:36:15.563376: finished training epoch 73
2023-09-03 18:36:15.603187: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:36:15.605316: The split file contains 1 splits.
2023-09-03 18:36:15.606270: Desired fold for training: 0
2023-09-03 18:36:15.607331: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:41:48.108494: dsc: 91.00%
2023-09-03 18:41:48.110214: miou: 83.48%
2023-09-03 18:41:48.111231: acc: 95.45%, sen: 91.37%, spe: 96.82%
2023-09-03 18:41:48.112586: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:41:48.113616: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:41:48.114597: finished real validation
2023-09-03 18:41:53.052661: train_loss -1.4377
2023-09-03 18:41:53.054200: val_loss -1.1131
2023-09-03 18:41:53.055725: Pseudo dice [0.9104]
2023-09-03 18:41:53.056868: Epoch time: 410.91 s
2023-09-03 18:41:54.184430: 
2023-09-03 18:41:54.186061: Epoch 74
2023-09-03 18:41:54.187282: Current learning rate: backbone 0.00077498, others 0.00077498
2023-09-03 18:41:54.188784: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:43:07.700777: finished training epoch 74
2023-09-03 18:43:07.730524: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:43:07.733283: The split file contains 1 splits.
2023-09-03 18:43:07.734595: Desired fold for training: 0
2023-09-03 18:43:07.735827: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:48:34.097236: dsc: 90.97%
2023-09-03 18:48:34.098797: miou: 83.43%
2023-09-03 18:48:34.099932: acc: 95.45%, sen: 91.11%, spe: 96.91%
2023-09-03 18:48:34.101555: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:48:34.102708: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:48:34.103767: finished real validation
2023-09-03 18:48:39.051660: train_loss -1.4382
2023-09-03 18:48:39.052983: val_loss -1.1166
2023-09-03 18:48:39.054825: Pseudo dice [0.9104]
2023-09-03 18:48:39.055957: Epoch time: 404.87 s
2023-09-03 18:48:40.200393: 
2023-09-03 18:48:40.202010: Epoch 75
2023-09-03 18:48:40.203190: Current learning rate: backbone 0.00077189, others 0.00077189
2023-09-03 18:48:40.204801: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:49:53.665729: finished training epoch 75
2023-09-03 18:49:53.706319: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:49:53.708756: The split file contains 1 splits.
2023-09-03 18:49:53.709982: Desired fold for training: 0
2023-09-03 18:49:53.711112: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 18:55:23.732231: dsc: 91.09%
2023-09-03 18:55:23.733598: miou: 83.64%
2023-09-03 18:55:23.734640: acc: 95.49%, sen: 91.75%, spe: 96.74%
2023-09-03 18:55:23.736833: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:55:23.738150: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 18:55:23.739395: finished real validation
2023-09-03 18:55:28.687770: train_loss -1.4384
2023-09-03 18:55:28.689253: val_loss -1.1037
2023-09-03 18:55:28.690441: Pseudo dice [0.9112]
2023-09-03 18:55:28.691477: Epoch time: 408.49 s
2023-09-03 18:55:29.824639: 
2023-09-03 18:55:29.826282: Epoch 76
2023-09-03 18:55:29.827395: Current learning rate: backbone 0.0007688, others 0.0007688
2023-09-03 18:55:29.828868: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 18:56:43.480150: finished training epoch 76
2023-09-03 18:56:43.511192: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 18:56:43.513262: The split file contains 1 splits.
2023-09-03 18:56:43.514248: Desired fold for training: 0
2023-09-03 18:56:43.515159: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:02:25.838513: dsc: 91.08%
2023-09-03 19:02:25.840453: miou: 83.63%
2023-09-03 19:02:25.841583: acc: 95.49%, sen: 91.64%, spe: 96.78%
2023-09-03 19:02:25.843132: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:02:25.844151: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:02:25.845171: finished real validation
2023-09-03 19:02:30.893482: train_loss -1.4388
2023-09-03 19:02:30.895360: val_loss -1.1233
2023-09-03 19:02:30.897008: Pseudo dice [0.915]
2023-09-03 19:02:30.898318: Epoch time: 421.07 s
2023-09-03 19:02:32.102628: 
2023-09-03 19:02:32.104259: Epoch 77
2023-09-03 19:02:32.105356: Current learning rate: backbone 0.00076571, others 0.00076571
2023-09-03 19:02:32.106974: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:03:46.117808: finished training epoch 77
2023-09-03 19:03:46.147199: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:03:46.150476: The split file contains 1 splits.
2023-09-03 19:03:46.162641: Desired fold for training: 0
2023-09-03 19:03:46.165505: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:09:18.608935: dsc: 90.95%
2023-09-03 19:09:18.610808: miou: 83.40%
2023-09-03 19:09:18.611937: acc: 95.43%, sen: 91.38%, spe: 96.79%
2023-09-03 19:09:18.613420: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:09:18.614519: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:09:18.615541: finished real validation
2023-09-03 19:09:23.696291: train_loss -1.4386
2023-09-03 19:09:23.698068: val_loss -1.104
2023-09-03 19:09:23.699464: Pseudo dice [0.9119]
2023-09-03 19:09:23.700701: Epoch time: 411.6 s
2023-09-03 19:09:25.098890: 
2023-09-03 19:09:25.100724: Epoch 78
2023-09-03 19:09:25.101891: Current learning rate: backbone 0.00076262, others 0.00076262
2023-09-03 19:09:25.103548: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:10:39.318733: finished training epoch 78
2023-09-03 19:10:39.352843: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:10:39.354833: The split file contains 1 splits.
2023-09-03 19:10:39.355940: Desired fold for training: 0
2023-09-03 19:10:39.356961: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:17:15.178555: dsc: 91.09%
2023-09-03 19:17:15.180121: miou: 83.63%
2023-09-03 19:17:15.181148: acc: 95.50%, sen: 91.43%, spe: 96.87%
2023-09-03 19:17:15.182623: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:17:15.183637: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:17:15.184646: finished real validation
2023-09-03 19:17:20.150367: train_loss -1.4389
2023-09-03 19:17:20.152115: val_loss -1.1072
2023-09-03 19:17:20.153825: Pseudo dice [0.9108]
2023-09-03 19:17:20.155628: Epoch time: 475.05 s
2023-09-03 19:17:21.328133: 
2023-09-03 19:17:21.329879: Epoch 79
2023-09-03 19:17:21.331071: Current learning rate: backbone 0.00075953, others 0.00075953
2023-09-03 19:17:21.332810: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:18:35.907726: finished training epoch 79
2023-09-03 19:18:35.937351: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:18:35.939823: The split file contains 1 splits.
2023-09-03 19:18:35.940912: Desired fold for training: 0
2023-09-03 19:18:35.941878: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:24:48.069481: dsc: 91.04%
2023-09-03 19:24:48.071166: miou: 83.55%
2023-09-03 19:24:48.072263: acc: 95.49%, sen: 91.07%, spe: 96.98%
2023-09-03 19:24:48.073892: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:24:48.074923: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:24:48.075923: finished real validation
2023-09-03 19:24:53.083411: train_loss -1.4394
2023-09-03 19:24:53.086157: val_loss -1.0929
2023-09-03 19:24:53.087599: Pseudo dice [0.9104]
2023-09-03 19:24:53.088704: Epoch time: 451.76 s
2023-09-03 19:24:56.357882: 
2023-09-03 19:24:56.360004: Epoch 80
2023-09-03 19:24:56.361310: Current learning rate: backbone 0.00075643, others 0.00075643
2023-09-03 19:24:56.363442: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:26:11.092749: finished training epoch 80
2023-09-03 19:26:11.129202: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:26:11.131630: The split file contains 1 splits.
2023-09-03 19:26:11.132980: Desired fold for training: 0
2023-09-03 19:26:11.134140: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:31:53.725256: dsc: 91.14%
2023-09-03 19:31:53.726844: miou: 83.72%
2023-09-03 19:31:53.727959: acc: 95.54%, sen: 91.14%, spe: 97.02%
2023-09-03 19:31:53.729357: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:31:53.730439: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:31:53.731467: finished real validation
2023-09-03 19:31:58.699988: train_loss -1.4388
2023-09-03 19:31:58.701726: val_loss -1.086
2023-09-03 19:31:58.703149: Pseudo dice [0.9079]
2023-09-03 19:31:58.704342: Epoch time: 422.34 s
2023-09-03 19:31:59.863289: 
2023-09-03 19:31:59.864847: Epoch 81
2023-09-03 19:31:59.866042: Current learning rate: backbone 0.00075334, others 0.00075334
2023-09-03 19:31:59.867666: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:33:14.270256: finished training epoch 81
2023-09-03 19:33:14.302348: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:33:14.304410: The split file contains 1 splits.
2023-09-03 19:33:14.305462: Desired fold for training: 0
2023-09-03 19:33:14.306427: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:38:35.386552: dsc: 91.02%
2023-09-03 19:38:35.388215: miou: 83.52%
2023-09-03 19:38:35.389235: acc: 95.49%, sen: 90.98%, spe: 97.00%
2023-09-03 19:38:35.390569: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:38:35.391627: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:38:35.392579: finished real validation
2023-09-03 19:38:40.343904: train_loss -1.4393
2023-09-03 19:38:40.346174: val_loss -1.1161
2023-09-03 19:38:40.347665: Pseudo dice [0.9123]
2023-09-03 19:38:40.349004: Epoch time: 400.48 s
2023-09-03 19:38:41.508906: 
2023-09-03 19:38:41.510664: Epoch 82
2023-09-03 19:38:41.511857: Current learning rate: backbone 0.00075024, others 0.00075024
2023-09-03 19:38:41.513402: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:39:55.153118: finished training epoch 82
2023-09-03 19:39:55.187421: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:39:55.190787: The split file contains 1 splits.
2023-09-03 19:39:55.192173: Desired fold for training: 0
2023-09-03 19:39:55.193520: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:45:24.294905: dsc: 90.88%
2023-09-03 19:45:24.296483: miou: 83.29%
2023-09-03 19:45:24.297537: acc: 95.42%, sen: 90.82%, spe: 96.96%
2023-09-03 19:45:24.298893: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:45:24.299958: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:45:24.300954: finished real validation
2023-09-03 19:45:29.263125: train_loss -1.4395
2023-09-03 19:45:29.264738: val_loss -1.0917
2023-09-03 19:45:29.266302: Pseudo dice [0.908]
2023-09-03 19:45:29.267584: Epoch time: 407.76 s
2023-09-03 19:45:30.351606: 
2023-09-03 19:45:30.353384: Epoch 83
2023-09-03 19:45:30.354813: Current learning rate: backbone 0.00074714, others 0.00074714
2023-09-03 19:45:30.356434: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:46:43.780579: finished training epoch 83
2023-09-03 19:46:43.809967: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:46:43.812022: The split file contains 1 splits.
2023-09-03 19:46:43.813180: Desired fold for training: 0
2023-09-03 19:46:43.814268: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:52:08.470449: dsc: 91.03%
2023-09-03 19:52:08.472821: miou: 83.54%
2023-09-03 19:52:08.474311: acc: 95.48%, sen: 91.22%, spe: 96.91%
2023-09-03 19:52:08.477312: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:52:08.478893: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:52:08.480204: finished real validation
2023-09-03 19:52:13.445758: train_loss -1.4403
2023-09-03 19:52:13.447734: val_loss -1.0815
2023-09-03 19:52:13.449643: Pseudo dice [0.909]
2023-09-03 19:52:13.451124: Epoch time: 403.1 s
2023-09-03 19:52:14.552308: 
2023-09-03 19:52:14.554057: Epoch 84
2023-09-03 19:52:14.555213: Current learning rate: backbone 0.00074405, others 0.00074405
2023-09-03 19:52:14.556849: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 19:53:28.028386: finished training epoch 84
2023-09-03 19:53:28.067401: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 19:53:28.069539: The split file contains 1 splits.
2023-09-03 19:53:28.070685: Desired fold for training: 0
2023-09-03 19:53:28.071822: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 19:58:53.300056: dsc: 91.25%
2023-09-03 19:58:53.301710: miou: 83.91%
2023-09-03 19:58:53.302949: acc: 95.59%, sen: 91.49%, spe: 96.96%
2023-09-03 19:58:53.304583: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:58:53.305682: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 19:58:53.306778: finished real validation
2023-09-03 19:58:58.274701: train_loss -1.4408
2023-09-03 19:58:58.276139: val_loss -1.1105
2023-09-03 19:58:58.277559: Pseudo dice [0.9127]
2023-09-03 19:58:58.278720: Epoch time: 403.72 s
2023-09-03 19:58:59.378057: 
2023-09-03 19:58:59.379782: Epoch 85
2023-09-03 19:58:59.380999: Current learning rate: backbone 0.00074094, others 0.00074094
2023-09-03 19:58:59.382567: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:00:12.957323: finished training epoch 85
2023-09-03 20:00:12.986033: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:00:12.987837: The split file contains 1 splits.
2023-09-03 20:00:12.988940: Desired fold for training: 0
2023-09-03 20:00:12.989949: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:05:44.505891: dsc: 90.95%
2023-09-03 20:05:44.507380: miou: 83.40%
2023-09-03 20:05:44.508466: acc: 95.42%, sen: 91.41%, spe: 96.77%
2023-09-03 20:05:44.509935: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:05:44.510978: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:05:44.511962: finished real validation
2023-09-03 20:05:49.481129: train_loss -1.4409
2023-09-03 20:05:49.482888: val_loss -1.0914
2023-09-03 20:05:49.484261: Pseudo dice [0.9108]
2023-09-03 20:05:49.485449: Epoch time: 410.1 s
2023-09-03 20:05:50.589611: 
2023-09-03 20:05:50.591281: Epoch 86
2023-09-03 20:05:50.592540: Current learning rate: backbone 0.00073784, others 0.00073784
2023-09-03 20:05:50.594061: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:07:04.594580: finished training epoch 86
2023-09-03 20:07:04.644052: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:07:04.645897: The split file contains 1 splits.
2023-09-03 20:07:04.647041: Desired fold for training: 0
2023-09-03 20:07:04.648130: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:12:43.248511: dsc: 91.08%
2023-09-03 20:12:43.250390: miou: 83.62%
2023-09-03 20:12:43.251537: acc: 95.51%, sen: 91.09%, spe: 97.00%
2023-09-03 20:12:43.252995: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:12:43.254122: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:12:43.255234: finished real validation
2023-09-03 20:12:48.227042: train_loss -1.4417
2023-09-03 20:12:48.228842: val_loss -1.1002
2023-09-03 20:12:48.230287: Pseudo dice [0.9116]
2023-09-03 20:12:48.231487: Epoch time: 417.64 s
2023-09-03 20:12:49.323960: 
2023-09-03 20:12:49.325540: Epoch 87
2023-09-03 20:12:49.326761: Current learning rate: backbone 0.00073474, others 0.00073474
2023-09-03 20:12:49.328328: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:14:03.762392: finished training epoch 87
2023-09-03 20:14:03.800561: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:14:03.802858: The split file contains 1 splits.
2023-09-03 20:14:03.804123: Desired fold for training: 0
2023-09-03 20:14:03.805345: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:19:31.857347: dsc: 91.19%
2023-09-03 20:19:31.858911: miou: 83.81%
2023-09-03 20:19:31.860069: acc: 95.56%, sen: 91.43%, spe: 96.95%
2023-09-03 20:19:31.861868: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:19:31.863081: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:19:31.864130: finished real validation
2023-09-03 20:19:36.816308: train_loss -1.4419
2023-09-03 20:19:36.818012: val_loss -1.1209
2023-09-03 20:19:36.819419: Pseudo dice [0.9149]
2023-09-03 20:19:36.820614: Epoch time: 407.49 s
2023-09-03 20:19:37.918895: 
2023-09-03 20:19:37.920466: Epoch 88
2023-09-03 20:19:37.921994: Current learning rate: backbone 0.00073163, others 0.00073163
2023-09-03 20:19:37.923569: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:20:51.751337: finished training epoch 88
2023-09-03 20:20:51.781909: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:20:51.784256: The split file contains 1 splits.
2023-09-03 20:20:51.785444: Desired fold for training: 0
2023-09-03 20:20:51.786547: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:26:24.367875: dsc: 91.02%
2023-09-03 20:26:24.369494: miou: 83.53%
2023-09-03 20:26:24.370655: acc: 95.48%, sen: 91.14%, spe: 96.94%
2023-09-03 20:26:24.372079: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:26:24.373477: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:26:24.374714: finished real validation
2023-09-03 20:26:29.308995: train_loss -1.4411
2023-09-03 20:26:29.310836: val_loss -1.1064
2023-09-03 20:26:29.312302: Pseudo dice [0.9126]
2023-09-03 20:26:29.313568: Epoch time: 411.39 s
2023-09-03 20:26:30.444369: 
2023-09-03 20:26:30.446051: Epoch 89
2023-09-03 20:26:30.447398: Current learning rate: backbone 0.00072853, others 0.00072853
2023-09-03 20:26:30.449388: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:27:43.867968: finished training epoch 89
2023-09-03 20:27:43.908690: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:27:43.910899: The split file contains 1 splits.
2023-09-03 20:27:43.912083: Desired fold for training: 0
2023-09-03 20:27:43.913162: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:33:07.861249: dsc: 91.12%
2023-09-03 20:33:07.862979: miou: 83.69%
2023-09-03 20:33:07.864259: acc: 95.54%, sen: 90.90%, spe: 97.11%
2023-09-03 20:33:07.865822: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:33:07.867052: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:33:07.868207: finished real validation
2023-09-03 20:33:12.816112: train_loss -1.4416
2023-09-03 20:33:12.817828: val_loss -1.1029
2023-09-03 20:33:12.819224: Pseudo dice [0.9126]
2023-09-03 20:33:12.820437: Epoch time: 402.37 s
2023-09-03 20:33:15.712982: 
2023-09-03 20:33:15.714651: Epoch 90
2023-09-03 20:33:15.716267: Current learning rate: backbone 0.00072542, others 0.00072542
2023-09-03 20:33:15.717920: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:34:29.925434: finished training epoch 90
2023-09-03 20:34:29.960733: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:34:29.963323: The split file contains 1 splits.
2023-09-03 20:34:29.964885: Desired fold for training: 0
2023-09-03 20:34:29.966214: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:39:57.168819: dsc: 91.23%
2023-09-03 20:39:57.170268: miou: 83.88%
2023-09-03 20:39:57.171391: acc: 95.57%, sen: 91.59%, spe: 96.91%
2023-09-03 20:39:57.172798: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:39:57.173954: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:39:57.175401: finished real validation
2023-09-03 20:40:02.104866: train_loss -1.4417
2023-09-03 20:40:02.106586: val_loss -1.0922
2023-09-03 20:40:02.108007: Pseudo dice [0.9114]
2023-09-03 20:40:02.109203: Epoch time: 406.39 s
2023-09-03 20:40:03.287851: 
2023-09-03 20:40:03.289294: Epoch 91
2023-09-03 20:40:03.290460: Current learning rate: backbone 0.00072231, others 0.00072231
2023-09-03 20:40:03.292024: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:41:17.018567: finished training epoch 91
2023-09-03 20:41:17.054119: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:41:17.056996: The split file contains 1 splits.
2023-09-03 20:41:17.058352: Desired fold for training: 0
2023-09-03 20:41:17.059720: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:46:52.497581: dsc: 91.18%
2023-09-03 20:46:52.499133: miou: 83.79%
2023-09-03 20:46:52.500334: acc: 95.54%, sen: 91.65%, spe: 96.85%
2023-09-03 20:46:52.501920: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:46:52.503156: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:46:52.504346: finished real validation
2023-09-03 20:46:57.486128: train_loss -1.4419
2023-09-03 20:46:57.487766: val_loss -1.1064
2023-09-03 20:46:57.489265: Pseudo dice [0.9126]
2023-09-03 20:46:57.490546: Epoch time: 414.2 s
2023-09-03 20:46:58.576552: 
2023-09-03 20:46:58.577988: Epoch 92
2023-09-03 20:46:58.579430: Current learning rate: backbone 0.0007192, others 0.0007192
2023-09-03 20:46:58.581234: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:48:12.384694: finished training epoch 92
2023-09-03 20:48:12.422047: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:48:12.424073: The split file contains 1 splits.
2023-09-03 20:48:12.425249: Desired fold for training: 0
2023-09-03 20:48:12.426411: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 20:53:43.831893: dsc: 91.10%
2023-09-03 20:53:43.833799: miou: 83.65%
2023-09-03 20:53:43.835259: acc: 95.52%, sen: 91.15%, spe: 96.99%
2023-09-03 20:53:43.837601: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:53:43.839403: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 20:53:43.840716: finished real validation
2023-09-03 20:53:48.828063: train_loss -1.4425
2023-09-03 20:53:48.829937: val_loss -1.0863
2023-09-03 20:53:48.831789: Pseudo dice [0.9098]
2023-09-03 20:53:48.833279: Epoch time: 410.25 s
2023-09-03 20:53:49.948601: 
2023-09-03 20:53:49.950512: Epoch 93
2023-09-03 20:53:49.951768: Current learning rate: backbone 0.00071608, others 0.00071608
2023-09-03 20:53:49.953354: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 20:55:03.799117: finished training epoch 93
2023-09-03 20:55:03.840821: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 20:55:03.844414: The split file contains 1 splits.
2023-09-03 20:55:03.845660: Desired fold for training: 0
2023-09-03 20:55:03.846831: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:00:34.612162: dsc: 91.14%
2023-09-03 21:00:34.614164: miou: 83.72%
2023-09-03 21:00:34.615863: acc: 95.53%, sen: 91.34%, spe: 96.94%
2023-09-03 21:00:34.618759: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:00:34.620011: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:00:34.621152: finished real validation
2023-09-03 21:00:39.573442: train_loss -1.4423
2023-09-03 21:00:39.575232: val_loss -1.0892
2023-09-03 21:00:39.576734: Pseudo dice [0.9107]
2023-09-03 21:00:39.578044: Epoch time: 409.63 s
2023-09-03 21:00:40.673904: 
2023-09-03 21:00:40.675467: Epoch 94
2023-09-03 21:00:40.676868: Current learning rate: backbone 0.00071297, others 0.00071297
2023-09-03 21:00:40.678482: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:01:54.411029: finished training epoch 94
2023-09-03 21:01:54.455738: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:01:54.457957: The split file contains 1 splits.
2023-09-03 21:01:54.459151: Desired fold for training: 0
2023-09-03 21:01:54.460306: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:08:02.676113: dsc: 91.13%
2023-09-03 21:08:02.677993: miou: 83.70%
2023-09-03 21:08:02.679179: acc: 95.51%, sen: 91.59%, spe: 96.83%
2023-09-03 21:08:02.680863: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:08:02.682041: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:08:02.683126: finished real validation
2023-09-03 21:08:07.639177: train_loss -1.4428
2023-09-03 21:08:07.640839: val_loss -1.0902
2023-09-03 21:08:07.642273: Pseudo dice [0.9084]
2023-09-03 21:08:07.643476: Epoch time: 446.97 s
2023-09-03 21:08:08.767273: 
2023-09-03 21:08:08.769005: Epoch 95
2023-09-03 21:08:08.770209: Current learning rate: backbone 0.00070985, others 0.00070985
2023-09-03 21:08:08.771814: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:09:22.606281: finished training epoch 95
2023-09-03 21:09:22.646421: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:09:22.648496: The split file contains 1 splits.
2023-09-03 21:09:22.649721: Desired fold for training: 0
2023-09-03 21:09:22.650899: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:14:46.424540: dsc: 91.13%
2023-09-03 21:14:46.426269: miou: 83.70%
2023-09-03 21:14:46.427379: acc: 95.52%, sen: 91.36%, spe: 96.92%
2023-09-03 21:14:46.428847: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:14:46.429984: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:14:46.431124: finished real validation
2023-09-03 21:14:51.402215: train_loss -1.4434
2023-09-03 21:14:51.403960: val_loss -1.0813
2023-09-03 21:14:51.405431: Pseudo dice [0.9097]
2023-09-03 21:14:51.406693: Epoch time: 402.64 s
2023-09-03 21:14:52.512789: 
2023-09-03 21:14:52.514351: Epoch 96
2023-09-03 21:14:52.515705: Current learning rate: backbone 0.00070674, others 0.00070674
2023-09-03 21:14:52.517470: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:16:06.062860: finished training epoch 96
2023-09-03 21:16:06.104622: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:16:06.107824: The split file contains 1 splits.
2023-09-03 21:16:06.109416: Desired fold for training: 0
2023-09-03 21:16:06.110924: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:21:33.108008: dsc: 91.02%
2023-09-03 21:21:33.109927: miou: 83.53%
2023-09-03 21:21:33.111046: acc: 95.48%, sen: 91.07%, spe: 96.96%
2023-09-03 21:21:33.112475: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:21:33.113686: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:21:33.114951: finished real validation
2023-09-03 21:21:38.065038: train_loss -1.443
2023-09-03 21:21:38.066872: val_loss -1.0993
2023-09-03 21:21:38.068509: Pseudo dice [0.9133]
2023-09-03 21:21:38.069771: Epoch time: 405.55 s
2023-09-03 21:21:39.178602: 
2023-09-03 21:21:39.180455: Epoch 97
2023-09-03 21:21:39.181786: Current learning rate: backbone 0.00070362, others 0.00070362
2023-09-03 21:21:39.183403: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:22:53.393993: finished training epoch 97
2023-09-03 21:22:53.424941: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:22:53.427167: The split file contains 1 splits.
2023-09-03 21:22:53.428324: Desired fold for training: 0
2023-09-03 21:22:53.429364: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:28:20.465488: dsc: 91.20%
2023-09-03 21:28:20.467242: miou: 83.82%
2023-09-03 21:28:20.468459: acc: 95.57%, sen: 91.36%, spe: 96.98%
2023-09-03 21:28:20.469988: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:28:20.471320: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:28:20.472490: finished real validation
2023-09-03 21:28:25.463975: train_loss -1.4438
2023-09-03 21:28:25.465949: val_loss -1.0771
2023-09-03 21:28:25.467525: Pseudo dice [0.9084]
2023-09-03 21:28:25.468771: Epoch time: 406.29 s
2023-09-03 21:28:26.576721: 
2023-09-03 21:28:26.578390: Epoch 98
2023-09-03 21:28:26.579727: Current learning rate: backbone 0.0007005, others 0.0007005
2023-09-03 21:28:26.581469: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:29:40.366614: finished training epoch 98
2023-09-03 21:29:40.404140: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:29:40.406199: The split file contains 1 splits.
2023-09-03 21:29:40.407387: Desired fold for training: 0
2023-09-03 21:29:40.408472: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:35:04.417846: dsc: 91.18%
2023-09-03 21:35:04.447950: miou: 83.80%
2023-09-03 21:35:04.449516: acc: 95.51%, sen: 92.35%, spe: 96.57%
2023-09-03 21:35:04.452044: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:35:04.453529: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:35:04.454929: finished real validation
2023-09-03 21:35:09.485667: train_loss -1.4439
2023-09-03 21:35:09.487474: val_loss -1.1009
2023-09-03 21:35:09.488916: Pseudo dice [0.9124]
2023-09-03 21:35:09.490167: Epoch time: 402.91 s
2023-09-03 21:35:10.676658: 
2023-09-03 21:35:10.678550: Epoch 99
2023-09-03 21:35:10.679871: Current learning rate: backbone 0.00069738, others 0.00069738
2023-09-03 21:35:10.681522: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:36:25.173339: finished training epoch 99
2023-09-03 21:36:25.203330: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:36:25.205534: The split file contains 1 splits.
2023-09-03 21:36:25.206675: Desired fold for training: 0
2023-09-03 21:36:25.207809: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:41:53.954775: dsc: 91.16%
2023-09-03 21:41:53.956466: miou: 83.75%
2023-09-03 21:41:53.957824: acc: 95.52%, sen: 91.71%, spe: 96.80%
2023-09-03 21:41:53.959408: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:41:53.961429: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:41:53.962982: finished real validation
2023-09-03 21:41:58.981963: train_loss -1.4446
2023-09-03 21:41:58.983842: val_loss -1.0864
2023-09-03 21:41:58.985555: Pseudo dice [0.9101]
2023-09-03 21:41:58.986895: Epoch time: 408.31 s
2023-09-03 21:42:01.940852: 
2023-09-03 21:42:01.942590: Epoch 100
2023-09-03 21:42:01.943872: Current learning rate: backbone 0.00069425, others 0.00069425
2023-09-03 21:42:01.945563: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:43:15.476305: finished training epoch 100
2023-09-03 21:43:15.554621: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:43:15.556922: The split file contains 1 splits.
2023-09-03 21:43:15.558131: Desired fold for training: 0
2023-09-03 21:43:15.559264: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:48:54.892044: dsc: 91.21%
2023-09-03 21:48:54.893623: miou: 83.83%
2023-09-03 21:48:54.894818: acc: 95.56%, sen: 91.63%, spe: 96.88%
2023-09-03 21:48:54.896336: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:48:54.897509: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:48:54.898627: finished real validation
2023-09-03 21:48:59.849915: train_loss -1.4444
2023-09-03 21:48:59.851770: val_loss -1.1316
2023-09-03 21:48:59.853413: Pseudo dice [0.916]
2023-09-03 21:48:59.854620: Epoch time: 417.91 s
2023-09-03 21:49:00.969312: 
2023-09-03 21:49:00.970904: Epoch 101
2023-09-03 21:49:00.972275: Current learning rate: backbone 0.00069113, others 0.00069113
2023-09-03 21:49:00.974518: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:50:14.845489: finished training epoch 101
2023-09-03 21:50:14.877991: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:50:14.880771: The split file contains 1 splits.
2023-09-03 21:50:14.882192: Desired fold for training: 0
2023-09-03 21:50:14.883589: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 21:55:42.795537: dsc: 91.04%
2023-09-03 21:55:42.797337: miou: 83.55%
2023-09-03 21:55:42.798433: acc: 95.48%, sen: 91.32%, spe: 96.87%
2023-09-03 21:55:42.799830: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:55:42.800967: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 21:55:42.802036: finished real validation
2023-09-03 21:55:47.782543: train_loss -1.4442
2023-09-03 21:55:47.784539: val_loss -1.1211
2023-09-03 21:55:47.786229: Pseudo dice [0.9153]
2023-09-03 21:55:47.787651: Epoch time: 406.81 s
2023-09-03 21:55:48.931950: 
2023-09-03 21:55:48.934053: Epoch 102
2023-09-03 21:55:48.935430: Current learning rate: backbone 0.000688, others 0.000688
2023-09-03 21:55:48.937287: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 21:57:03.453341: finished training epoch 102
2023-09-03 21:57:03.484087: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 21:57:03.486313: The split file contains 1 splits.
2023-09-03 21:57:03.487500: Desired fold for training: 0
2023-09-03 21:57:03.488575: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:03:09.827396: dsc: 91.16%
2023-09-03 22:03:09.858922: miou: 83.75%
2023-09-03 22:03:09.862014: acc: 95.53%, sen: 91.63%, spe: 96.84%
2023-09-03 22:03:09.864263: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:03:09.866106: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:03:09.867951: finished real validation
2023-09-03 22:03:14.932824: train_loss -1.4451
2023-09-03 22:03:14.934913: val_loss -1.0901
2023-09-03 22:03:14.936679: Pseudo dice [0.912]
2023-09-03 22:03:14.938149: Epoch time: 446.0 s
2023-09-03 22:03:16.078621: 
2023-09-03 22:03:16.080674: Epoch 103
2023-09-03 22:03:16.082126: Current learning rate: backbone 0.00068487, others 0.00068487
2023-09-03 22:03:16.084060: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:04:30.373523: finished training epoch 103
2023-09-03 22:04:30.415210: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:04:30.417480: The split file contains 1 splits.
2023-09-03 22:04:30.419073: Desired fold for training: 0
2023-09-03 22:04:30.420602: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:10:11.380994: dsc: 91.18%
2023-09-03 22:10:11.383157: miou: 83.80%
2023-09-03 22:10:11.384418: acc: 95.57%, sen: 91.13%, spe: 97.06%
2023-09-03 22:10:11.386014: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:10:11.387482: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:10:11.388650: finished real validation
2023-09-03 22:10:16.336153: train_loss -1.4447
2023-09-03 22:10:16.337958: val_loss -1.0745
2023-09-03 22:10:16.339528: Pseudo dice [0.9106]
2023-09-03 22:10:16.341013: Epoch time: 420.26 s
2023-09-03 22:10:17.459280: 
2023-09-03 22:10:17.461222: Epoch 104
2023-09-03 22:10:17.462819: Current learning rate: backbone 0.00068174, others 0.00068174
2023-09-03 22:10:17.464562: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:11:30.898782: finished training epoch 104
2023-09-03 22:11:30.939901: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:11:30.942304: The split file contains 1 splits.
2023-09-03 22:11:30.943622: Desired fold for training: 0
2023-09-03 22:11:30.944784: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:17:13.851955: dsc: 91.22%
2023-09-03 22:17:13.853877: miou: 83.85%
2023-09-03 22:17:13.855061: acc: 95.57%, sen: 91.48%, spe: 96.94%
2023-09-03 22:17:13.856705: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:17:13.857888: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:17:13.858994: finished real validation
2023-09-03 22:17:18.815871: train_loss -1.4451
2023-09-03 22:17:18.817576: val_loss -1.1006
2023-09-03 22:17:18.819078: Pseudo dice [0.9135]
2023-09-03 22:17:18.820303: Epoch time: 421.36 s
2023-09-03 22:17:19.930398: 
2023-09-03 22:17:19.932116: Epoch 105
2023-09-03 22:17:19.933423: Current learning rate: backbone 0.00067861, others 0.00067861
2023-09-03 22:17:19.935046: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:18:33.645113: finished training epoch 105
2023-09-03 22:18:33.683653: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:18:33.685613: The split file contains 1 splits.
2023-09-03 22:18:33.686887: Desired fold for training: 0
2023-09-03 22:18:33.688915: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:24:06.043752: dsc: 91.13%
2023-09-03 22:24:06.045590: miou: 83.70%
2023-09-03 22:24:06.046851: acc: 95.54%, sen: 91.01%, spe: 97.07%
2023-09-03 22:24:06.048537: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:24:06.049780: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:24:06.050893: finished real validation
2023-09-03 22:24:11.016584: train_loss -1.4451
2023-09-03 22:24:11.018353: val_loss -1.0911
2023-09-03 22:24:11.019899: Pseudo dice [0.9095]
2023-09-03 22:24:11.021200: Epoch time: 411.09 s
2023-09-03 22:24:12.127815: 
2023-09-03 22:24:12.129547: Epoch 106
2023-09-03 22:24:12.130844: Current learning rate: backbone 0.00067548, others 0.00067548
2023-09-03 22:24:12.132551: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:25:25.487768: finished training epoch 106
2023-09-03 22:25:25.525253: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:25:25.527534: The split file contains 1 splits.
2023-09-03 22:25:25.528960: Desired fold for training: 0
2023-09-03 22:25:25.530340: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:31:13.005315: dsc: 91.22%
2023-09-03 22:31:13.006961: miou: 83.85%
2023-09-03 22:31:13.008139: acc: 95.58%, sen: 91.27%, spe: 97.03%
2023-09-03 22:31:13.009697: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:31:13.010887: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:31:13.011997: finished real validation
2023-09-03 22:31:17.973082: train_loss -1.4451
2023-09-03 22:31:17.974786: val_loss -1.0891
2023-09-03 22:31:17.976376: Pseudo dice [0.9108]
2023-09-03 22:31:17.977916: Epoch time: 425.85 s
2023-09-03 22:31:19.097277: 
2023-09-03 22:31:19.098917: Epoch 107
2023-09-03 22:31:19.100193: Current learning rate: backbone 0.00067235, others 0.00067235
2023-09-03 22:31:19.101782: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:32:32.630700: finished training epoch 107
2023-09-03 22:32:32.694132: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:32:32.699553: The split file contains 1 splits.
2023-09-03 22:32:32.701167: Desired fold for training: 0
2023-09-03 22:32:32.702798: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:37:56.535691: dsc: 91.17%
2023-09-03 22:37:56.537427: miou: 83.78%
2023-09-03 22:37:56.538879: acc: 95.54%, sen: 91.58%, spe: 96.87%
2023-09-03 22:37:56.541104: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:37:56.542569: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:37:56.544020: finished real validation
2023-09-03 22:38:01.571163: train_loss -1.4455
2023-09-03 22:38:01.572946: val_loss -1.0875
2023-09-03 22:38:01.574613: Pseudo dice [0.9129]
2023-09-03 22:38:01.576190: Epoch time: 402.48 s
2023-09-03 22:38:02.791740: 
2023-09-03 22:38:02.793451: Epoch 108
2023-09-03 22:38:02.794853: Current learning rate: backbone 0.00066921, others 0.00066921
2023-09-03 22:38:02.796688: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:39:16.970884: finished training epoch 108
2023-09-03 22:39:17.011091: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:39:17.013337: The split file contains 1 splits.
2023-09-03 22:39:17.014684: Desired fold for training: 0
2023-09-03 22:39:17.015876: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:45:31.352056: dsc: 91.27%
2023-09-03 22:45:31.353691: miou: 83.94%
2023-09-03 22:45:31.354834: acc: 95.59%, sen: 91.71%, spe: 96.89%
2023-09-03 22:45:31.356281: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:45:31.357510: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:45:31.358601: finished real validation
2023-09-03 22:45:36.323798: train_loss -1.4458
2023-09-03 22:45:36.325404: val_loss -1.0939
2023-09-03 22:45:36.327582: Pseudo dice [0.9125]
2023-09-03 22:45:36.329345: Epoch time: 453.53 s
2023-09-03 22:45:37.444411: 
2023-09-03 22:45:37.446021: Epoch 109
2023-09-03 22:45:37.447331: Current learning rate: backbone 0.00066607, others 0.00066607
2023-09-03 22:45:37.448961: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:46:51.389611: finished training epoch 109
2023-09-03 22:46:51.431206: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:46:51.433169: The split file contains 1 splits.
2023-09-03 22:46:51.434449: Desired fold for training: 0
2023-09-03 22:46:51.435823: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:52:23.384098: dsc: 91.10%
2023-09-03 22:52:23.385789: miou: 83.65%
2023-09-03 22:52:23.387080: acc: 95.48%, sen: 91.92%, spe: 96.68%
2023-09-03 22:52:23.388799: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:52:23.390003: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:52:23.391341: finished real validation
2023-09-03 22:52:28.352645: train_loss -1.4451
2023-09-03 22:52:28.354616: val_loss -1.1013
2023-09-03 22:52:28.359083: Pseudo dice [0.9125]
2023-09-03 22:52:28.360641: Epoch time: 410.91 s
2023-09-03 22:52:31.324298: 
2023-09-03 22:52:31.326104: Epoch 110
2023-09-03 22:52:31.328901: Current learning rate: backbone 0.00066293, others 0.00066293
2023-09-03 22:52:31.330674: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 22:53:44.986136: finished training epoch 110
2023-09-03 22:53:45.014951: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 22:53:45.017288: The split file contains 1 splits.
2023-09-03 22:53:45.018632: Desired fold for training: 0
2023-09-03 22:53:45.019772: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 22:59:39.984982: dsc: 91.14%
2023-09-03 22:59:39.986835: miou: 83.72%
2023-09-03 22:59:39.988069: acc: 95.55%, sen: 91.09%, spe: 97.04%
2023-09-03 22:59:39.989691: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:59:39.990935: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 22:59:39.992112: finished real validation
2023-09-03 22:59:44.985815: train_loss -1.4456
2023-09-03 22:59:44.987808: val_loss -1.1022
2023-09-03 22:59:44.989520: Pseudo dice [0.9122]
2023-09-03 22:59:44.990881: Epoch time: 433.66 s
2023-09-03 22:59:46.126288: 
2023-09-03 22:59:46.127902: Epoch 111
2023-09-03 22:59:46.129192: Current learning rate: backbone 0.00065979, others 0.00065979
2023-09-03 22:59:46.130904: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:00:59.915675: finished training epoch 111
2023-09-03 23:00:59.958105: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:00:59.961138: The split file contains 1 splits.
2023-09-03 23:00:59.962596: Desired fold for training: 0
2023-09-03 23:00:59.963912: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:06:33.447527: dsc: 91.04%
2023-09-03 23:06:33.449450: miou: 83.56%
2023-09-03 23:06:33.451138: acc: 95.50%, sen: 91.04%, spe: 96.99%
2023-09-03 23:06:33.454124: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:06:33.455702: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:06:33.457411: finished real validation
2023-09-03 23:06:38.422198: train_loss -1.4456
2023-09-03 23:06:38.424133: val_loss -1.09
2023-09-03 23:06:38.425753: Pseudo dice [0.9113]
2023-09-03 23:06:38.427118: Epoch time: 412.3 s
2023-09-03 23:06:39.554901: 
2023-09-03 23:06:39.557052: Epoch 112
2023-09-03 23:06:39.558418: Current learning rate: backbone 0.00065665, others 0.00065665
2023-09-03 23:06:39.560382: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:07:53.293813: finished training epoch 112
2023-09-03 23:07:53.353336: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:07:53.355510: The split file contains 1 splits.
2023-09-03 23:07:53.356756: Desired fold for training: 0
2023-09-03 23:07:53.357976: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:14:23.193211: dsc: 91.18%
2023-09-03 23:14:23.195007: miou: 83.79%
2023-09-03 23:14:23.196232: acc: 95.53%, sen: 91.88%, spe: 96.75%
2023-09-03 23:14:23.197795: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:14:23.199107: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:14:23.200276: finished real validation
2023-09-03 23:14:28.206513: train_loss -1.4461
2023-09-03 23:14:28.208786: val_loss -1.0742
2023-09-03 23:14:28.211036: Pseudo dice [0.9095]
2023-09-03 23:14:28.212863: Epoch time: 468.65 s
2023-09-03 23:14:29.347494: 
2023-09-03 23:14:29.349493: Epoch 113
2023-09-03 23:14:29.350879: Current learning rate: backbone 0.0006535, others 0.0006535
2023-09-03 23:14:29.352811: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:15:42.975424: finished training epoch 113
2023-09-03 23:15:43.011042: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:15:43.024719: The split file contains 1 splits.
2023-09-03 23:15:43.026109: Desired fold for training: 0
2023-09-03 23:15:43.027339: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:21:12.827651: dsc: 91.19%
2023-09-03 23:21:12.829674: miou: 83.81%
2023-09-03 23:21:12.831160: acc: 95.55%, sen: 91.55%, spe: 96.90%
2023-09-03 23:21:12.833528: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:21:12.835098: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:21:12.836554: finished real validation
2023-09-03 23:21:17.798484: train_loss -1.4463
2023-09-03 23:21:17.800616: val_loss -1.0939
2023-09-03 23:21:17.802430: Pseudo dice [0.9143]
2023-09-03 23:21:17.803825: Epoch time: 408.45 s
2023-09-03 23:21:18.952693: 
2023-09-03 23:21:18.954472: Epoch 114
2023-09-03 23:21:18.955755: Current learning rate: backbone 0.00065036, others 0.00065036
2023-09-03 23:21:18.957495: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:22:33.299724: finished training epoch 114
2023-09-03 23:22:33.330960: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:22:33.333309: The split file contains 1 splits.
2023-09-03 23:22:33.334631: Desired fold for training: 0
2023-09-03 23:22:33.335878: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:28:03.804486: dsc: 91.20%
2023-09-03 23:28:03.806170: miou: 83.82%
2023-09-03 23:28:03.807411: acc: 95.57%, sen: 91.23%, spe: 97.03%
2023-09-03 23:28:03.808946: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:28:03.810307: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:28:03.811570: finished real validation
2023-09-03 23:28:08.776631: train_loss -1.4461
2023-09-03 23:28:08.778409: val_loss -1.1106
2023-09-03 23:28:08.779930: Pseudo dice [0.9145]
2023-09-03 23:28:08.781250: Epoch time: 409.83 s
2023-09-03 23:28:09.894831: 
2023-09-03 23:28:09.896552: Epoch 115
2023-09-03 23:28:09.897977: Current learning rate: backbone 0.00064721, others 0.00064721
2023-09-03 23:28:09.900398: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:29:23.909628: finished training epoch 115
2023-09-03 23:29:23.952132: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:29:23.955668: The split file contains 1 splits.
2023-09-03 23:29:23.957496: Desired fold for training: 0
2023-09-03 23:29:23.959194: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:34:48.263870: dsc: 91.24%
2023-09-03 23:34:48.265609: miou: 83.90%
2023-09-03 23:34:48.266995: acc: 95.56%, sen: 91.87%, spe: 96.81%
2023-09-03 23:34:48.268641: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:34:48.269890: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:34:48.271049: finished real validation
2023-09-03 23:34:53.225569: train_loss -1.4466
2023-09-03 23:34:53.227155: val_loss -1.0814
2023-09-03 23:34:53.228590: Pseudo dice [0.9116]
2023-09-03 23:34:53.229810: Epoch time: 403.33 s
2023-09-03 23:34:54.371632: 
2023-09-03 23:34:54.373537: Epoch 116
2023-09-03 23:34:54.374899: Current learning rate: backbone 0.00064406, others 0.00064406
2023-09-03 23:34:54.376644: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:36:07.953046: finished training epoch 116
2023-09-03 23:36:07.990745: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:36:07.993009: The split file contains 1 splits.
2023-09-03 23:36:07.994171: Desired fold for training: 0
2023-09-03 23:36:07.995281: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:41:35.680016: dsc: 91.11%
2023-09-03 23:41:35.683896: miou: 83.67%
2023-09-03 23:41:35.685781: acc: 95.53%, sen: 91.07%, spe: 97.03%
2023-09-03 23:41:35.688780: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:41:35.690406: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:41:35.691898: finished real validation
2023-09-03 23:41:40.748127: train_loss -1.4463
2023-09-03 23:41:40.751941: val_loss -1.0836
2023-09-03 23:41:40.755686: Pseudo dice [0.9111]
2023-09-03 23:41:40.761191: Epoch time: 406.38 s
2023-09-03 23:41:41.890949: 
2023-09-03 23:41:41.894608: Epoch 117
2023-09-03 23:41:41.896337: Current learning rate: backbone 0.00064091, others 0.00064091
2023-09-03 23:41:41.899268: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:42:55.832773: finished training epoch 117
2023-09-03 23:42:55.872061: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:42:55.874126: The split file contains 1 splits.
2023-09-03 23:42:55.875377: Desired fold for training: 0
2023-09-03 23:42:55.876537: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:48:22.020900: dsc: 91.27%
2023-09-03 23:48:22.022558: miou: 83.94%
2023-09-03 23:48:22.023808: acc: 95.61%, sen: 91.26%, spe: 97.07%
2023-09-03 23:48:22.025428: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:48:22.026670: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:48:22.027843: finished real validation
2023-09-03 23:48:26.981754: train_loss -1.4471
2023-09-03 23:48:26.983803: val_loss -1.0646
2023-09-03 23:48:26.985636: Pseudo dice [0.9081]
2023-09-03 23:48:26.987083: Epoch time: 405.09 s
2023-09-03 23:48:28.124301: 
2023-09-03 23:48:28.126644: Epoch 118
2023-09-03 23:48:28.128425: Current learning rate: backbone 0.00063776, others 0.00063776
2023-09-03 23:48:28.130232: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:49:41.696676: finished training epoch 118
2023-09-03 23:49:41.726857: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:49:41.729418: The split file contains 1 splits.
2023-09-03 23:49:41.730696: Desired fold for training: 0
2023-09-03 23:49:41.732046: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-03 23:55:11.309652: dsc: 91.19%
2023-09-03 23:55:11.311442: miou: 83.80%
2023-09-03 23:55:11.312773: acc: 95.56%, sen: 91.29%, spe: 97.00%
2023-09-03 23:55:11.314392: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:55:11.316153: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-03 23:55:11.317348: finished real validation
2023-09-03 23:55:16.287506: train_loss -1.4471
2023-09-03 23:55:16.289929: val_loss -1.0851
2023-09-03 23:55:16.292307: Pseudo dice [0.9121]
2023-09-03 23:55:16.294397: Epoch time: 408.16 s
2023-09-03 23:55:17.440313: 
2023-09-03 23:55:17.442205: Epoch 119
2023-09-03 23:55:17.443599: Current learning rate: backbone 0.0006346, others 0.0006346
2023-09-03 23:55:17.445307: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-03 23:56:31.037819: finished training epoch 119
2023-09-03 23:56:31.094707: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-03 23:56:31.096972: The split file contains 1 splits.
2023-09-03 23:56:31.098973: Desired fold for training: 0
2023-09-03 23:56:31.100491: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:02:01.526049: dsc: 91.16%
2023-09-04 00:02:01.528129: miou: 83.76%
2023-09-04 00:02:01.529762: acc: 95.55%, sen: 91.25%, spe: 96.99%
2023-09-04 00:02:01.532357: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:02:01.533966: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:02:01.535407: finished real validation
2023-09-04 00:02:06.494005: train_loss -1.4468
2023-09-04 00:02:06.495890: val_loss -1.0784
2023-09-04 00:02:06.497541: Pseudo dice [0.9101]
2023-09-04 00:02:06.499011: Epoch time: 409.06 s
2023-09-04 00:02:09.417195: 
2023-09-04 00:02:09.418876: Epoch 120
2023-09-04 00:02:09.423910: Current learning rate: backbone 0.00063145, others 0.00063145
2023-09-04 00:02:09.425642: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:03:23.035135: finished training epoch 120
2023-09-04 00:03:23.144239: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:03:23.147757: The split file contains 1 splits.
2023-09-04 00:03:23.149634: Desired fold for training: 0
2023-09-04 00:03:23.150994: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:09:01.473860: dsc: 91.19%
2023-09-04 00:09:01.475684: miou: 83.81%
2023-09-04 00:09:01.476989: acc: 95.54%, sen: 91.70%, spe: 96.83%
2023-09-04 00:09:01.478550: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:09:01.479775: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:09:01.480962: finished real validation
2023-09-04 00:09:06.453559: train_loss -1.448
2023-09-04 00:09:06.456332: val_loss -1.0746
2023-09-04 00:09:06.458442: Pseudo dice [0.9097]
2023-09-04 00:09:06.459928: Epoch time: 417.04 s
2023-09-04 00:09:07.620155: 
2023-09-04 00:09:07.622114: Epoch 121
2023-09-04 00:09:07.623613: Current learning rate: backbone 0.00062829, others 0.00062829
2023-09-04 00:09:07.625506: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:10:21.702289: finished training epoch 121
2023-09-04 00:10:21.749753: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:10:21.752001: The split file contains 1 splits.
2023-09-04 00:10:21.753287: Desired fold for training: 0
2023-09-04 00:10:21.754546: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:16:05.075176: dsc: 91.26%
2023-09-04 00:16:05.077190: miou: 83.92%
2023-09-04 00:16:05.078571: acc: 95.60%, sen: 91.33%, spe: 97.03%
2023-09-04 00:16:05.080206: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:16:05.081579: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:16:05.082829: finished real validation
2023-09-04 00:16:10.074363: train_loss -1.447
2023-09-04 00:16:10.076325: val_loss -1.0804
2023-09-04 00:16:10.078060: Pseudo dice [0.9113]
2023-09-04 00:16:10.079413: Epoch time: 422.46 s
2023-09-04 00:16:11.253171: 
2023-09-04 00:16:11.255196: Epoch 122
2023-09-04 00:16:11.256728: Current learning rate: backbone 0.00062513, others 0.00062513
2023-09-04 00:16:11.259082: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:17:25.929364: finished training epoch 122
2023-09-04 00:17:25.973020: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:17:25.975338: The split file contains 1 splits.
2023-09-04 00:17:25.976667: Desired fold for training: 0
2023-09-04 00:17:25.977930: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:22:49.876014: dsc: 91.25%
2023-09-04 00:22:49.878005: miou: 83.92%
2023-09-04 00:22:49.879627: acc: 95.58%, sen: 91.69%, spe: 96.89%
2023-09-04 00:22:49.882199: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:22:49.883923: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:22:49.885336: finished real validation
2023-09-04 00:22:54.912076: train_loss -1.4474
2023-09-04 00:22:54.914944: val_loss -1.0531
2023-09-04 00:22:54.917448: Pseudo dice [0.9097]
2023-09-04 00:22:54.919318: Epoch time: 403.66 s
2023-09-04 00:22:56.092238: 
2023-09-04 00:22:56.094181: Epoch 123
2023-09-04 00:22:56.095648: Current learning rate: backbone 0.00062197, others 0.00062197
2023-09-04 00:22:56.097707: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:24:09.616332: finished training epoch 123
2023-09-04 00:24:09.657890: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:24:09.660184: The split file contains 1 splits.
2023-09-04 00:24:09.661545: Desired fold for training: 0
2023-09-04 00:24:09.662792: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:29:44.972665: dsc: 91.14%
2023-09-04 00:29:44.974746: miou: 83.73%
2023-09-04 00:29:44.976155: acc: 95.52%, sen: 91.76%, spe: 96.78%
2023-09-04 00:29:44.977757: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:29:44.979286: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:29:44.980498: finished real validation
2023-09-04 00:29:49.933468: train_loss -1.4473
2023-09-04 00:29:49.935305: val_loss -1.063
2023-09-04 00:29:49.936868: Pseudo dice [0.9077]
2023-09-04 00:29:49.938644: Epoch time: 413.84 s
2023-09-04 00:29:51.076323: 
2023-09-04 00:29:51.078202: Epoch 124
2023-09-04 00:29:51.079684: Current learning rate: backbone 0.0006188, others 0.0006188
2023-09-04 00:29:51.081464: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:31:04.706999: finished training epoch 124
2023-09-04 00:31:04.737128: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:31:04.739640: The split file contains 1 splits.
2023-09-04 00:31:04.740967: Desired fold for training: 0
2023-09-04 00:31:04.742508: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:36:39.544128: dsc: 91.17%
2023-09-04 00:36:39.545964: miou: 83.77%
2023-09-04 00:36:39.547360: acc: 95.56%, sen: 91.18%, spe: 97.03%
2023-09-04 00:36:39.549123: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:36:39.550594: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:36:39.551913: finished real validation
2023-09-04 00:36:44.499129: train_loss -1.4479
2023-09-04 00:36:44.501023: val_loss -1.0502
2023-09-04 00:36:44.502571: Pseudo dice [0.9079]
2023-09-04 00:36:44.503982: Epoch time: 413.42 s
2023-09-04 00:36:45.641536: 
2023-09-04 00:36:45.643240: Epoch 125
2023-09-04 00:36:45.644540: Current learning rate: backbone 0.00061564, others 0.00061564
2023-09-04 00:36:45.646239: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:37:59.642675: finished training epoch 125
2023-09-04 00:37:59.679832: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:37:59.681971: The split file contains 1 splits.
2023-09-04 00:37:59.683916: Desired fold for training: 0
2023-09-04 00:37:59.685889: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:43:32.463228: dsc: 91.17%
2023-09-04 00:43:32.465069: miou: 83.77%
2023-09-04 00:43:32.466476: acc: 95.53%, sen: 91.73%, spe: 96.81%
2023-09-04 00:43:32.468315: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:43:32.469857: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:43:32.471176: finished real validation
2023-09-04 00:43:37.434711: train_loss -1.4478
2023-09-04 00:43:37.436566: val_loss -1.0733
2023-09-04 00:43:37.438119: Pseudo dice [0.9084]
2023-09-04 00:43:37.439458: Epoch time: 411.79 s
2023-09-04 00:43:38.594617: 
2023-09-04 00:43:38.596293: Epoch 126
2023-09-04 00:43:38.597590: Current learning rate: backbone 0.00061247, others 0.00061247
2023-09-04 00:43:38.599308: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:44:52.199510: finished training epoch 126
2023-09-04 00:44:52.229297: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:44:52.231765: The split file contains 1 splits.
2023-09-04 00:44:52.233063: Desired fold for training: 0
2023-09-04 00:44:52.234226: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:50:25.304890: dsc: 91.22%
2023-09-04 00:50:25.306809: miou: 83.85%
2023-09-04 00:50:25.308304: acc: 95.55%, sen: 91.87%, spe: 96.79%
2023-09-04 00:50:25.310756: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:50:25.312354: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:50:25.313814: finished real validation
2023-09-04 00:50:30.285071: train_loss -1.4485
2023-09-04 00:50:30.287186: val_loss -1.0924
2023-09-04 00:50:30.289344: Pseudo dice [0.9119]
2023-09-04 00:50:30.291091: Epoch time: 411.69 s
2023-09-04 00:50:31.495521: 
2023-09-04 00:50:31.497535: Epoch 127
2023-09-04 00:50:31.499190: Current learning rate: backbone 0.0006093, others 0.0006093
2023-09-04 00:50:31.501676: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:51:46.000235: finished training epoch 127
2023-09-04 00:51:46.031067: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:51:46.033519: The split file contains 1 splits.
2023-09-04 00:51:46.034901: Desired fold for training: 0
2023-09-04 00:51:46.036189: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 00:57:25.410549: dsc: 91.20%
2023-09-04 00:57:25.412325: miou: 83.82%
2023-09-04 00:57:25.413616: acc: 95.56%, sen: 91.49%, spe: 96.93%
2023-09-04 00:57:25.415365: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:57:25.416710: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 00:57:25.417976: finished real validation
2023-09-04 00:57:30.429247: train_loss -1.4485
2023-09-04 00:57:30.431189: val_loss -1.0794
2023-09-04 00:57:30.432820: Pseudo dice [0.9118]
2023-09-04 00:57:30.434199: Epoch time: 418.94 s
2023-09-04 00:57:31.576476: 
2023-09-04 00:57:31.578444: Epoch 128
2023-09-04 00:57:31.579809: Current learning rate: backbone 0.00060613, others 0.00060613
2023-09-04 00:57:31.581615: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 00:58:45.562310: finished training epoch 128
2023-09-04 00:58:45.597513: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 00:58:45.599787: The split file contains 1 splits.
2023-09-04 00:58:45.601232: Desired fold for training: 0
2023-09-04 00:58:45.602513: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:04:16.513061: dsc: 91.18%
2023-09-04 01:04:16.515069: miou: 83.78%
2023-09-04 01:04:16.516435: acc: 95.52%, sen: 92.02%, spe: 96.70%
2023-09-04 01:04:16.518095: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:04:16.519910: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:04:16.521324: finished real validation
2023-09-04 01:04:21.525163: train_loss -1.4479
2023-09-04 01:04:21.600331: val_loss -1.0641
2023-09-04 01:04:21.602566: Pseudo dice [0.9114]
2023-09-04 01:04:21.604502: Epoch time: 409.95 s
2023-09-04 01:04:22.782291: 
2023-09-04 01:04:22.784397: Epoch 129
2023-09-04 01:04:22.785823: Current learning rate: backbone 0.00060296, others 0.00060296
2023-09-04 01:04:22.787622: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:05:36.744847: finished training epoch 129
2023-09-04 01:05:36.775272: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:05:36.777850: The split file contains 1 splits.
2023-09-04 01:05:36.779160: Desired fold for training: 0
2023-09-04 01:05:36.780364: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:11:01.902270: dsc: 91.11%
2023-09-04 01:11:01.904136: miou: 83.68%
2023-09-04 01:11:01.905536: acc: 95.51%, sen: 91.53%, spe: 96.85%
2023-09-04 01:11:01.907298: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:11:01.908634: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:11:01.910159: finished real validation
2023-09-04 01:11:06.885545: train_loss -1.4486
2023-09-04 01:11:06.887431: val_loss -1.0903
2023-09-04 01:11:06.889101: Pseudo dice [0.9125]
2023-09-04 01:11:06.890516: Epoch time: 404.1 s
2023-09-04 01:11:09.856929: 
2023-09-04 01:11:09.858811: Epoch 130
2023-09-04 01:11:09.860426: Current learning rate: backbone 0.00059978, others 0.00059978
2023-09-04 01:11:09.862233: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:12:24.344354: finished training epoch 130
2023-09-04 01:12:24.377734: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:12:24.380248: The split file contains 1 splits.
2023-09-04 01:12:24.381632: Desired fold for training: 0
2023-09-04 01:12:24.383011: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:17:55.619805: dsc: 91.14%
2023-09-04 01:17:55.621703: miou: 83.71%
2023-09-04 01:17:55.623080: acc: 95.53%, sen: 91.41%, spe: 96.91%
2023-09-04 01:17:55.624775: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:17:55.626104: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:17:55.627341: finished real validation
2023-09-04 01:18:01.819734: train_loss -1.4482
2023-09-04 01:18:01.821588: val_loss -1.0684
2023-09-04 01:18:01.823179: Pseudo dice [0.9097]
2023-09-04 01:18:01.824575: Epoch time: 411.96 s
2023-09-04 01:18:03.271238: 
2023-09-04 01:18:03.273068: Epoch 131
2023-09-04 01:18:03.274531: Current learning rate: backbone 0.00059661, others 0.00059661
2023-09-04 01:18:03.276312: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:19:17.301872: finished training epoch 131
2023-09-04 01:19:17.342046: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:19:17.344282: The split file contains 1 splits.
2023-09-04 01:19:17.345526: Desired fold for training: 0
2023-09-04 01:19:17.346747: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:25:25.937967: dsc: 91.10%
2023-09-04 01:25:25.940400: miou: 83.66%
2023-09-04 01:25:25.941752: acc: 95.51%, sen: 91.38%, spe: 96.90%
2023-09-04 01:25:25.943485: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:25:25.944845: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:25:25.946200: finished real validation
2023-09-04 01:25:30.894238: train_loss -1.4485
2023-09-04 01:25:30.896102: val_loss -1.0776
2023-09-04 01:25:30.897707: Pseudo dice [0.9129]
2023-09-04 01:25:30.899010: Epoch time: 447.62 s
2023-09-04 01:25:32.047980: 
2023-09-04 01:25:32.050055: Epoch 132
2023-09-04 01:25:32.051482: Current learning rate: backbone 0.00059343, others 0.00059343
2023-09-04 01:25:32.053227: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:26:45.504782: finished training epoch 132
2023-09-04 01:26:45.544699: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:26:45.547188: The split file contains 1 splits.
2023-09-04 01:26:45.548624: Desired fold for training: 0
2023-09-04 01:26:45.549980: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:32:13.332722: dsc: 91.23%
2023-09-04 01:32:13.334719: miou: 83.87%
2023-09-04 01:32:13.336189: acc: 95.57%, sen: 91.53%, spe: 96.93%
2023-09-04 01:32:13.338080: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:32:13.339509: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:32:13.340876: finished real validation
2023-09-04 01:32:18.298539: train_loss -1.4487
2023-09-04 01:32:18.300447: val_loss -1.0589
2023-09-04 01:32:18.302072: Pseudo dice [0.9089]
2023-09-04 01:32:18.303465: Epoch time: 406.25 s
2023-09-04 01:32:19.431046: 
2023-09-04 01:32:19.433005: Epoch 133
2023-09-04 01:32:19.434547: Current learning rate: backbone 0.00059025, others 0.00059025
2023-09-04 01:32:19.436397: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:33:33.024692: finished training epoch 133
2023-09-04 01:33:33.055465: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:33:33.058783: The split file contains 1 splits.
2023-09-04 01:33:33.060551: Desired fold for training: 0
2023-09-04 01:33:33.062199: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:39:04.421875: dsc: 91.14%
2023-09-04 01:39:04.423672: miou: 83.72%
2023-09-04 01:39:04.425024: acc: 95.51%, sen: 91.80%, spe: 96.76%
2023-09-04 01:39:04.426713: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:39:04.428108: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:39:04.429419: finished real validation
2023-09-04 01:39:09.379695: train_loss -1.449
2023-09-04 01:39:09.381893: val_loss -1.0692
2023-09-04 01:39:09.384034: Pseudo dice [0.9096]
2023-09-04 01:39:09.385784: Epoch time: 409.95 s
2023-09-04 01:39:10.518648: 
2023-09-04 01:39:10.520445: Epoch 134
2023-09-04 01:39:10.521899: Current learning rate: backbone 0.00058707, others 0.00058707
2023-09-04 01:39:10.523666: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:40:24.316674: finished training epoch 134
2023-09-04 01:40:24.359043: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:40:24.361616: The split file contains 1 splits.
2023-09-04 01:40:24.363012: Desired fold for training: 0
2023-09-04 01:40:24.364308: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:45:55.994438: dsc: 91.15%
2023-09-04 01:45:55.996774: miou: 83.74%
2023-09-04 01:45:55.998870: acc: 95.51%, sen: 91.88%, spe: 96.74%
2023-09-04 01:45:56.001992: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:45:56.004204: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:45:56.006512: finished real validation
2023-09-04 01:46:00.968561: train_loss -1.4488
2023-09-04 01:46:00.970687: val_loss -1.083
2023-09-04 01:46:00.972554: Pseudo dice [0.9126]
2023-09-04 01:46:00.973972: Epoch time: 410.45 s
2023-09-04 01:46:02.113336: 
2023-09-04 01:46:02.115426: Epoch 135
2023-09-04 01:46:02.116839: Current learning rate: backbone 0.00058388, others 0.00058388
2023-09-04 01:46:02.118720: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:47:16.200463: finished training epoch 135
2023-09-04 01:47:16.230478: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:47:16.233645: The split file contains 1 splits.
2023-09-04 01:47:16.234984: Desired fold for training: 0
2023-09-04 01:47:16.237040: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:52:46.570536: dsc: 91.17%
2023-09-04 01:52:46.572556: miou: 83.77%
2023-09-04 01:52:46.574635: acc: 95.54%, sen: 91.46%, spe: 96.91%
2023-09-04 01:52:46.576645: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:52:46.578392: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:52:46.579903: finished real validation
2023-09-04 01:52:51.547936: train_loss -1.4493
2023-09-04 01:52:51.549882: val_loss -1.0681
2023-09-04 01:52:51.551539: Pseudo dice [0.9096]
2023-09-04 01:52:51.552960: Epoch time: 409.44 s
2023-09-04 01:52:52.715224: 
2023-09-04 01:52:52.717166: Epoch 136
2023-09-04 01:52:52.718555: Current learning rate: backbone 0.0005807, others 0.0005807
2023-09-04 01:52:52.720404: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 01:54:06.366406: finished training epoch 136
2023-09-04 01:54:06.419938: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 01:54:06.422418: The split file contains 1 splits.
2023-09-04 01:54:06.423872: Desired fold for training: 0
2023-09-04 01:54:06.425235: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 01:59:34.708173: dsc: 91.21%
2023-09-04 01:59:34.710193: miou: 83.85%
2023-09-04 01:59:34.711690: acc: 95.57%, sen: 91.36%, spe: 96.99%
2023-09-04 01:59:34.713485: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:59:34.714915: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 01:59:34.716247: finished real validation
2023-09-04 01:59:39.675702: train_loss -1.4498
2023-09-04 01:59:39.677809: val_loss -1.0808
2023-09-04 01:59:39.679532: Pseudo dice [0.9119]
2023-09-04 01:59:39.681036: Epoch time: 406.96 s
2023-09-04 01:59:40.830468: 
2023-09-04 01:59:40.832408: Epoch 137
2023-09-04 01:59:40.833878: Current learning rate: backbone 0.00057751, others 0.00057751
2023-09-04 01:59:40.835997: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:00:54.712481: finished training epoch 137
2023-09-04 02:00:54.742302: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:00:54.744531: The split file contains 1 splits.
2023-09-04 02:00:54.745983: Desired fold for training: 0
2023-09-04 02:00:54.747456: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:06:35.631438: dsc: 91.15%
2023-09-04 02:06:35.633486: miou: 83.74%
2023-09-04 02:06:35.634988: acc: 95.54%, sen: 91.23%, spe: 96.99%
2023-09-04 02:06:35.636926: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:06:35.639070: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:06:35.641447: finished real validation
2023-09-04 02:06:40.601002: train_loss -1.4498
2023-09-04 02:06:40.602803: val_loss -1.0784
2023-09-04 02:06:40.604327: Pseudo dice [0.9116]
2023-09-04 02:06:40.605665: Epoch time: 419.77 s
2023-09-04 02:06:41.827053: 
2023-09-04 02:06:41.829149: Epoch 138
2023-09-04 02:06:41.830692: Current learning rate: backbone 0.00057432, others 0.00057432
2023-09-04 02:06:41.832713: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:07:55.769833: finished training epoch 138
2023-09-04 02:07:55.823286: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:07:55.825498: The split file contains 1 splits.
2023-09-04 02:07:55.826923: Desired fold for training: 0
2023-09-04 02:07:55.828269: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:13:24.438146: dsc: 91.28%
2023-09-04 02:13:24.441055: miou: 83.95%
2023-09-04 02:13:24.442741: acc: 95.59%, sen: 91.68%, spe: 96.91%
2023-09-04 02:13:24.445458: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:13:24.447133: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:13:24.448707: finished real validation
2023-09-04 02:13:29.404135: train_loss -1.4501
2023-09-04 02:13:29.406015: val_loss -1.0833
2023-09-04 02:13:29.407760: Pseudo dice [0.9121]
2023-09-04 02:13:29.409308: Epoch time: 407.58 s
2023-09-04 02:13:30.560344: 
2023-09-04 02:13:30.562342: Epoch 139
2023-09-04 02:13:30.563854: Current learning rate: backbone 0.00057113, others 0.00057113
2023-09-04 02:13:30.565704: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:14:44.586673: finished training epoch 139
2023-09-04 02:14:44.622796: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:14:44.625359: The split file contains 1 splits.
2023-09-04 02:14:44.626856: Desired fold for training: 0
2023-09-04 02:14:44.628319: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:20:08.049604: dsc: 91.26%
2023-09-04 02:20:08.052012: miou: 83.93%
2023-09-04 02:20:08.053692: acc: 95.60%, sen: 91.40%, spe: 97.01%
2023-09-04 02:20:08.056117: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:20:08.057805: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:20:08.059400: finished real validation
2023-09-04 02:20:13.005011: train_loss -1.4502
2023-09-04 02:20:13.006956: val_loss -1.073
2023-09-04 02:20:13.008683: Pseudo dice [0.9101]
2023-09-04 02:20:13.010248: Epoch time: 402.45 s
2023-09-04 02:20:16.168578: 
2023-09-04 02:20:16.170687: Epoch 140
2023-09-04 02:20:16.172246: Current learning rate: backbone 0.00056794, others 0.00056794
2023-09-04 02:20:16.174165: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:21:29.692189: finished training epoch 140
2023-09-04 02:21:29.725995: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:21:29.728875: The split file contains 1 splits.
2023-09-04 02:21:29.730973: Desired fold for training: 0
2023-09-04 02:21:29.732542: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:27:01.928570: dsc: 91.13%
2023-09-04 02:27:01.930531: miou: 83.70%
2023-09-04 02:27:01.931915: acc: 95.50%, sen: 91.91%, spe: 96.70%
2023-09-04 02:27:01.933595: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:27:01.934924: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:27:01.936178: finished real validation
2023-09-04 02:27:06.888407: train_loss -1.4501
2023-09-04 02:27:06.890215: val_loss -1.0591
2023-09-04 02:27:06.891961: Pseudo dice [0.9104]
2023-09-04 02:27:06.893327: Epoch time: 410.72 s
2023-09-04 02:27:08.027491: 
2023-09-04 02:27:08.029443: Epoch 141
2023-09-04 02:27:08.030986: Current learning rate: backbone 0.00056474, others 0.00056474
2023-09-04 02:27:08.032974: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:28:21.552750: finished training epoch 141
2023-09-04 02:28:21.584900: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:28:21.587680: The split file contains 1 splits.
2023-09-04 02:28:21.589169: Desired fold for training: 0
2023-09-04 02:28:21.590642: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:33:50.423322: dsc: 91.28%
2023-09-04 02:33:50.425321: miou: 83.95%
2023-09-04 02:33:50.426817: acc: 95.59%, sen: 91.75%, spe: 96.88%
2023-09-04 02:33:50.428643: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:33:50.430086: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:33:50.431507: finished real validation
2023-09-04 02:33:55.370951: train_loss -1.4502
2023-09-04 02:33:55.372851: val_loss -1.1018
2023-09-04 02:33:55.374479: Pseudo dice [0.9149]
2023-09-04 02:33:55.375919: Epoch time: 407.34 s
2023-09-04 02:33:56.517008: 
2023-09-04 02:33:56.519001: Epoch 142
2023-09-04 02:33:56.520510: Current learning rate: backbone 0.00056154, others 0.00056154
2023-09-04 02:33:56.522465: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:35:10.038539: finished training epoch 142
2023-09-04 02:35:10.081354: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:35:10.084033: The split file contains 1 splits.
2023-09-04 02:35:10.085458: Desired fold for training: 0
2023-09-04 02:35:10.086813: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:40:40.019964: dsc: 91.11%
2023-09-04 02:40:40.021592: miou: 83.67%
2023-09-04 02:40:40.022915: acc: 95.49%, sen: 91.87%, spe: 96.71%
2023-09-04 02:40:40.024536: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:40:40.025842: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:40:40.027076: finished real validation
2023-09-04 02:40:44.967119: train_loss -1.4497
2023-09-04 02:40:44.969188: val_loss -1.0752
2023-09-04 02:40:44.970976: Pseudo dice [0.9111]
2023-09-04 02:40:44.972532: Epoch time: 408.45 s
2023-09-04 02:40:46.123695: 
2023-09-04 02:40:46.125349: Epoch 143
2023-09-04 02:40:46.126783: Current learning rate: backbone 0.00055834, others 0.00055834
2023-09-04 02:40:46.129260: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:42:00.305176: finished training epoch 143
2023-09-04 02:42:00.339638: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:42:00.342610: The split file contains 1 splits.
2023-09-04 02:42:00.344168: Desired fold for training: 0
2023-09-04 02:42:00.345712: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:47:29.538771: dsc: 91.19%
2023-09-04 02:47:29.540540: miou: 83.80%
2023-09-04 02:47:29.541968: acc: 95.54%, sen: 91.75%, spe: 96.81%
2023-09-04 02:47:29.543862: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:47:29.545235: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:47:29.546533: finished real validation
2023-09-04 02:47:34.480945: train_loss -1.4501
2023-09-04 02:47:34.482698: val_loss -1.052
2023-09-04 02:47:34.484260: Pseudo dice [0.9111]
2023-09-04 02:47:34.485638: Epoch time: 408.36 s
2023-09-04 02:47:35.698840: 
2023-09-04 02:47:35.700802: Epoch 144
2023-09-04 02:47:35.702240: Current learning rate: backbone 0.00055514, others 0.00055514
2023-09-04 02:47:35.704101: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:48:49.967446: finished training epoch 144
2023-09-04 02:48:49.996689: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:48:49.998949: The split file contains 1 splits.
2023-09-04 02:48:50.000232: Desired fold for training: 0
2023-09-04 02:48:50.001555: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 02:54:14.104147: dsc: 91.26%
2023-09-04 02:54:14.106276: miou: 83.93%
2023-09-04 02:54:14.107754: acc: 95.58%, sen: 91.75%, spe: 96.87%
2023-09-04 02:54:14.109519: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:54:14.110997: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 02:54:14.112377: finished real validation
2023-09-04 02:54:19.063626: train_loss -1.4504
2023-09-04 02:54:19.066038: val_loss -1.0832
2023-09-04 02:54:19.068362: Pseudo dice [0.9135]
2023-09-04 02:54:19.070273: Epoch time: 403.37 s
2023-09-04 02:54:20.220521: 
2023-09-04 02:54:20.222623: Epoch 145
2023-09-04 02:54:20.224145: Current learning rate: backbone 0.00055194, others 0.00055194
2023-09-04 02:54:20.226038: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 02:55:34.558075: finished training epoch 145
2023-09-04 02:55:34.599555: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 02:55:34.601842: The split file contains 1 splits.
2023-09-04 02:55:34.603326: Desired fold for training: 0
2023-09-04 02:55:34.604647: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:01:04.194427: dsc: 91.28%
2023-09-04 03:01:04.196332: miou: 83.96%
2023-09-04 03:01:04.197732: acc: 95.60%, sen: 91.64%, spe: 96.92%
2023-09-04 03:01:04.199432: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:01:04.200747: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:01:04.202040: finished real validation
2023-09-04 03:01:09.143573: train_loss -1.4504
2023-09-04 03:01:09.145925: val_loss -1.0744
2023-09-04 03:01:09.148198: Pseudo dice [0.9126]
2023-09-04 03:01:09.150058: Epoch time: 408.92 s
2023-09-04 03:01:10.295577: 
2023-09-04 03:01:10.297563: Epoch 146
2023-09-04 03:01:10.300094: Current learning rate: backbone 0.00054873, others 0.00054873
2023-09-04 03:01:10.302715: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:02:24.856061: finished training epoch 146
2023-09-04 03:02:24.903307: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:02:24.905926: The split file contains 1 splits.
2023-09-04 03:02:24.907445: Desired fold for training: 0
2023-09-04 03:02:24.908850: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:07:49.757614: dsc: 91.26%
2023-09-04 03:07:49.759666: miou: 83.92%
2023-09-04 03:07:49.761143: acc: 95.59%, sen: 91.44%, spe: 96.99%
2023-09-04 03:07:49.762929: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:07:49.764303: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:07:49.765626: finished real validation
2023-09-04 03:07:54.707330: train_loss -1.4507
2023-09-04 03:07:54.709480: val_loss -1.0839
2023-09-04 03:07:54.711182: Pseudo dice [0.9139]
2023-09-04 03:07:54.712695: Epoch time: 404.41 s
2023-09-04 03:07:55.858055: 
2023-09-04 03:07:55.860177: Epoch 147
2023-09-04 03:07:55.861745: Current learning rate: backbone 0.00054552, others 0.00054552
2023-09-04 03:07:55.863633: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:09:09.722959: finished training epoch 147
2023-09-04 03:09:09.766072: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:09:09.768511: The split file contains 1 splits.
2023-09-04 03:09:09.769974: Desired fold for training: 0
2023-09-04 03:09:09.771752: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:14:34.217427: dsc: 91.25%
2023-09-04 03:14:34.219361: miou: 83.90%
2023-09-04 03:14:34.220819: acc: 95.58%, sen: 91.50%, spe: 96.96%
2023-09-04 03:14:34.222651: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:14:34.224176: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:14:34.225567: finished real validation
2023-09-04 03:14:39.177583: train_loss -1.4505
2023-09-04 03:14:39.179650: val_loss -1.087
2023-09-04 03:14:39.182446: Pseudo dice [0.9132]
2023-09-04 03:14:39.185615: Epoch time: 403.32 s
2023-09-04 03:14:40.348690: 
2023-09-04 03:14:40.350938: Epoch 148
2023-09-04 03:14:40.352718: Current learning rate: backbone 0.00054231, others 0.00054231
2023-09-04 03:14:40.355112: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:15:54.356943: finished training epoch 148
2023-09-04 03:15:54.403470: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:15:54.405881: The split file contains 1 splits.
2023-09-04 03:15:54.407336: Desired fold for training: 0
2023-09-04 03:15:54.409349: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:21:18.266552: dsc: 91.23%
2023-09-04 03:21:18.268482: miou: 83.87%
2023-09-04 03:21:18.269967: acc: 95.57%, sen: 91.55%, spe: 96.92%
2023-09-04 03:21:18.271757: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:21:18.273189: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:21:18.274550: finished real validation
2023-09-04 03:21:23.227394: train_loss -1.4511
2023-09-04 03:21:23.229386: val_loss -1.1021
2023-09-04 03:21:23.231162: Pseudo dice [0.9168]
2023-09-04 03:21:23.232687: Epoch time: 402.88 s
2023-09-04 03:21:23.234109: Yayy! New best EMA pseudo Dice: 0.9124
2023-09-04 03:21:26.650500: 
2023-09-04 03:21:26.652635: Epoch 149
2023-09-04 03:21:26.654215: Current learning rate: backbone 0.0005391, others 0.0005391
2023-09-04 03:21:26.656096: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:22:40.597820: finished training epoch 149
2023-09-04 03:22:40.657951: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:22:40.660412: The split file contains 1 splits.
2023-09-04 03:22:40.662008: Desired fold for training: 0
2023-09-04 03:22:40.663477: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:28:06.977996: dsc: 91.18%
2023-09-04 03:28:06.979897: miou: 83.79%
2023-09-04 03:28:06.981280: acc: 95.54%, sen: 91.61%, spe: 96.87%
2023-09-04 03:28:06.982993: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:28:06.984393: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:28:06.985812: finished real validation
2023-09-04 03:28:11.918125: train_loss -1.4512
2023-09-04 03:28:11.920208: val_loss -1.0827
2023-09-04 03:28:11.921929: Pseudo dice [0.9113]
2023-09-04 03:28:11.923456: Epoch time: 405.27 s
2023-09-04 03:28:14.961754: 
2023-09-04 03:28:14.963645: Epoch 150
2023-09-04 03:28:14.965142: Current learning rate: backbone 0.00053589, others 0.00053589
2023-09-04 03:28:14.967050: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:29:29.193675: finished training epoch 150
2023-09-04 03:29:29.225699: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:29:29.228480: The split file contains 1 splits.
2023-09-04 03:29:29.229974: Desired fold for training: 0
2023-09-04 03:29:29.231414: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:34:57.218821: dsc: 91.26%
2023-09-04 03:34:57.220625: miou: 83.92%
2023-09-04 03:34:57.222102: acc: 95.58%, sen: 91.65%, spe: 96.91%
2023-09-04 03:34:57.223833: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:34:57.225415: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:34:57.226793: finished real validation
2023-09-04 03:35:02.166787: train_loss -1.451
2023-09-04 03:35:02.168819: val_loss -1.0613
2023-09-04 03:35:02.171361: Pseudo dice [0.9117]
2023-09-04 03:35:02.173436: Epoch time: 407.21 s
2023-09-04 03:35:03.364090: 
2023-09-04 03:35:03.365991: Epoch 151
2023-09-04 03:35:03.367581: Current learning rate: backbone 0.00053267, others 0.00053267
2023-09-04 03:35:03.369544: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:36:16.966270: finished training epoch 151
2023-09-04 03:36:16.996240: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:36:16.998605: The split file contains 1 splits.
2023-09-04 03:36:17.000056: Desired fold for training: 0
2023-09-04 03:36:17.001418: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:41:50.301158: dsc: 91.28%
2023-09-04 03:41:50.303149: miou: 83.95%
2023-09-04 03:41:50.304551: acc: 95.60%, sen: 91.59%, spe: 96.94%
2023-09-04 03:41:50.306257: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:41:50.307697: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:41:50.309065: finished real validation
2023-09-04 03:41:55.247843: train_loss -1.451
2023-09-04 03:41:55.249855: val_loss -1.075
2023-09-04 03:41:55.251627: Pseudo dice [0.9114]
2023-09-04 03:41:55.253121: Epoch time: 411.89 s
2023-09-04 03:41:56.420312: 
2023-09-04 03:41:56.422167: Epoch 152
2023-09-04 03:41:56.424081: Current learning rate: backbone 0.00052945, others 0.00052945
2023-09-04 03:41:56.426566: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:43:11.118025: finished training epoch 152
2023-09-04 03:43:11.167084: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:43:11.169785: The split file contains 1 splits.
2023-09-04 03:43:11.171720: Desired fold for training: 0
2023-09-04 03:43:11.173604: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:49:37.374958: dsc: 91.21%
2023-09-04 03:49:37.376802: miou: 83.84%
2023-09-04 03:49:37.378206: acc: 95.55%, sen: 91.70%, spe: 96.85%
2023-09-04 03:49:37.379863: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:49:37.381256: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:49:37.382566: finished real validation
2023-09-04 03:49:42.413673: train_loss -1.451
2023-09-04 03:49:42.416008: val_loss -1.0675
2023-09-04 03:49:42.417960: Pseudo dice [0.9124]
2023-09-04 03:49:42.419598: Epoch time: 465.99 s
2023-09-04 03:49:43.600646: 
2023-09-04 03:49:43.602875: Epoch 153
2023-09-04 03:49:43.604399: Current learning rate: backbone 0.00052623, others 0.00052623
2023-09-04 03:49:43.606413: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:50:57.959614: finished training epoch 153
2023-09-04 03:50:57.989485: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:50:57.992991: The split file contains 1 splits.
2023-09-04 03:50:57.994640: Desired fold for training: 0
2023-09-04 03:50:57.996081: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 03:57:40.386506: dsc: 91.18%
2023-09-04 03:57:40.388538: miou: 83.78%
2023-09-04 03:57:40.390049: acc: 95.53%, sen: 91.83%, spe: 96.77%
2023-09-04 03:57:40.391856: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:57:40.393311: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 03:57:40.394788: finished real validation
2023-09-04 03:57:45.464243: train_loss -1.4515
2023-09-04 03:57:45.466482: val_loss -1.0611
2023-09-04 03:57:45.468307: Pseudo dice [0.9114]
2023-09-04 03:57:45.469885: Epoch time: 481.87 s
2023-09-04 03:57:46.683058: 
2023-09-04 03:57:46.685162: Epoch 154
2023-09-04 03:57:46.687130: Current learning rate: backbone 0.00052301, others 0.00052301
2023-09-04 03:57:46.689574: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 03:59:01.922952: finished training epoch 154
2023-09-04 03:59:01.954448: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 03:59:01.956776: The split file contains 1 splits.
2023-09-04 03:59:01.958281: Desired fold for training: 0
2023-09-04 03:59:01.959673: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:04:41.629868: dsc: 91.21%
2023-09-04 04:04:41.631984: miou: 83.84%
2023-09-04 04:04:41.633418: acc: 95.56%, sen: 91.63%, spe: 96.88%
2023-09-04 04:04:41.635133: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:04:41.636520: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:04:41.638041: finished real validation
2023-09-04 04:04:46.689610: train_loss -1.4516
2023-09-04 04:04:46.691778: val_loss -1.0707
2023-09-04 04:04:46.693540: Pseudo dice [0.9105]
2023-09-04 04:04:46.695847: Epoch time: 420.01 s
2023-09-04 04:04:47.860116: 
2023-09-04 04:04:47.862142: Epoch 155
2023-09-04 04:04:47.863689: Current learning rate: backbone 0.00051978, others 0.00051978
2023-09-04 04:04:47.865601: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:06:02.470076: finished training epoch 155
2023-09-04 04:06:02.503593: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:06:02.505969: The split file contains 1 splits.
2023-09-04 04:06:02.507394: Desired fold for training: 0
2023-09-04 04:06:02.508762: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:11:34.017769: dsc: 91.25%
2023-09-04 04:11:34.019736: miou: 83.91%
2023-09-04 04:11:34.021182: acc: 95.60%, sen: 91.25%, spe: 97.06%
2023-09-04 04:11:34.022892: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:11:34.024279: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:11:34.025616: finished real validation
2023-09-04 04:11:38.997306: train_loss -1.4515
2023-09-04 04:11:38.999439: val_loss -1.1002
2023-09-04 04:11:39.001177: Pseudo dice [0.9166]
2023-09-04 04:11:39.002675: Epoch time: 411.14 s
2023-09-04 04:11:40.171356: 
2023-09-04 04:11:40.173291: Epoch 156
2023-09-04 04:11:40.174872: Current learning rate: backbone 0.00051656, others 0.00051656
2023-09-04 04:11:40.176832: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:12:54.141192: finished training epoch 156
2023-09-04 04:12:54.225755: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:12:54.228149: The split file contains 1 splits.
2023-09-04 04:12:54.229714: Desired fold for training: 0
2023-09-04 04:12:54.231209: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:18:22.480087: dsc: 91.23%
2023-09-04 04:18:22.482038: miou: 83.87%
2023-09-04 04:18:22.483638: acc: 95.56%, sen: 91.86%, spe: 96.80%
2023-09-04 04:18:22.485396: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:18:22.486892: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:18:22.488303: finished real validation
2023-09-04 04:18:27.454659: train_loss -1.4518
2023-09-04 04:18:27.456663: val_loss -1.081
2023-09-04 04:18:27.458436: Pseudo dice [0.9148]
2023-09-04 04:18:27.460007: Epoch time: 407.28 s
2023-09-04 04:18:27.461472: Yayy! New best EMA pseudo Dice: 0.9127
2023-09-04 04:18:30.352117: 
2023-09-04 04:18:30.354339: Epoch 157
2023-09-04 04:18:30.355995: Current learning rate: backbone 0.00051333, others 0.00051333
2023-09-04 04:18:30.357995: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:19:44.000188: finished training epoch 157
2023-09-04 04:19:44.030328: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:19:44.033688: The split file contains 1 splits.
2023-09-04 04:19:44.035588: Desired fold for training: 0
2023-09-04 04:19:44.037355: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:25:19.168223: dsc: 91.17%
2023-09-04 04:25:19.170319: miou: 83.77%
2023-09-04 04:25:19.171832: acc: 95.53%, sen: 91.79%, spe: 96.78%
2023-09-04 04:25:19.173933: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:25:19.175585: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:25:19.177107: finished real validation
2023-09-04 04:25:24.137513: train_loss -1.4518
2023-09-04 04:25:24.139534: val_loss -1.0888
2023-09-04 04:25:24.141399: Pseudo dice [0.9147]
2023-09-04 04:25:24.143081: Epoch time: 413.79 s
2023-09-04 04:25:24.144651: Yayy! New best EMA pseudo Dice: 0.9129
2023-09-04 04:25:27.021041: 
2023-09-04 04:25:27.023170: Epoch 158
2023-09-04 04:25:27.024793: Current learning rate: backbone 0.00051009, others 0.00051009
2023-09-04 04:25:27.026762: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:26:40.709567: finished training epoch 158
2023-09-04 04:26:40.740716: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:26:40.743330: The split file contains 1 splits.
2023-09-04 04:26:40.744792: Desired fold for training: 0
2023-09-04 04:26:40.746171: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:32:07.857955: dsc: 91.28%
2023-09-04 04:32:07.859975: miou: 83.96%
2023-09-04 04:32:07.861504: acc: 95.60%, sen: 91.62%, spe: 96.93%
2023-09-04 04:32:07.863313: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:32:07.864823: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:32:07.866230: finished real validation
2023-09-04 04:32:12.819703: train_loss -1.4518
2023-09-04 04:32:12.821772: val_loss -1.0722
2023-09-04 04:32:12.823478: Pseudo dice [0.9122]
2023-09-04 04:32:12.825015: Epoch time: 405.8 s
2023-09-04 04:32:13.997527: 
2023-09-04 04:32:13.999341: Epoch 159
2023-09-04 04:32:14.000936: Current learning rate: backbone 0.00050686, others 0.00050686
2023-09-04 04:32:14.002884: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:33:27.613225: finished training epoch 159
2023-09-04 04:33:27.689943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:33:27.692358: The split file contains 1 splits.
2023-09-04 04:33:27.693961: Desired fold for training: 0
2023-09-04 04:33:27.695469: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:38:53.806929: dsc: 91.14%
2023-09-04 04:38:53.808653: miou: 83.71%
2023-09-04 04:38:53.810153: acc: 95.51%, sen: 91.72%, spe: 96.79%
2023-09-04 04:38:53.812143: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:38:53.814338: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:38:53.815647: finished real validation
2023-09-04 04:38:58.788744: train_loss -1.4516
2023-09-04 04:38:58.790787: val_loss -1.0882
2023-09-04 04:38:58.792635: Pseudo dice [0.915]
2023-09-04 04:38:58.794310: Epoch time: 404.79 s
2023-09-04 04:39:00.602920: Yayy! New best EMA pseudo Dice: 0.913
2023-09-04 04:39:03.600690: 
2023-09-04 04:39:03.602745: Epoch 160
2023-09-04 04:39:03.604456: Current learning rate: backbone 0.00050362, others 0.00050362
2023-09-04 04:39:03.606504: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:40:17.734970: finished training epoch 160
2023-09-04 04:40:17.766047: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:40:17.769837: The split file contains 1 splits.
2023-09-04 04:40:17.771753: Desired fold for training: 0
2023-09-04 04:40:17.773640: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:45:51.065926: dsc: 91.25%
2023-09-04 04:45:51.067657: miou: 83.91%
2023-09-04 04:45:51.069112: acc: 95.58%, sen: 91.60%, spe: 96.92%
2023-09-04 04:45:51.070811: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:45:51.072232: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:45:51.073627: finished real validation
2023-09-04 04:45:56.007863: train_loss -1.4515
2023-09-04 04:45:56.009948: val_loss -1.0632
2023-09-04 04:45:56.011727: Pseudo dice [0.912]
2023-09-04 04:45:56.013415: Epoch time: 412.41 s
2023-09-04 04:45:57.183550: 
2023-09-04 04:45:57.185392: Epoch 161
2023-09-04 04:45:57.186941: Current learning rate: backbone 0.00050038, others 0.00050038
2023-09-04 04:45:57.188832: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:47:11.578639: finished training epoch 161
2023-09-04 04:47:11.608332: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:47:11.611599: The split file contains 1 splits.
2023-09-04 04:47:11.613466: Desired fold for training: 0
2023-09-04 04:47:11.615186: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:52:41.362197: dsc: 91.17%
2023-09-04 04:52:41.364162: miou: 83.76%
2023-09-04 04:52:41.365559: acc: 95.54%, sen: 91.48%, spe: 96.91%
2023-09-04 04:52:41.367232: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:52:41.368662: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:52:41.369993: finished real validation
2023-09-04 04:52:46.424911: train_loss -1.4522
2023-09-04 04:52:46.427199: val_loss -1.0532
2023-09-04 04:52:46.429112: Pseudo dice [0.9097]
2023-09-04 04:52:46.430716: Epoch time: 409.24 s
2023-09-04 04:52:47.656377: 
2023-09-04 04:52:47.658740: Epoch 162
2023-09-04 04:52:47.660448: Current learning rate: backbone 0.00049714, others 0.00049714
2023-09-04 04:52:47.662800: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 04:54:01.875927: finished training epoch 162
2023-09-04 04:54:01.917690: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 04:54:01.920081: The split file contains 1 splits.
2023-09-04 04:54:01.921906: Desired fold for training: 0
2023-09-04 04:54:01.924174: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 04:59:35.695661: dsc: 91.24%
2023-09-04 04:59:35.697813: miou: 83.89%
2023-09-04 04:59:35.699427: acc: 95.56%, sen: 92.01%, spe: 96.75%
2023-09-04 04:59:35.701327: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:59:35.702927: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 04:59:35.704628: finished real validation
2023-09-04 04:59:40.778139: train_loss -1.452
2023-09-04 04:59:40.780391: val_loss -1.0519
2023-09-04 04:59:40.782487: Pseudo dice [0.9093]
2023-09-04 04:59:40.784140: Epoch time: 413.12 s
2023-09-04 04:59:41.978986: 
2023-09-04 04:59:41.981164: Epoch 163
2023-09-04 04:59:41.982793: Current learning rate: backbone 0.0004939, others 0.0004939
2023-09-04 04:59:41.984999: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:00:56.546194: finished training epoch 163
2023-09-04 05:00:56.603943: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:00:56.606239: The split file contains 1 splits.
2023-09-04 05:00:56.607714: Desired fold for training: 0
2023-09-04 05:00:56.609001: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:07:28.642662: dsc: 91.10%
2023-09-04 05:07:28.644732: miou: 83.66%
2023-09-04 05:07:28.646274: acc: 95.50%, sen: 91.57%, spe: 96.82%
2023-09-04 05:07:28.648107: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:07:28.649614: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:07:28.651051: finished real validation
2023-09-04 05:07:33.679702: train_loss -1.4516
2023-09-04 05:07:33.681811: val_loss -1.0808
2023-09-04 05:07:33.683545: Pseudo dice [0.9148]
2023-09-04 05:07:33.685102: Epoch time: 471.7 s
2023-09-04 05:07:34.861339: 
2023-09-04 05:07:34.863319: Epoch 164
2023-09-04 05:07:34.864942: Current learning rate: backbone 0.00049065, others 0.00049065
2023-09-04 05:07:34.866915: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:08:49.624240: finished training epoch 164
2023-09-04 05:08:49.665528: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:08:49.667858: The split file contains 1 splits.
2023-09-04 05:08:49.669444: Desired fold for training: 0
2023-09-04 05:08:49.670931: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:14:18.308358: dsc: 91.13%
2023-09-04 05:14:18.310317: miou: 83.70%
2023-09-04 05:14:18.311833: acc: 95.52%, sen: 91.49%, spe: 96.87%
2023-09-04 05:14:18.313639: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:14:18.315130: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:14:18.316629: finished real validation
2023-09-04 05:14:23.282717: train_loss -1.4517
2023-09-04 05:14:23.285079: val_loss -1.0731
2023-09-04 05:14:23.287031: Pseudo dice [0.9105]
2023-09-04 05:14:23.288676: Epoch time: 408.42 s
2023-09-04 05:14:24.431384: 
2023-09-04 05:14:24.433396: Epoch 165
2023-09-04 05:14:24.434916: Current learning rate: backbone 0.00048741, others 0.00048741
2023-09-04 05:14:24.436854: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:15:38.559718: finished training epoch 165
2023-09-04 05:15:38.604332: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:15:38.606777: The split file contains 1 splits.
2023-09-04 05:15:38.608344: Desired fold for training: 0
2023-09-04 05:15:38.610243: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:21:02.720675: dsc: 91.25%
2023-09-04 05:21:02.723083: miou: 83.90%
2023-09-04 05:21:02.724932: acc: 95.57%, sen: 91.87%, spe: 96.81%
2023-09-04 05:21:02.727600: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:21:02.729428: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:21:02.731163: finished real validation
2023-09-04 05:21:07.695118: train_loss -1.4525
2023-09-04 05:21:07.697123: val_loss -1.0722
2023-09-04 05:21:07.698903: Pseudo dice [0.9112]
2023-09-04 05:21:07.700478: Epoch time: 403.27 s
2023-09-04 05:21:08.833887: 
2023-09-04 05:21:08.835880: Epoch 166
2023-09-04 05:21:08.837518: Current learning rate: backbone 0.00048416, others 0.00048416
2023-09-04 05:21:08.839544: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:22:22.738098: finished training epoch 166
2023-09-04 05:22:22.768376: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:22:22.770981: The split file contains 1 splits.
2023-09-04 05:22:22.772812: Desired fold for training: 0
2023-09-04 05:22:22.774427: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:27:36.843127: dsc: 91.21%
2023-09-04 05:27:36.845395: miou: 83.84%
2023-09-04 05:27:36.846968: acc: 95.55%, sen: 91.81%, spe: 96.80%
2023-09-04 05:27:36.848834: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:27:36.850691: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:27:36.852468: finished real validation
2023-09-04 05:27:41.803060: train_loss -1.4524
2023-09-04 05:27:41.805132: val_loss -1.0709
2023-09-04 05:27:41.807052: Pseudo dice [0.9143]
2023-09-04 05:27:41.808765: Epoch time: 392.97 s
2023-09-04 05:27:42.926824: 
2023-09-04 05:27:42.928851: Epoch 167
2023-09-04 05:27:42.930554: Current learning rate: backbone 0.0004809, others 0.0004809
2023-09-04 05:27:42.932613: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:28:56.662117: finished training epoch 167
2023-09-04 05:28:56.698040: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:28:56.702045: The split file contains 1 splits.
2023-09-04 05:28:56.703702: Desired fold for training: 0
2023-09-04 05:28:56.705247: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:34:17.580250: dsc: 91.19%
2023-09-04 05:34:17.582400: miou: 83.80%
2023-09-04 05:34:17.583967: acc: 95.56%, sen: 91.33%, spe: 96.98%
2023-09-04 05:34:17.585846: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:34:17.587361: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:34:17.588814: finished real validation
2023-09-04 05:34:22.541511: train_loss -1.4524
2023-09-04 05:34:22.543456: val_loss -1.0704
2023-09-04 05:34:22.545239: Pseudo dice [0.9116]
2023-09-04 05:34:22.546820: Epoch time: 399.62 s
2023-09-04 05:34:23.693618: 
2023-09-04 05:34:23.695609: Epoch 168
2023-09-04 05:34:23.697210: Current learning rate: backbone 0.00047765, others 0.00047765
2023-09-04 05:34:23.699041: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:35:37.258850: finished training epoch 168
2023-09-04 05:35:37.323169: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:35:37.325633: The split file contains 1 splits.
2023-09-04 05:35:37.327255: Desired fold for training: 0
2023-09-04 05:35:37.328819: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:40:54.529887: dsc: 91.30%
2023-09-04 05:40:54.531695: miou: 83.99%
2023-09-04 05:40:54.533262: acc: 95.60%, sen: 91.73%, spe: 96.90%
2023-09-04 05:40:54.535099: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:40:54.536627: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:40:54.538130: finished real validation
2023-09-04 05:40:59.487702: train_loss -1.4528
2023-09-04 05:40:59.489971: val_loss -1.0309
2023-09-04 05:40:59.491792: Pseudo dice [0.9056]
2023-09-04 05:40:59.493396: Epoch time: 395.8 s
2023-09-04 05:41:00.661069: 
2023-09-04 05:41:00.663450: Epoch 169
2023-09-04 05:41:00.665586: Current learning rate: backbone 0.00047439, others 0.00047439
2023-09-04 05:41:00.668700: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:42:14.204621: finished training epoch 169
2023-09-04 05:42:14.273922: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:42:14.276883: The split file contains 1 splits.
2023-09-04 05:42:14.278674: Desired fold for training: 0
2023-09-04 05:42:14.280797: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:47:32.638686: dsc: 91.24%
2023-09-04 05:47:32.640720: miou: 83.90%
2023-09-04 05:47:32.642251: acc: 95.58%, sen: 91.60%, spe: 96.92%
2023-09-04 05:47:32.644149: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:47:32.645667: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:47:32.647160: finished real validation
2023-09-04 05:47:37.589388: train_loss -1.453
2023-09-04 05:47:37.591489: val_loss -1.0705
2023-09-04 05:47:37.593311: Pseudo dice [0.9117]
2023-09-04 05:47:37.594883: Epoch time: 396.93 s
2023-09-04 05:47:40.486760: 
2023-09-04 05:47:40.488464: Epoch 170
2023-09-04 05:47:40.490012: Current learning rate: backbone 0.00047113, others 0.00047113
2023-09-04 05:47:40.491836: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:48:54.642268: finished training epoch 170
2023-09-04 05:48:54.685531: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:48:54.689300: The split file contains 1 splits.
2023-09-04 05:48:54.691724: Desired fold for training: 0
2023-09-04 05:48:54.693823: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 05:54:29.986279: dsc: 91.28%
2023-09-04 05:54:29.988379: miou: 83.96%
2023-09-04 05:54:29.990006: acc: 95.59%, sen: 91.79%, spe: 96.87%
2023-09-04 05:54:29.991866: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:54:29.993415: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 05:54:29.994901: finished real validation
2023-09-04 05:54:35.007985: train_loss -1.4528
2023-09-04 05:54:35.010316: val_loss -1.0836
2023-09-04 05:54:35.012194: Pseudo dice [0.9138]
2023-09-04 05:54:35.013827: Epoch time: 414.52 s
2023-09-04 05:54:36.206059: 
2023-09-04 05:54:36.208177: Epoch 171
2023-09-04 05:54:36.209818: Current learning rate: backbone 0.00046787, others 0.00046787
2023-09-04 05:54:36.211828: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 05:55:49.745920: finished training epoch 171
2023-09-04 05:55:49.775652: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 05:55:49.778017: The split file contains 1 splits.
2023-09-04 05:55:49.779803: Desired fold for training: 0
2023-09-04 05:55:49.781629: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:01:35.109174: dsc: 91.24%
2023-09-04 06:01:35.111316: miou: 83.90%
2023-09-04 06:01:35.112969: acc: 95.57%, sen: 91.68%, spe: 96.88%
2023-09-04 06:01:35.114952: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:01:35.116559: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:01:35.118135: finished real validation
2023-09-04 06:01:40.073930: train_loss -1.4531
2023-09-04 06:01:40.076072: val_loss -1.0672
2023-09-04 06:01:40.078408: Pseudo dice [0.912]
2023-09-04 06:01:40.080180: Epoch time: 423.87 s
2023-09-04 06:01:41.241438: 
2023-09-04 06:01:41.243604: Epoch 172
2023-09-04 06:01:41.245323: Current learning rate: backbone 0.0004646, others 0.0004646
2023-09-04 06:01:41.247519: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:02:55.030530: finished training epoch 172
2023-09-04 06:02:55.126436: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:02:55.129065: The split file contains 1 splits.
2023-09-04 06:02:55.130733: Desired fold for training: 0
2023-09-04 06:02:55.132308: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:09:25.009018: dsc: 91.18%
2023-09-04 06:09:25.078979: miou: 83.79%
2023-09-04 06:09:25.080557: acc: 95.54%, sen: 91.70%, spe: 96.83%
2023-09-04 06:09:25.082387: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:09:25.083963: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:09:25.085640: finished real validation
2023-09-04 06:09:30.128612: train_loss -1.4528
2023-09-04 06:09:30.130655: val_loss -1.0694
2023-09-04 06:09:30.132521: Pseudo dice [0.9112]
2023-09-04 06:09:30.134097: Epoch time: 468.89 s
2023-09-04 06:09:31.321328: 
2023-09-04 06:09:31.323520: Epoch 173
2023-09-04 06:09:31.325181: Current learning rate: backbone 0.00046133, others 0.00046133
2023-09-04 06:09:31.327342: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:10:45.707989: finished training epoch 173
2023-09-04 06:10:45.745525: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:10:45.748222: The split file contains 1 splits.
2023-09-04 06:10:45.749682: Desired fold for training: 0
2023-09-04 06:10:45.751158: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:17:17.309861: dsc: 91.18%
2023-09-04 06:17:17.312251: miou: 83.79%
2023-09-04 06:17:17.313838: acc: 95.55%, sen: 91.39%, spe: 96.95%
2023-09-04 06:17:17.315760: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:17:17.317271: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:17:17.318797: finished real validation
2023-09-04 06:17:22.346816: train_loss -1.453
2023-09-04 06:17:22.348862: val_loss -1.0736
2023-09-04 06:17:22.350694: Pseudo dice [0.9128]
2023-09-04 06:17:22.352360: Epoch time: 471.03 s
2023-09-04 06:17:23.510756: 
2023-09-04 06:17:23.512710: Epoch 174
2023-09-04 06:17:23.514412: Current learning rate: backbone 0.00045806, others 0.00045806
2023-09-04 06:17:23.516452: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:18:37.035772: finished training epoch 174
2023-09-04 06:18:37.063246: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:18:37.065766: The split file contains 1 splits.
2023-09-04 06:18:37.067621: Desired fold for training: 0
2023-09-04 06:18:37.069208: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:23:58.334058: dsc: 91.19%
2023-09-04 06:23:58.336305: miou: 83.80%
2023-09-04 06:23:58.337906: acc: 95.55%, sen: 91.60%, spe: 96.87%
2023-09-04 06:23:58.339805: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:23:58.341357: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:23:58.342893: finished real validation
2023-09-04 06:24:03.399475: train_loss -1.4525
2023-09-04 06:24:03.402102: val_loss -1.0671
2023-09-04 06:24:03.404275: Pseudo dice [0.9115]
2023-09-04 06:24:03.406209: Epoch time: 399.89 s
2023-09-04 06:24:04.598286: 
2023-09-04 06:24:04.600752: Epoch 175
2023-09-04 06:24:04.602547: Current learning rate: backbone 0.00045479, others 0.00045479
2023-09-04 06:24:04.604802: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:25:18.524190: finished training epoch 175
2023-09-04 06:25:18.553954: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:25:18.558556: The split file contains 1 splits.
2023-09-04 06:25:18.560131: Desired fold for training: 0
2023-09-04 06:25:18.561659: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:30:53.340321: dsc: 91.19%
2023-09-04 06:30:53.342364: miou: 83.81%
2023-09-04 06:30:53.344144: acc: 95.54%, sen: 91.81%, spe: 96.80%
2023-09-04 06:30:53.346164: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:30:53.347837: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:30:53.349633: finished real validation
2023-09-04 06:30:58.300653: train_loss -1.4527
2023-09-04 06:30:58.302767: val_loss -1.0862
2023-09-04 06:30:58.304828: Pseudo dice [0.913]
2023-09-04 06:30:58.306517: Epoch time: 413.7 s
2023-09-04 06:30:59.447326: 
2023-09-04 06:30:59.449471: Epoch 176
2023-09-04 06:30:59.450981: Current learning rate: backbone 0.00045151, others 0.00045151
2023-09-04 06:30:59.452829: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:32:12.934543: finished training epoch 176
2023-09-04 06:32:12.971790: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:32:12.974453: The split file contains 1 splits.
2023-09-04 06:32:12.976028: Desired fold for training: 0
2023-09-04 06:32:12.977529: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:37:33.882926: dsc: 91.13%
2023-09-04 06:37:33.885051: miou: 83.70%
2023-09-04 06:37:33.886630: acc: 95.50%, sen: 91.89%, spe: 96.71%
2023-09-04 06:37:33.888448: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:37:33.890021: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:37:33.891511: finished real validation
2023-09-04 06:37:38.840074: train_loss -1.4529
2023-09-04 06:37:38.842074: val_loss -1.0703
2023-09-04 06:37:38.843981: Pseudo dice [0.9122]
2023-09-04 06:37:38.845671: Epoch time: 399.39 s
2023-09-04 06:37:39.993616: 
2023-09-04 06:37:39.995632: Epoch 177
2023-09-04 06:37:39.997357: Current learning rate: backbone 0.00044823, others 0.00044823
2023-09-04 06:37:39.999313: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:38:53.990083: finished training epoch 177
2023-09-04 06:38:54.026707: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:38:54.029324: The split file contains 1 splits.
2023-09-04 06:38:54.031306: Desired fold for training: 0
2023-09-04 06:38:54.032918: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:44:15.675432: dsc: 91.19%
2023-09-04 06:44:15.677757: miou: 83.81%
2023-09-04 06:44:15.679436: acc: 95.54%, sen: 91.78%, spe: 96.81%
2023-09-04 06:44:15.681389: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:44:15.683149: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:44:15.684831: finished real validation
2023-09-04 06:44:20.638952: train_loss -1.4533
2023-09-04 06:44:20.641217: val_loss -1.0618
2023-09-04 06:44:20.643127: Pseudo dice [0.9122]
2023-09-04 06:44:20.645067: Epoch time: 400.65 s
2023-09-04 06:44:21.774435: 
2023-09-04 06:44:21.776706: Epoch 178
2023-09-04 06:44:21.778455: Current learning rate: backbone 0.00044495, others 0.00044495
2023-09-04 06:44:21.780572: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:45:35.279454: finished training epoch 178
2023-09-04 06:45:35.309074: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:45:35.311497: The split file contains 1 splits.
2023-09-04 06:45:35.313115: Desired fold for training: 0
2023-09-04 06:45:35.314641: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:51:06.304359: dsc: 91.15%
2023-09-04 06:51:06.306597: miou: 83.74%
2023-09-04 06:51:06.308291: acc: 95.53%, sen: 91.64%, spe: 96.83%
2023-09-04 06:51:06.310182: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:51:06.311739: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:51:06.313205: finished real validation
2023-09-04 06:51:11.269493: train_loss -1.4531
2023-09-04 06:51:11.272101: val_loss -1.094
2023-09-04 06:51:11.273865: Pseudo dice [0.9155]
2023-09-04 06:51:11.275435: Epoch time: 409.5 s
2023-09-04 06:51:12.427312: 
2023-09-04 06:51:12.430003: Epoch 179
2023-09-04 06:51:12.431566: Current learning rate: backbone 0.00044167, others 0.00044167
2023-09-04 06:51:12.434159: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:52:25.937685: finished training epoch 179
2023-09-04 06:52:25.970117: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:52:25.972644: The split file contains 1 splits.
2023-09-04 06:52:25.974222: Desired fold for training: 0
2023-09-04 06:52:25.975828: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 06:57:49.934664: dsc: 91.14%
2023-09-04 06:57:49.936681: miou: 83.72%
2023-09-04 06:57:49.938384: acc: 95.53%, sen: 91.33%, spe: 96.94%
2023-09-04 06:57:49.940506: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:57:49.942154: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 06:57:49.943851: finished real validation
2023-09-04 06:57:54.910067: train_loss -1.4537
2023-09-04 06:57:54.912197: val_loss -1.0718
2023-09-04 06:57:54.914029: Pseudo dice [0.9122]
2023-09-04 06:57:54.915636: Epoch time: 402.48 s
2023-09-04 06:57:57.905691: 
2023-09-04 06:57:57.907827: Epoch 180
2023-09-04 06:57:57.909581: Current learning rate: backbone 0.00043838, others 0.00043838
2023-09-04 06:57:57.911645: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 06:59:11.494407: finished training epoch 180
2023-09-04 06:59:11.524087: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 06:59:11.526516: The split file contains 1 splits.
2023-09-04 06:59:11.528166: Desired fold for training: 0
2023-09-04 06:59:11.529719: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:04:27.801023: dsc: 91.15%
2023-09-04 07:04:27.803124: miou: 83.74%
2023-09-04 07:04:27.804747: acc: 95.53%, sen: 91.48%, spe: 96.90%
2023-09-04 07:04:27.806644: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:04:27.808260: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:04:27.809800: finished real validation
2023-09-04 07:04:32.799409: train_loss -1.4538
2023-09-04 07:04:32.801681: val_loss -1.0549
2023-09-04 07:04:32.804085: Pseudo dice [0.9114]
2023-09-04 07:04:32.806314: Epoch time: 394.9 s
2023-09-04 07:04:33.969892: 
2023-09-04 07:04:33.971838: Epoch 181
2023-09-04 07:04:33.973503: Current learning rate: backbone 0.00043509, others 0.00043509
2023-09-04 07:04:33.975493: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:05:47.549009: finished training epoch 181
2023-09-04 07:05:47.593584: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:05:47.596493: The split file contains 1 splits.
2023-09-04 07:05:47.598198: Desired fold for training: 0
2023-09-04 07:05:47.599838: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:11:56.350266: dsc: 91.26%
2023-09-04 07:11:56.352377: miou: 83.93%
2023-09-04 07:11:56.353971: acc: 95.59%, sen: 91.64%, spe: 96.91%
2023-09-04 07:11:56.355803: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:11:56.357349: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:11:56.358974: finished real validation
2023-09-04 07:12:01.334239: train_loss -1.4538
2023-09-04 07:12:01.336288: val_loss -1.0599
2023-09-04 07:12:01.338161: Pseudo dice [0.9103]
2023-09-04 07:12:01.339842: Epoch time: 447.37 s
2023-09-04 07:12:02.483151: 
2023-09-04 07:12:02.485023: Epoch 182
2023-09-04 07:12:02.486707: Current learning rate: backbone 0.0004318, others 0.0004318
2023-09-04 07:12:02.488669: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:13:16.002391: finished training epoch 182
2023-09-04 07:13:16.031843: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:13:16.035303: The split file contains 1 splits.
2023-09-04 07:13:16.037483: Desired fold for training: 0
2023-09-04 07:13:16.039645: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:19:53.443264: dsc: 91.19%
2023-09-04 07:19:53.445422: miou: 83.80%
2023-09-04 07:19:53.447101: acc: 95.56%, sen: 91.40%, spe: 96.95%
2023-09-04 07:19:53.449083: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:19:53.450732: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:19:53.452540: finished real validation
2023-09-04 07:19:58.450449: train_loss -1.4539
2023-09-04 07:19:58.452784: val_loss -1.0781
2023-09-04 07:19:58.455262: Pseudo dice [0.9146]
2023-09-04 07:19:58.457504: Epoch time: 475.97 s
2023-09-04 07:19:59.630406: 
2023-09-04 07:19:59.632368: Epoch 183
2023-09-04 07:19:59.634030: Current learning rate: backbone 0.00042851, others 0.00042851
2023-09-04 07:19:59.636028: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:21:13.245898: finished training epoch 183
2023-09-04 07:21:13.286634: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:21:13.288910: The split file contains 1 splits.
2023-09-04 07:21:13.290626: Desired fold for training: 0
2023-09-04 07:21:13.292145: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:27:05.166694: dsc: 91.25%
2023-09-04 07:27:05.168960: miou: 83.90%
2023-09-04 07:27:05.170878: acc: 95.58%, sen: 91.49%, spe: 96.96%
2023-09-04 07:27:05.173498: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:27:05.175491: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:27:05.177295: finished real validation
2023-09-04 07:27:10.145234: train_loss -1.4533
2023-09-04 07:27:10.147518: val_loss -1.0704
2023-09-04 07:27:10.149549: Pseudo dice [0.9108]
2023-09-04 07:27:10.151664: Epoch time: 430.52 s
2023-09-04 07:27:11.323551: 
2023-09-04 07:27:11.325552: Epoch 184
2023-09-04 07:27:11.327061: Current learning rate: backbone 0.00042521, others 0.00042521
2023-09-04 07:27:11.329025: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:28:25.369821: finished training epoch 184
2023-09-04 07:28:25.429048: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:28:25.433697: The split file contains 1 splits.
2023-09-04 07:28:25.436050: Desired fold for training: 0
2023-09-04 07:28:25.439219: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:34:37.960525: dsc: 91.10%
2023-09-04 07:34:37.962636: miou: 83.66%
2023-09-04 07:34:37.964188: acc: 95.51%, sen: 91.48%, spe: 96.86%
2023-09-04 07:34:37.966035: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:34:37.967610: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:34:37.969136: finished real validation
2023-09-04 07:34:42.942688: train_loss -1.454
2023-09-04 07:34:42.944777: val_loss -1.0565
2023-09-04 07:34:42.946693: Pseudo dice [0.9108]
2023-09-04 07:34:42.948348: Epoch time: 451.62 s
2023-09-04 07:34:44.109763: 
2023-09-04 07:34:44.112381: Epoch 185
2023-09-04 07:34:44.114051: Current learning rate: backbone 0.00042191, others 0.00042191
2023-09-04 07:34:44.116234: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:35:58.082536: finished training epoch 185
2023-09-04 07:35:58.123318: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:35:58.126131: The split file contains 1 splits.
2023-09-04 07:35:58.127806: Desired fold for training: 0
2023-09-04 07:35:58.129462: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:41:12.711558: dsc: 91.22%
2023-09-04 07:41:12.713983: miou: 83.86%
2023-09-04 07:41:12.715690: acc: 95.58%, sen: 91.27%, spe: 97.03%
2023-09-04 07:41:12.717623: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:41:12.719264: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:41:12.720869: finished real validation
2023-09-04 07:41:17.695343: train_loss -1.4537
2023-09-04 07:41:17.697248: val_loss -1.0792
2023-09-04 07:41:17.698959: Pseudo dice [0.9124]
2023-09-04 07:41:17.700472: Epoch time: 393.59 s
2023-09-04 07:41:18.854219: 
2023-09-04 07:41:18.856314: Epoch 186
2023-09-04 07:41:18.858079: Current learning rate: backbone 0.00041861, others 0.00041861
2023-09-04 07:41:18.860169: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:42:32.312545: finished training epoch 186
2023-09-04 07:42:32.343602: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:42:32.346126: The split file contains 1 splits.
2023-09-04 07:42:32.347732: Desired fold for training: 0
2023-09-04 07:42:32.349280: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:47:54.801100: dsc: 91.21%
2023-09-04 07:47:54.803491: miou: 83.83%
2023-09-04 07:47:54.805554: acc: 95.56%, sen: 91.64%, spe: 96.87%
2023-09-04 07:47:54.808346: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:47:54.810248: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:47:54.812126: finished real validation
2023-09-04 07:47:59.780453: train_loss -1.4541
2023-09-04 07:47:59.782767: val_loss -1.0597
2023-09-04 07:47:59.784699: Pseudo dice [0.9122]
2023-09-04 07:47:59.786514: Epoch time: 400.93 s
2023-09-04 07:48:00.938298: 
2023-09-04 07:48:00.940506: Epoch 187
2023-09-04 07:48:00.942392: Current learning rate: backbone 0.0004153, others 0.0004153
2023-09-04 07:48:00.944387: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:49:14.386620: finished training epoch 187
2023-09-04 07:49:14.420412: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:49:14.426000: The split file contains 1 splits.
2023-09-04 07:49:14.427640: Desired fold for training: 0
2023-09-04 07:49:14.429244: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 07:54:32.446766: dsc: 91.21%
2023-09-04 07:54:32.448803: miou: 83.85%
2023-09-04 07:54:32.450552: acc: 95.55%, sen: 91.80%, spe: 96.81%
2023-09-04 07:54:32.452660: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:54:32.454277: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 07:54:32.455849: finished real validation
2023-09-04 07:54:37.427747: train_loss -1.4537
2023-09-04 07:54:37.429795: val_loss -1.08
2023-09-04 07:54:37.431626: Pseudo dice [0.9148]
2023-09-04 07:54:37.433182: Epoch time: 396.49 s
2023-09-04 07:54:38.588325: 
2023-09-04 07:54:38.590305: Epoch 188
2023-09-04 07:54:38.592360: Current learning rate: backbone 0.00041199, others 0.00041199
2023-09-04 07:54:38.594456: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 07:55:52.106726: finished training epoch 188
2023-09-04 07:55:52.137974: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 07:55:52.140898: The split file contains 1 splits.
2023-09-04 07:55:52.142528: Desired fold for training: 0
2023-09-04 07:55:52.144056: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:01:09.443740: dsc: 91.25%
2023-09-04 08:01:09.445607: miou: 83.91%
2023-09-04 08:01:09.447464: acc: 95.57%, sen: 91.79%, spe: 96.85%
2023-09-04 08:01:09.450060: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:01:09.451891: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:01:09.453629: finished real validation
2023-09-04 08:01:14.411479: train_loss -1.4544
2023-09-04 08:01:14.413679: val_loss -1.0558
2023-09-04 08:01:14.415683: Pseudo dice [0.9121]
2023-09-04 08:01:14.417491: Epoch time: 395.82 s
2023-09-04 08:01:15.584565: 
2023-09-04 08:01:15.586575: Epoch 189
2023-09-04 08:01:15.588334: Current learning rate: backbone 0.00040868, others 0.00040868
2023-09-04 08:01:15.590656: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:02:29.134239: finished training epoch 189
2023-09-04 08:02:29.177416: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:02:29.180185: The split file contains 1 splits.
2023-09-04 08:02:29.181883: Desired fold for training: 0
2023-09-04 08:02:29.183535: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:07:48.897207: dsc: 91.20%
2023-09-04 08:07:48.899464: miou: 83.82%
2023-09-04 08:07:48.901151: acc: 95.55%, sen: 91.60%, spe: 96.88%
2023-09-04 08:07:48.903071: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:07:48.904697: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:07:48.906245: finished real validation
2023-09-04 08:07:53.885024: train_loss -1.4542
2023-09-04 08:07:53.887293: val_loss -1.0766
2023-09-04 08:07:53.889228: Pseudo dice [0.9147]
2023-09-04 08:07:53.891073: Epoch time: 398.3 s
2023-09-04 08:07:56.805396: 
2023-09-04 08:07:56.807705: Epoch 190
2023-09-04 08:07:56.809599: Current learning rate: backbone 0.00040536, others 0.00040536
2023-09-04 08:07:56.811803: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:09:10.555033: finished training epoch 190
2023-09-04 08:09:10.584224: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:09:10.586673: The split file contains 1 splits.
2023-09-04 08:09:10.588261: Desired fold for training: 0
2023-09-04 08:09:10.589857: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:14:27.405181: dsc: 91.18%
2023-09-04 08:14:27.407298: miou: 83.79%
2023-09-04 08:14:27.409031: acc: 95.55%, sen: 91.52%, spe: 96.90%
2023-09-04 08:14:27.411023: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:14:27.412694: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:14:27.414361: finished real validation
2023-09-04 08:14:32.381045: train_loss -1.4537
2023-09-04 08:14:32.383306: val_loss -1.0574
2023-09-04 08:14:32.385212: Pseudo dice [0.911]
2023-09-04 08:14:32.386957: Epoch time: 395.58 s
2023-09-04 08:14:33.560416: 
2023-09-04 08:14:33.562686: Epoch 191
2023-09-04 08:14:33.564425: Current learning rate: backbone 0.00040205, others 0.00040205
2023-09-04 08:14:33.566513: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:15:47.704672: finished training epoch 191
2023-09-04 08:15:47.747925: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:15:47.751255: The split file contains 1 splits.
2023-09-04 08:15:47.753543: Desired fold for training: 0
2023-09-04 08:15:47.755617: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:21:00.409645: dsc: 91.26%
2023-09-04 08:21:00.411854: miou: 83.93%
2023-09-04 08:21:00.413553: acc: 95.59%, sen: 91.60%, spe: 96.93%
2023-09-04 08:21:00.415558: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:21:00.417429: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:21:00.419831: finished real validation
2023-09-04 08:21:05.383637: train_loss -1.4546
2023-09-04 08:21:05.385838: val_loss -1.0611
2023-09-04 08:21:05.387688: Pseudo dice [0.9122]
2023-09-04 08:21:05.389587: Epoch time: 391.82 s
2023-09-04 08:21:06.540254: 
2023-09-04 08:21:06.542489: Epoch 192
2023-09-04 08:21:06.544219: Current learning rate: backbone 0.00039872, others 0.00039872
2023-09-04 08:21:06.546339: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:22:20.016921: finished training epoch 192
2023-09-04 08:22:20.059174: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:22:20.062061: The split file contains 1 splits.
2023-09-04 08:22:20.063869: Desired fold for training: 0
2023-09-04 08:22:20.065631: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:27:47.593864: dsc: 91.24%
2023-09-04 08:27:47.596139: miou: 83.89%
2023-09-04 08:27:47.597800: acc: 95.58%, sen: 91.50%, spe: 96.95%
2023-09-04 08:27:47.599817: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:27:47.601560: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:27:47.603129: finished real validation
2023-09-04 08:27:52.569203: train_loss -1.454
2023-09-04 08:27:52.571657: val_loss -1.0378
2023-09-04 08:27:52.573694: Pseudo dice [0.9092]
2023-09-04 08:27:52.575585: Epoch time: 406.03 s
2023-09-04 08:27:53.753745: 
2023-09-04 08:27:53.755887: Epoch 193
2023-09-04 08:27:53.757764: Current learning rate: backbone 0.0003954, others 0.0003954
2023-09-04 08:27:53.759931: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:29:07.236835: finished training epoch 193
2023-09-04 08:29:07.268190: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:29:07.272606: The split file contains 1 splits.
2023-09-04 08:29:07.275044: Desired fold for training: 0
2023-09-04 08:29:07.277243: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:34:28.141868: dsc: 91.22%
2023-09-04 08:34:28.143795: miou: 83.86%
2023-09-04 08:34:28.145495: acc: 95.56%, sen: 91.66%, spe: 96.87%
2023-09-04 08:34:28.147479: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:34:28.149161: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:34:28.150769: finished real validation
2023-09-04 08:34:33.128455: train_loss -1.4543
2023-09-04 08:34:33.130766: val_loss -1.0545
2023-09-04 08:34:33.132877: Pseudo dice [0.9134]
2023-09-04 08:34:33.134743: Epoch time: 399.38 s
2023-09-04 08:34:34.300921: 
2023-09-04 08:34:34.302921: Epoch 194
2023-09-04 08:34:34.304676: Current learning rate: backbone 0.00039207, others 0.00039207
2023-09-04 08:34:34.306710: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:35:47.741824: finished training epoch 194
2023-09-04 08:35:47.771526: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:35:47.774880: The split file contains 1 splits.
2023-09-04 08:35:47.776838: Desired fold for training: 0
2023-09-04 08:35:47.778720: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:41:09.540015: dsc: 91.19%
2023-09-04 08:41:09.542359: miou: 83.81%
2023-09-04 08:41:09.543969: acc: 95.53%, sen: 92.09%, spe: 96.68%
2023-09-04 08:41:09.546061: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:41:09.548060: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:41:09.549968: finished real validation
2023-09-04 08:41:14.539763: train_loss -1.4547
2023-09-04 08:41:14.541932: val_loss -1.0513
2023-09-04 08:41:14.544172: Pseudo dice [0.9116]
2023-09-04 08:41:14.546079: Epoch time: 400.24 s
2023-09-04 08:41:15.722367: 
2023-09-04 08:41:15.724556: Epoch 195
2023-09-04 08:41:15.726431: Current learning rate: backbone 0.00038874, others 0.00038874
2023-09-04 08:41:15.728731: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:42:29.247952: finished training epoch 195
2023-09-04 08:42:29.297760: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:42:29.300617: The split file contains 1 splits.
2023-09-04 08:42:29.302298: Desired fold for training: 0
2023-09-04 08:42:29.303946: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:47:48.887857: dsc: 91.21%
2023-09-04 08:47:48.890083: miou: 83.84%
2023-09-04 08:47:48.891719: acc: 95.56%, sen: 91.51%, spe: 96.93%
2023-09-04 08:47:48.893719: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:47:48.895386: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:47:48.897001: finished real validation
2023-09-04 08:47:53.871016: train_loss -1.4546
2023-09-04 08:47:53.873357: val_loss -1.0561
2023-09-04 08:47:53.875312: Pseudo dice [0.912]
2023-09-04 08:47:53.877198: Epoch time: 398.15 s
2023-09-04 08:47:55.053378: 
2023-09-04 08:47:55.055506: Epoch 196
2023-09-04 08:47:55.057189: Current learning rate: backbone 0.00038541, others 0.00038541
2023-09-04 08:47:55.059105: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:49:08.610597: finished training epoch 196
2023-09-04 08:49:08.653647: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:49:08.656101: The split file contains 1 splits.
2023-09-04 08:49:08.657943: Desired fold for training: 0
2023-09-04 08:49:08.659529: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 08:54:25.412885: dsc: 91.22%
2023-09-04 08:54:25.415189: miou: 83.86%
2023-09-04 08:54:25.416955: acc: 95.57%, sen: 91.44%, spe: 96.96%
2023-09-04 08:54:25.418954: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:54:25.420786: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 08:54:25.422454: finished real validation
2023-09-04 08:54:30.411780: train_loss -1.4544
2023-09-04 08:54:30.414222: val_loss -1.0651
2023-09-04 08:54:30.416186: Pseudo dice [0.9112]
2023-09-04 08:54:30.417907: Epoch time: 395.36 s
2023-09-04 08:54:31.596551: 
2023-09-04 08:54:31.598783: Epoch 197
2023-09-04 08:54:31.600546: Current learning rate: backbone 0.00038207, others 0.00038207
2023-09-04 08:54:31.602770: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 08:55:45.196301: finished training epoch 197
2023-09-04 08:55:45.240885: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 08:55:45.244100: The split file contains 1 splits.
2023-09-04 08:55:45.246432: Desired fold for training: 0
2023-09-04 08:55:45.248122: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:01:04.183643: dsc: 91.25%
2023-09-04 09:01:04.185931: miou: 83.91%
2023-09-04 09:01:04.187768: acc: 95.57%, sen: 91.78%, spe: 96.85%
2023-09-04 09:01:04.189894: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:01:04.191642: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:01:04.193704: finished real validation
2023-09-04 09:01:09.188474: train_loss -1.455
2023-09-04 09:01:09.190738: val_loss -1.0494
2023-09-04 09:01:09.192695: Pseudo dice [0.9096]
2023-09-04 09:01:09.194453: Epoch time: 397.59 s
2023-09-04 09:01:10.351660: 
2023-09-04 09:01:10.353857: Epoch 198
2023-09-04 09:01:10.355608: Current learning rate: backbone 0.00037873, others 0.00037873
2023-09-04 09:01:10.357916: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:02:23.798771: finished training epoch 198
2023-09-04 09:02:23.840408: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:02:23.842929: The split file contains 1 splits.
2023-09-04 09:02:23.844666: Desired fold for training: 0
2023-09-04 09:02:23.846314: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:07:41.677858: dsc: 91.24%
2023-09-04 09:07:41.679848: miou: 83.89%
2023-09-04 09:07:41.681394: acc: 95.57%, sen: 91.80%, spe: 96.83%
2023-09-04 09:07:41.683229: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:07:41.684749: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:07:41.686215: finished real validation
2023-09-04 09:07:46.664971: train_loss -1.4543
2023-09-04 09:07:46.667068: val_loss -1.0631
2023-09-04 09:07:46.668976: Pseudo dice [0.9127]
2023-09-04 09:07:46.670661: Epoch time: 396.31 s
2023-09-04 09:07:47.828163: 
2023-09-04 09:07:47.830348: Epoch 199
2023-09-04 09:07:47.832149: Current learning rate: backbone 0.00037539, others 0.00037539
2023-09-04 09:07:47.834335: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:09:01.220348: finished training epoch 199
2023-09-04 09:09:01.258116: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:09:01.260704: The split file contains 1 splits.
2023-09-04 09:09:01.262431: Desired fold for training: 0
2023-09-04 09:09:01.264257: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:14:21.077037: dsc: 91.25%
2023-09-04 09:14:21.079225: miou: 83.92%
2023-09-04 09:14:21.080938: acc: 95.59%, sen: 91.56%, spe: 96.94%
2023-09-04 09:14:21.082885: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:14:21.084707: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:14:21.086460: finished real validation
2023-09-04 09:14:26.062931: train_loss -1.4549
2023-09-04 09:14:26.065243: val_loss -1.0674
2023-09-04 09:14:26.067299: Pseudo dice [0.9147]
2023-09-04 09:14:26.069161: Epoch time: 398.24 s
2023-09-04 09:14:29.112624: 
2023-09-04 09:14:29.114731: Epoch 200
2023-09-04 09:14:29.116557: Current learning rate: backbone 0.00037204, others 0.00037204
2023-09-04 09:14:29.118663: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:15:42.591825: finished training epoch 200
2023-09-04 09:15:42.633854: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:15:42.636724: The split file contains 1 splits.
2023-09-04 09:15:42.638346: Desired fold for training: 0
2023-09-04 09:15:42.640029: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:21:00.209067: dsc: 91.25%
2023-09-04 09:21:00.210763: miou: 83.91%
2023-09-04 09:21:00.212161: acc: 95.57%, sen: 91.85%, spe: 96.82%
2023-09-04 09:21:00.213798: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:21:00.215216: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:21:00.216853: finished real validation
2023-09-04 09:21:05.186352: train_loss -1.4549
2023-09-04 09:21:05.188543: val_loss -1.0912
2023-09-04 09:21:05.190576: Pseudo dice [0.9171]
2023-09-04 09:21:05.192328: Epoch time: 396.08 s
2023-09-04 09:21:06.364127: 
2023-09-04 09:21:06.366286: Epoch 201
2023-09-04 09:21:06.368261: Current learning rate: backbone 0.00036869, others 0.00036869
2023-09-04 09:21:06.370409: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:22:19.776707: finished training epoch 201
2023-09-04 09:22:19.807576: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:22:19.811487: The split file contains 1 splits.
2023-09-04 09:22:19.814004: Desired fold for training: 0
2023-09-04 09:22:19.816200: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:27:38.896307: dsc: 91.23%
2023-09-04 09:27:38.898442: miou: 83.87%
2023-09-04 09:27:38.900209: acc: 95.57%, sen: 91.54%, spe: 96.93%
2023-09-04 09:27:38.902309: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:27:38.904060: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:27:38.905783: finished real validation
2023-09-04 09:27:43.877813: train_loss -1.4551
2023-09-04 09:27:43.887912: val_loss -1.0951
2023-09-04 09:27:43.893288: Pseudo dice [0.9173]
2023-09-04 09:27:43.895137: Epoch time: 397.52 s
2023-09-04 09:27:43.896805: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-04 09:27:46.890240: 
2023-09-04 09:27:46.892341: Epoch 202
2023-09-04 09:27:46.894233: Current learning rate: backbone 0.00036534, others 0.00036534
2023-09-04 09:27:46.896430: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:29:00.414765: finished training epoch 202
2023-09-04 09:29:00.451488: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:29:00.454507: The split file contains 1 splits.
2023-09-04 09:29:00.456242: Desired fold for training: 0
2023-09-04 09:29:00.457866: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:34:17.985618: dsc: 91.21%
2023-09-04 09:34:17.987821: miou: 83.84%
2023-09-04 09:34:17.989427: acc: 95.55%, sen: 91.85%, spe: 96.79%
2023-09-04 09:34:17.991395: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:34:17.993036: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:34:17.994606: finished real validation
2023-09-04 09:34:22.978310: train_loss -1.4543
2023-09-04 09:34:22.980746: val_loss -1.0711
2023-09-04 09:34:22.982872: Pseudo dice [0.9132]
2023-09-04 09:34:22.984724: Epoch time: 396.09 s
2023-09-04 09:34:22.986572: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-04 09:34:25.954303: 
2023-09-04 09:34:25.956571: Epoch 203
2023-09-04 09:34:25.958341: Current learning rate: backbone 0.00036198, others 0.00036198
2023-09-04 09:34:25.960469: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:35:39.568449: finished training epoch 203
2023-09-04 09:35:39.606839: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:35:39.610238: The split file contains 1 splits.
2023-09-04 09:35:39.612018: Desired fold for training: 0
2023-09-04 09:35:39.613830: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:41:39.634700: dsc: 91.27%
2023-09-04 09:41:39.636700: miou: 83.95%
2023-09-04 09:41:39.638745: acc: 95.60%, sen: 91.57%, spe: 96.95%
2023-09-04 09:41:39.640782: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:41:39.642422: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:41:39.643837: finished real validation
2023-09-04 09:41:44.623780: train_loss -1.455
2023-09-04 09:41:44.625956: val_loss -1.0689
2023-09-04 09:41:44.627883: Pseudo dice [0.9134]
2023-09-04 09:41:44.629591: Epoch time: 438.67 s
2023-09-04 09:41:44.631145: Yayy! New best EMA pseudo Dice: 0.9131
2023-09-04 09:41:47.556297: 
2023-09-04 09:41:47.558743: Epoch 204
2023-09-04 09:41:47.560562: Current learning rate: backbone 0.00035862, others 0.00035862
2023-09-04 09:41:47.562670: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:43:01.141329: finished training epoch 204
2023-09-04 09:43:01.212271: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:43:01.214881: The split file contains 1 splits.
2023-09-04 09:43:01.216714: Desired fold for training: 0
2023-09-04 09:43:01.218441: This split has 1886 training and 808 validation cases.
start computing score....
2023-09-04 09:49:00.558074: dsc: 91.25%
2023-09-04 09:49:00.560611: miou: 83.91%
2023-09-04 09:49:00.562300: acc: 95.58%, sen: 91.77%, spe: 96.85%
2023-09-04 09:49:00.564446: current best miou: 0.8405481254653594 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:49:00.566231: current best dsc: 0.9133671799566093 at epoch: 39, (39, 0.8405481254653594, 0.9133671799566093)
2023-09-04 09:49:00.568030: finished real validation
2023-09-04 09:49:05.556404: train_loss -1.4552
2023-09-04 09:49:05.558865: val_loss -1.0513
2023-09-04 09:49:05.561060: Pseudo dice [0.9124]
2023-09-04 09:49:05.563146: Epoch time: 438.0 s
2023-09-04 09:49:06.750148: 
2023-09-04 09:49:06.752698: Epoch 205
2023-09-04 09:49:06.754879: Current learning rate: backbone 0.00035526, others 0.00035526
2023-09-04 09:49:06.757056: start training, 250
==========num_iterations_per_epoch: 250===========
2023-09-04 09:50:20.579382: finished training epoch 205
2023-09-04 09:50:20.617735: Using splits from existing split file: /tmp/ypeng4/preprocessed_data/Dataset124_ISIC2018/splits_final.json
2023-09-04 09:50:20.620530: The split file contains 1 splits.
2023-09-04 09:50:20.622437: Desired fold for training: 0
2023-09-04 09:50:20.624332: This split has 1886 training and 808 validation cases.
